# Project Report: api

> Generated: 2025-11-30 09:35:00
> Path: `/home/dojevou/projects/midi-software-center/temp_api_report`

## Legend

| Symbol | Meaning |
|--------|---------|
| ‚úÖ | **Excellent** - Score ‚â• 8/10 or Maintainability ‚â• 65 |
| ‚ö†Ô∏è | **Warning** - Score 5-8/10 or Maintainability 40-65 |
| ‚ùå | **Needs Work** - Score < 5/10 or Maintainability < 40 |
| üîí | **Security** - Security-related finding or issue |
| üêõ | **Bug** - Potential bug or error detected |
| üìÅ | **File/Folder** - File system related item |
| üìä | **Metrics** - Statistical data or analysis |
| üìù | **Documentation** - Docstring or comment related |
| üîç | **Analysis** - Currently being analyzed |
| üì¶ | **Package** - Dependency or import related |
| üöÄ | **Performance** - Performance or optimization related |

## Table of Contents

- [Legend](#legend)
- [Summary](#summary)
- [Project Statistics](#project-statistics)
- [Code Quality](#code-quality)
- [Dependencies](#dependencies)
- [File Structure](#file-structure)
- [TODOs and FIXMEs](#todos-and-fixmes)
- [File Details](#file-details)

## Summary

| Metric | Value |
|--------|-------|
| Total Files | 23 |
| Total Lines | 10,693 |
| Lines of Code | 9,456 |
| Functions | 0 |
| Classes | 0 |
| Avg Pylint Score | 0.00/10 |
| Docstring Coverage | 0.0% |

## Project Statistics

### Files by Extension

| Extension | Count | Lines |
|-----------|-------|-------|
| .rs | 22 | 9,472 |
| .ts | 1 | 1,221 |

## Code Quality

## Dependencies

## File Structure

```
temp_api_report/
‚îú‚îÄ‚îÄ analysis.rs
‚îú‚îÄ‚îÄ analyze.rs
‚îú‚îÄ‚îÄ api.ts
‚îú‚îÄ‚îÄ archive_import.rs
‚îú‚îÄ‚îÄ automation.rs
‚îú‚îÄ‚îÄ database.rs
‚îú‚îÄ‚îÄ daw.rs
‚îú‚îÄ‚îÄ export.rs
‚îú‚îÄ‚îÄ file_import.rs
‚îú‚îÄ‚îÄ files.rs
‚îú‚îÄ‚îÄ midi.rs
‚îú‚îÄ‚îÄ mixer.rs
‚îú‚îÄ‚îÄ mod.rs
‚îú‚îÄ‚îÄ pipeline.rs
‚îú‚îÄ‚îÄ progress.rs
‚îú‚îÄ‚îÄ project.rs
‚îú‚îÄ‚îÄ search.rs
‚îú‚îÄ‚îÄ sequencer.rs
‚îú‚îÄ‚îÄ split_file.rs
‚îî‚îÄ‚îÄ stats.rs
    ... and 3 more
```

## TODOs and FIXMEs

*No TODOs or FIXMEs found*

## File Details

### `analysis.rs` {#analysis-rs}

- **Lines**: 365 (code: 332, comments: 0, blank: 33)

#### Source Code

```rust
/// Analysis Tauri commands
///
/// Grown-up Script: I/O wrapper for musical analysis and compatibility matching.
/// Updated to use proper JOINs with actual database schema.
use crate::commands::AppState;
use crate::core::compatibility;
use crate::models::analysis::CompatibleFile;
use crate::models::midi_file::MidiFile;
use tauri::State;
use tracing::{debug, error};

/// Find files that are musically compatible with a given file
///
/// Returns files sorted by compatibility score (highest first).
/// Considers key signature, BPM, and time signature.
///
/// # Arguments
/// * `file_id` - The reference file to find compatible files for
/// * `max_results` - Maximum number of results to return (default: 20, max: 100)
#[tauri::command]
pub async fn find_compatible_files(
    file_id: i32,
    max_results: Option<i32>,
    state: State<'_, AppState>,
) -> Result<Vec<CompatibleFile>, String> {
    debug!("Finding compatible files for file ID: {}", file_id);

    let max = max_results.unwrap_or(20).min(100);

    // Get reference file with proper JOINs
    let ref_file = sqlx::query_as!(
        MidiFile,
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.file_size_bytes,
            f.content_hash as "content_hash!",
            f.is_multi_track as "is_multi_track!",
            f.parent_file_id as "parent_file_id?",
            f.track_number as "track_number?",
            f.total_tracks as "total_tracks?",
            f.manufacturer as "manufacturer?",
            f.collection_name as "collection_name?",
            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as "folder_tags!",
            f.parent_folder as "parent_folder?",
            f.num_tracks,
            f.created_at as "created_at!",
            f.analyzed_at as "analyzed_at?",
            mm.bpm::FLOAT8 as "bpm?",
            mm.key_signature::TEXT as "key_signature?",
            CASE
                WHEN mm.time_signature_numerator IS NOT NULL
                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT
                ELSE NULL
            END as "time_signature?",
            f.duration_seconds::FLOAT8 as "duration_seconds?",
            COALESCE(mm.total_notes, 0) as "total_notes!",
            fc.primary_category::TEXT as "primary_category?"
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE f.id = $1
        "#,
        file_id as i64
    )
    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| {
        error!("Failed to get reference file: {}", e);
        format!("Failed to get reference file: {}", e)
    })?;

    let ref_file = ref_file.ok_or_else(|| format!("File with ID {} not found", file_id))?;

    debug!(
        "Reference file - BPM: {:?}, Key: {:?}, Time sig: {:?}",
        ref_file.bpm, ref_file.key_signature, ref_file.time_signature
    );

    // Get all other files with proper JOINs
    let candidate_files = sqlx::query_as!(
        MidiFile,
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.file_size_bytes,
            f.content_hash as "content_hash!",
            f.is_multi_track as "is_multi_track!",
            f.parent_file_id as "parent_file_id?",
            f.track_number as "track_number?",
            f.total_tracks as "total_tracks?",
            f.manufacturer as "manufacturer?",
            f.collection_name as "collection_name?",
            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as "folder_tags!",
            f.parent_folder as "parent_folder?",
            f.num_tracks,
            f.created_at as "created_at!",
            f.analyzed_at as "analyzed_at?",
            mm.bpm::FLOAT8 as "bpm?",
            mm.key_signature::TEXT as "key_signature?",
            CASE
                WHEN mm.time_signature_numerator IS NOT NULL
                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT
                ELSE NULL
            END as "time_signature?",
            f.duration_seconds::FLOAT8 as "duration_seconds?",
            COALESCE(mm.total_notes, 0) as "total_notes!",
            fc.primary_category::TEXT as "primary_category?"
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE f.id != $1
        LIMIT 500
        "#,
        file_id as i64
    )
    .fetch_all(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| {
        error!("Failed to fetch candidate files: {}", e);
        format!("Failed to fetch files: {}", e)
    })?;

    let mut compatible_files: Vec<CompatibleFile> = candidate_files
        .iter()
        .map(|candidate| {
            // Use Trusty Module to calculate compatibility (pure function)
            let score = compatibility::calculate_compatibility(&ref_file, candidate);

            // Calculate BPM-based time stretch suggestion
            let suggested_bpm_multiplier =
                if let (Some(ref_bpm), Some(cand_bpm)) = (ref_file.bpm, candidate.bpm) {
                    let ratio = cand_bpm / ref_bpm;
                    // Suggest multiplier if it's a simple ratio
                    if (ratio - 0.5).abs() < 0.05 {
                        Some(0.5)
                    } else if (ratio - 2.0).abs() < 0.1 {
                        Some(2.0)
                    } else if (ratio - 1.5).abs() < 0.1 {
                        Some(1.5)
                    } else if (ratio - 0.75).abs() < 0.05 {
                        Some(0.75)
                    } else {
                        None
                    }
                } else {
                    None
                };

            CompatibleFile {
                id: candidate.id as i32,
                file_name: candidate.filename.clone(),
                compatibility_score: score.total_score as i32, // Convert f32 to i32
                key_match: ref_file.key_signature == candidate.key_signature,
                bpm_difference: if let (Some(ref_bpm), Some(cand_bpm)) =
                    (ref_file.bpm, candidate.bpm)
                {
                    Some((ref_bpm - cand_bpm).abs() as f32)
                } else {
                    None
                },
                time_signature_match: ref_file.time_signature == candidate.time_signature,
                suggested_bpm_multiplier,
                category: candidate.primary_category.clone(),
            }
        })
        .collect();

    // Sort by compatibility score (descending)
    compatible_files.sort_by(|a, b| b.compatibility_score.cmp(&a.compatibility_score));

    // Take top N results
    compatible_files.truncate(max as usize);

    debug!(
        "Returning {} compatible files (top score: {})",
        compatible_files.len(),
        compatible_files.first().map(|f| f.compatibility_score).unwrap_or(0)
    );

    Ok(compatible_files)
}

/// Add file to favorites
#[tauri::command]
pub async fn add_favorite(file_id: i32, state: State<'_, AppState>) -> Result<(), String> {
    debug!("Adding file {} to favorites", file_id);

    // Insert into favorites table (ON CONFLICT DO NOTHING to handle duplicates)
    sqlx::query!(
        "INSERT INTO favorites (file_id) VALUES ($1) ON CONFLICT (file_id) DO NOTHING",
        file_id as i64
    )
    .execute(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| {
        error!("Failed to add favorite: {}", e);
        format!("Failed to add favorite: {}", e)
    })?;

    debug!("Successfully added file {} to favorites", file_id);
    Ok(())
}

/// Remove file from favorites
#[tauri::command]
pub async fn remove_favorite(file_id: i32, state: State<'_, AppState>) -> Result<(), String> {
    debug!("Removing file {} from favorites", file_id);

    sqlx::query!("DELETE FROM favorites WHERE file_id = $1", file_id as i64)
        .execute(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
        .await
        .map_err(|e| {
            error!("Failed to remove favorite: {}", e);
            format!("Failed to remove favorite: {}", e)
        })?;

    debug!("Successfully removed file {} from favorites", file_id);
    Ok(())
}

/// Check if a file is favorited
#[tauri::command]
pub async fn is_favorite(file_id: i32, state: State<'_, AppState>) -> Result<bool, String> {
    let result = sqlx::query!(
        "SELECT EXISTS(SELECT 1 FROM favorites WHERE file_id = $1) as is_fav",
        file_id as i64
    )
    .fetch_one(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| format!("Failed to check favorite status: {}", e))?;

    Ok(result.is_fav.unwrap_or(false))
}

/// Get all favorite files with full details
#[tauri::command]
pub async fn get_favorites(
    state: State<'_, AppState>,
) -> Result<Vec<crate::models::midi_file::FileDetails>, String> {
    debug!("Getting all favorite files");

    let favorites = sqlx::query_as!(
        crate::models::midi_file::FileDetails,
        r#"
        SELECT
            f.id as "id!",
            f.filename as "filename!",
            f.filepath as "filepath!",
            f.file_size_bytes as "file_size_bytes!",
            f.num_tracks as "track_count!",
            f.content_hash as "content_hash!",
            f.parent_folder as "parent_folder?",
            f.created_at as "created_at!",
            mm.bpm::FLOAT8 as "bpm?",
            mm.key_signature::TEXT as "key_signature?",
            CASE
                WHEN mm.time_signature_numerator IS NOT NULL
                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT
                ELSE NULL
            END as "time_signature?",
            f.duration_seconds::FLOAT8 as "duration_seconds?",
            COALESCE(mm.total_notes, 0) > 0 as "has_notes!",
            mm.total_notes as "total_notes?",
            mm.is_percussive as "has_drums?",
            fc.primary_category::TEXT as "primary_category?",
            f.manufacturer as "manufacturer?",
            f.collection_name as "collection_name?",
            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as "tags!",
            true as "is_favorite!"
        FROM favorites fav
        INNER JOIN files f ON fav.file_id = f.id
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        ORDER BY fav.created_at DESC
        "#
    )
    .fetch_all(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| {
        error!("Failed to fetch favorites: {}", e);
        format!("Failed to fetch favorites: {}", e)
    })?;

    debug!("Retrieved {} favorite files", favorites.len());
    Ok(favorites)
}

/// Get usage statistics
#[tauri::command]
pub async fn get_usage_stats(state: State<'_, AppState>) -> Result<String, String> {
    debug!("Getting usage statistics");

    // Gather various statistics using proper table and column names
    let total_files: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM files")
        .fetch_one(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
        .await
        .map_err(|e| format!("Failed to count files: {}", e))?;

    let total_duration: Option<f64> = sqlx::query_scalar(
        "SELECT SUM(duration_seconds) FROM files WHERE duration_seconds IS NOT NULL",
    )
    .fetch_one(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| format!("Failed to sum duration: {}", e))?;

    let total_notes: Option<i64> =
        sqlx::query_scalar("SELECT SUM(total_notes) FROM musical_metadata")
            .fetch_one(
                state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?,
            )
            .await
            .map_err(|e| format!("Failed to sum notes: {}", e))?;

    let avg_bpm: Option<f64> =
        sqlx::query_scalar("SELECT AVG(bpm) FROM musical_metadata WHERE bpm IS NOT NULL")
            .fetch_one(
                state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?,
            )
            .await
            .map_err(|e| format!("Failed to calculate average BPM: {}", e))?;

    // Most common key
    let most_common_key: Option<(String,)> = sqlx::query_as(
        "SELECT key_signature::TEXT
         FROM musical_metadata
         WHERE key_signature IS NOT NULL
         GROUP BY key_signature
         ORDER BY COUNT(*) DESC
         LIMIT 1",
    )
    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| format!("Failed to find most common key: {}", e))?;

    // Most common time signature
    let most_common_time: Option<(String,)> = sqlx::query_as(
        "SELECT time_signature_numerator::TEXT || '/' || time_signature_denominator::TEXT
         FROM musical_metadata
         WHERE time_signature_numerator IS NOT NULL
           AND time_signature_denominator IS NOT NULL
         GROUP BY time_signature_numerator, time_signature_denominator
         ORDER BY COUNT(*) DESC
         LIMIT 1",
    )
    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
    .await
    .map_err(|e| format!("Failed to find most common time signature: {}", e))?;

    // Format as JSON
    let stats = serde_json::json!({
        "total_files": total_files,
        "total_duration_hours": total_duration.unwrap_or(0.0) / 3600.0,
        "total_notes": total_notes.unwrap_or(0),
        "average_bpm": avg_bpm.unwrap_or(0.0),
        "most_common_key": most_common_key.map(|(k,)| k),
        "most_common_time_signature": most_common_time.map(|(t,)| t),
    });

    Ok(stats.to_string())
}

```

### `analyze.rs` {#analyze-rs}

- **Lines**: 2044 (code: 1798, comments: 0, blank: 246)

#### Source Code

```rust
use crate::core::analysis::bpm_detector::detect_bpm;
use crate::core::analysis::chord_analyzer::analyze_chords;
use crate::core::analysis::drum_analyzer::analyze_drum_midi;
use crate::core::analysis::key_detector::detect_key;
/// Musical Analysis Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION
///
/// Architecture: Grown-up Script
/// Purpose: Analyze all imported MIDI files using existing analysis modules
///
/// This module processes 1.1M+ imported files by:
/// - Reading unanalyzed files from database in batches
/// - Parallel processing with buffer_unordered (32 workers)
/// - Running BPM detection, key detection, and auto-tagging
/// - Batch database inserts for musical_metadata
/// - Real-time progress updates
///
/// Performance Target: 400-500 files/sec (complete 1.1M files in ~40-60 minutes)
use crate::AppState;
use midi_library_shared::core::midi::parser::parse_midi_file;
use midi_library_shared::core::midi::types::{Event, MidiFile, TextType};
// Unused: use crate::core::analysis::auto_tagger::{AutoTagger, Tag};

use futures::stream::{self, StreamExt};
use serde::{Deserialize, Serialize};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use tauri::{Emitter, State, Window};
use tokio::sync::Mutex;

// For JSON serialization of variation timelines
extern crate serde_json;

//=============================================================================
// TYPE DEFINITIONS
//=============================================================================

/// Progress event for real-time UI updates
#[derive(Debug, Clone, Serialize)]
#[allow(dead_code)]
pub struct AnalysisProgress {
    pub current: usize,
    pub total: usize,
    pub current_file: String,
    pub rate: f64, // files per second
    pub eta_seconds: f64,
}

/// Summary of analysis operation results
#[derive(Debug, Clone, Serialize, Deserialize)]
#[allow(dead_code)]
pub struct AnalysisSummary {
    pub total_files: usize,
    pub analyzed: usize,
    pub skipped: usize,
    pub errors: Vec<String>,
    pub duration_secs: f64,
    pub rate: f64, // files per second
}

/// File record from database
#[derive(Debug, Clone, sqlx::FromRow)]
#[allow(dead_code)]
pub struct FileRecord {
    pub id: i64,
    pub filepath: String,
    pub filename: String,
}

/// Analyzed file data ready for database insertion
#[derive(Debug, Clone)]
#[allow(dead_code)]
pub struct AnalyzedFile {
    pub file_id: i64,

    // Tempo
    pub tempo_bpm: Option<f64>,
    pub bpm_confidence: Option<f64>,
    pub has_tempo_variation: bool,

    // Key
    pub key_signature: Option<String>,
    pub key_confidence: Option<f64>,
    pub scale_type: Option<String>,

    // Time signature
    pub time_signature_num: Option<i16>,
    pub time_signature_den: Option<i16>,

    // Duration
    pub duration_seconds: Option<f64>,
    pub duration_ticks: Option<i32>,

    // Note analysis
    pub note_count: i32,
    pub unique_pitches: Option<i32>,
    pub pitch_range_low: Option<i16>,
    pub pitch_range_high: Option<i16>,
    pub pitch_range_semitones: Option<i16>,

    // Velocity
    pub avg_velocity: Option<f64>,
    pub velocity_range_low: Option<i16>,
    pub velocity_range_high: Option<i16>,

    // Note density
    pub note_density: Option<f64>,

    // Polyphony
    pub polyphony_max: Option<i16>,
    pub polyphony_avg: Option<f64>,

    // Characteristics
    pub is_monophonic: bool,
    pub is_polyphonic: bool,
    pub is_percussive: bool,

    // Chord analysis
    pub has_chords: bool,
    pub chord_progression: Option<Vec<String>>,
    pub chord_types: Option<Vec<String>>,
    pub has_seventh_chords: bool,
    pub has_extended_chords: bool,
    pub chord_change_rate: Option<f32>,
    pub chord_complexity_score: Option<f32>,

    // Melody
    pub has_melody: bool,
    pub melodic_range: Option<i16>,

    // Variation tracking (JSON timelines)
    pub tempo_changes: Option<String>,
    pub key_changes: Option<String>,
    pub time_signature_changes: Option<String>,

    // Controller analysis (JSON)
    pub controller_data: Option<String>,

    // Articulation/Performance analysis (JSON)
    pub articulation_data: Option<String>,

    // Structure/Form analysis (JSON)
    pub structure_data: Option<String>,

    // Complexity
    pub complexity_score: Option<f64>,

    // Additional properties
    pub instruments: Vec<String>,
    pub track_instruments: Vec<TrackInstrument>,
    pub has_pitch_bend: bool,
    pub has_cc_messages: bool,
}

//=============================================================================
// TAURI COMMANDS
//=============================================================================

/// Analyze all unanalyzed MIDI files (HIGH-PERFORMANCE PARALLEL VERSION)
///
/// This command:
/// 1. Reads unanalyzed files from database in batches
/// 2. Processes them in parallel with 32 workers
/// 3. Runs BPM detection, key detection, note analysis
/// 4. Batch inserts results into musical_metadata
/// 5. Updates files.analyzed_at timestamp
/// 6. Shows real-time progress
#[tauri::command]
pub async fn start_analysis(
    state: State<'_, AppState>,
    window: Window,
) -> Result<AnalysisSummary, String> {
    let start_time = std::time::Instant::now();
    let pool: sqlx::PgPool = state.database.pool().await;

    // Get total count of unanalyzed files
    let total: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM files WHERE analyzed_at IS NULL")
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("Failed to count unanalyzed files: {}", e))?;

    println!("üîç Found {} unanalyzed files", total);

    if total == 0 {
        return Ok(AnalysisSummary {
            total_files: 0,
            analyzed: 0,
            skipped: 0,
            errors: vec![],
            duration_secs: 0.0,
            rate: 0.0,
        });
    }

    // Parallel processing configuration
    let concurrency_limit = 32; // Process 32 files concurrently
    let batch_size = 1000; // Fetch files in batches of 1000

    println!("üöÄ Starting analysis:");
    println!("  Concurrency: {} workers", concurrency_limit);
    println!("  Batch size: {} files", batch_size);

    // Thread-safe counters
    let analyzed = Arc::new(AtomicUsize::new(0));
    let skipped = Arc::new(AtomicUsize::new(0));
    let errors = Arc::new(Mutex::new(Vec::new()));
    let current_index = Arc::new(AtomicUsize::new(0));

    // Semaphore to limit concurrency
    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));

    // Batch buffer for database inserts
    let analyzed_files = Arc::new(Mutex::new(Vec::new()));

    let total_usize = total as usize;

    // Process files in batches
    let mut offset = 0i64;

    loop {
        // Fetch batch of unanalyzed files
        let files: Vec<FileRecord> = sqlx::query_as(
            "SELECT id, filepath, filename
             FROM files
             WHERE analyzed_at IS NULL
             ORDER BY id
             LIMIT $1 OFFSET $2",
        )
        .bind(batch_size)
        .bind(offset)
        .fetch_all(&pool)
        .await
        .map_err(|e| format!("Failed to fetch files: {}", e))?;

        if files.is_empty() {
            break;
        }

        let batch_len = files.len();
        println!(
            "üì¶ Processing batch: {} files (offset: {})",
            batch_len, offset
        );

        // Process batch in parallel
        stream::iter(files)
            .map(|file_record| {
                // Clone Arc pointers for each concurrent task
                let sem = Arc::clone(&semaphore);
                let analyzed = Arc::clone(&analyzed);
                let skipped = Arc::clone(&skipped);
                let errors = Arc::clone(&errors);
                let current_index = Arc::clone(&current_index);
                let analyzed_files = Arc::clone(&analyzed_files);
                let window = window.clone();

                    let pool = pool.clone();
                async move {
                    // Acquire semaphore permit (blocks if at limit)
                    let _permit = match sem.acquire().await {
                        Ok(permit) => permit,
                        Err(e) => {
                            let error_msg = format!("FATAL: Semaphore unavailable during analysis: {}", e);
                            eprintln!("ERROR: {}", error_msg);

                            // Track this as an error
                            errors.lock().await.push(error_msg);

                            // Mark file as skipped
                            skipped.fetch_add(1, Ordering::SeqCst);
                            return;
                        }
                    };

                    let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;

                    // Emit progress every 10 files
                    if current.is_multiple_of(10) || current == total_usize {
                        let elapsed = start_time.elapsed().as_secs_f64();
                        let rate = if elapsed > 0.0 { current as f64 / elapsed } else { 0.0 };
                        let remaining = total_usize - current;
                        let eta_seconds = if rate > 0.0 { remaining as f64 / rate } else { 0.0 };

                        if let Err(e) = window.emit("analysis-progress", AnalysisProgress {
                            current,
                            total: total_usize,
                            current_file: file_record.filename.clone(),
                            rate,
                            eta_seconds,
                        }) {
                            // Log but don't fail the operation
                            eprintln!("WARNING: Failed to emit analysis progress (file {}): {}",
                                      file_record.filename, e);
                        }

                        // Print progress every 100 files
                        if current.is_multiple_of(100) {
                            println!(
                                "Analyzing: {}/{} ({:.1}%) - {:.1} files/sec - ETA: {:.0}s",
                                current,
                                total_usize,
                                (current as f64 / total_usize as f64) * 100.0,
                                rate,
                                eta_seconds
                            );
                        }
                    }

                    // Analyze the file
                    match analyze_single_file(&file_record).await {
                        Ok(analyzed_data) => {
                            // Add to batch for insertion
                            analyzed_files.lock().await.push(analyzed_data);
                            analyzed.fetch_add(1, Ordering::SeqCst);

                            // Flush batch if it reaches threshold (100 files)
                            let mut files = analyzed_files.lock().await;
                            if files.len() >= 100 {
                                let batch: Vec<AnalyzedFile> = files.drain(..).collect();
                                drop(files); // Release lock

                                // CRITICAL: Database batch insert - if this fails, analysis data is lost
                                if let Err(e) = batch_insert_analyzed_files(&batch, &pool).await {
                                    let error_msg = format!("Batch insert failed: {}", e);
                                    eprintln!("ERROR: {}", error_msg);

                                    // Record the error and mark files as skipped
                                    errors.lock().await.push(error_msg);
                                    skipped.fetch_add(batch.len(), Ordering::SeqCst);
                                }
                            }
                        }
                        Err(e) => {
                            let error_msg = format!("{}: {}", file_record.filepath, e);
                            errors.lock().await.push(error_msg);
                            skipped.fetch_add(1, Ordering::SeqCst);
                        }
                    }
                }
            })
            .buffer_unordered(concurrency_limit) // ‚Üê THE MAGIC: Process N files concurrently!
            .collect::<Vec<_>>()
            .await;

        offset += batch_size;
    }

    // Flush remaining batch
    let remaining_files = analyzed_files.lock().await;
    if !remaining_files.is_empty() {
        let batch: Vec<AnalyzedFile> = remaining_files.iter().cloned().collect();
        drop(remaining_files);

        if let Err(e) = batch_insert_analyzed_files(&batch, &pool).await {
            errors.lock().await.push(format!("Final batch insert failed: {}", e));
        }
    }

    // Calculate final statistics
    let duration = start_time.elapsed().as_secs_f64();
    let analyzed_count = analyzed.load(Ordering::SeqCst);
    let rate = if duration > 0.0 {
        analyzed_count as f64 / duration
    } else {
        0.0
    };

    println!("\n‚úÖ Analysis complete!");
    println!("  Total files: {}", total_usize);
    println!("  Analyzed: {}", analyzed_count);
    println!("  Skipped: {}", skipped.load(Ordering::SeqCst));
    println!("  Duration: {:.1}s", duration);
    println!("  Rate: {:.1} files/sec", rate);

    // Extract errors before creating summary
    let error_list = errors.lock().await.clone();

    Ok(AnalysisSummary {
        total_files: total_usize,
        analyzed: analyzed_count,
        skipped: skipped.load(Ordering::SeqCst),
        errors: error_list,
        duration_secs: duration,
        rate,
    })
}

//=============================================================================
// CORE ANALYSIS LOGIC
//=============================================================================

/// Analyze a single MIDI file using all analysis modules
pub async fn analyze_single_file(
    file_record: &FileRecord,
) -> Result<AnalyzedFile, Box<dyn std::error::Error + Send + Sync>> {
    // 1. Read MIDI file from filesystem
    let file_bytes = tokio::fs::read(&file_record.filepath).await?;

    // 2. Parse MIDI file (Trusty Module)
    let midi_file = parse_midi_file(&file_bytes)?;

    // 3. BPM Detection (Trusty Module)
    let bpm_result = detect_bpm(&midi_file);
    let tempo_bpm = if bpm_result.confidence > 0.3 {
        Some(bpm_result.bpm)
    } else {
        None
    };
    let bpm_confidence = Some(bpm_result.confidence);
    let has_tempo_variation = !bpm_result.metadata.is_constant;

    // 4. Key Detection (Trusty Module)
    let key_result = detect_key(&midi_file);
    let key_signature = if key_result.confidence > 0.5 {
        Some(key_result.key.clone())
    } else {
        None
    };
    let key_confidence = Some(key_result.confidence);
    let scale_type = Some(key_result.scale_type.to_string());

    // 5. Extract time signature from MIDI events
    let (time_signature_num, time_signature_den) = extract_time_signature(&midi_file);

    // 6. Calculate duration
    let duration_ticks = calculate_total_ticks(&midi_file);
    let duration_seconds = calculate_duration_seconds(&midi_file, bpm_result.bpm);

    // 7. Note analysis
    let note_stats = analyze_notes(&midi_file);

    // 8. Track-level analysis (per-channel instruments)
    let track_instruments = analyze_tracks(&midi_file);

    // 9. Extract instruments (legacy - from text events + program changes)
    let instruments = extract_instrument_names(&midi_file);

    // 10. Detect MIDI features
    let has_pitch_bend = detect_pitch_bend(&midi_file);
    let has_cc_messages = detect_cc_messages(&midi_file);

    // 10. Chord analysis
    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as u32;
    let chord_analysis = analyze_chords(&midi_file, ticks_per_quarter);
    let has_chords = !chord_analysis.progression.is_empty();
    let chord_progression = if has_chords {
        Some(chord_analysis.progression)
    } else {
        None
    };
    let chord_types = if !chord_analysis.types.is_empty() {
        Some(chord_analysis.types)
    } else {
        None
    };

    // 11. Drum analysis (if percussion file)
    let drum_analysis = if note_stats.is_percussive {
        Some(analyze_drum_midi(&midi_file))
    } else {
        None
    };

    // 12. Melody detection (simple heuristic: monophonic content)
    let has_melody = note_stats.is_monophonic || (note_stats.polyphony_avg.map_or(false, |p| p < 2.0) && note_stats.note_count > 10);
    let melodic_range = if has_melody {
        note_stats.pitch_range_semitones
    } else {
        None
    };

    // 13. Extract variation timelines (tempo, key, time signature changes)
    let tempo_changes = extract_tempo_changes(&midi_file);
    let key_changes = extract_key_changes(&midi_file);
    let time_signature_changes = extract_time_signature_changes(&midi_file);

    // 14. Controller analysis (CC messages)
    let controller_data = analyze_controllers(&midi_file);

    // 15. Articulation/Performance analysis
    let tempo_us_per_qn = (60_000_000.0 / bpm_result.bpm) as u32;
    let articulation_data = analyze_articulation(&midi_file, tempo_us_per_qn);

    // 16. Structure/Form analysis
    let structure_data = analyze_structure(&midi_file);

    // 17. Calculate complexity score (simple heuristic)
    let complexity_score = calculate_complexity_score(&note_stats, &midi_file);

    Ok(AnalyzedFile {
        file_id: file_record.id,
        tempo_bpm,
        bpm_confidence,
        has_tempo_variation,
        key_signature,
        key_confidence,
        scale_type,
        time_signature_num,
        time_signature_den,
        duration_seconds,
        duration_ticks: Some(duration_ticks),
        note_count: note_stats.note_count,
        unique_pitches: note_stats.unique_pitches,
        pitch_range_low: note_stats.pitch_range_low,
        pitch_range_high: note_stats.pitch_range_high,
        pitch_range_semitones: note_stats.pitch_range_semitones,
        avg_velocity: note_stats.avg_velocity,
        velocity_range_low: note_stats.velocity_range_low,
        velocity_range_high: note_stats.velocity_range_high,
        note_density: note_stats.note_density,
        polyphony_max: note_stats.polyphony_max,
        polyphony_avg: note_stats.polyphony_avg,
        is_monophonic: note_stats.is_monophonic,
        is_polyphonic: note_stats.is_polyphonic,
        is_percussive: note_stats.is_percussive,
        has_chords,
        chord_progression,
        chord_types,
        has_seventh_chords: chord_analysis.has_sevenths,
        has_extended_chords: chord_analysis.has_extended,
        chord_change_rate: chord_analysis.change_rate,
        chord_complexity_score: Some(chord_analysis.complexity_score),
        has_melody,
        melodic_range,
        tempo_changes,
        key_changes,
        time_signature_changes,
        controller_data,
        articulation_data,
        structure_data,
        complexity_score,
        instruments,
        track_instruments,
        has_pitch_bend,
        has_cc_messages,
    })
}

/// Batch insert analyzed files into musical_metadata and update files.analyzed_at
pub async fn batch_insert_analyzed_files(
    files: &[AnalyzedFile],
    pool: &sqlx::PgPool,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    if files.is_empty() {
        return Ok(());
    }

    let mut tx = pool.begin().await?;

    for file in files {
        // Insert or update musical_metadata
        sqlx::query(
            r#"
            INSERT INTO musical_metadata (
                file_id,
                bpm,
                bpm_confidence,
                has_tempo_changes,
                key_signature,
                key_confidence,
                time_signature_numerator,
                time_signature_denominator,
                total_notes,
                unique_pitches,
                pitch_range_min,
                pitch_range_max,
                avg_velocity,
                note_density,
                polyphony_max,
                polyphony_avg,
                is_monophonic,
                is_polyphonic,
                is_percussive,
                has_chords,
                chord_progression,
                chord_types,
                has_seventh_chords,
                has_extended_chords,
                chord_change_rate,
                chord_complexity_score,
                has_melody,
                melodic_range,
                tempo_changes,
                key_changes,
                time_signature_changes,
                controller_data,
                articulation_data,
                structure_data
            ) VALUES ($1, $2, $3, $4, $5::musical_key, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21::jsonb, $22, $23, $24, $25, $26, $27, $28, $29::jsonb, $30::jsonb, $31::jsonb, $32::jsonb, $33::jsonb, $34::jsonb)
            ON CONFLICT (file_id) DO UPDATE SET
                bpm = EXCLUDED.bpm,
                bpm_confidence = EXCLUDED.bpm_confidence,
                has_tempo_changes = EXCLUDED.has_tempo_changes,
                key_signature = EXCLUDED.key_signature,
                key_confidence = EXCLUDED.key_confidence,
                time_signature_numerator = EXCLUDED.time_signature_numerator,
                time_signature_denominator = EXCLUDED.time_signature_denominator,
                total_notes = EXCLUDED.total_notes,
                unique_pitches = EXCLUDED.unique_pitches,
                pitch_range_min = EXCLUDED.pitch_range_min,
                pitch_range_max = EXCLUDED.pitch_range_max,
                avg_velocity = EXCLUDED.avg_velocity,
                note_density = EXCLUDED.note_density,
                polyphony_max = EXCLUDED.polyphony_max,
                polyphony_avg = EXCLUDED.polyphony_avg,
                is_monophonic = EXCLUDED.is_monophonic,
                is_polyphonic = EXCLUDED.is_polyphonic,
                is_percussive = EXCLUDED.is_percussive,
                has_chords = EXCLUDED.has_chords,
                chord_progression = EXCLUDED.chord_progression,
                chord_types = EXCLUDED.chord_types,
                has_seventh_chords = EXCLUDED.has_seventh_chords,
                has_extended_chords = EXCLUDED.has_extended_chords,
                chord_change_rate = EXCLUDED.chord_change_rate,
                chord_complexity_score = EXCLUDED.chord_complexity_score,
                has_melody = EXCLUDED.has_melody,
                melodic_range = EXCLUDED.melodic_range,
                tempo_changes = EXCLUDED.tempo_changes,
                key_changes = EXCLUDED.key_changes,
                time_signature_changes = EXCLUDED.time_signature_changes,
                controller_data = EXCLUDED.controller_data,
                articulation_data = EXCLUDED.articulation_data,
                structure_data = EXCLUDED.structure_data
            "#
        )
        .bind(file.file_id)
        .bind(file.tempo_bpm)
        .bind(file.bpm_confidence)
        .bind(file.has_tempo_variation)
        .bind(&file.key_signature)
        .bind(file.key_confidence)
        .bind(file.time_signature_num)
        .bind(file.time_signature_den)
        .bind(file.note_count)
        .bind(file.unique_pitches)
        .bind(file.pitch_range_low)
        .bind(file.pitch_range_high)
        .bind(file.avg_velocity)
        .bind(file.note_density)
        .bind(file.polyphony_max)
        .bind(file.polyphony_avg)
        .bind(file.is_monophonic)
        .bind(file.is_polyphonic)
        .bind(file.is_percussive)
        .bind(file.has_chords)
        .bind(file.chord_progression.as_ref().map(|v| serde_json::to_string(v).ok()).flatten())
        .bind(&file.chord_types)
        .bind(file.has_seventh_chords)
        .bind(file.has_extended_chords)
        .bind(file.chord_change_rate)
        .bind(file.chord_complexity_score)
        .bind(file.has_melody)
        .bind(file.melodic_range)
        .bind(&file.tempo_changes)
        .bind(&file.key_changes)
        .bind(&file.time_signature_changes)
        .bind(&file.controller_data)
        .bind(&file.articulation_data)
        .bind(&file.structure_data)
        .execute(&mut *tx)
        .await?;

        // Insert track instruments into file_instruments table
        for inst in &file.track_instruments {
            sqlx::query(
                r#"
                INSERT INTO file_instruments (
                    file_id, channel, program_number, program_name,
                    instrument_family, instrument_type, note_count,
                    is_primary, avg_velocity, pitch_range_low, pitch_range_high
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                ON CONFLICT (file_id, channel, program_number) DO UPDATE SET
                    program_name = EXCLUDED.program_name,
                    instrument_family = EXCLUDED.instrument_family,
                    instrument_type = EXCLUDED.instrument_type,
                    note_count = EXCLUDED.note_count,
                    is_primary = EXCLUDED.is_primary,
                    avg_velocity = EXCLUDED.avg_velocity,
                    pitch_range_low = EXCLUDED.pitch_range_low,
                    pitch_range_high = EXCLUDED.pitch_range_high
                "#
            )
            .bind(file.file_id)
            .bind(inst.channel)
            .bind(inst.program_number)
            .bind(&inst.program_name)
            .bind(&inst.instrument_family)
            .bind(&inst.instrument_type)
            .bind(inst.note_count)
            .bind(inst.is_primary)
            .bind(inst.avg_velocity)
            .bind(inst.pitch_range_low)
            .bind(inst.pitch_range_high)
            .execute(&mut *tx)
            .await?;
        }

        // Update files.analyzed_at timestamp
        sqlx::query("UPDATE files SET analyzed_at = NOW() WHERE id = $1")
            .bind(file.file_id)
            .execute(&mut *tx)
            .await?;
    }

    tx.commit().await?;

    Ok(())
}

//=============================================================================
// HELPER FUNCTIONS - MIDI ANALYSIS
//=============================================================================

/// Note statistics
#[derive(Debug, Clone)]
#[allow(dead_code)]
struct NoteStats {
    note_count: i32,
    unique_pitches: Option<i32>,
    pitch_range_low: Option<i16>,
    pitch_range_high: Option<i16>,
    pitch_range_semitones: Option<i16>,
    avg_velocity: Option<f64>,
    velocity_range_low: Option<i16>,
    velocity_range_high: Option<i16>,
    note_density: Option<f64>,
    polyphony_max: Option<i16>,
    polyphony_avg: Option<f64>,
    is_monophonic: bool,
    is_polyphonic: bool,
    is_percussive: bool,
}

/// Analyze notes in MIDI file
fn analyze_notes(midi_file: &MidiFile) -> NoteStats {
    let mut note_count = 0;
    let mut unique_pitch_set = std::collections::HashSet::new();
    let mut min_pitch = 127u8;
    let mut max_pitch = 0u8;
    let mut min_velocity = 127u8;
    let mut max_velocity = 0u8;
    let mut velocity_sum = 0u32;
    let mut active_notes_per_tick: std::collections::HashMap<u32, usize> =
        std::collections::HashMap::new();
    let mut max_tick = 0u32;
    let mut percussive_note_count = 0; // Notes on channel 10 (GM drums)

    for track in &midi_file.tracks {
        let mut current_tick = 0u32;
        let mut active_notes = std::collections::HashSet::new();

        for timed_event in &track.events {
            current_tick += timed_event.delta_ticks;
            max_tick = max_tick.max(current_tick);

            match &timed_event.event {
                Event::NoteOn { note, velocity, channel } if *velocity > 0 => {
                    note_count += 1;
                    unique_pitch_set.insert(*note);
                    min_pitch = min_pitch.min(*note);
                    max_pitch = max_pitch.max(*note);
                    min_velocity = min_velocity.min(*velocity);
                    max_velocity = max_velocity.max(*velocity);
                    velocity_sum += *velocity as u32;

                    // Channel 10 (index 9) is standard GM drums
                    if *channel == 9 {
                        percussive_note_count += 1;
                    }

                    active_notes.insert(*note);
                    active_notes_per_tick.insert(current_tick, active_notes.len());
                },
                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } => {
                    active_notes.remove(note);
                },
                _ => {},
            }
        }
    }

    let unique_pitches = if note_count > 0 {
        Some(unique_pitch_set.len() as i32)
    } else {
        None
    };

    let avg_velocity = if note_count > 0 {
        Some(velocity_sum as f64 / note_count as f64)
    } else {
        None
    };

    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);

    // Calculate average polyphony
    let polyphony_avg = if !active_notes_per_tick.is_empty() {
        let sum: usize = active_notes_per_tick.values().sum();
        Some(sum as f64 / active_notes_per_tick.len() as f64)
    } else {
        None
    };

    // Monophonic: max polyphony is 1
    let is_monophonic = polyphony_max == Some(1);

    // Polyphonic: max polyphony > 1
    let is_polyphonic = polyphony_max.map_or(false, |p| p > 1);

    // Percussive: >50% of notes on channel 10 OR pitch range in drum range (35-81)
    let is_percussive = if note_count > 0 {
        let drum_ratio = percussive_note_count as f64 / note_count as f64;
        let in_drum_range = min_pitch >= 27 && max_pitch <= 87; // GM drum range with buffer
        drum_ratio > 0.5 || in_drum_range
    } else {
        false
    };

    // Calculate note density (notes per second)
    let duration_seconds = if max_tick > 0 {
        // Estimate duration assuming 120 BPM if no tempo events
        let ticks_per_beat = midi_file.header.ticks_per_quarter_note as f64;
        let seconds_per_beat = 0.5; // 120 BPM = 0.5 seconds per beat
        Some((max_tick as f64 / ticks_per_beat) * seconds_per_beat)
    } else {
        None
    };

    let note_density = if let Some(duration) = duration_seconds {
        if duration > 0.0 {
            Some(note_count as f64 / duration)
        } else {
            None
        }
    } else {
        None
    };

    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count > 0 {
        let semitones = max_pitch.saturating_sub(min_pitch) as i16;
        (
            Some(min_pitch as i16),
            Some(max_pitch as i16),
            Some(semitones),
        )
    } else {
        (None, None, None)
    };

    let (velocity_range_low, velocity_range_high) = if note_count > 0 {
        (Some(min_velocity as i16), Some(max_velocity as i16))
    } else {
        (None, None)
    };

    NoteStats {
        note_count,
        unique_pitches,
        pitch_range_low,
        pitch_range_high,
        pitch_range_semitones,
        avg_velocity,
        velocity_range_low,
        velocity_range_high,
        note_density,
        polyphony_max,
        polyphony_avg,
        is_monophonic,
        is_polyphonic,
        is_percussive,
    }
}

/// Extract time signature from MIDI file
fn extract_time_signature(midi_file: &MidiFile) -> (Option<i16>, Option<i16>) {
    for track in &midi_file.tracks {
        for timed_event in &track.events {
            if let Event::TimeSignature { numerator, denominator, .. } = &timed_event.event {
                // MIDI stores denominator as power of 2 (2 = quarter note, 3 = eighth note, etc.)
                let denom_value = 2i16.pow(*denominator as u32);
                return (Some(*numerator as i16), Some(denom_value));
            }
        }
    }

    // Default to 4/4 if not found
    (Some(4), Some(4))
}

/// Calculate total number of ticks in MIDI file
fn calculate_total_ticks(midi_file: &MidiFile) -> i32 {
    let mut max_ticks = 0u32;

    for track in &midi_file.tracks {
        let mut track_ticks = 0u32;
        for timed_event in &track.events {
            track_ticks += timed_event.delta_ticks;
        }
        max_ticks = max_ticks.max(track_ticks);
    }

    max_ticks as i32
}

/// Calculate duration in seconds
fn calculate_duration_seconds(midi_file: &MidiFile, bpm: f64) -> Option<f64> {
    let total_ticks = calculate_total_ticks(midi_file) as f64;
    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;

    if total_ticks > 0.0 && ticks_per_quarter > 0.0 && bpm > 0.0 {
        let quarters = total_ticks / ticks_per_quarter;
        let minutes = quarters / bpm;
        let seconds = minutes * 60.0;
        Some(seconds)
    } else {
        None
    }
}

/// Extract instrument names from MIDI file
fn extract_instrument_names(midi_file: &MidiFile) -> Vec<String> {
    let mut instruments = Vec::new();

    for track in &midi_file.tracks {
        for timed_event in &track.events {
            match &timed_event.event {
                Event::Text { text_type, text } => {
                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName)
                        && !instruments.contains(text)
                    {
                        instruments.push(text.clone());
                    }
                },
                Event::ProgramChange { program, .. } => {
                    if let Some(instrument_name) = program_to_instrument_name(*program) {
                        if !instruments.contains(&instrument_name) {
                            instruments.push(instrument_name);
                        }
                    }
                },
                _ => {},
            }
        }
    }

    instruments
}

/// Map MIDI General MIDI program number to instrument name
fn program_to_instrument_name(program: u8) -> Option<String> {
    match program {
        0..=7 => Some("Piano".to_string()),
        8..=15 => Some("Keys".to_string()),
        16..=23 => Some("Organ".to_string()),
        24..=31 => Some("Guitar".to_string()),
        32..=39 => Some("Bass".to_string()),
        40..=47 => Some("Strings".to_string()),
        48..=55 => Some("Ensemble".to_string()),
        56..=63 => Some("Brass".to_string()),
        64..=71 => Some("Woodwind".to_string()),
        72..=79 => Some("Flute".to_string()),
        80..=87 => Some("Lead".to_string()),
        88..=95 => Some("Pad".to_string()),
        96..=103 => Some("FX".to_string()),
        104..=111 => Some("Ethnic".to_string()),
        112..=119 => Some("Percussion".to_string()),
        120..=127 => Some("FX".to_string()),
        _ => None,
    }
}

/// Detect if MIDI file contains pitch bend events
fn detect_pitch_bend(midi_file: &MidiFile) -> bool {
    for track in &midi_file.tracks {
        for timed_event in &track.events {
            if matches!(&timed_event.event, Event::PitchBend { .. }) {
                return true;
            }
        }
    }
    false
}

/// Detect if MIDI file contains control change messages
fn detect_cc_messages(midi_file: &MidiFile) -> bool {
    for track in &midi_file.tracks {
        for timed_event in &track.events {
            if matches!(&timed_event.event, Event::ControlChange { .. }) {
                return true;
            }
        }
    }
    false
}

/// Track-level instrument information
#[derive(Debug, Clone)]
pub struct TrackInstrument {
    pub channel: i16,
    pub program_number: i16,
    pub program_name: String,
    pub instrument_family: String,
    pub instrument_type: String,
    pub note_count: i32,
    pub avg_velocity: Option<f64>,
    pub pitch_range_low: Option<i16>,
    pub pitch_range_high: Option<i16>,
    pub is_primary: bool,
}

/// Analyze tracks and extract per-channel instrument information
fn analyze_tracks(midi_file: &MidiFile) -> Vec<TrackInstrument> {
    let mut channel_data: std::collections::HashMap<u8, TrackInstrument> = std::collections::HashMap::new();

    // Extract program changes and note events per channel
    for track in &midi_file.tracks {
        let mut current_programs: std::collections::HashMap<u8, u8> = std::collections::HashMap::new();

        for timed_event in &track.events {
            match &timed_event.event {
                Event::ProgramChange { channel, program } => {
                    current_programs.insert(*channel, *program);
                }
                Event::NoteOn { channel, note, velocity } if *velocity > 0 => {
                    let program = current_programs.get(channel).copied().unwrap_or(0);

                    let entry = channel_data.entry(*channel).or_insert_with(|| {
                        let (name, family, inst_type) = get_instrument_info(program);
                        TrackInstrument {
                            channel: *channel as i16,
                            program_number: program as i16,
                            program_name: name,
                            instrument_family: family,
                            instrument_type: inst_type,
                            note_count: 0,
                            avg_velocity: None,
                            pitch_range_low: None,
                            pitch_range_high: None,
                            is_primary: false,
                        }
                    });

                    entry.note_count += 1;

                    // Update pitch range
                    entry.pitch_range_low = Some(entry.pitch_range_low.map_or(*note as i16, |l| l.min(*note as i16)));
                    entry.pitch_range_high = Some(entry.pitch_range_high.map_or(*note as i16, |h| h.max(*note as i16)));

                    // Update average velocity (running average)
                    if let Some(avg) = entry.avg_velocity {
                        entry.avg_velocity = Some((avg * (entry.note_count - 1) as f64 + *velocity as f64) / entry.note_count as f64);
                    } else {
                        entry.avg_velocity = Some(*velocity as f64);
                    }
                }
                _ => {}
            }
        }
    }

    // Convert to vec and mark primary instrument (most notes)
    let mut instruments: Vec<TrackInstrument> = channel_data.into_values().collect();
    if let Some(max_notes) = instruments.iter().map(|i| i.note_count).max() {
        for inst in &mut instruments {
            if inst.note_count == max_notes {
                inst.is_primary = true;
                break;
            }
        }
    }

    instruments
}

/// Extract tempo changes from MIDI meta events
fn extract_tempo_changes(midi_file: &MidiFile) -> Option<String> {
    let mut tempo_changes = Vec::new();
    let mut current_tick = 0u32;

    for track in &midi_file.tracks {
        let mut track_tick = 0u32;
        for timed_event in &track.events {
            track_tick += timed_event.delta_ticks;

            if let Event::TempoChange { microseconds_per_quarter } = &timed_event.event {
                let bpm = 60_000_000.0 / *microseconds_per_quarter as f64;
                tempo_changes.push(serde_json::json!({
                    "tick": track_tick,
                    "bpm": ((bpm * 100.0) as f64).round() / 100.0 // Round to 2 decimals
                }));
            }
        }
        current_tick = current_tick.max(track_tick);
    }

    if tempo_changes.is_empty() {
        None
    } else {
        Some(serde_json::to_string(&tempo_changes).unwrap_or_default())
    }
}

/// Extract key signature changes from MIDI meta events
fn extract_key_changes(midi_file: &MidiFile) -> Option<String> {
    let mut key_changes = Vec::new();
    let mut current_tick = 0u32;

    for track in &midi_file.tracks {
        let mut track_tick = 0u32;
        for timed_event in &track.events {
            track_tick += timed_event.delta_ticks;

            if let Event::KeySignature { sharps_flats, is_minor } = &timed_event.event {
                let key_name = get_key_name(*sharps_flats, *is_minor);
                key_changes.push(serde_json::json!({
                    "tick": track_tick,
                    "key": key_name
                }));
            }
        }
        current_tick = current_tick.max(track_tick);
    }

    if key_changes.is_empty() {
        None
    } else {
        Some(serde_json::to_string(&key_changes).unwrap_or_default())
    }
}

/// Extract time signature changes from MIDI meta events
fn extract_time_signature_changes(midi_file: &MidiFile) -> Option<String> {
    let mut time_sig_changes = Vec::new();
    let mut current_tick = 0u32;

    for track in &midi_file.tracks {
        let mut track_tick = 0u32;
        for timed_event in &track.events {
            track_tick += timed_event.delta_ticks;

            if let Event::TimeSignature { numerator, denominator, .. } = &timed_event.event {
                let denom_value = 2i32.pow(*denominator as u32);
                time_sig_changes.push(serde_json::json!({
                    "tick": track_tick,
                    "numerator": numerator,
                    "denominator": denom_value
                }));
            }
        }
        current_tick = current_tick.max(track_tick);
    }

    if time_sig_changes.is_empty() {
        None
    } else {
        Some(serde_json::to_string(&time_sig_changes).unwrap_or_default())
    }
}

/// Convert sharps/flats to key name
fn get_key_name(sharps_flats: i8, is_minor: bool) -> String {
    let major_keys = ["C", "G", "D", "A", "E", "B", "F#", "C#", "F", "Bb", "Eb", "Ab", "Db", "Gb", "Cb"];
    let minor_keys = ["Am", "Em", "Bm", "F#m", "C#m", "G#m", "D#m", "A#m", "Dm", "Gm", "Cm", "Fm", "Bbm", "Ebm", "Abm"];

    let index = if sharps_flats >= 0 {
        sharps_flats as usize
    } else {
        // For flats: -1 -> index 8 (F), -2 -> index 9 (Bb), etc.
        (8 - sharps_flats - 1) as usize
    };

    if is_minor {
        minor_keys.get(index).unwrap_or(&"Unknown").to_string()
    } else {
        major_keys.get(index).unwrap_or(&"Unknown").to_string()
    }
}

/// Controller statistics for a single CC number
#[derive(Debug, Clone)]
struct ControllerStats {
    cc_number: u8,
    count: u32,
    min_value: u8,
    max_value: u8,
    avg_value: f64,
}

/// Analyze MIDI controller (CC) messages
fn analyze_controllers(midi_file: &MidiFile) -> Option<String> {
    use std::collections::HashMap;

    // Track statistics for each controller number
    let mut controller_data: HashMap<u8, (u32, u8, u8, u64)> = HashMap::new(); // (count, min, max, sum)

    // High-priority controllers to track
    let priority_controllers = [1, 2, 7, 10, 11, 64]; // Modulation, Breath, Volume, Pan, Expression, Sustain

    for track in &midi_file.tracks {
        for timed_event in &track.events {
            if let Event::ControlChange { controller, value, .. } = &timed_event.event {
                let entry = controller_data.entry(*controller).or_insert((0, 255, 0, 0));
                entry.0 += 1; // count
                entry.1 = entry.1.min(*value); // min
                entry.2 = entry.2.max(*value); // max
                entry.3 += *value as u64; // sum for average
            }
        }
    }

    if controller_data.is_empty() {
        return None;
    }

    // Build JSON array of controller statistics
    let mut controllers = Vec::new();

    // First add priority controllers if present
    for &cc in &priority_controllers {
        if let Some(&(count, min, max, sum)) = controller_data.get(&cc) {
            let avg = sum as f64 / count as f64;
            controllers.push(serde_json::json!({
                "cc": cc,
                "name": get_cc_name(cc),
                "count": count,
                "min": min,
                "max": max,
                "avg": (avg * 100.0).round() / 100.0
            }));
        }
    }

    // Then add other controllers with significant usage (>10 events)
    for (&cc, &(count, min, max, sum)) in &controller_data {
        if !priority_controllers.contains(&cc) && count > 10 {
            let avg = sum as f64 / count as f64;
            controllers.push(serde_json::json!({
                "cc": cc,
                "name": get_cc_name(cc),
                "count": count,
                "min": min,
                "max": max,
                "avg": (avg * 100.0).round() / 100.0
            }));
        }
    }

    if controllers.is_empty() {
        None
    } else {
        Some(serde_json::to_string(&controllers).unwrap_or_default())
    }
}

/// Get human-readable name for CC number
fn get_cc_name(cc: u8) -> &'static str {
    match cc {
        0 => "Bank Select",
        1 => "Modulation Wheel",
        2 => "Breath Controller",
        4 => "Foot Controller",
        5 => "Portamento Time",
        6 => "Data Entry",
        7 => "Channel Volume",
        8 => "Balance",
        10 => "Pan",
        11 => "Expression",
        64 => "Sustain Pedal",
        65 => "Portamento",
        66 => "Sostenuto",
        67 => "Soft Pedal",
        68 => "Legato Footswitch",
        69 => "Hold 2",
        71 => "Resonance",
        72 => "Release Time",
        73 => "Attack Time",
        74 => "Cutoff Frequency",
        84 => "Portamento Control",
        91 => "Reverb",
        92 => "Tremolo",
        93 => "Chorus",
        94 => "Detune",
        95 => "Phaser",
        _ => "Other",
    }
}

/// Articulation and performance characteristics
#[derive(Debug, Clone)]
struct ArticulationAnalysis {
    legato_percentage: f64,
    staccato_percentage: f64,
    avg_note_duration_ms: f64,
    timing_deviation_ms: f64,
    dynamic_range: u8,
    velocity_variance: f64,
}

/// Analyze articulation and performance characteristics
fn analyze_articulation(midi_file: &MidiFile, tempo_us_per_qn: u32) -> Option<String> {
    let tpq = midi_file.header.ticks_per_quarter_note as f64;
    let us_per_tick = tempo_us_per_qn as f64 / tpq;
    let ms_per_tick = us_per_tick / 1000.0;

    // Track note events per channel
    let mut note_events: std::collections::HashMap<(u8, u8), (u32, u8)> = std::collections::HashMap::new(); // (channel, pitch) -> (start_tick, velocity)
    let mut note_durations: Vec<f64> = Vec::new();
    let mut note_velocities: Vec<u8> = Vec::new();
    let mut timing_deviations: Vec<f64> = Vec::new();
    let mut legato_count = 0;
    let mut staccato_count = 0;
    let mut total_notes = 0;

    for track in &midi_file.tracks {
        let mut current_tick = 0u32;
        let mut active_notes: std::collections::HashSet<(u8, u8)> = std::collections::HashSet::new();

        for timed_event in &track.events {
            current_tick += timed_event.delta_ticks;

            match &timed_event.event {
                Event::NoteOn { channel, note, velocity } if *velocity > 0 => {
                    // Check for legato (note starts while others are active)
                    if !active_notes.is_empty() {
                        legato_count += 1;
                    }

                    active_notes.insert((*channel, *note));
                    note_events.insert((*channel, *note), (current_tick, *velocity));
                    note_velocities.push(*velocity);

                    // Calculate timing deviation from grid (16th note = tpq/4)
                    let grid_size = (tpq / 4.0) as u32; // 16th note grid
                    let deviation = (current_tick % grid_size) as f64;
                    let normalized_deviation = if deviation > grid_size as f64 / 2.0 {
                        grid_size as f64 - deviation
                    } else {
                        deviation
                    };
                    timing_deviations.push(normalized_deviation * ms_per_tick);

                    total_notes += 1;
                }
                Event::NoteOff { channel, note, .. } | Event::NoteOn { channel, note, velocity: 0 } => {
                    if let Some((start_tick, _)) = note_events.remove(&(*channel, *note)) {
                        let duration_ticks = current_tick.saturating_sub(start_tick);
                        let duration_ms = duration_ticks as f64 * ms_per_tick;
                        note_durations.push(duration_ms);

                        // Staccato detection: very short notes (<100ms)
                        if duration_ms < 100.0 {
                            staccato_count += 1;
                        }
                    }
                    active_notes.remove(&(*channel, *note));
                }
                _ => {}
            }
        }
    }

    if total_notes == 0 {
        return None;
    }

    // Calculate statistics
    let legato_percentage = (legato_count as f64 / total_notes as f64) * 100.0;
    let staccato_percentage = (staccato_count as f64 / total_notes as f64) * 100.0;

    let avg_note_duration = note_durations.iter().sum::<f64>() / note_durations.len().max(1) as f64;

    let avg_timing_deviation = timing_deviations.iter().sum::<f64>() / timing_deviations.len().max(1) as f64;

    let min_velocity = *note_velocities.iter().min().unwrap_or(&0);
    let max_velocity = *note_velocities.iter().max().unwrap_or(&127);
    let dynamic_range = max_velocity.saturating_sub(min_velocity);

    let avg_velocity = note_velocities.iter().map(|&v| v as f64).sum::<f64>() / note_velocities.len().max(1) as f64;
    let velocity_variance = note_velocities.iter()
        .map(|&v| {
            let diff = v as f64 - avg_velocity;
            diff * diff
        })
        .sum::<f64>() / note_velocities.len().max(1) as f64;

    let result = serde_json::json!({
        "legato_percentage": (legato_percentage * 100.0).round() / 100.0,
        "staccato_percentage": (staccato_percentage * 100.0).round() / 100.0,
        "avg_note_duration_ms": (avg_note_duration * 100.0).round() / 100.0,
        "timing_deviation_ms": (avg_timing_deviation * 100.0).round() / 100.0,
        "dynamic_range": dynamic_range,
        "velocity_variance": (velocity_variance * 100.0).round() / 100.0,
        "is_humanized": avg_timing_deviation > 2.0, // >2ms average deviation suggests human/humanized performance
        "is_legato": legato_percentage > 30.0,
        "is_staccato": staccato_percentage > 50.0,
    });

    Some(serde_json::to_string(&result).unwrap_or_default())
}

/// Analyze musical structure and form
fn analyze_structure(midi_file: &MidiFile) -> Option<String> {
    // Divide the file into segments (every 4 measures, assuming 4/4)
    let tpq = midi_file.header.ticks_per_quarter_note as u32;
    let segment_size = tpq * 16; // 4 measures in 4/4 time (16 quarter notes)

    // Find total duration in ticks
    let mut max_tick = 0u32;
    for track in &midi_file.tracks {
        let mut current_tick = 0u32;
        for event in &track.events {
            current_tick += event.delta_ticks;
        }
        max_tick = max_tick.max(current_tick);
    }

    if max_tick < segment_size {
        return None; // File too short for structure analysis
    }

    // Create segment hashes based on note patterns
    let num_segments = (max_tick / segment_size) as usize;
    let mut segment_hashes: Vec<u64> = vec![0; num_segments];

    for track in &midi_file.tracks {
        let mut current_tick = 0u32;
        for event in &track.events {
            current_tick += event.delta_ticks;

            if let Event::NoteOn { note, velocity, .. } = &event.event {
                if *velocity > 0 {
                    let segment_idx = (current_tick / segment_size) as usize;
                    if segment_idx < num_segments {
                        // Simple hash: combine note and position within segment
                        let position = current_tick % segment_size;
                        let hash = ((*note as u64) << 32) | position as u64;
                        segment_hashes[segment_idx] ^= hash; // XOR for simplicity
                    }
                }
            }
        }
    }

    // Find repeated patterns
    let mut pattern_map: std::collections::HashMap<u64, Vec<usize>> = std::collections::HashMap::new();
    for (idx, &hash) in segment_hashes.iter().enumerate() {
        if hash != 0 {
            pattern_map.entry(hash).or_insert_with(Vec::new).push(idx);
        }
    }

    // Identify major repeated sections (appears 2+ times)
    let mut repeated_sections: Vec<(usize, usize)> = Vec::new(); // (pattern_id, count)
    let mut pattern_id = 0;
    for (_hash, positions) in pattern_map.iter() {
        if positions.len() >= 2 {
            repeated_sections.push((pattern_id, positions.len()));
            pattern_id += 1;
        }
    }

    // Calculate repetition percentage
    let total_repeated: usize = repeated_sections.iter().map(|(_, count)| count).sum();
    let repetition_percentage = if num_segments > 0 {
        (total_repeated as f64 / num_segments as f64) * 100.0
    } else {
        0.0
    };

    // Estimate form based on number of unique patterns
    let num_unique = pattern_map.len();
    let estimated_form = if num_unique <= 2 {
        "Simple (AA or AB)"
    } else if num_unique <= 4 {
        "Song Form (AABA or ABAB)"
    } else if num_unique <= 6 {
        "Complex (ABABCB or similar)"
    } else {
        "Through-composed"
    };

    let result = serde_json::json!({
        "num_segments": num_segments,
        "num_unique_patterns": num_unique,
        "num_repeated_patterns": repeated_sections.len(),
        "repetition_percentage": (repetition_percentage * 100.0).round() / 100.0,
        "estimated_form": estimated_form,
        "has_repetition": repetition_percentage > 20.0,
        "is_through_composed": num_unique > 6,
    });

    Some(serde_json::to_string(&result).unwrap_or_default())
}

/// Get instrument information from GM program number
fn get_instrument_info(program: u8) -> (String, String, String) {
    match program {
        0..=7 => ("Piano".to_string(), "Keyboard".to_string(), "Acoustic Piano".to_string()),
        8..=15 => ("Chromatic Percussion".to_string(), "Keyboard".to_string(), "Celesta/Glockenspiel".to_string()),
        16..=23 => ("Organ".to_string(), "Keyboard".to_string(), "Drawbar Organ".to_string()),
        24..=31 => ("Guitar".to_string(), "Strings".to_string(), "Acoustic Guitar".to_string()),
        32..=39 => ("Bass".to_string(), "Strings".to_string(), "Electric Bass".to_string()),
        40..=47 => ("Strings".to_string(), "Strings".to_string(), "Violin/Viola".to_string()),
        48..=55 => ("Ensemble".to_string(), "Ensemble".to_string(), "String Ensemble".to_string()),
        56..=63 => ("Brass".to_string(), "Brass".to_string(), "Trumpet/Trombone".to_string()),
        64..=71 => ("Reed".to_string(), "Reed".to_string(), "Saxophone".to_string()),
        72..=79 => ("Pipe".to_string(), "Pipe".to_string(), "Flute/Piccolo".to_string()),
        80..=87 => ("Synth Lead".to_string(), "Synth".to_string(), "Lead Synth".to_string()),
        88..=95 => ("Synth Pad".to_string(), "Synth".to_string(), "Pad Synth".to_string()),
        96..=103 => ("Synth Effects".to_string(), "Synth".to_string(), "FX Synth".to_string()),
        104..=111 => ("Ethnic".to_string(), "Ethnic".to_string(), "Sitar/Shamisen".to_string()),
        112..=119 => ("Percussive".to_string(), "Percussion".to_string(), "Timpani/Taiko".to_string()),
        120..=127 => ("Sound Effects".to_string(), "SFX".to_string(), "Sound Effect".to_string()),
        _ => ("Unknown".to_string(), "Unknown".to_string(), "Unknown".to_string()),
    }
}

/// Calculate complexity score based on various factors
fn calculate_complexity_score(note_stats: &NoteStats, midi_file: &MidiFile) -> Option<f64> {
    if note_stats.note_count == 0 {
        return Some(0.0);
    }

    let mut score = 0.0;

    // Factor 1: Note density (notes per second)
    // Assume average 120 BPM for rough estimate
    let duration_est = calculate_total_ticks(midi_file) as f64
        / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);
    if duration_est > 0.0 {
        let note_density = note_stats.note_count as f64 / duration_est;
        score += (note_density / 10.0).min(30.0); // Max 30 points
    }

    // Factor 2: Pitch range (wider range = more complex)
    if let Some(semitones) = note_stats.pitch_range_semitones {
        score += (semitones as f64 / 2.0).min(20.0); // Max 20 points
    }

    // Factor 3: Polyphony (more simultaneous notes = more complex)
    if let Some(polyphony) = note_stats.polyphony_max {
        score += (polyphony as f64 * 5.0).min(25.0); // Max 25 points
    }

    // Factor 4: Track count
    let track_count = midi_file.tracks.len() as f64;
    score += (track_count * 2.0).min(15.0); // Max 15 points

    // Factor 5: Velocity variation
    if let (Some(low), Some(high)) = (
        note_stats.velocity_range_low,
        note_stats.velocity_range_high,
    ) {
        let velocity_range = (high - low) as f64;
        score += (velocity_range / 10.0).min(10.0); // Max 10 points
    }

    // Normalize to 0-100 scale
    Some(score.min(100.0))
}

//=============================================================================
// TESTS
//=============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_program_to_instrument_name() {
        assert_eq!(program_to_instrument_name(0), Some("Piano".to_string()));
        assert_eq!(program_to_instrument_name(32), Some("Bass".to_string()));
        assert_eq!(program_to_instrument_name(80), Some("Lead".to_string()));
    }

    #[test]
    fn test_complexity_score_empty() {
        let note_stats = NoteStats {
            note_count: 0,
            unique_pitches: None,
            pitch_range_low: None,
            pitch_range_high: None,
            pitch_range_semitones: None,
            avg_velocity: None,
            velocity_range_low: None,
            velocity_range_high: None,
            note_density: None,
            polyphony_max: None,
            polyphony_avg: None,
            is_monophonic: false,
            is_polyphonic: false,
            is_percussive: false,
        };

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 0,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![],
        };

        let score = calculate_complexity_score(&note_stats, &midi_file);
        assert_eq!(score, Some(0.0));
    }

    #[test]
    fn test_extract_tempo_changes() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::TempoChange {
                            microseconds_per_quarter: 500_000, // 120 BPM
                        },
                    },
                    TimedEvent {
                        delta_ticks: 1920,
                        event: Event::TempoChange {
                            microseconds_per_quarter: 600_000, // 100 BPM
                        },
                    },
                ],
            }],
        };

        let result = extract_tempo_changes(&midi_file);
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: Vec<serde_json::Value> = serde_json::from_str(&json_str).unwrap();

        assert_eq!(parsed.len(), 2);
        assert_eq!(parsed[0]["tick"], 0);
        assert_eq!(parsed[0]["bpm"], 120.0);
        assert_eq!(parsed[1]["tick"], 1920);
        assert_eq!(parsed[1]["bpm"], 100.0);
    }

    #[test]
    fn test_extract_key_changes() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::KeySignature {
                            sharps_flats: 0,  // C major
                            is_minor: false,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 1920,
                        event: Event::KeySignature {
                            sharps_flats: 2,  // D major
                            is_minor: false,
                        },
                    },
                ],
            }],
        };

        let result = extract_key_changes(&midi_file);
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: Vec<serde_json::Value> = serde_json::from_str(&json_str).unwrap();

        assert_eq!(parsed.len(), 2);
        assert_eq!(parsed[0]["tick"], 0);
        assert_eq!(parsed[0]["key"], "C");
        assert_eq!(parsed[1]["tick"], 1920);
        assert_eq!(parsed[1]["key"], "D");
    }

    #[test]
    fn test_extract_time_signature_changes() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::TimeSignature {
                            numerator: 4,
                            denominator: 2,  // 2^2 = 4, so 4/4 time
                            clocks_per_click: 24,
                            thirty_seconds_per_quarter: 8,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 1920,
                        event: Event::TimeSignature {
                            numerator: 3,
                            denominator: 2,  // 2^2 = 4, so 3/4 time
                            clocks_per_click: 24,
                            thirty_seconds_per_quarter: 8,
                        },
                    },
                ],
            }],
        };

        let result = extract_time_signature_changes(&midi_file);
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: Vec<serde_json::Value> = serde_json::from_str(&json_str).unwrap();

        assert_eq!(parsed.len(), 2);
        assert_eq!(parsed[0]["tick"], 0);
        assert_eq!(parsed[0]["numerator"], 4);
        assert_eq!(parsed[0]["denominator"], 4);
        assert_eq!(parsed[1]["tick"], 1920);
        assert_eq!(parsed[1]["numerator"], 3);
        assert_eq!(parsed[1]["denominator"], 4);
    }

    #[test]
    fn test_get_key_name() {
        // Major keys with sharps
        assert_eq!(get_key_name(0, false), "C");
        assert_eq!(get_key_name(1, false), "G");
        assert_eq!(get_key_name(2, false), "D");

        // Major keys with flats
        assert_eq!(get_key_name(-1, false), "F");
        assert_eq!(get_key_name(-2, false), "Bb");

        // Minor keys
        assert_eq!(get_key_name(0, true), "Am");
        assert_eq!(get_key_name(1, true), "Em");
        assert_eq!(get_key_name(-1, true), "Dm");
    }

    #[test]
    fn test_analyze_controllers() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::ControlChange {
                            channel: 0,
                            controller: 7,  // Volume
                            value: 100,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::ControlChange {
                            channel: 0,
                            controller: 10,  // Pan
                            value: 64,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::ControlChange {
                            channel: 0,
                            controller: 1,  // Modulation
                            value: 50,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::ControlChange {
                            channel: 0,
                            controller: 1,  // Modulation again
                            value: 70,
                        },
                    },
                ],
            }],
        };

        let result = analyze_controllers(&midi_file);
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: Vec<serde_json::Value> = serde_json::from_str(&json_str).unwrap();

        // Should have 3 controllers (1, 7, 10)
        assert_eq!(parsed.len(), 3);

        // Find the modulation controller (CC1)
        let mod_controller = parsed.iter().find(|c| c["cc"] == 1).unwrap();
        assert_eq!(mod_controller["name"], "Modulation Wheel");
        assert_eq!(mod_controller["count"], 2);
        assert_eq!(mod_controller["min"], 50);
        assert_eq!(mod_controller["max"], 70);
        assert_eq!(mod_controller["avg"], 60.0);
    }

    #[test]
    fn test_analyze_controllers_empty() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn {
                            channel: 0,
                            note: 60,
                            velocity: 100,
                        },
                    },
                ],
            }],
        };

        let result = analyze_controllers(&midi_file);
        assert!(result.is_none());
    }

    #[test]
    fn test_get_cc_name() {
        assert_eq!(get_cc_name(1), "Modulation Wheel");
        assert_eq!(get_cc_name(7), "Channel Volume");
        assert_eq!(get_cc_name(10), "Pan");
        assert_eq!(get_cc_name(64), "Sustain Pedal");
        assert_eq!(get_cc_name(99), "Other");
    }

    #[test]
    fn test_analyze_articulation() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    // First note - normal duration
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn {
                            channel: 0,
                            note: 60,
                            velocity: 100,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 240, // Half a quarter note
                        event: Event::NoteOff {
                            channel: 0,
                            note: 60,
                            velocity: 64,
                        },
                    },
                    // Second note - legato (overlaps conceptually)
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn {
                            channel: 0,
                            note: 64,
                            velocity: 80,
                        },
                    },
                    TimedEvent {
                        delta_ticks: 120, // Staccato (short)
                        event: Event::NoteOff {
                            channel: 0,
                            note: 64,
                            velocity: 64,
                        },
                    },
                ],
            }],
        };

        let result = analyze_articulation(&midi_file, 500_000); // 120 BPM
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: serde_json::Value = serde_json::from_str(&json_str).unwrap();

        // Verify structure
        assert!(parsed["legato_percentage"].is_number());
        assert!(parsed["staccato_percentage"].is_number());
        assert!(parsed["avg_note_duration_ms"].is_number());
        assert!(parsed["timing_deviation_ms"].is_number());
        assert!(parsed["dynamic_range"].is_number());
        assert!(parsed["velocity_variance"].is_number());
        assert!(parsed["is_humanized"].is_boolean());
        assert!(parsed["is_legato"].is_boolean());
        assert!(parsed["is_staccato"].is_boolean());

        // Dynamic range should be 100 - 80 = 20
        assert_eq!(parsed["dynamic_range"], 20);
    }

    #[test]
    fn test_analyze_articulation_empty() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![],
            }],
        };

        let result = analyze_articulation(&midi_file, 500_000);
        assert!(result.is_none());
    }

    #[test]
    fn test_analyze_structure() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        // Create a MIDI file with repeated patterns (simulate AABA form)
        let tpq = 480;
        let measure_ticks = (tpq * 4) as u32; // 4 beats per measure

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: tpq,
            },
            tracks: vec![Track {
                events: vec![
                    // Section A (4 measures)
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn { channel: 0, note: 60, velocity: 100 },
                    },
                    TimedEvent {
                        delta_ticks: measure_ticks * 4,
                        event: Event::NoteOff { channel: 0, note: 60, velocity: 64 },
                    },
                    // Section A repeated (4 measures)
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn { channel: 0, note: 60, velocity: 100 },
                    },
                    TimedEvent {
                        delta_ticks: measure_ticks * 4,
                        event: Event::NoteOff { channel: 0, note: 60, velocity: 64 },
                    },
                    // Section B (4 measures) - different pattern
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn { channel: 0, note: 64, velocity: 100 },
                    },
                    TimedEvent {
                        delta_ticks: measure_ticks * 4,
                        event: Event::NoteOff { channel: 0, note: 64, velocity: 64 },
                    },
                ],
            }],
        };

        let result = analyze_structure(&midi_file);
        assert!(result.is_some());

        let json_str = result.unwrap();
        let parsed: serde_json::Value = serde_json::from_str(&json_str).unwrap();

        // Verify structure
        assert!(parsed["num_segments"].is_number());
        assert!(parsed["num_unique_patterns"].is_number());
        assert!(parsed["num_repeated_patterns"].is_number());
        assert!(parsed["repetition_percentage"].is_number());
        assert!(parsed["estimated_form"].is_string());
        assert!(parsed["has_repetition"].is_boolean());
        assert!(parsed["is_through_composed"].is_boolean());

        // Should have at least 3 segments (3 x 4 measures)
        assert!(parsed["num_segments"].as_u64().unwrap() >= 3);
    }

    #[test]
    fn test_analyze_structure_too_short() {
        use midi_library_shared::core::midi::types::{Event, TimedEvent, Track};

        let midi_file = MidiFile {
            header: midi_library_shared::core::midi::types::Header {
                format: 1,
                num_tracks: 1,
                ticks_per_quarter_note: 480,
            },
            tracks: vec![Track {
                events: vec![
                    TimedEvent {
                        delta_ticks: 0,
                        event: Event::NoteOn { channel: 0, note: 60, velocity: 100 },
                    },
                    TimedEvent {
                        delta_ticks: 100, // Very short file
                        event: Event::NoteOff { channel: 0, note: 60, velocity: 64 },
                    },
                ],
            }],
        };

        let result = analyze_structure(&midi_file);
        assert!(result.is_none()); // Too short for structure analysis
    }
}

```

### `api.ts` {#api-ts}

- **Lines**: 1221 (code: 1125, comments: 0, blank: 96)

#### Source Code

```typescript
import { invoke } from '@tauri-apps/api/core';
import type {
  FileMetadata,
  FileDetails,
  SearchFilters,
  SearchResponse,
  ImportProgress,
  ImportSummary,
  Track,
  TrackProperties,
  PlaybackPosition,
  PlaybackState,
  MidiDevice,
  MidiPattern,
  CompatibleFile,
  DAWWindowState,
  TrackInfo,
  TransportInfo,
  MixerState,
  AutomationLane,
  AutomationPoint,
  ParameterType,
  CurveType,
  TrackDetails,
  MidiFile,
  DatabaseFilters,
  SearchResults,
  DatabaseStats,
  PipelineProgress,
  ImportStats,
  AnalysisResults,
  FileParams,
} from './types';

// ============================================================================
// MIDI HARDWARE COMMANDS (6 total)
// ============================================================================

export const api = {
  midi: {
    /**
     * List all available MIDI output devices
     * Backend: daw/src-tauri/src/commands/midi.rs:15
     */
    listDevices: async (): Promise<MidiDevice[]> => {
      try {
        return await invoke('midi_list_devices');
      } catch (error) {
        console.error('Failed to list MIDI devices:', error);
        throw error;
      }
    },

    /**
     * Connect to a specific MIDI device by name
     * Backend: daw/src-tauri/src/commands/midi.rs:25
     */
    connect: async (deviceName: string): Promise<void> => {
      try {
        await invoke('midi_connect', { device_name: deviceName });
      } catch (error) {
        console.error('Failed to connect to MIDI device:', error);
        throw error;
      }
    },

    /**
     * Disconnect from current MIDI device
     * Backend: daw/src-tauri/src/commands/midi.rs:36
     */
    disconnect: async (): Promise<void> => {
      try {
        await invoke('midi_disconnect');
      } catch (error) {
        console.error('Failed to disconnect MIDI device:', error);
        throw error;
      }
    },

    /**
     * Check if MIDI device is currently connected
     * Backend: daw/src-tauri/src/commands/midi.rs:47
     */
    isConnected: async (): Promise<boolean> => {
      try {
        return await invoke('midi_is_connected');
      } catch (error) {
        console.error('Failed to check MIDI connection:', error);
        throw error;
      }
    },

    /**
     * Get current MIDI device info
     * Backend: daw/src-tauri/src/commands/midi.rs:57
     */
    getCurrentDevice: async (): Promise<MidiDevice | undefined> => {
      try {
        return await invoke('midi_get_current_device');
      } catch (error) {
        console.error('Failed to get current MIDI device:', error);
        throw error;
      }
    },

    /**
     * Send a test note to verify MIDI connection
     * Backend: daw/src-tauri/src/commands/midi.rs:75
     * ‚úÖ CORRECTED: Added missing channel parameter
     */
    sendTestNote: async (channel: number, note: number, velocity: number): Promise<void> => {
      try {
        await invoke('midi_send_test_note', { channel, note, velocity });
      } catch (error) {
        console.error('Failed to send test note:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // SEQUENCER COMMANDS (13 total)
  // ============================================================================

  sequencer: {
    /**
     * Start sequencer playback
     * Backend: daw/src-tauri/src/commands/sequencer.rs:14
     */
    start: async (): Promise<void> => {
      try {
        await invoke('start_sequencer');
      } catch (error) {
        console.error('Failed to start sequencer:', error);
        throw error;
      }
    },

    /**
     * Stop sequencer playback (resets position)
     * Backend: daw/src-tauri/src/commands/sequencer.rs:22
     */
    stop: async (): Promise<void> => {
      try {
        await invoke('stop_sequencer');
      } catch (error) {
        console.error('Failed to stop sequencer:', error);
        throw error;
      }
    },

    /**
     * Pause sequencer playback (maintains position)
     * Backend: daw/src-tauri/src/commands/sequencer.rs:31
     */
    pause: async (): Promise<void> => {
      try {
        await invoke('pause_sequencer');
      } catch (error) {
        console.error('Failed to pause sequencer:', error);
        throw error;
      }
    },

    /**
     * Resume sequencer playback from paused state
     * Backend: daw/src-tauri/src/commands/sequencer.rs:40
     */
    resume: async (): Promise<void> => {
      try {
        await invoke('resume_sequencer');
      } catch (error) {
        console.error('Failed to resume sequencer:', error);
        throw error;
      }
    },

    /**
     * Get current playback position
     * Backend: daw/src-tauri/src/commands/sequencer.rs:48
     */
    getPosition: async (): Promise<PlaybackPosition> => {
      try {
        return await invoke('get_playback_position');
      } catch (error) {
        console.error('Failed to get playback position:', error);
        throw error;
      }
    },

    /**
     * Seek to a specific position
     * Backend: daw/src-tauri/src/commands/sequencer.rs:61
     * ‚úÖ CORRECTED: Takes (bar, beat) not tick
     */
    seekPosition: async (bar: number, beat: number): Promise<void> => {
      try {
        await invoke('seek_position', { bar, beat });
      } catch (error) {
        console.error('Failed to seek position:', error);
        throw error;
      }
    },

    /**
     * Set global tempo (BPM)
     * Backend: daw/src-tauri/src/commands/sequencer.rs:74
     */
    setTempo: async (bpm: number): Promise<void> => {
      try {
        await invoke('set_tempo', { bpm });
      } catch (error) {
        console.error('Failed to set tempo:', error);
        throw error;
      }
    },

    /**
     * Get current tempo
     * Backend: daw/src-tauri/src/commands/sequencer.rs:83
     */
    getTempo: async (): Promise<number> => {
      try {
        return await invoke('get_tempo');
      } catch (error) {
        console.error('Failed to get tempo:', error);
        throw error;
      }
    },

    /**
     * Add a track to the sequencer
     * Backend: daw/src-tauri/src/commands/sequencer.rs:98
     */
    addTrack: async (fileId: number, channel: number): Promise<Track> => {
      try {
        return await invoke('add_track', { file_id: fileId, channel });
      } catch (error) {
        console.error('Failed to add track:', error);
        throw error;
      }
    },

    /**
     * Remove a track from the sequencer
     * Backend: daw/src-tauri/src/commands/sequencer.rs:145
     */
    removeTrack: async (trackId: number): Promise<void> => {
      try {
        await invoke('remove_track', { track_id: trackId });
      } catch (error) {
        console.error('Failed to remove track:', error);
        throw error;
      }
    },

    /**
     * Update track properties (mute, solo, volume, pan)
     * Backend: daw/src-tauri/src/commands/sequencer.rs:161
     */
    updateTrack: async (trackId: number, properties: TrackProperties): Promise<void> => {
      try {
        await invoke('update_track', { track_id: trackId, properties });
      } catch (error) {
        console.error('Failed to update track:', error);
        throw error;
      }
    },

    /**
     * Get all tracks in current project
     * Backend: daw/src-tauri/src/commands/sequencer.rs:177
     */
    getTracks: async (): Promise<Track[]> => {
      try {
        return await invoke('get_tracks');
      } catch (error) {
        console.error('Failed to get tracks:', error);
        throw error;
      }
    },

    /**
     * Load tracks into sequencer and prepare for playback
     * Backend: daw/src-tauri/src/commands/sequencer.rs:186
     */
    loadTracks: async (): Promise<void> => {
      try {
        await invoke('load_sequencer_tracks');
      } catch (error) {
        console.error('Failed to load tracks:', error);
        throw error;
      }
    },

    /**
     * Check if sequencer is currently playing
     * Backend: daw/src-tauri/src/commands/sequencer.rs:195
     */
    isPlaying: async (): Promise<boolean> => {
      try {
        return await invoke('is_sequencer_playing');
      } catch (error) {
        console.error('Failed to check if playing:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // SEARCH COMMANDS (3 total)
  // ============================================================================

  search: {
    /**
     * Search for files with filters
     * Backend: daw/src-tauri/src/commands/search.rs:25
     */
    files: async (filters: SearchFilters): Promise<SearchResponse> => {
      try {
        return await invoke('search_files', { filters });
      } catch (error) {
        console.error('Failed to search files:', error);
        throw error;
      }
    },

    /**
     * Get detailed information about a specific file
     * Backend: daw/src-tauri/src/commands/search.rs:219
     */
    getDetails: async (fileId: number): Promise<FileDetails> => {
      try {
        return await invoke('get_file_details', { file_id: fileId });
      } catch (error) {
        console.error('Failed to get file details:', error);
        throw error;
      }
    },

    /**
     * Get search suggestions for autocomplete
     * Backend: daw/src-tauri/src/commands/search.rs:278
     * ‚úÖ CORRECTED: Added missing field parameter
     */
    getSuggestions: async (query: string, field: string): Promise<string[]> => {
      try {
        return await invoke('get_search_suggestions', { query, field });
      } catch (error) {
        console.error('Failed to get search suggestions:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // ANALYSIS COMMANDS (6 total)
  // ============================================================================

  analysis: {
    /**
     * Find files that are musically compatible
     * Backend: daw/src-tauri/src/commands/analysis.rs:22
     */
    findCompatible: async (fileId: number, maxResults?: number): Promise<CompatibleFile[]> => {
      try {
        return await invoke('find_compatible_files', { file_id: fileId, max_results: maxResults });
      } catch (error) {
        console.error('Failed to find compatible files:', error);
        throw error;
      }
    },

    /**
     * Add file to favorites
     * Backend: daw/src-tauri/src/commands/analysis.rs:181
     */
    addFavorite: async (fileId: number): Promise<void> => {
      try {
        await invoke('add_favorite', { file_id: fileId });
      } catch (error) {
        console.error('Failed to add favorite:', error);
        throw error;
      }
    },

    /**
     * Remove file from favorites
     * Backend: daw/src-tauri/src/commands/analysis.rs:205
     */
    removeFavorite: async (fileId: number): Promise<void> => {
      try {
        await invoke('remove_favorite', { file_id: fileId });
      } catch (error) {
        console.error('Failed to remove favorite:', error);
        throw error;
      }
    },

    /**
     * Check if a file is favorited
     * Backend: daw/src-tauri/src/commands/analysis.rs:228
     */
    isFavorite: async (fileId: number): Promise<boolean> => {
      try {
        return await invoke('is_favorite', { file_id: fileId });
      } catch (error) {
        console.error('Failed to check favorite:', error);
        throw error;
      }
    },

    /**
     * Get all favorite files with full details
     * Backend: daw/src-tauri/src/commands/analysis.rs:245
     */
    getFavorites: async (): Promise<FileDetails[]> => {
      try {
        return await invoke('get_favorites');
      } catch (error) {
        console.error('Failed to get favorites:', error);
        throw error;
      }
    },

    /**
     * Get usage statistics
     * Backend: daw/src-tauri/src/commands/analysis.rs:298
     */
    getUsageStats: async (): Promise<string> => {
      try {
        return await invoke('get_usage_stats');
      } catch (error) {
        console.error('Failed to get usage stats:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // PROJECT COMMANDS (3 total)
  // ============================================================================

  project: {
    /**
     * Load multiple MIDI files as sequencer tracks
     * Backend: daw/src-tauri/src/commands/project.rs:31
     */
    loadMultipleTracks: async (fileIds: number[]): Promise<Track[]> => {
      try {
        return await invoke('load_multiple_tracks', { file_ids: fileIds });
      } catch (error) {
        console.error('Failed to load multiple tracks:', error);
        throw error;
      }
    },

    /**
     * Clear all tracks from the sequencer
     * Backend: daw/src-tauri/src/commands/project.rs:119
     */
    clearAllTracks: async (): Promise<void> => {
      try {
        await invoke('clear_all_tracks');
      } catch (error) {
        console.error('Failed to clear all tracks:', error);
        throw error;
      }
    },

    /**
     * Get detailed information about loaded tracks
     * Backend: daw/src-tauri/src/commands/project.rs:135
     */
    getTrackDetails: async (): Promise<TrackDetails[]> => {
      try {
        return await invoke('get_track_details');
      } catch (error) {
        console.error('Failed to get track details:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // EXPORT COMMANDS (1 total)
  // ============================================================================

  export: {
    /**
     * Export project as MIDI file
     * Backend: daw/src-tauri/src/commands/export.rs
     */
    projectAsMidi: async (outputPath: string): Promise<void> => {
      try {
        await invoke('export_project_midi', { output_path: outputPath });
      } catch (error) {
        console.error('Failed to export project as MIDI:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // PIPELINE COMMANDS (5 total) - Import, Analysis, Archive, Progress
  // Backend: daw/src-tauri/src/commands/pipeline.rs
  // ============================================================================

  pipeline: {
    /**
     * Import multiple MIDI files
     * Backend: daw/src-tauri/src/commands/pipeline.rs:56
     */
    importFiles: async (filePaths: string[]): Promise<ImportStats> => {
      try {
        return await invoke('pipeline_import_files', { file_paths: filePaths });
      } catch (error) {
        console.error('Failed to import files:', error);
        throw error;
      }
    },

    /**
     * Analyze MIDI files by IDs
     * Backend: daw/src-tauri/src/commands/pipeline.rs:156
     */
    analyzeFiles: async (fileIds: number[]): Promise<AnalysisResults> => {
      try {
        return await invoke('pipeline_analyze_files', { file_ids: fileIds });
      } catch (error) {
        console.error('Failed to analyze files:', error);
        throw error;
      }
    },

    /**
     * Archive MIDI files to ZIP
     * Backend: daw/src-tauri/src/commands/pipeline.rs:254
     */
    archiveFiles: async (fileIds: number[], archivePath: string): Promise<ImportStats> => {
      try {
        return await invoke('pipeline_archive_files', {
          file_ids: fileIds,
          archive_path: archivePath
        });
      } catch (error) {
        console.error('Failed to archive files:', error);
        throw error;
      }
    },

    /**
     * Get current pipeline progress
     * Backend: daw/src-tauri/src/commands/pipeline.rs:356
     */
    getProgress: async (): Promise<PipelineProgress> => {
      try {
        return await invoke('pipeline_get_progress');
      } catch (error) {
        console.error('Failed to get progress:', error);
        throw error;
      }
    },

    /**
     * Cancel current pipeline operation
     * Backend: daw/src-tauri/src/commands/pipeline.rs:362
     */
    cancel: async (): Promise<void> => {
      try {
        await invoke('pipeline_cancel');
      } catch (error) {
        console.error('Failed to cancel pipeline:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // DATABASE COMMANDS (5 total) - Search, Metadata, Add/Remove, Stats
  // Backend: daw/src-tauri/src/commands/database.rs
  // ============================================================================

  database: {
    /**
     * Search database with filters
     * Backend: daw/src-tauri/src/commands/database.rs:48
     */
    search: async (filters: DatabaseFilters): Promise<SearchResults> => {
      try {
        return await invoke('database_search', { filters });
      } catch (error) {
        console.error('Database search failed:', error);
        throw error;
      }
    },

    /**
     * Get file metadata by ID
     * Backend: daw/src-tauri/src/commands/database.rs:131
     */
    getFileMetadata: async (id: number): Promise<MidiFile | null> => {
      try {
        return await invoke('database_get_file_metadata', { id });
      } catch (error) {
        console.error('Get file metadata failed:', error);
        throw error;
      }
    },

    /**
     * Add file to database
     * Backend: daw/src-tauri/src/commands/database.rs:166
     */
    addFile: async (params: FileParams): Promise<number> => {
      try {
        return await invoke('database_add_file', { ...params });
      } catch (error) {
        console.error('Add file failed:', error);
        throw error;
      }
    },

    /**
     * Remove file from database
     * Backend: daw/src-tauri/src/commands/database.rs:201
     */
    removeFile: async (id: number): Promise<void> => {
      try {
        await invoke('database_remove_file', { id });
      } catch (error) {
        console.error('Remove file failed:', error);
        throw error;
      }
    },

    /**
     * Get database statistics
     * Backend: daw/src-tauri/src/commands/database.rs:219
     */
    getStats: async (): Promise<DatabaseStats> => {
      try {
        return await invoke('database_get_stats');
      } catch (error) {
        console.error('Get stats failed:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // WINDOW SYSTEM COMMANDS (33 total) ‚úÖ ALL NEW - COMPLETELY MISSING FROM V1.0
  // ============================================================================

  window: {
    /**
     * Get DAW window state
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    getDawState: async (): Promise<DAWWindowState> => {
      try {
        return await invoke('get_daw_state');
      } catch (error) {
        console.error('Failed to get DAW state:', error);
        throw error;
      }
    },

    /**
     * Reset DAW window state to defaults
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    resetDawState: async (): Promise<void> => {
      try {
        await invoke('reset_daw_state');
      } catch (error) {
        console.error('Failed to reset DAW state:', error);
        throw error;
      }
    },

    /**
     * Start transport playback
     * Backend: daw/src-tauri/src/commands/window.rs:44
     */
    playTransport: async (): Promise<void> => {
      try {
        await invoke('play_transport');
      } catch (error) {
        console.error('Failed to play transport:', error);
        throw error;
      }
    },

    /**
     * Stop transport and reset position
     * Backend: daw/src-tauri/src/commands/window.rs:52
     */
    stopTransport: async (): Promise<void> => {
      try {
        await invoke('stop_transport');
      } catch (error) {
        console.error('Failed to stop transport:', error);
        throw error;
      }
    },

    /**
     * Pause transport at current position
     * Backend: daw/src-tauri/src/commands/window.rs:61
     */
    pauseTransport: async (): Promise<void> => {
      try {
        await invoke('pause_transport');
      } catch (error) {
        console.error('Failed to pause transport:', error);
        throw error;
      }
    },

    /**
     * Set playback position
     * Backend: daw/src-tauri/src/commands/window.rs:72
     */
    setPlaybackPosition: async (bar: number, beat: number, tick: number): Promise<void> => {
      try {
        await invoke('set_playback_position', { bar, beat, tick });
      } catch (error) {
        console.error('Failed to set playback position:', error);
        throw error;
      }
    },

    /**
     * Get playback state
     * Backend: daw/src-tauri/src/commands/window.rs:94
     */
    getPlaybackState: async (): Promise<PlaybackState> => {
      try {
        return await invoke('get_playback_state');
      } catch (error) {
        console.error('Failed to get playback state:', error);
        throw error;
      }
    },

    /**
     * Set BPM
     * Backend: daw/src-tauri/src/commands/window.rs:107
     */
    setBpm: async (bpm: number): Promise<void> => {
      try {
        await invoke('set_bpm', { bpm });
      } catch (error) {
        console.error('Failed to set BPM:', error);
        throw error;
      }
    },

    /**
     * Get BPM
     * Backend: daw/src-tauri/src/commands/window.rs:119
     */
    getBpm: async (): Promise<number> => {
      try {
        return await invoke('get_bpm');
      } catch (error) {
        console.error('Failed to get BPM:', error);
        throw error;
      }
    },

    /**
     * Set time signature
     * Backend: daw/src-tauri/src/commands/window.rs:126
     */
    setTimeSignature: async (numerator: number, denominator: number): Promise<void> => {
      try {
        await invoke('set_time_signature', { numerator, denominator });
      } catch (error) {
        console.error('Failed to set time signature:', error);
        throw error;
      }
    },

    /**
     * Get time signature
     * Backend: daw/src-tauri/src/commands/window.rs:147
     */
    getTimeSignature: async (): Promise<[number, number]> => {
      try {
        return await invoke('get_time_signature');
      } catch (error) {
        console.error('Failed to get time signature:', error);
        throw error;
      }
    },

    /**
     * Set key signature
     * Backend: daw/src-tauri/src/commands/window.rs:157
     */
    setKeySignature: async (key: string): Promise<void> => {
      try {
        await invoke('set_key_signature', { key });
      } catch (error) {
        console.error('Failed to set key signature:', error);
        throw error;
      }
    },

    /**
     * Get key signature
     * Backend: daw/src-tauri/src/commands/window.rs:173
     */
    getKeySignature: async (): Promise<string> => {
      try {
        return await invoke('get_key_signature');
      } catch (error) {
        console.error('Failed to get key signature:', error);
        throw error;
      }
    },

    /**
     * Add new track to window state
     * Backend: daw/src-tauri/src/commands/window.rs:184
     */
    addWindowTrack: async (label: string): Promise<number> => {
      try {
        return await invoke('add_window_track', { label });
      } catch (error) {
        console.error('Failed to add window track:', error);
        throw error;
      }
    },

    /**
     * Remove track from window state
     * Backend: daw/src-tauri/src/commands/window.rs:202
     */
    removeWindowTrack: async (trackId: number): Promise<void> => {
      try {
        await invoke('remove_window_track', { track_id: trackId });
      } catch (error) {
        console.error('Failed to remove window track:', error);
        throw error;
      }
    },

    /**
     * Get all window tracks
     * Backend: daw/src-tauri/src/commands/window.rs:216
     */
    getAllWindowTracks: async (): Promise<TrackInfo[]> => {
      try {
        return await invoke('get_all_window_tracks');
      } catch (error) {
        console.error('Failed to get all window tracks:', error);
        throw error;
      }
    },

    /**
     * Set track visibility
     * Backend: daw/src-tauri/src/commands/window.rs:225
     */
    setTrackVisible: async (trackId: number, visible: boolean): Promise<void> => {
      try {
        await invoke('set_track_visible', { track_id: trackId, visible });
      } catch (error) {
        console.error('Failed to set track visible:', error);
        throw error;
      }
    },

    /**
     * Set track muted state
     * Backend: daw/src-tauri/src/commands/window.rs:240
     */
    setTrackMuted: async (trackId: number, muted: boolean): Promise<void> => {
      try {
        await invoke('set_track_muted', { track_id: trackId, muted });
      } catch (error) {
        console.error('Failed to set track muted:', error);
        throw error;
      }
    },

    /**
     * Set track soloed state
     * Backend: daw/src-tauri/src/commands/window.rs:262
     */
    setTrackSoloed: async (trackId: number, soloed: boolean): Promise<void> => {
      try {
        await invoke('set_track_soloed', { track_id: trackId, soloed });
      } catch (error) {
        console.error('Failed to set track soloed:', error);
        throw error;
      }
    },

    /**
     * Get track info
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    getTrackInfo: async (trackId: number): Promise<TrackInfo> => {
      try {
        return await invoke('get_track_info', { track_id: trackId });
      } catch (error) {
        console.error('Failed to get track info:', error);
        throw error;
      }
    },

    /**
     * Update track label
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    updateTrackLabel: async (trackId: number, label: string): Promise<void> => {
      try {
        await invoke('update_track_label', { track_id: trackId, label });
      } catch (error) {
        console.error('Failed to update track label:', error);
        throw error;
      }
    },

    /**
     * Set loop enabled
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setLoopEnabled: async (enabled: boolean): Promise<void> => {
      try {
        await invoke('set_loop_enabled', { enabled });
      } catch (error) {
        console.error('Failed to set loop enabled:', error);
        throw error;
      }
    },

    /**
     * Set loop range (start/end in ticks)
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setLoopRange: async (start: number, end: number): Promise<void> => {
      try {
        await invoke('set_loop_range', { start, end });
      } catch (error) {
        console.error('Failed to set loop range:', error);
        throw error;
      }
    },

    /**
     * Set metronome enabled
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setMetronomeEnabled: async (enabled: boolean): Promise<void> => {
      try {
        await invoke('set_metronome_enabled', { enabled });
      } catch (error) {
        console.error('Failed to set metronome enabled:', error);
        throw error;
      }
    },

    /**
     * Set metronome volume (0.0-1.0)
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setMetronomeVolume: async (volume: number): Promise<void> => {
      try {
        await invoke('set_metronome_volume', { volume });
      } catch (error) {
        console.error('Failed to set metronome volume:', error);
        throw error;
      }
    },

    /**
     * Get transport info
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    getTransportInfo: async (): Promise<TransportInfo> => {
      try {
        return await invoke('get_transport_info');
      } catch (error) {
        console.error('Failed to get transport info:', error);
        throw error;
      }
    },

    /**
     * Get mixer state
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    getMixerState: async (): Promise<MixerState> => {
      try {
        return await invoke('get_mixer_state');
      } catch (error) {
        console.error('Failed to get mixer state:', error);
        throw error;
      }
    },

    /**
     * Set channel volume
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setChannelVolume: async (trackId: number, volume: number): Promise<void> => {
      try {
        await invoke('set_channel_volume', { track_id: trackId, volume });
      } catch (error) {
        console.error('Failed to set channel volume:', error);
        throw error;
      }
    },

    /**
     * Set channel pan
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setChannelPan: async (trackId: number, pan: number): Promise<void> => {
      try {
        await invoke('set_channel_pan', { track_id: trackId, pan });
      } catch (error) {
        console.error('Failed to set channel pan:', error);
        throw error;
      }
    },

    /**
     * Set channel mute
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setChannelMute: async (trackId: number, muted: boolean): Promise<void> => {
      try {
        await invoke('set_channel_mute', { track_id: trackId, muted });
      } catch (error) {
        console.error('Failed to set channel mute:', error);
        throw error;
      }
    },

    /**
     * Set channel solo
     * Backend: daw/src-tauri/src/commands/window.rs
     */
    setChannelSolo: async (trackId: number, soloed: boolean): Promise<void> => {
      try {
        await invoke('set_channel_solo', { track_id: trackId, soloed });
      } catch (error) {
        console.error('Failed to set channel solo:', error);
        throw error;
      }
    },
  },

  // ============================================================================
  // AUTOMATION COMMANDS (12 total) ‚úÖ ALL NEW - COMPLETELY MISSING FROM V1.0
  // ============================================================================

  automation: {
    /**
     * Create automation lane
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    createLane: async (trackId: number, parameterType: ParameterType): Promise<number> => {
      try {
        return await invoke('create_automation_lane', { track_id: trackId, parameter_type: parameterType });
      } catch (error) {
        console.error('Failed to create automation lane:', error);
        throw error;
      }
    },

    /**
     * Delete automation lane
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    deleteLane: async (laneId: number): Promise<void> => {
      try {
        await invoke('delete_automation_lane', { lane_id: laneId });
      } catch (error) {
        console.error('Failed to delete automation lane:', error);
        throw error;
      }
    },

    /**
     * Get all automation lanes for track
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    getAllLanes: async (trackId: number): Promise<AutomationLane[]> => {
      try {
        return await invoke('get_all_automation_lanes', { track_id: trackId });
      } catch (error) {
        console.error('Failed to get all automation lanes:', error);
        throw error;
      }
    },

    /**
     * Add automation point
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    addPoint: async (laneId: number, tick: number, value: number): Promise<number> => {
      try {
        return await invoke('add_automation_point', { lane_id: laneId, tick, value });
      } catch (error) {
        console.error('Failed to add automation point:', error);
        throw error;
      }
    },

    /**
     * Update automation point
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    updatePoint: async (pointId: number, tick: number, value: number): Promise<void> => {
      try {
        await invoke('update_automation_point', { point_id: pointId, tick, value });
      } catch (error) {
        console.error('Failed to update automation point:', error);
        throw error;
      }
    },

    /**
     * Delete automation point
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    deletePoint: async (pointId: number): Promise<void> => {
      try {
        await invoke('delete_automation_point', { point_id: pointId });
      } catch (error) {
        console.error('Failed to delete automation point:', error);
        throw error;
      }
    },

    /**
     * Get automation points in range
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    getPointsInRange: async (laneId: number, startTick: number, endTick: number): Promise<AutomationPoint[]> => {
      try {
        return await invoke('get_automation_points_in_range', { lane_id: laneId, start_tick: startTick, end_tick: endTick });
      } catch (error) {
        console.error('Failed to get automation points in range:', error);
        throw error;
      }
    },

    /**
     * Set curve type for automation lane
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    setCurveType: async (laneId: number, curveType: CurveType): Promise<void> => {
      try {
        await invoke('set_automation_curve_type', { lane_id: laneId, curve_type: curveType });
      } catch (error) {
        console.error('Failed to set automation curve type:', error);
        throw error;
      }
    },

    /**
     * Scale automation values
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    scaleValues: async (laneId: number, factor: number): Promise<void> => {
      try {
        await invoke('scale_automation_values', { lane_id: laneId, factor });
      } catch (error) {
        console.error('Failed to scale automation values:', error);
        throw error;
      }
    },

    /**
     * Offset automation values
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    offsetValues: async (laneId: number, offset: number): Promise<void> => {
      try {
        await invoke('offset_automation_values', { lane_id: laneId, offset });
      } catch (error) {
        console.error('Failed to offset automation values:', error);
        throw error;
      }
    },

    /**
     * Smooth automation values
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    smoothValues: async (laneId: number, windowSize: number): Promise<void> => {
      try {
        await invoke('smooth_automation_values', { lane_id: laneId, window_size: windowSize });
      } catch (error) {
        console.error('Failed to smooth automation values:', error);
        throw error;
      }
    },

    /**
     * Clear automation range
     * Backend: daw/src-tauri/src/commands/automation.rs
     */
    clearRange: async (laneId: number, startTick: number, endTick: number): Promise<void> => {
      try {
        await invoke('clear_automation_range', { lane_id: laneId, start_tick: startTick, end_tick: endTick });
      } catch (error) {
        console.error('Failed to clear automation range:', error);
        throw error;
      }
    },
  },
};
```

### `archive_import.rs` {#archive-import-rs}

- **Lines**: 248 (code: 222, comments: 0, blank: 26)

#### Source Code

```rust
use crate::commands::file_import::import_directory;
use crate::io::decompressor::extractor::{extract_archive, ExtractionConfig};
/// Archive Collection Import Command
///
/// Processes entire collections of nested archives, extracting and importing
/// all MIDI files with automatic tagging.
///
/// # Archetype: Grown-up Script (Tauri Command Wrapper)
/// - Thin wrapper around core functionality
/// - Coordinates decompressor + file import modules
/// - Provides progress feedback to UI
use crate::AppState;
use serde::{Deserialize, Serialize};
use std::path::Path;
use tauri::{Emitter, State, Window};

/// Helper function to cleanup temp directories with proper error logging
fn cleanup_temp_dir(path: &Path) {
    if let Err(e) = std::fs::remove_dir_all(path) {
        eprintln!("WARNING: Failed to cleanup temp directory {}: {}", path.display(), e);
        eprintln!("  This may lead to disk space accumulation - manual cleanup may be required");
    }
}

/// Summary of archive collection import
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchiveImportSummary {
    pub total_archives: usize,
    pub total_files_imported: usize,
    pub total_files_skipped: usize,
    pub total_errors: usize,
    pub duration_secs: f64,
    pub archives_processed: Vec<ArchiveStatus>,
}

/// Status of individual archive processing
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchiveStatus {
    pub archive_name: String,
    pub midi_files_found: usize,
    pub files_imported: usize,
    pub success: bool,
    pub error_message: Option<String>,
}

/// Import entire collection of archives (recursively extracts and imports all MIDI files)
///
/// # Arguments
/// * `collection_path` - Directory containing zip archives
/// * `state` - Application state
/// * `window` - Tauri window for progress events
///
/// # Frontend Usage
/// ```typescript
/// await invoke('import_archive_collection', {
///   collectionPath: '/home/user/midi-collection/'
/// });
/// ```
#[tauri::command]
pub async fn import_archive_collection(
    collection_path: String,
    state: State<'_, AppState>,
    window: Window,
) -> Result<ArchiveImportSummary, String> {
    let start_time = std::time::Instant::now();
    let collection_dir = Path::new(&collection_path);

    if !collection_dir.exists() {
        return Err(format!(
            "Collection directory not found: {}",
            collection_path
        ));
    }

    if !collection_dir.is_dir() {
        return Err(format!("Path is not a directory: {}", collection_path));
    }

    println!(
        "\nüöÄ Starting archive collection import from: {}",
        collection_path
    );
    println!("üì¶ Scanning for zip archives...\n");

    // Scan for zip files
    let archives: Vec<_> = std::fs::read_dir(collection_dir)
        .map_err(|e| format!("Failed to read directory: {}", e))?
        .filter_map(|entry| entry.ok())
        .filter(|entry| {
            entry
                .path()
                .extension()
                .and_then(|ext| ext.to_str())
                .map(|ext| ext.eq_ignore_ascii_case("zip"))
                .unwrap_or(false)
        })
        .collect();

    let total_archives = archives.len();
    println!("‚úÖ Found {} archives to process\n", total_archives);

    let mut archive_statuses = Vec::new();
    let mut total_files_imported = 0;
    let mut total_files_skipped = 0;
    let mut total_errors = 0;

    // Process each archive
    for (index, entry) in archives.iter().enumerate() {
        let archive_path = entry.path();
        let archive_name = archive_path
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");
        println!(
            "üì¶ [{}/{}] Processing: {}",
            index + 1,
            total_archives,
            archive_name
        );
        println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

        // Emit progress event
        let _ = window.emit(
            "archive-progress",
            serde_json::json!({
                "current": index + 1,
                "total": total_archives,
                "archive_name": archive_name
            }),
        );

        // Process this archive
        let status =
            process_single_archive(&archive_path, &archive_name, state.clone(), window.clone())
                .await;

        match &status {
            Ok(s) => {
                total_files_imported += s.files_imported;
                total_files_skipped += s.midi_files_found.saturating_sub(s.files_imported);
                println!(
                    "‚úÖ Success: {} MIDIs found, {} imported\n",
                    s.midi_files_found, s.files_imported
                );
            },
            Err(e) => {
                total_errors += 1;
                println!("‚ùå Error: {}\n", e);
            },
        }

        archive_statuses.push(status.unwrap_or_else(|e| ArchiveStatus {
            archive_name: archive_name.clone(),
            midi_files_found: 0,
            files_imported: 0,
            success: false,
            error_message: Some(e),
        }));
    }

    let duration = start_time.elapsed();
    let duration_secs = duration.as_secs_f64();

    println!("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
    println!("‚ïë      ARCHIVE COLLECTION IMPORT COMPLETE      ‚ïë");
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë Archives Processed: {:>28} ‚ïë", total_archives);
    println!("‚ïë Files Imported:     {:>28} ‚ïë", total_files_imported);
    println!("‚ïë Files Skipped:      {:>28} ‚ïë", total_files_skipped);
    println!("‚ïë Errors:             {:>28} ‚ïë", total_errors);
    println!("‚ïë Duration:           {:>25.1}s ‚ïë", duration_secs);
    println!(
        "‚ïë Rate:               {:>23.0} f/s ‚ïë",
        total_files_imported as f64 / duration_secs
    );
    println!("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");

    Ok(ArchiveImportSummary {
        total_archives,
        total_files_imported,
        total_files_skipped,
        total_errors,
        duration_secs,
        archives_processed: archive_statuses,
    })
}

/// Process a single archive file
async fn process_single_archive(
    archive_path: &Path,
    archive_name: &str,
    state: State<'_, AppState>,
    window: Window,
) -> Result<ArchiveStatus, String> {
    // Create temporary extraction directory
    let temp_dir = std::env::temp_dir().join(format!("midi_extract_{}", uuid::Uuid::new_v4()));
    std::fs::create_dir_all(&temp_dir)
        .map_err(|e| format!("Failed to create temp directory: {}", e))?;

    // Extract with recursive decompression
    println!("   üìÇ Extracting (recursive, max depth 10)...");
    let config = ExtractionConfig::default(); // Uses max_depth: 10
    let extract_result = extract_archive(archive_path, &temp_dir, &config)
        .map_err(|e| format!("Extraction failed: {}", e))?;

    let midi_count = extract_result.midi_files.len();
    println!("   üéµ Found {} MIDI files", midi_count);

    if midi_count == 0 {
        // Cleanup and return
        cleanup_temp_dir(&temp_dir);
        return Ok(ArchiveStatus {
            archive_name: archive_name.to_string(),
            midi_files_found: 0,
            files_imported: 0,
            success: true,
            error_message: None,
        });
    }

    // Import extracted files using existing import_directory command
    println!("   üíæ Importing to database with auto-tagging...");
    let import_result = import_directory(
        temp_dir.to_string_lossy().to_string(),
        true,                                                    // recursive
        Some(archive_name.trim_end_matches(".zip").to_string()), // category from archive name
        state.clone(),
        window.clone(),
    )
    .await;

    // Cleanup temp directory
    cleanup_temp_dir(&temp_dir);

    match import_result {
        Ok(summary) => Ok(ArchiveStatus {
            archive_name: archive_name.to_string(),
            midi_files_found: midi_count,
            files_imported: summary.imported,
            success: true,
            error_message: None,
        }),
        Err(e) => Err(format!("Import failed: {}", e)),
    }
}

```

### `automation.rs` {#automation-rs}

- **Lines**: 495 (code: 416, comments: 0, blank: 79)

#### Source Code

```rust
/// Automation commands for Tauri frontend
///
/// Grown-up Script: Tauri commands with side effects for automation management.
use crate::automation::{AutomationLane, AutomationManager, CurveType, ParameterType};
use std::sync::Mutex;
use tauri::State;

/// Global automation manager state
pub struct AutomationState {
    manager: Mutex<AutomationManager>,
}

impl AutomationState {
    pub fn new() -> Self {
        Self { manager: Mutex::new(AutomationManager::new()) }
    }
}

impl Default for AutomationState {
    fn default() -> Self {
        Self::new()
    }
}

/// Create automation lane
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter to automate
///
/// # Returns
/// Lane ID, or error message
#[tauri::command]
pub fn create_automation_lane(
    track_id: i32,
    parameter_type: ParameterType,
    state: State<'_, AutomationState>,
) -> Result<i32, String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.create_lane(track_id, parameter_type)
}

/// Delete automation lane
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn delete_automation_lane(
    track_id: i32,
    parameter_type: ParameterType,
    state: State<'_, AutomationState>,
) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.delete_lane(track_id, parameter_type)
}

/// Add automation point
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
/// * `time` - Time in ticks
/// * `value` - Normalized value (0.0-1.0)
///
/// # Returns
/// Point ID, or error message
#[tauri::command]
pub fn add_automation_point(
    track_id: i32,
    parameter_type: ParameterType,
    time: u64,
    value: f64,
    state: State<'_, AutomationState>,
) -> Result<i32, String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.add_point(track_id, parameter_type, time, value)
}

/// Remove automation point
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
/// * `point_id` - Point ID to remove
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn remove_automation_point(
    track_id: i32,
    parameter_type: ParameterType,
    point_id: i32,
    state: State<'_, AutomationState>,
) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.remove_point(track_id, parameter_type, point_id)
}

/// Move automation point
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
/// * `point_id` - Point ID to move
/// * `new_time` - New time position
/// * `new_value` - New normalized value
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn move_automation_point(
    track_id: i32,
    parameter_type: ParameterType,
    point_id: i32,
    new_time: u64,
    new_value: f64,
    state: State<'_, AutomationState>,
) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.move_point(track_id, parameter_type, point_id, new_time, new_value)
}

/// Set automation curve type
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
/// * `curve_type` - New curve type
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn set_automation_curve_type(
    track_id: i32,
    parameter_type: ParameterType,
    curve_type: CurveType,
    state: State<'_, AutomationState>,
) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.set_curve_type(track_id, parameter_type, curve_type)
}

/// Get automation lane
///
/// # Arguments
/// * `track_id` - Parent track ID
/// * `parameter_type` - Parameter type
///
/// # Returns
/// Automation lane, or error message
#[tauri::command]
pub fn get_automation_lane(
    track_id: i32,
    parameter_type: ParameterType,
    state: State<'_, AutomationState>,
) -> Result<AutomationLane, String> {
    let manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.get_lane(track_id, parameter_type)
}

/// Get all automation lanes for track
///
/// # Arguments
/// * `track_id` - Track ID
///
/// # Returns
/// Vector of all lanes for track
#[tauri::command]
pub fn get_track_automation(
    track_id: i32,
    state: State<'_, AutomationState>,
) -> Result<Vec<AutomationLane>, String> {
    let manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    Ok(manager.get_track_lanes(track_id))
}

/// Get automation value at specific time
///
/// # Arguments
/// * `track_id` - Track ID
/// * `parameter_type` - Parameter type
/// * `time` - Time in ticks
///
/// # Returns
/// Interpolated value, or None if no automation
#[tauri::command]
pub fn get_automation_value(
    track_id: i32,
    parameter_type: ParameterType,
    time: u64,
    state: State<'_, AutomationState>,
) -> Result<Option<f64>, String> {
    let manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    Ok(manager.get_value_at(track_id, parameter_type, time))
}

/// Clear all automation for track
///
/// # Arguments
/// * `track_id` - Track ID
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn clear_track_automation(
    track_id: i32,
    state: State<'_, AutomationState>,
) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.remove_track(track_id);
    Ok(())
}

/// Clear all automation
///
/// # Returns
/// Ok or error message
#[tauri::command]
pub fn clear_all_automation(state: State<'_, AutomationState>) -> Result<(), String> {
    let mut manager = state.manager.lock().map_err(|e| format!("Failed to lock manager: {}", e))?;

    manager.clear_all();
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::automation::AutomationManager;

    // Test the automation manager directly (not Tauri commands)
    #[test]
    fn test_create_automation_lane() {
        let mut manager = AutomationManager::new();
        let result = manager.create_lane(1, ParameterType::Volume);
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), 1);
    }

    #[test]
    fn test_create_duplicate_lane_fails() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.create_lane(1, ParameterType::Volume);
        assert!(result.is_err());
    }

    #[test]
    fn test_delete_automation_lane() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.delete_lane(1, ParameterType::Volume);
        assert!(result.is_ok());
    }

    #[test]
    fn test_delete_nonexistent_lane_fails() {
        let mut manager = AutomationManager::new();
        let result = manager.delete_lane(1, ParameterType::Volume);
        assert!(result.is_err());
    }

    #[test]
    fn test_add_automation_point() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.add_point(1, ParameterType::Volume, 100, 0.5);
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), 1);
    }

    #[test]
    fn test_add_point_to_nonexistent_lane_fails() {
        let mut manager = AutomationManager::new();
        let result = manager.add_point(1, ParameterType::Volume, 100, 0.5);
        assert!(result.is_err());
    }

    #[test]
    fn test_remove_automation_point() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        let point_id = manager.add_point(1, ParameterType::Volume, 100, 0.5).unwrap();

        let result = manager.remove_point(1, ParameterType::Volume, point_id);
        assert!(result.is_ok());
    }

    #[test]
    fn test_remove_nonexistent_point_fails() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.remove_point(1, ParameterType::Volume, 999);
        assert!(result.is_err());
    }

    #[test]
    fn test_move_automation_point() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        let point_id = manager.add_point(1, ParameterType::Volume, 100, 0.5).unwrap();

        let result = manager.move_point(1, ParameterType::Volume, point_id, 200, 0.7);
        assert!(result.is_ok());
    }

    #[test]
    fn test_move_point_clamps_value() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        let point_id = manager.add_point(1, ParameterType::Volume, 100, 0.5).unwrap();

        // Try to move to out-of-range value
        let result = manager.move_point(1, ParameterType::Volume, point_id, 200, 2.0);
        assert!(result.is_ok());

        // Verify value was clamped
        let value = manager.get_value_at(1, ParameterType::Volume, 200);
        assert_eq!(value, Some(1.0));
    }

    #[test]
    fn test_set_automation_curve_type() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.set_curve_type(1, ParameterType::Volume, CurveType::Bezier);
        assert!(result.is_ok());
    }

    #[test]
    fn test_get_automation_lane() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let result = manager.get_lane(1, ParameterType::Volume);
        assert!(result.is_ok());
        let lane = result.unwrap();
        assert_eq!(lane.track_id, 1);
        assert_eq!(lane.parameter_type, ParameterType::Volume);
    }

    #[test]
    fn test_get_nonexistent_lane_fails() {
        let manager = AutomationManager::new();
        let result = manager.get_lane(1, ParameterType::Volume);
        assert!(result.is_err());
    }

    #[test]
    fn test_get_track_automation() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.create_lane(1, ParameterType::Pan).unwrap();

        let lanes = manager.get_track_lanes(1);
        assert_eq!(lanes.len(), 2);
    }

    #[test]
    fn test_get_track_automation_empty() {
        let manager = AutomationManager::new();
        let lanes = manager.get_track_lanes(999);
        assert_eq!(lanes.len(), 0);
    }

    #[test]
    fn test_get_automation_value() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.add_point(1, ParameterType::Volume, 100, 0.5).unwrap();

        let value = manager.get_value_at(1, ParameterType::Volume, 100);
        assert_eq!(value, Some(0.5));
    }

    #[test]
    fn test_get_automation_value_interpolated() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.add_point(1, ParameterType::Volume, 0, 0.0).unwrap();
        manager.add_point(1, ParameterType::Volume, 100, 1.0).unwrap();

        // Midpoint should be ~0.5 for linear interpolation
        let value = manager.get_value_at(1, ParameterType::Volume, 50).unwrap();
        assert!((value - 0.5).abs() < 0.01);
    }

    #[test]
    fn test_get_automation_value_no_points() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        let value = manager.get_value_at(1, ParameterType::Volume, 100);
        assert_eq!(value, None);
    }

    #[test]
    fn test_clear_track_automation() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();

        manager.remove_track(1);

        let lanes = manager.get_track_lanes(1);
        assert_eq!(lanes.len(), 0);
    }

    #[test]
    fn test_clear_all_automation() {
        let mut manager = AutomationManager::new();
        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.create_lane(2, ParameterType::Pan).unwrap();

        manager.clear_all();

        let lanes1 = manager.get_track_lanes(1);
        let lanes2 = manager.get_track_lanes(2);
        assert_eq!(lanes1.len(), 0);
        assert_eq!(lanes2.len(), 0);
    }

    #[test]
    fn test_multiple_tracks() {
        let mut manager = AutomationManager::new();

        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.create_lane(2, ParameterType::Volume).unwrap();

        manager.add_point(1, ParameterType::Volume, 100, 0.3).unwrap();
        manager.add_point(2, ParameterType::Volume, 100, 0.7).unwrap();

        let value1 = manager.get_value_at(1, ParameterType::Volume, 100);
        let value2 = manager.get_value_at(2, ParameterType::Volume, 100);

        assert_eq!(value1, Some(0.3));
        assert_eq!(value2, Some(0.7));
    }

    #[test]
    fn test_multiple_parameter_types() {
        let mut manager = AutomationManager::new();

        manager.create_lane(1, ParameterType::Volume).unwrap();
        manager.create_lane(1, ParameterType::Pan).unwrap();
        manager.create_lane(1, ParameterType::CC(7)).unwrap();

        let lanes = manager.get_track_lanes(1);
        assert_eq!(lanes.len(), 3);
    }

    #[test]
    fn test_workflow_create_add_move_remove() {
        let mut manager = AutomationManager::new();

        // Create lane
        manager.create_lane(1, ParameterType::Volume).unwrap();

        // Add points
        let p1 = manager.add_point(1, ParameterType::Volume, 0, 0.0).unwrap();
        let p2 = manager.add_point(1, ParameterType::Volume, 100, 1.0).unwrap();

        // Move point
        manager.move_point(1, ParameterType::Volume, p1, 50, 0.3).unwrap();

        // Verify value
        let value = manager.get_value_at(1, ParameterType::Volume, 50);
        assert_eq!(value, Some(0.3));

        // Remove point
        manager.remove_point(1, ParameterType::Volume, p2).unwrap();

        // Verify only one point remains
        let lane = manager.get_lane(1, ParameterType::Volume).unwrap();
        assert_eq!(lane.curve.point_count(), 1);
    }
}

```

### `database.rs` {#database-rs}

- **Lines**: 237 (code: 203, comments: 0, blank: 34)

#### Source Code

```rust
use serde::{Deserialize, Serialize};
use tauri::{command, State};
use sqlx::Row;
use chrono::{DateTime, Utc};
use tracing::info;

use crate::commands::AppState;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct MidiFile {
    pub id: i64,
    pub file_path: String,
    pub file_name: String,
    pub bpm: f32,
    pub key_signature: String,
    pub tags: Vec<String>,
    pub duration: f32,
    pub track_count: i32,
    pub file_size: i64,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Debug, Serialize, Deserialize, Default)]
pub struct SearchFilters {
    pub query: Option<String>,
    pub bpm_min: Option<f32>,
    pub bpm_max: Option<f32>,
    pub key: Option<String>,
    pub tag: Option<String>,
    pub limit: Option<i64>,
    pub offset: Option<i64>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct SearchResults {
    pub files: Vec<MidiFile>,
    pub total_count: i64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct DatabaseStats {
    pub total_files: i64,
    pub avg_bpm: f32,
    pub total_size: i64,
}

#[command]
pub async fn database_search(
    state: State<'_, AppState>,
    filters: SearchFilters,
) -> Result<SearchResults, String> {
    let pool = state.db_pool.as_ref().ok_or("Database not available".to_string())?;

    // Build WHERE clause dynamically
    let mut where_clause = String::new();

    if let Some(q) = &filters.query {
        where_clause.push_str(&format!(" AND (file_name ILIKE '%{}%' OR tags::text ILIKE '%{}%')",
            q.replace("'", "''"), q.replace("'", "''")));
    }

    if let Some(min) = filters.bpm_min {
        where_clause.push_str(&format!(" AND bpm >= {}", min));
    }

    if let Some(max) = filters.bpm_max {
        where_clause.push_str(&format!(" AND bpm <= {}", max));
    }

    if let Some(k) = &filters.key {
        where_clause.push_str(&format!(" AND key_signature = '{}'", k.replace("'", "''")));
    }

    if let Some(t) = &filters.tag {
        where_clause.push_str(&format!(" AND tags ? '{}'", t.replace("'", "''")));
    }

    let limit = filters.limit.unwrap_or(50);
    let offset = filters.offset.unwrap_or(0);

    // Build count query
    let count_query = format!(
        "SELECT COUNT(*) as count FROM files WHERE 1=1{}",
        where_clause
    );

    // Fetch total count using sqlx::query with Row API
    let count_row = sqlx::query(&count_query)
        .fetch_one(pool)
        .await
        .map_err(|e| format!("Count query failed: {}", e))?;

    let total_count: i64 = count_row.try_get("count")
        .map_err(|e| format!("Failed to extract count: {}", e))?;

    // Build select query
    let select_query = format!(
        "SELECT id, file_path, file_name, bpm, key_signature, tags, duration, track_count, file_size, created_at, updated_at FROM files WHERE 1=1{} ORDER BY id LIMIT {} OFFSET {}",
        where_clause, limit, offset
    );

    // Fetch rows using sqlx::query with Row API and map to tuple
    let rows = sqlx::query(&select_query)
        .fetch_all(pool)
        .await
        .map_err(|e| format!("Search query failed: {}", e))?;

    let files = rows.into_iter()
        .map(|row| {
            let tags_bytes: Vec<u8> = row.try_get("tags").unwrap_or_default();
            MidiFile {
                id: row.try_get("id").unwrap_or(0),
                file_path: row.try_get("file_path").unwrap_or_default(),
                file_name: row.try_get("file_name").unwrap_or_default(),
                bpm: row.try_get("bpm").unwrap_or(120.0),
                key_signature: row.try_get("key_signature").unwrap_or_else(|_| "C Major".to_string()),
                tags: bincode::deserialize(&tags_bytes).unwrap_or_default(),
                duration: row.try_get("duration").unwrap_or(0.0),
                track_count: row.try_get("track_count").unwrap_or(1),
                file_size: row.try_get("file_size").unwrap_or(0),
                created_at: row.try_get("created_at").unwrap_or_else(|_| Utc::now()),
                updated_at: row.try_get("updated_at").unwrap_or_else(|_| Utc::now()),
            }
        })
        .collect();

    Ok(SearchResults { files, total_count })
}

#[command]
pub async fn database_get_file_metadata(
    state: State<'_, AppState>,
    id: i64,
) -> Result<Option<MidiFile>, String> {
    let pool = state.db_pool.as_ref().ok_or("Database not available".to_string())?;

    let row = sqlx::query_as::<_, (i64, String, String, f32, String, Vec<u8>, f32, i32, i64, DateTime<Utc>, DateTime<Utc>)>(
        "SELECT id, file_path, file_name, bpm, key_signature, tags, duration, track_count, file_size, created_at, updated_at FROM files WHERE id = $1"
    )
    .bind(id)
    .fetch_optional(pool)
    .await
    .map_err(|e| format!("Fetch failed: {}", e))?;

    if let Some((id, file_path, file_name, bpm, key_signature, tags_bytes, duration, track_count, file_size, created_at, updated_at)) = row {
        let tags = bincode::deserialize(&tags_bytes).unwrap_or_default();
        Ok(Some(MidiFile {
            id,
            file_path,
            file_name,
            bpm,
            key_signature,
            tags,
            duration,
            track_count,
            file_size,
            created_at,
            updated_at,
        }))
    } else {
        Ok(None)
    }
}

#[command]
pub async fn database_add_file(
    state: State<'_, AppState>,
    file_path: String,
    file_name: String,
    bpm: Option<f32>,
    key_signature: Option<String>,
    tags: Option<Vec<String>>,
    duration: Option<f32>,
    track_count: Option<i32>,
    file_size: Option<i64>,
) -> Result<i64, String> {
    let pool = state.db_pool.as_ref().ok_or("Database not available".to_string())?;

    let tags_bytes = bincode::serialize(&tags.unwrap_or_default()).map_err(|e| format!("Serialize error: {}", e))?;

    let (id,): (i64,) = sqlx::query_as(
        "INSERT INTO files (file_path, file_name, bpm, key_signature, tags, duration, track_count, file_size) VALUES ($1, $2, $3, $4, $5, $6, $7, $8) RETURNING id"
    )
    .bind(file_path)
    .bind(file_name)
    .bind(bpm.unwrap_or(120.0))
    .bind(key_signature.unwrap_or("C Major".to_string()))
    .bind(tags_bytes)
    .bind(duration.unwrap_or(0.0))
    .bind(track_count.unwrap_or(1))
    .bind(file_size.unwrap_or(0))
    .fetch_one(pool)
    .await
    .map_err(|e| format!("Insert failed: {}", e))?;

    info!("Database: Added file ID {}", id);
    Ok(id)
}

#[command]
pub async fn database_remove_file(state: State<'_, AppState>, id: i64) -> Result<(), String> {
    let pool = state.db_pool.as_ref().ok_or("Database not available".to_string())?;

    let result = sqlx::query("DELETE FROM files WHERE id = $1")
        .bind(id)
        .execute(pool)
        .await
        .map_err(|e| format!("Delete failed: {}", e))?;

    if result.rows_affected() > 0 {
        info!("Database: Removed file ID {}", id);
        Ok(())
    } else {
        Err("File not found".to_string())
    }
}

#[command]
pub async fn database_get_stats(state: State<'_, AppState>) -> Result<DatabaseStats, String> {
    let pool = state.db_pool.as_ref().ok_or("Database not available".to_string())?;

    let row = sqlx::query("SELECT COUNT(*) as total_files, AVG(bpm) as avg_bpm, SUM(file_size) as total_size FROM files")
        .fetch_one(pool)
        .await
        .map_err(|e| format!("Stats query failed: {}", e))?;

    let total_files: i64 = row.try_get("total_files").map_err(|_| "Total files column missing".to_string())?;
    let avg_bpm: Option<f32> = row.try_get("avg_bpm").map_err(|_| "Avg BPM column missing".to_string())?;
    let total_size: Option<i64> = row.try_get("total_size").map_err(|_| "Total size column missing".to_string())?;

    Ok(DatabaseStats {
        total_files,
        avg_bpm: avg_bpm.unwrap_or(120.0),
        total_size: total_size.unwrap_or(0),
    })
}
```

### `daw.rs` {#daw-rs}

- **Lines**: 530 (code: 464, comments: 0, blank: 66)

#### Source Code

```rust
use serde::{Deserialize, Serialize};
use tauri::{command, Emitter, State, Window};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::time::interval;
use midly::{Smf, MidiMessage, Timing};
use tracing::info;

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct Track {
    pub id: u32,
    pub name: String,
    pub instrument: String,
    pub color: String,
    pub volume: f32,
    pub pan: f32,
    pub muted: bool,
    pub solo: bool,
    pub clips: Vec<Clip>,
    pub effects: Vec<Effect>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct Clip {
    pub id: u64,
    pub name: String,
    pub start_time: f64,
    pub duration: f64,
    pub file_path: Option<String>,
    pub notes: Vec<MidiNote>,
    pub color: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct MidiNote {
    pub pitch: u8,
    pub velocity: u8,
    pub start_time: f64,
    pub duration: f64,
    pub channel: u8,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct Effect {
    pub id: u32,
    pub name: String,
    pub enabled: bool,
    pub parameters: serde_json::Value,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct TransportState {
    pub playing: bool,
    pub recording: bool,
    pub looping: bool,
    pub loop_start: f64,
    pub loop_end: f64,
    pub position: f64,
    pub bpm: f32,
    pub time_signature: (u8, u8),
    pub metronome_enabled: bool,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct PlaybackInfo {
    pub position: f64,
    pub bar: u32,
    pub beat: u32,
    pub tick: u32,
    pub bpm: f32,
    pub time_signature: (u8, u8),
    pub total_bars: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct TimelineMarker {
    pub position: f64,
    pub name: String,
    pub color: String,
}

#[derive(Debug, Clone)]
pub struct DawState {
    pub transport: Arc<Mutex<TransportState>>,
    pub tracks: Arc<Mutex<Vec<Track>>>,
    pub markers: Arc<Mutex<Vec<TimelineMarker>>>,
    pub current_project: Arc<Mutex<Option<String>>>,
    pub playback_handle: Arc<Mutex<Option<tokio::task::JoinHandle<()>>>>,
}

impl Default for DawState {
    fn default() -> Self {
        Self {
            transport: Arc::new(Mutex::new(TransportState {
                playing: false,
                recording: false,
                looping: false,
                loop_start: 0.0,
                loop_end: 120.0,
                position: 0.0,
                bpm: 120.0,
                time_signature: (4, 4),
                metronome_enabled: true,
            })),
            tracks: Arc::new(Mutex::new(Vec::new())),
            markers: Arc::new(Mutex::new(Vec::new())),
            current_project: Arc::new(Mutex::new(None)),
            playback_handle: Arc::new(Mutex::new(None)),
        }
    }
}

#[command]
pub async fn daw_play(
    state: State<'_, DawState>,
    window: Window,
) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    if transport.playing {
        return Ok(()); // Already playing
    }
    transport.playing = true;

    // Start playback task if not running
    let mut handle_guard = state.playback_handle.lock().unwrap();
    if handle_guard.is_none() {
        let window_clone = window.clone();
        let state_clone = Arc::new(state.inner().clone());
        let task_handle = tokio::spawn(playback_loop(window_clone, state_clone));
        *handle_guard = Some(task_handle);
    }

    let _ = window.emit("daw::playback-started", transport.position);
    info!("DAW: Playback started at position {}", transport.position);
    Ok(())
}

#[command]
pub async fn daw_pause(
    state: State<'_, DawState>,
    window: Window,
) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    if !transport.playing {
        return Ok(()); // Not playing
    }
    transport.playing = false;

    let _ = window.emit("daw::playback-paused", transport.position);
    info!("DAW: Playback paused at position {}", transport.position);
    Ok(())
}

#[command]
pub async fn daw_stop(
    state: State<'_, DawState>,
    window: Window,
) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.playing = false;
    transport.recording = false;
    transport.position = 0.0;

    // Stop playback task
    let mut handle = state.playback_handle.lock().unwrap();
    if let Some(h) = handle.take() {
        h.abort();
    }

    let _ = window.emit("daw::playback-stopped", ());
    info!("DAW: Playback stopped and reset");
    Ok(())
}

#[command]
pub async fn daw_record(state: State<'_, DawState>) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.recording = !transport.recording;
    info!("DAW: Recording {}", if transport.recording { "started" } else { "stopped" });
    Ok(())
}

#[command]
pub async fn daw_set_bpm(state: State<'_, DawState>, bpm: f32) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.bpm = bpm.clamp(30.0, 300.0);
    info!("DAW: BPM set to {}", transport.bpm);
    Ok(())
}

#[command]
pub async fn daw_set_time_signature(
    state: State<'_, DawState>,
    numerator: u8,
    denominator: u8,
) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.time_signature = (numerator, denominator);
    info!("DAW: Time signature set to {}/{}", numerator, denominator);
    Ok(())
}

#[command]
pub async fn daw_set_loop(
    state: State<'_, DawState>,
    start: f64,
    end: f64,
    enabled: bool,
) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.looping = enabled;
    transport.loop_start = start;
    transport.loop_end = end;
    info!("DAW: Loop {} from {} to {}", if enabled { "enabled" } else { "disabled" }, start, end);
    Ok(())
}

#[command]
pub async fn daw_set_metronome(state: State<'_, DawState>, enabled: bool) -> Result<(), String> {
    let mut transport = state.transport.lock().unwrap();
    transport.metronome_enabled = enabled;
    info!("DAW: Metronome {}", if enabled { "enabled" } else { "disabled" });
    Ok(())
}

#[command]
pub async fn daw_get_transport_state(state: State<'_, DawState>) -> Result<TransportState, String> {
    let transport = state.transport.lock().unwrap();
    Ok(transport.clone())
}

#[command]
pub async fn daw_get_playback_info(state: State<'_, DawState>) -> Result<PlaybackInfo, String> {
    let transport = state.transport.lock().unwrap();
    let ticks_per_beat = 480u32;
    let beats_per_bar = transport.time_signature.0 as f64;

    let total_seconds = transport.position;
    let seconds_per_beat = 60.0 / transport.bpm as f64;
    let total_beats = total_seconds / seconds_per_beat;

    let bar = (total_beats / beats_per_bar).floor() as u32;
    let beat = (total_beats % beats_per_bar).floor() as u32;
    let beat_fraction = total_beats.fract();
    let tick = (beat_fraction * ticks_per_beat as f64).floor() as u32;

    Ok(PlaybackInfo {
        position: transport.position,
        bar,
        beat,
        tick,
        bpm: transport.bpm,
        time_signature: transport.time_signature,
        total_bars: 100, // Placeholder
    })
}

#[command]
pub async fn daw_get_tracks(state: State<'_, DawState>) -> Result<Vec<Track>, String> {
    let tracks = state.tracks.lock().unwrap();
    Ok(tracks.clone())
}

#[command]
pub async fn daw_add_track(
    state: State<'_, DawState>,
    name: String,
    instrument: String,
    color: Option<String>,
) -> Result<Track, String> {
    let mut tracks = state.tracks.lock().unwrap();
    let id = tracks.len() as u32 + 1;

    let track = Track {
        id,
        name,
        instrument,
        color: color.unwrap_or_else(|| "#3498db".to_string()),
        ..Default::default()
    };

    tracks.push(track.clone());
    info!("DAW: Added track '{}' ({}) with ID {}", track.name, track.instrument, id);
    Ok(track)
}

#[command]
pub async fn daw_remove_track(state: State<'_, DawState>, track_id: u32) -> Result<(), String> {
    let mut tracks = state.tracks.lock().unwrap();
    let initial_len = tracks.len();
    tracks.retain(|t| t.id != track_id);

    if tracks.len() < initial_len {
        info!("DAW: Removed track ID {}", track_id);
        Ok(())
    } else {
        Err(format!("Track ID {} not found", track_id))
    }
}

#[command]
pub async fn daw_update_track(state: State<'_, DawState>, updated_track: Track) -> Result<(), String> {
    let mut tracks = state.tracks.lock().unwrap();

    if let Some(track) = tracks.iter_mut().find(|t| t.id == updated_track.id) {
        *track = updated_track;
        info!("DAW: Updated track ID {}", track.id);
        Ok(())
    } else {
        Err(format!("Track ID {} not found", updated_track.id))
    }
}

#[command]
pub async fn daw_set_track_mute(state: State<'_, DawState>, track_id: u32, muted: bool) -> Result<(), String> {
    let mut tracks = state.tracks.lock().unwrap();

    if let Some(track) = tracks.iter_mut().find(|t| t.id == track_id) {
        track.muted = muted;
        info!("DAW: {} track ID {}", if muted { "Muted" } else { "Unmuted" }, track_id);
        Ok(())
    } else {
        Err(format!("Track ID {} not found", track_id))
    }
}

#[command]
pub async fn daw_set_track_solo(state: State<'_, DawState>, track_id: u32, solo: bool) -> Result<(), String> {
    let mut tracks = state.tracks.lock().unwrap();

    if let Some(track) = tracks.iter_mut().find(|t| t.id == track_id) {
        track.solo = solo;
        info!("DAW: {} solo for track ID {}", if solo { "Set" } else { "Cleared" }, track_id);
        Ok(())
    } else {
        Err(format!("Track ID {} not found", track_id))
    }
}

#[command]
pub async fn daw_add_clip(
    state: State<'_, DawState>,
    track_id: u32,
    name: String,
    start_time: f64,
    duration: f64,
    file_path: Option<String>,
) -> Result<Clip, String> {
    let mut tracks = state.tracks.lock().unwrap();

    if let Some(track) = tracks.iter_mut().find(|t| t.id == track_id) {
        let clip_id = track.clips.len() as u64 + 1;
        let clip = Clip {
            id: clip_id,
            name,
            start_time,
            duration,
            file_path,
            notes: Vec::new(),
            color: "#e74c3c".to_string(),
        };

        track.clips.push(clip.clone());
        info!("DAW: Added clip '{}' to track ID {} at time {}", clip.name, track_id, start_time);
        Ok(clip)
    } else {
        Err(format!("Track ID {} not found", track_id))
    }
}

#[command]
pub async fn daw_remove_clip(state: State<'_, DawState>, track_id: u32, clip_id: u64) -> Result<(), String> {
    let mut tracks = state.tracks.lock().unwrap();

    if let Some(track) = tracks.iter_mut().find(|t| t.id == track_id) {
        let initial_len = track.clips.len();
        track.clips.retain(|c| c.id != clip_id);

        if track.clips.len() < initial_len {
            info!("DAW: Removed clip ID {} from track ID {}", clip_id, track_id);
            Ok(())
        } else {
            Err(format!("Clip ID {} not found in track ID {}", clip_id, track_id))
        }
    } else {
        Err(format!("Track ID {} not found", track_id))
    }
}

#[command]
pub async fn daw_load_midi_file(_state: State<'_, DawState>, file_path: String) -> Result<Track, String> {
    let bytes = std::fs::read(&file_path).map_err(|e| e.to_string())?;
    let smf = Smf::parse(&bytes).map_err(|e| format!("MIDI parse error: {}", e))?;

    let file_name = std::path::Path::new(&file_path)
        .file_stem()
        .and_then(|s| s.to_str())
        .unwrap_or("Unknown")
        .to_string();

    let mut notes = Vec::new();
    let current_time: f64 = 0.0;

    // Extract ticks per beat from header timing
    let ticks_per_beat = match smf.header.timing {
        Timing::Metrical(ticks) => ticks.as_int() as f64,
        Timing::Timecode(_, _) => 480.0, // Default for timecode format
    };
    let bpm = 120.0; // Default, can be extracted from tempo events

    for track_events in smf.tracks {
        let mut track_time = 0.0;
        for event in track_events {
            // Convert u28 delta to f64 using as_int()
            let delta_ticks = event.delta.as_int() as f64;
            track_time += delta_ticks / ticks_per_beat * (60.0 / bpm);
            if let midly::TrackEventKind::Midi { channel, message } = event.kind {
                match message {
                    MidiMessage::NoteOn { key, vel } if vel > 0 => {
                        notes.push(MidiNote {
                            pitch: key.as_int(),
                            velocity: vel.as_int(),
                            start_time: track_time,
                            duration: 0.5, // Default, can be calculated from note off
                            channel: channel.as_int(),
                        });
                    }
                    _ => {}
                }
            }
        }
    }

    let track = Track {
        id: 0, // To be set on add
        name: file_name.clone(),
        instrument: "MIDI".to_string(),
        color: "#9b59b6".to_string(),
        volume: 0.8,
        pan: 0.0,
        muted: false,
        solo: false,
        clips: vec![Clip {
            id: 1,
            name: file_name,
            start_time: 0.0,
            duration: current_time.max(1.0),
            file_path: Some(file_path),
            notes,
            color: "#9b59b6".to_string(),
        }],
        effects: Vec::new(),
    };

    info!("DAW: Loaded MIDI file with {} notes", track.clips[0].notes.len());
    Ok(track)
}

#[command]
pub async fn daw_get_markers(state: State<'_, DawState>) -> Result<Vec<TimelineMarker>, String> {
    let markers = state.markers.lock().unwrap();
    Ok(markers.clone())
}

#[command]
pub async fn daw_add_marker(
    state: State<'_, DawState>,
    position: f64,
    name: String,
    color: Option<String>,
) -> Result<(), String> {
    let mut markers = state.markers.lock().unwrap();

    let marker = TimelineMarker {
        position,
        name: name.clone(),
        color: color.unwrap_or_else(|| "#f39c12".to_string()),
    };

    markers.push(marker);
    info!("DAW: Added marker '{}' at position {}", name, position);
    Ok(())
}

// Playback loop task
async fn playback_loop(window: Window, state: Arc<DawState>) {
    let mut interval = interval(Duration::from_millis(16)); // ~60 FPS
    let start_instant = Instant::now();

    loop {
        interval.tick().await;

        // Check if playing
        let playing = {
            let transport = state.transport.lock().unwrap();
            transport.playing
        };
        if !playing {
            break;
        }

        // Update position
        let mut transport = state.transport.lock().unwrap();
        let elapsed = start_instant.elapsed().as_secs_f64();
        transport.position = elapsed % transport.loop_end.max(1.0);

        // Handle looping
        if transport.looping && transport.position >= transport.loop_end {
            transport.position = transport.loop_start;
        }

        // Emit position update
        let _ = window.emit("daw::position-updated", transport.position);

        // Metronome
        if transport.metronome_enabled {
            let beats_per_bar = transport.time_signature.0 as f64;
            let seconds_per_beat = 60.0 / transport.bpm as f64;
            let current_beat = (transport.position / seconds_per_beat) % beats_per_bar;

            if current_beat < 0.1 { // New beat
                let _ = window.emit("daw::metronome-click", ());
            }
        }

        drop(transport);
    }

    info!("DAW: Playback loop stopped");
}
```

### `export.rs` {#export-rs}

- **Lines**: 196 (code: 179, comments: 0, blank: 17)

#### Source Code

```rust
/// Export Tauri commands
///
/// Grown-up Script: Handles exporting sequencer projects and MIDI data.
/// Delegates MIDI file generation to Trusty Modules (pure functions).
use crate::core::midi::writer;
use crate::models::midi::{MidiEvent, MidiEventType};
use std::path::PathBuf;
use tracing::{debug, error, info};

/// Export project as MIDI file
///
/// Uses MIDI writer Trusty Module (pure function) to generate MIDI data.
///
/// TODO for full implementation:
/// - Get events from sequencer engine
/// - Merge all tracks into event list
/// - Apply track properties (volume, pan as MIDI CC)
/// - Support tempo map changes
///
/// Current implementation creates a demonstration MIDI file.
#[tauri::command]
pub async fn export_project_midi(output_path: String) -> Result<(), String> {
    debug!("Exporting project to MIDI file: {}", output_path);

    let path = PathBuf::from(&output_path);

    // Validate path
    if let Some(parent) = path.parent() {
        if !parent.exists() {
            return Err(format!(
                "Parent directory does not exist: {}",
                parent.display()
            ));
        }
    }

    // Validate extension
    if path.extension().and_then(|s| s.to_str()) != Some("mid")
        && path.extension().and_then(|s| s.to_str()) != Some("midi")
    {
        return Err("Output file must have .mid or .midi extension".to_string());
    }

    // TODO: Get events from sequencer engine
    // For now, create a simple demonstration pattern
    let events = create_demo_events();

    // Use Trusty Module (pure function) to generate MIDI file
    let midi_data = writer::write_midi_file(&events, 480, 120.0).map_err(|e| {
        error!("Failed to generate MIDI data: {}", e);
        format!("Failed to generate MIDI: {}", e)
    })?;

    // I/O operation (Grown-up Script responsibility)
    std::fs::write(&path, midi_data).map_err(|e| {
        error!("Failed to write MIDI file: {}", e);
        format!("Failed to write file: {}", e)
    })?;

    info!("Exported project to: {}", output_path);
    Ok(())
}

/// Create demonstration MIDI events
///
/// This is a placeholder for integration with the sequencer.
/// A real implementation would:
/// 1. Get all tracks from the sequencer engine
/// 2. Merge events from all enabled tracks
/// 3. Apply track properties (mute, solo, volume, pan)
/// 4. Sort events by timestamp
///
/// Current implementation creates a simple C major arpeggio pattern.
fn create_demo_events() -> Vec<MidiEvent> {
    vec![
        // C major arpeggio (C-E-G-C)
        MidiEvent {
            event_type: MidiEventType::NoteOn,
            tick: 0,
            channel: 0,
            note: Some(60), // C
            velocity: Some(80),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOff,
            tick: 480, // 1 beat later
            channel: 0,
            note: Some(60),
            velocity: Some(0),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOn,
            tick: 480,
            channel: 0,
            note: Some(64), // E
            velocity: Some(80),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOff,
            tick: 960, // 2 beats
            channel: 0,
            note: Some(64),
            velocity: Some(0),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOn,
            tick: 960,
            channel: 0,
            note: Some(67), // G
            velocity: Some(80),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOff,
            tick: 1440, // 3 beats
            channel: 0,
            note: Some(67),
            velocity: Some(0),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOn,
            tick: 1440,
            channel: 0,
            note: Some(72), // C (octave higher)
            velocity: Some(80),
            controller: None,
            value: None,
            program: None,
        },
        MidiEvent {
            event_type: MidiEventType::NoteOff,
            tick: 1920, // 4 beats (1 bar)
            channel: 0,
            note: Some(72),
            velocity: Some(0),
            controller: None,
            value: None,
            program: None,
        },
    ]
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_create_demo_events() {
        let events = create_demo_events();

        // Should create 8 events (4 note on + 4 note off)
        assert_eq!(events.len(), 8);

        // First event should be Note On at tick 0
        assert_eq!(events[0].event_type, MidiEventType::NoteOn);
        assert_eq!(events[0].tick, 0);
        assert_eq!(events[0].note, Some(60)); // Middle C

        // Last event should be Note Off at tick 1920 (1 bar)
        assert_eq!(events[7].event_type, MidiEventType::NoteOff);
        assert_eq!(events[7].tick, 1920);
        assert_eq!(events[7].note, Some(72)); // High C
    }

    #[test]
    fn test_export_uses_trusty_module() {
        // Verify we're using the MIDI writer Trusty Module
        let events = create_demo_events();
        let result = writer::write_midi_file(&events, 480, 120.0);

        assert!(result.is_ok());
        let midi_data = result.unwrap();

        // Verify MIDI header
        assert_eq!(&midi_data[0..4], b"MThd");
        // Verify track chunk
        assert_eq!(&midi_data[14..18], b"MTrk");
    }
}

```

### `file_import.rs` {#file-import-rs}

- **Lines**: 1135 (code: 1000, comments: 0, blank: 135)

#### Source Code

```rust
use crate::core::analysis::auto_tagger::{AutoTagger, Tag};
use crate::core::analysis::bpm_detector::detect_bpm;
use crate::core::analysis::key_detector::detect_key;
use crate::core::analysis::FilenameMetadata;
use crate::core::hash::calculate_file_hash;
use crate::core::performance::concurrency::{
    calculate_optimal_concurrency, detect_system_resources,
};
use crate::database::batch_insert::BatchInserter;
use crate::core::naming::generator::generate_production_filename;
/// File Import Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION
///
/// Architecture: Grown-up Script
/// Purpose: Tauri commands for importing MIDI files with parallel processing
///
/// This module integrates ALL optimizations:
/// - BLAKE3 hashing (7x faster than SHA-256)
/// - Parallel processing with buffer_unordered (40x speedup)
/// - Batch database inserts (10x faster writes)
/// - Dynamic concurrency tuning (optimal for any system)
///
/// Performance Targets:
/// - 1,000 files: < 2 seconds
/// - 10,000 files: ~25 seconds
/// - 3,000,000 files: 1.5-2 hours (400-500 files/sec)
use crate::AppState;
use midi_library_shared::core::midi::parser::parse_midi_file;
use midi_library_shared::core::midi::text_metadata::TextMetadata;

use futures::stream::{self, StreamExt};
use serde::{Deserialize, Serialize};
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use tauri::{Emitter, State, Window};
use tokio::sync::Mutex;

//=============================================================================
// TYPE DEFINITIONS
//=============================================================================

/// Progress event for real-time UI updates
#[derive(Clone, Debug, Deserialize, Serialize)]
pub struct ImportProgress {
    pub current: usize,
    pub total: usize,
    pub current_file: String,
    pub rate: f64, // files per second
}

/// Summary of import operation results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ImportSummary {
    pub total_files: usize,
    pub imported: usize,
    pub skipped: usize,
    pub errors: Vec<String>,
    pub duration_secs: f64,
    pub rate: f64, // files per second
}

/// File metadata returned from database
#[derive(Debug, Clone, Serialize, sqlx::FromRow)]
pub struct FileMetadata {
    pub id: i64,
    pub filename: String,
    pub original_filename: String,
    pub filepath: String,
    #[sqlx(rename = "content_hash_hex")]
    pub content_hash: String, // Hex-encoded for JSON response
    pub file_size_bytes: i64,
    pub bpm: Option<f64>,
    pub key_signature: Option<String>,
}

/// Intermediate structure for batch processing
#[derive(Debug, Clone)]
struct ProcessedFile {
    filename: String,
    original_filename: String,
    filepath: String,
    parent_folder: Option<String>, // Parent directory name (e.g., "bass", "drums")
    content_hash: Vec<u8>,
    file_size_bytes: i64,
    category: Option<String>, // Handled separately via file_categories table
    bpm: Option<f64>,         // numeric(6,2) in DB - from MIDI analysis
    key_signature: Option<String>, // from MIDI analysis
    tags: Vec<Tag>,           // Auto-extracted tags from filename, path, and MIDI content
    // Filename-based metadata (Phase 2 - Auto-Tagger v2.1)
    filename_bpm: Option<f32>,
    filename_key: Option<String>,
    filename_genres: Vec<String>,
    structure_tags: Vec<String>,
    track_number: Option<u32>,
    // Text metadata from MIDI file content
    track_names: Vec<String>,
    copyright: Option<String>,
    instrument_names_text: Vec<String>, // From MIDI text events
    markers: Vec<String>,
    lyrics: Vec<String>,
}

//=============================================================================
// TAURI COMMANDS (Thin Wrappers - Grown-up Script Pattern)
//=============================================================================

/// Import a single MIDI file (implementation for tests and reuse)
pub async fn import_single_file_impl(
    file_path: String,
    category: Option<String>,
    state: &AppState,
) -> Result<FileMetadata, String> {
    let path = Path::new(&file_path);

    if !path.exists() {
        return Err(format!("File not found: {}", file_path));
    }

    if !is_midi_file(path) {
        return Err("Not a MIDI file".to_string());
    }

    // Process the file (calls Trusty Modules)
    let processed = process_single_file(path, category.clone())
        .await
        .map_err(|e| format!("Failed to process file: {}", e))?;

    // Insert to database
    let pool = state.database.pool().await;
    let file_id = insert_single_file(&processed, &pool)
        .await
        .map_err(|e| format!("Failed to insert file: {}", e))?;

    // Retrieve the complete record
    let file = sqlx::query_as::<_, FileMetadata>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.original_filename,
            f.filepath,
            encode(f.content_hash, 'hex') as content_hash_hex,
            f.file_size_bytes,
            m.bpm,
            m.key_signature::text as key_signature
        FROM files f
        LEFT JOIN musical_metadata m ON f.id = m.file_id
        WHERE f.id = $1
        "#,
    )
    .bind(file_id)
    .fetch_one(&pool)
    .await
    .map_err(|e| format!("Failed to retrieve file: {}", e))?;

    Ok(file)
}

/// Import a single MIDI file
///
/// This is a thin wrapper that:
/// 1. Validates the file path
/// 2. Calls process_single_file (the actual logic)
/// 3. Inserts to database and returns the result
#[tauri::command]
pub async fn import_single_file(
    file_path: String,
    category: Option<String>,
    state: State<'_, AppState>,
    window: Window,
) -> Result<FileMetadata, String> {
    let file = import_single_file_impl(file_path, category, &state).await?;

    // Emit progress event
    if let Err(e) = window.emit(
        "import-progress",
        ImportProgress { current: 1, total: 1, current_file: file.filename.clone(), rate: 1.0 },
    ) {
        eprintln!("WARNING: Failed to emit import progress event: {}", e);
        // Note: Don't fail the operation - emit failure shouldn't stop import
    }

    Ok(file)
}

/// Import all MIDI files from a directory (implementation for tests and reuse)
pub async fn import_directory_impl(
    directory_path: String,
    recursive: bool,
    category: Option<String>,
    state: &AppState,
) -> Result<ImportSummary, String> {
    let start_time = std::time::Instant::now();
    let path = Path::new(&directory_path);

    if !path.exists() {
        return Err(format!("Directory not found: {}", directory_path));
    }

    // Collect all MIDI files
    let files = if recursive {
        find_midi_files_recursive(path)
    } else {
        find_midi_files_shallow(path)
    }
    .map_err(|e| format!("Error scanning directory: {}", e))?;

    let total = files.len();

    if total == 0 {
        return Ok(ImportSummary {
            total_files: 0,
            imported: 0,
            skipped: 0,
            errors: vec![],
            duration_secs: 0.0,
            rate: 0.0,
        });
    }

    // OPTIMIZATION 0: Batch deduplication check (skip duplicates before expensive processing)
    println!("üîç Pre-scanning {} files for duplicates...", total);
    let dedup_start = std::time::Instant::now();

    // Calculate hashes for all files in parallel (fast - only hashing, no parsing)
    let hash_concurrency = std::cmp::min(total, 64); // Use up to 64 threads for hashing
    let hash_semaphore = Arc::new(tokio::sync::Semaphore::new(hash_concurrency));
    let file_hash_pairs: Vec<(PathBuf, Option<Vec<u8>>)> = stream::iter(files.clone())
        .map(|file_path| {
            let sem = Arc::clone(&hash_semaphore);
            async move {
                let _permit = sem.acquire().await.ok()?;
                match calculate_file_hash(&file_path) {
                    Ok(hash) => Some((file_path, Some(hash.to_vec()))),
                    Err(_) => Some((file_path, None)),
                }
            }
        })
        .buffer_unordered(hash_concurrency)
        .filter_map(|x| async { x })
        .collect()
        .await;

    // Extract valid hashes and separate error files
    let mut file_to_hash: std::collections::HashMap<PathBuf, Vec<u8>> = std::collections::HashMap::new();
    let mut hash_error_files = Vec::new();

    for (file_path, hash_opt) in file_hash_pairs {
        match hash_opt {
            Some(hash) => {
                file_to_hash.insert(file_path, hash);
            }
            None => {
                hash_error_files.push(file_path);
            }
        }
    }

    // Query database for existing hashes (batch query - single round trip)
    let pool = state.database.pool().await;
    let hashes_to_check: Vec<Vec<u8>> = file_to_hash.values().cloned().collect();

    let existing_hashes: std::collections::HashSet<Vec<u8>> = if !hashes_to_check.is_empty() {
        // Query in chunks of 10000 to avoid parameter limit
        let chunk_size = 10000;
        let mut all_existing = std::collections::HashSet::new();

        for chunk in hashes_to_check.chunks(chunk_size) {
            let existing: Vec<Vec<u8>> = sqlx::query_scalar(
                "SELECT content_hash FROM files WHERE content_hash = ANY($1)"
            )
            .bind(chunk)
            .fetch_all(&pool)
            .await
            .map_err(|e| format!("Database query failed: {}", e))?;

            all_existing.extend(existing);
        }
        all_existing
    } else {
        std::collections::HashSet::new()
    };

    // Filter out files that already exist
    let files_to_process: Vec<PathBuf> = file_to_hash
        .iter()
        .filter(|(_, hash)| !existing_hashes.contains(*hash))
        .map(|(path, _)| path.clone())
        .collect();

    let duplicates_found = total - files_to_process.len() - hash_error_files.len();
    let dedup_elapsed = dedup_start.elapsed().as_secs_f64();

    println!("‚úì Deduplication complete in {:.2}s", dedup_elapsed);
    println!("  Total files: {}", total);
    println!("  Duplicates skipped: {}", duplicates_found);
    println!("  Hash errors: {}", hash_error_files.len());
    println!("  New files to process: {}", files_to_process.len());

    // If no new files to process, return early
    if files_to_process.is_empty() && hash_error_files.is_empty() {
        return Ok(ImportSummary {
            total_files: total,
            imported: 0,
            skipped: duplicates_found,
            errors: vec![],
            duration_secs: dedup_elapsed,
            rate: 0.0,
        });
    }

    // OPTIMIZATION 1: Dynamic concurrency based on system resources
    let resources = detect_system_resources();
    let concurrency_limit = calculate_optimal_concurrency(&resources);

    println!("üöÄ System resources detected:");
    println!("  CPU cores: {}", resources.cpu_cores);
    println!(
        "  Available memory: {:.2} GB",
        resources.available_memory_gb
    );
    println!("  Optimal concurrency: {}", concurrency_limit);

    // Thread-safe counters for parallel processing
    let imported = Arc::new(AtomicUsize::new(0));
    let skipped = Arc::new(AtomicUsize::new(duplicates_found)); // Pre-populate with dedup skips
    let errors = Arc::new(Mutex::new(Vec::new()));
    let current_index = Arc::new(AtomicUsize::new(0));

    // Semaphore to limit concurrency
    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));

    // OPTIMIZATION 2: Batch inserter for database writes
    let batch_inserter = Arc::new(BatchInserter::new(pool.clone(), 1000));
    let processed_files = Arc::new(Mutex::new(Vec::new()));

    let category_clone = category.clone();
    let _total_clone = total;

    // ‚ö° PARALLEL PROCESSING WITH ALL OPTIMIZATIONS (only process new files)
    stream::iter(files_to_process)
        .map(|file_path| {
            // Clone Arc pointers for each concurrent task
            let sem = Arc::clone(&semaphore);
            let category = category_clone.clone();
            let imported = Arc::clone(&imported);
            let skipped = Arc::clone(&skipped);
            let errors = Arc::clone(&errors);
            let current_index = Arc::clone(&current_index);
            let processed_files = Arc::clone(&processed_files);
            let batch_inserter = Arc::clone(&batch_inserter);

            async move {
                // Acquire semaphore permit (blocks if at limit)
                let _permit = match sem.acquire().await {
                    Ok(permit) => permit,
                    Err(e) => {
                        // Semaphore closed - this is a fatal error condition
                        let error_msg = format!("FATAL: Semaphore unavailable during file import: {}", e);
                        eprintln!("ERROR: {}", error_msg);

                        // Track this as an error
                        errors.lock().await.push(error_msg);

                        // Mark file as skipped
                        skipped.fetch_add(1, Ordering::SeqCst);
                        return;
                    }
                };

                let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;

                // Emit progress every 10 files (reduce UI spam)
                // Note: window emission is skipped in _impl version (used by tests)
                // The original Tauri command wrapper will handle emission
                let _elapsed = start_time.elapsed().as_secs_f64();
                let _rate = if _elapsed > 0.0 { current as f64 / _elapsed } else { 0.0 };

                // Progress tracking available for batch processing metrics
                // In the Tauri command wrapper, this would emit an event

                // OPTIMIZATION 3: Process file with BLAKE3 hashing
                match process_single_file(&file_path, category).await {
                    Ok(processed) => {
                        // Add to batch for insertion
                        processed_files.lock().await.push(processed);
                        imported.fetch_add(1, Ordering::SeqCst);

                        // Flush batch if it reaches threshold
                        let mut files = processed_files.lock().await;
                        if files.len() >= 100 {
                            let batch: Vec<ProcessedFile> = files.drain(..).collect();
                            drop(files); // Release lock

                            // Convert ProcessedFile to FileRecord for batch insert
                            let file_records: Vec<crate::database::batch_insert::FileRecord> = batch.iter().map(|f| {
                                crate::database::batch_insert::FileRecord::new(
                                    f.filename.clone(),
                                    f.original_filename.clone(),
                                    f.filepath.clone(),
                                    f.parent_folder.clone(),
                                    hex::encode(&f.content_hash), // Convert bytea to hex string
                                    f.file_size_bytes,
                                    f.category.clone(),
                                )
                            }).collect();

                            // Batch insert with proper error handling
                            if let Err(e) = batch_inserter.insert_files_batch(file_records).await {
                                let error_msg = format!("Batch insert failed: {}", e);
                                eprintln!("ERROR: {}", error_msg);

                                // Record the error
                                errors.lock().await.push(error_msg);

                                // Mark files as skipped (conservative estimate: entire batch failed)
                                skipped.fetch_add(batch.len(), Ordering::SeqCst);
                            }
                        }
                    }
                    Err(e) => {
                        let error_msg = format!("{}: {}", file_path.display(), e);
                        errors.lock().await.push(error_msg);
                        skipped.fetch_add(1, Ordering::SeqCst);
                    }
                }
            }
        })
        .buffer_unordered(concurrency_limit)  // ‚Üê THE MAGIC: Process N files concurrently!
        .collect::<Vec<_>>()
        .await;

    // OPTIMIZATION 4: Flush remaining batch
    let remaining_files = processed_files.lock().await;
    if !remaining_files.is_empty() {
        let batch: Vec<ProcessedFile> = remaining_files.iter().cloned().collect();
        drop(remaining_files); // Release lock before async operation

        // Convert ProcessedFile to FileRecord for batch insert
        let file_records: Vec<crate::database::batch_insert::FileRecord> = batch
            .iter()
            .map(|f| {
                crate::database::batch_insert::FileRecord::new(
                    f.filename.clone(),
                    f.original_filename.clone(),
                    f.filepath.clone(),
                    f.parent_folder.clone(),
                    hex::encode(&f.content_hash), // Convert bytea to hex string
                    f.file_size_bytes,
                    f.category.clone(),
                )
            })
            .collect();

        if let Err(e) = batch_inserter.insert_files_batch(file_records).await {
            errors.lock().await.push(format!("Final batch insert failed: {}", e));
        }
    }

    // Calculate final statistics
    let duration = start_time.elapsed().as_secs_f64();
    let imported_count = imported.load(Ordering::SeqCst);
    let rate = if duration > 0.0 {
        imported_count as f64 / duration
    } else {
        0.0
    };

    // Extract errors before creating summary
    let error_list = errors.lock().await.clone();

    Ok(ImportSummary {
        total_files: total,
        imported: imported_count,
        skipped: skipped.load(Ordering::SeqCst),
        errors: error_list,
        duration_secs: duration,
        rate,
    })
}

/// Import all MIDI files from a directory (HIGH-PERFORMANCE PARALLEL VERSION)
///
/// This implementation integrates ALL optimizations:
/// - Dynamic concurrency based on system resources
/// - BLAKE3 hashing (7x faster)
/// - Batch database inserts (10x faster)
/// - Parallel processing with buffer_unordered
/// - Progress updates throttled (every 10 files)
/// - Semaphore to limit concurrency
#[tauri::command]
pub async fn import_directory(
    directory_path: String,
    recursive: bool,
    category: Option<String>,
    state: State<'_, AppState>,
    _window: Window,
) -> Result<ImportSummary, String> {
    import_directory_impl(directory_path, recursive, category, &state).await
}

//=============================================================================
// CORE LOGIC (Grown-up Script - orchestrates Trusty Modules)
//=============================================================================

/// Process a single MIDI file and prepare for database insertion
///
/// This function orchestrates multiple Trusty Modules:
/// - hash::blake3 (BLAKE3 hashing - 7x faster than SHA-256)
/// - midi::parser (MIDI parsing)
/// - analysis::bpm_detector (tempo detection)
/// - analysis::key_detector (key signature detection)
/// - analysis::auto_tagger (intelligent tag extraction)
/// - naming::generator (filename generation)
async fn process_single_file(
    file_path: &Path,
    category: Option<String>,
) -> Result<ProcessedFile, Box<dyn std::error::Error + Send + Sync>> {
    // 1. Generate BLAKE3 hash for deduplication (7x faster than SHA-256)
    let hash_bytes = calculate_file_hash(file_path)?;
    let content_hash: Vec<u8> = hash_bytes.to_vec(); // Convert [u8; 32] to Vec<u8> for bytea

    // 2. Read file bytes
    let file_bytes = tokio::fs::read(file_path).await?;

    // 3. Parse MIDI file (Trusty Module)
    let midi_file = parse_midi_file(&file_bytes)?;

    // 4. Extract parent folder name
    let parent_folder = file_path
        .parent()
        .and_then(|p| p.file_name())
        .and_then(|n| n.to_str())
        .map(|s| s.to_string());

    // 5. Extract metadata (Trusty Modules)
    let bpm_result = detect_bpm(&midi_file);
    let bpm = if bpm_result.confidence > 0.5 {
        Some(bpm_result.bpm) // Keep as f64 for numeric(6,2)
    } else {
        None
    };

    let key_result = detect_key(&midi_file);
    let key_signature = if key_result.confidence > 0.5 {
        Some(key_result.key.clone())
    } else {
        None
    };

    // 5b. Extract text metadata (track names, copyright, lyrics, markers)
    let text_meta = TextMetadata::extract(&midi_file);

    // 6. Get file info
    let original_filename = file_path
        .file_name()
        .and_then(|n| n.to_str())
        .ok_or("Invalid filename")?
        .to_string();

    let filepath = file_path.to_str().ok_or("Invalid file path")?.to_string();

    // 6b. Generate Production template filename
    // Extract pack name from parent folder
    let pack_name = parent_folder.clone().unwrap_or_else(|| "Unknown".to_string());

    // Extract time signature from MIDI events (default to 4-4 if not found)
    let time_signature = extract_time_signature(&midi_file).unwrap_or_else(|| "4-4".to_string());

    // Clean original filename (remove extension, sanitize)
    let original_name_clean = original_filename
        .trim_end_matches(".mid")
        .trim_end_matches(".MID")
        .to_string();

    // Determine category for filename
    let detected_category = category.clone().unwrap_or_else(|| "MIDI".to_string());

    // Generate standardized Production filename
    // Format: {CATEGORY}_{TIMESIG}_{BPM}BPM_{KEY}_{ID}_{PACK}_{ORIGINAL}.mid
    let filename = generate_production_filename(
        &detected_category,
        bpm.unwrap_or(120.0), // Default BPM if not detected
        &key_signature.clone().unwrap_or_else(|| "C".to_string()), // Default key
        "000000", // Placeholder - database assigns real ID
        &time_signature,
        &pack_name,
        &original_name_clean,
    );

    let file_size_bytes = tokio::fs::metadata(file_path).await?.len() as i64;

    // 7. Extract MIDI instruments for tag extraction
    let midi_instruments = extract_instrument_names(&midi_file);

    // 8. Auto-tag extraction (NEW: intelligently extract tags from filename, path, and MIDI content)
    let auto_tagger =
        AutoTagger::new().map_err(|e| format!("Failed to initialize auto-tagger: {}", e))?;
    let tags = auto_tagger.extract_tags(
        &filepath,
        &filename,
        &midi_instruments,
        bpm,
        key_signature.as_deref(),
        Some(&midi_file), // Pass parsed MidiFile for drum analysis (v2.1 enhancement)
    );

    // Phase 2: Extract filename metadata (Auto-Tagger v2.1)
    let filename_meta = FilenameMetadata::extract_from_filename(&filename);

    Ok(ProcessedFile {
        filename,
        original_filename,
        filepath,
        parent_folder,
        content_hash,
        file_size_bytes,
        category,
        bpm,
        key_signature,
        tags,
        // Filename-based metadata (convert f64 to f32 for database)
        filename_bpm: filename_meta.bpm.map(|v| v as f32),
        filename_key: filename_meta.key,
        filename_genres: filename_meta.genres,
        structure_tags: filename_meta.structure_tags,
        track_number: filename_meta.track_number,
        // Text metadata from MIDI file
        track_names: text_meta.track_names,
        copyright: text_meta.copyright,
        instrument_names_text: text_meta.instrument_names,
        markers: text_meta.markers,
        lyrics: text_meta.lyrics,
    })
}

/// Extract instrument names from MIDI file for tag extraction
fn extract_instrument_names(
    midi: &midi_library_shared::core::midi::types::MidiFile,
) -> Vec<String> {
    use midi_library_shared::core::midi::types::{Event, TextType};

    let mut instruments = Vec::new();

    for track in &midi.tracks {
        for timed_event in &track.events {
            match &timed_event.event {
                // Extract track/instrument names from MIDI text events
                Event::Text { text_type, text } => {
                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {
                        instruments.push(text.clone());
                    }
                },
                // Map MIDI program changes to GM instrument names
                Event::ProgramChange { program, .. } => {
                    if let Some(instrument_name) = program_to_instrument_name(*program) {
                        instruments.push(instrument_name);
                    }
                },
                _ => {},
            }
        }
    }

    instruments
}

/// Extract time signature from MIDI file events
/// Returns format like "4-4" for 4/4 time, or None if not found
fn extract_time_signature(midi: &midi_library_shared::core::midi::types::MidiFile) -> Option<String> {
    use midi_library_shared::core::midi::types::Event;

    // Search all tracks for TimeSignature event
    for track in &midi.tracks {
        for timed_event in &track.events {
            if let Event::TimeSignature { numerator, denominator, .. } = &timed_event.event {
                // Convert denominator from power-of-2 format (e.g., 2 = quarter note = 4)
                let denom_value = 2_u8.pow(*denominator as u32);
                return Some(format!("{}-{}", numerator, denom_value));
            }
        }
    }

    None // No time signature found
}

/// Map MIDI General MIDI program number to instrument name
fn program_to_instrument_name(program: u8) -> Option<String> {
    // General MIDI Level 1 Sound Set
    match program {
        // Piano (0-7)
        0..=7 => Some("Piano".to_string()),
        // Chromatic Percussion (8-15)
        8..=15 => Some("Keys".to_string()),
        // Organ (16-23)
        16..=23 => Some("Organ".to_string()),
        // Guitar (24-31)
        24..=31 => Some("Guitar".to_string()),
        // Bass (32-39)
        32..=39 => Some("Bass".to_string()),
        // Strings (40-47)
        40..=47 => Some("Strings".to_string()),
        // Ensemble (48-55)
        48..=55 => Some("Ensemble".to_string()),
        // Brass (56-63)
        56..=63 => Some("Brass".to_string()),
        // Reed (64-71)
        64..=71 => Some("Woodwind".to_string()),
        // Pipe (72-79)
        72..=79 => Some("Flute".to_string()),
        // Synth Lead (80-87)
        80..=87 => Some("Lead".to_string()),
        // Synth Pad (88-95)
        88..=95 => Some("Pad".to_string()),
        // Synth Effects (96-103)
        96..=103 => Some("FX".to_string()),
        // Ethnic (104-111)
        104..=111 => Some("Ethnic".to_string()),
        // Percussive (112-119)
        112..=119 => Some("Percussion".to_string()),
        // Sound Effects (120-127)
        120..=127 => Some("FX".to_string()),
        _ => None,
    }
}

/// Insert a single file to database (used by single file import)
async fn insert_single_file(
    file: &ProcessedFile,
    pool: &sqlx::PgPool,
) -> Result<i64, Box<dyn std::error::Error + Send + Sync>> {
    // Insert in transaction
    let mut tx = pool.begin().await?;

    // Calculate metadata source for tracking
    let metadata_source = match (&file.bpm, &file.filename_bpm) {
        (Some(_), Some(_)) => "both",
        (Some(_), None) => "analyzed",
        (None, Some(_)) => "filename",
        (None, None) => "none",
    };

    // Insert file with ON CONFLICT to handle duplicates
    let file_id_opt = sqlx::query_scalar::<_, i64>(
        r#"
        INSERT INTO files (
            filename,
            original_filename,
            filepath,
            content_hash,
            file_size_bytes,
            num_tracks,
            filename_bpm,
            filename_key,
            filename_genres,
            structure_tags,
            track_number,
            metadata_source,
            track_names,
            copyright,
            instrument_names_text,
            markers,
            lyrics,
            created_at
        ) VALUES ($1, $2, $3, $4, $5, 1, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, NOW())
        ON CONFLICT (content_hash) DO NOTHING
        RETURNING id
        "#,
    )
    .bind(&file.filename)
    .bind(&file.original_filename)
    .bind(&file.filepath)
    .bind(&file.content_hash)
    .bind(file.file_size_bytes)
    .bind(file.filename_bpm)
    .bind(file.filename_key.as_ref())
    .bind(&file.filename_genres)
    .bind(&file.structure_tags)
    .bind(file.track_number.map(|n| n as i32))
    .bind(metadata_source)
    .bind(&file.track_names)
    .bind(file.copyright.as_ref())
    .bind(&file.instrument_names_text)
    .bind(&file.markers)
    .bind(&file.lyrics)
    .fetch_optional(&mut *tx)
    .await?;

    // If file already exists (conflict), return error
    let file_id: i64 = match file_id_opt {
        Some(id) => id,
        None => {
            tx.rollback().await?;
            return Err("File already exists (duplicate hash)".into());
        },
    };

    // Insert musical metadata if available
    if file.bpm.is_some() || file.key_signature.is_some() {
        sqlx::query(
            r#"
            INSERT INTO musical_metadata (
                file_id,
                bpm,
                key_signature,
                time_signature_numerator,
                time_signature_denominator
            ) VALUES ($1, $2, $3::musical_key, 4, 4)
            ON CONFLICT (file_id) DO UPDATE SET
                bpm = EXCLUDED.bpm,
                key_signature = EXCLUDED.key_signature
            "#,
        )
        .bind(file_id)
        .bind(file.bpm)
        .bind(file.key_signature.as_deref())
        .execute(&mut *tx)
        .await?;
    }

    // Handle category if provided
    if let Some(ref category_name) = file.category {
        // Get or create category
        let category_id = sqlx::query_scalar::<_, i64>(
            r#"
            INSERT INTO categories (name, created_at)
            VALUES ($1, NOW())
            ON CONFLICT (name) DO UPDATE SET name = EXCLUDED.name
            RETURNING id
            "#,
        )
        .bind(category_name)
        .fetch_one(&mut *tx)
        .await?;

        // Link file to category
        sqlx::query(
            r#"
            INSERT INTO file_categories (file_id, category_id)
            VALUES ($1, $2)
            ON CONFLICT DO NOTHING
            "#,
        )
        .bind(file_id)
        .bind(category_id)
        .execute(&mut *tx)
        .await?;
    }

    // Insert auto-generated tags
    if !file.tags.is_empty() {
        // Prepare tag data (name, category)
        let tag_data: Vec<(String, Option<String>)> =
            file.tags.iter().map(|tag| (tag.name.clone(), tag.category.clone())).collect();

        // Create/get tags and insert file_tags associations
        for (name, category) in tag_data {
            // Get or create tag
            let tag_id = sqlx::query_scalar::<_, i32>(
                r#"
                INSERT INTO tags (name, category, usage_count, created_at)
                VALUES ($1, $2, 0, NOW())
                ON CONFLICT (name) DO UPDATE
                SET name = EXCLUDED.name
                RETURNING id
                "#,
            )
            .bind(&name)
            .bind(category.as_deref())
            .fetch_one(&mut *tx)
            .await?;

            // Associate tag with file
            sqlx::query(
                r#"
                INSERT INTO file_tags (file_id, tag_id, added_at, added_by)
                VALUES ($1, $2, NOW(), 'system')
                ON CONFLICT (file_id, tag_id) DO NOTHING
                "#,
            )
            .bind(file_id)
            .bind(tag_id)
            .execute(&mut *tx)
            .await?;
        }
    }

    tx.commit().await?;

    Ok(file_id)
}

//=============================================================================
// HELPER FUNCTIONS
//=============================================================================

/// Recursively collect all MIDI files in a directory
fn find_midi_files_recursive(dir: &Path) -> Result<Vec<PathBuf>, std::io::Error> {
    let mut files = Vec::new();

    for entry in std::fs::read_dir(dir)? {
        let entry = entry?;
        let path = entry.path();

        if path.is_dir() {
            match find_midi_files_recursive(&path) {
                Ok(subfiles) => files.extend(subfiles),
                Err(e) => {
                    eprintln!(
                        "Warning: Failed to read directory {}: {}",
                        path.display(),
                        e
                    );
                    // Continue with other directories
                },
            }
        } else if is_midi_file(&path) {
            files.push(path);
        }
    }

    Ok(files)
}

/// Finds MIDI files in directory (non-recursive)
fn find_midi_files_shallow(dir: &Path) -> Result<Vec<PathBuf>, std::io::Error> {
    let mut files = Vec::new();

    for entry in std::fs::read_dir(dir)? {
        let entry = entry?;
        let path = entry.path();

        if path.is_file() && is_midi_file(&path) {
            files.push(path);
        }
    }

    Ok(files)
}

/// Check if a file is a MIDI file based on extension
fn is_midi_file(path: &Path) -> bool {
    path.extension()
        .and_then(|ext| ext.to_str())
        .map(|ext| ext.eq_ignore_ascii_case("mid") || ext.eq_ignore_ascii_case("midi"))
        .unwrap_or(false)
}

//=============================================================================
// TESTS
//=============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_is_midi_file() {
        assert!(is_midi_file(Path::new("test.mid")));
        assert!(is_midi_file(Path::new("test.MID")));
        assert!(is_midi_file(Path::new("test.midi")));
        assert!(is_midi_file(Path::new("test.MIDI")));
        assert!(!is_midi_file(Path::new("test.txt")));
        assert!(!is_midi_file(Path::new("test")));
    }

    #[test]
    fn test_find_midi_files_shallow() {
        let temp_dir = tempfile::tempdir().unwrap();
        let test_dir = temp_dir.path();

        std::fs::write(test_dir.join("file1.mid"), b"").unwrap();
        std::fs::write(test_dir.join("file2.midi"), b"").unwrap();
        std::fs::write(test_dir.join("file3.txt"), b"").unwrap();

        let files = find_midi_files_shallow(test_dir).unwrap();
        assert_eq!(files.len(), 2);
    }

    #[test]
    fn test_find_midi_files_recursive() {
        let temp_dir = tempfile::tempdir().unwrap();
        let test_dir = temp_dir.path();
        let sub_dir = test_dir.join("subdir");
        std::fs::create_dir(&sub_dir).unwrap();

        std::fs::write(test_dir.join("file1.mid"), b"").unwrap();
        std::fs::write(sub_dir.join("file2.mid"), b"").unwrap();

        let files = find_midi_files_recursive(test_dir).unwrap();
        assert_eq!(files.len(), 2);
    }

    #[tokio::test]
    #[ignore] // Requires specific test MIDI file at /tmp/midi_test_import/Vengeance_Deep_House_Kick_128_C.mid
    async fn test_auto_tagging_import() {
        println!("\nüß™ Starting auto-tagging integration test...");

        // 1. Connect to test database
        let database_url = "postgresql://midiuser:145278963@localhost:5433/midi_library";
        let pool = match sqlx::PgPool::connect(database_url).await {
            Ok(pool) => {
                println!("‚úÖ Connected to database");
                pool
            },
            Err(e) => {
                panic!("‚ùå Failed to connect to database: {:?}", e);
            },
        };

        // 2. Verify test file exists
        let test_file_path =
            std::path::Path::new("/tmp/midi_test_import/Vengeance_Deep_House_Kick_128_C.mid");
        if !test_file_path.exists() {
            panic!("‚ùå Test file not found: {:?}", test_file_path);
        }
        println!("‚úÖ Test file found: {:?}", test_file_path);

        // 3. Process the file (extracts tags)
        println!("üìù Processing file...");
        let processed = match process_single_file(test_file_path, Some("test".to_string())).await {
            Ok(p) => {
                println!("‚úÖ File processed successfully");
                println!("   Filename: {}", p.filename);
                println!("   Tags extracted: {}", p.tags.len());
                for tag in &p.tags {
                    match &tag.category {
                        Some(cat) => println!("     - {}:{}", cat, tag.name),
                        None => println!("     - {}", tag.name),
                    }
                }
                p
            },
            Err(e) => {
                panic!("‚ùå Failed to process file: {:?}", e);
            },
        };

        // 4. Insert into database (including tags)
        println!("üíæ Inserting into database...");
        let file_id = match insert_single_file(&processed, &pool).await {
            Ok(id) => {
                println!("‚úÖ File inserted with ID: {}", id);
                id
            },
            Err(e) => {
                panic!("‚ùå Failed to insert file: {:?}", e);
            },
        };

        // 5. Verify tags were stored in database
        println!("üîç Verifying tags in database...");
        let tags: Vec<(String, Option<String>)> = sqlx::query_as(
            r#"
            SELECT t.name, t.category
            FROM tags t
            JOIN file_tags ft ON t.id = ft.tag_id
            WHERE ft.file_id = $1
            ORDER BY t.category, t.name
            "#,
        )
        .bind(file_id)
        .fetch_all(&pool)
        .await
        .expect("Failed to fetch tags from database");

        println!("‚úÖ Tags found in database: {}", tags.len());
        for (name, category) in &tags {
            match category {
                Some(cat) => println!("     - {}:{}", cat, name),
                None => println!("     - {}", name),
            }
        }

        // 6. Verify expected tags exist
        let tag_names: Vec<String> = tags
            .iter()
            .map(|(name, cat)| match cat {
                Some(c) => format!("{}:{}", c, name),
                None => name.clone(),
            })
            .collect();

        println!("\nüîç Checking for expected tags...");

        // Check for "vengeance" tag (should be brand:vengeance or just vengeance)
        let has_vengeance = tag_names.iter().any(|t| t.to_lowercase().contains("vengeance"));
        assert!(
            has_vengeance,
            "‚ùå Missing 'vengeance' tag. Found tags: {:?}",
            tag_names
        );
        println!("   ‚úÖ Found vengeance tag");

        // Check for "house" tag (should be genre:house or just house)
        let has_house = tag_names.iter().any(|t| t.to_lowercase().contains("house"));
        assert!(
            has_house,
            "‚ùå Missing 'house' tag. Found tags: {:?}",
            tag_names
        );
        println!("   ‚úÖ Found house tag");

        // Check for "kick" tag (should be instrument:kick or category:kick)
        let has_kick = tag_names.iter().any(|t| t.to_lowercase().contains("kick"));
        assert!(
            has_kick,
            "‚ùå Missing 'kick' tag. Found tags: {:?}",
            tag_names
        );
        println!("   ‚úÖ Found kick tag");

        // Check for BPM tag
        let has_bpm = tag_names.iter().any(|t| t.contains("bpm:") || t.contains("128"));
        assert!(has_bpm, "‚ùå Missing BPM tag. Found tags: {:?}", tag_names);
        println!("   ‚úÖ Found BPM tag");

        // Check for key tag
        let has_key = tag_names
            .iter()
            .any(|t| t.to_lowercase().contains("key:") || t.to_lowercase().contains(":c"));
        assert!(has_key, "‚ùå Missing key tag. Found tags: {:?}", tag_names);
        println!("   ‚úÖ Found key tag");

        println!("\n‚úÖ ‚úÖ ‚úÖ ALL AUTO-TAGGING TESTS PASSED! ‚úÖ ‚úÖ ‚úÖ\n");

        // Cleanup: Remove test file from database
        sqlx::query("DELETE FROM files WHERE id = $1")
            .bind(file_id)
            .execute(&pool)
            .await
            .expect("Failed to cleanup test file");
        println!("üßπ Cleaned up test data");
    }
}

```

### `files.rs` {#files-rs}

- **Lines**: 495 (code: 451, comments: 0, blank: 44)

#### Source Code

```rust
// src-tauri/src/commands/files.rs
//
// ARCHETYPE: MANAGER (Grown-up Script)
// PURPOSE: Tauri commands for file operations with database I/O
//
// ‚úÖ CAN: Perform database I/O (queries)
// ‚úÖ CAN: Have side effects (database reads/writes)
// ‚úÖ CAN: Be async
// ‚úÖ SHOULD: Handle errors using AppError
// ‚ùå MUST NOT: Contain complex business logic
// ‚ùå MUST NOT: Have UI concerns
// ‚ùå SHOULD: Delegate complex logic to separate modules

use chrono::{DateTime, Utc};
use serde::Serialize;
use sqlx::FromRow;
use tauri::State;

use crate::AppState;

// =============================================================================
// DATA STRUCTURES
// =============================================================================

/// MIDI file record with musical metadata
///
/// Combined data from files and musical_metadata tables.
/// Used for displaying file information in the UI.
///
/// # Archetype: Trusty Module (data structure)
///
/// This is a pure data container with no behavior.
#[derive(Debug, FromRow, Serialize)]
pub struct MidiFile {
    /// Unique file ID
    pub id: i64,

    /// Display filename (e.g., "my-song.mid")
    pub filename: String,

    /// Full path to file (e.g., "/library/bass/my-song.mid")
    pub filepath: String,

    /// Original filename before processing
    #[serde(rename = "originalFilename")]
    pub original_filename: String,

    /// Primary category (e.g., "BASS", "LEAD")
    pub category: String,

    /// Parent folder name (e.g., "bass", "drums", "leads")
    #[serde(rename = "parentFolder")]
    pub parent_folder: Option<String>,

    /// File size in bytes
    #[serde(rename = "fileSize")]
    pub file_size: i64,

    /// Detected BPM (nullable)
    pub bpm: Option<f64>,

    /// Detected key signature (nullable, e.g., "C", "Am")
    #[serde(rename = "key")]
    pub key_signature: Option<String>,

    /// Duration in seconds (nullable)
    #[serde(rename = "duration")]
    pub duration_seconds: Option<f64>,

    /// Timestamp when file was added to database
    #[serde(rename = "createdAt")]
    pub created_at: DateTime<Utc>,

    /// Timestamp when file was last updated
    #[serde(rename = "updatedAt")]
    pub updated_at: DateTime<Utc>,
}

// =============================================================================
// TAURI COMMANDS - MANAGER ARCHETYPE
// =============================================================================

/// Test database connection
///
/// Verifies that the database is reachable and responds to queries.
///
/// # Manager Archetype
/// - ‚úÖ Performs I/O (database query)
/// - ‚úÖ Has side effects (network call to database)
/// - ‚úÖ Handles errors properly (converts to String)
/// - ‚ùå No complex business logic
///
/// # Returns
///
/// * `Result<bool, String>` - True if connected, error message if failed
///
/// # Frontend Usage
///
/// ```typescript
/// const connected = await invoke<boolean>('test_db_connection');
/// if (connected) {
///   console.log('Database is ready');
/// }
/// ```
#[tauri::command]
pub async fn test_db_connection(state: State<'_, AppState>) -> Result<bool, String> {
    state
        .database
        .test_connection()
        .await
        .map_err(|e| format!("Database connection failed: {}", e))
}

/// Get total count of files in database (implementation for tests and reuse)
///
/// Internal implementation that accepts &AppState for testing without Tauri context.
///
/// # Arguments
/// * `state` - Application state containing database connection
///
/// # Returns
/// * `Result<i64, String>` - Total file count or error message
pub async fn get_file_count_impl(state: &AppState) -> Result<i64, String> {
    let pool = state.database.pool().await;
    let count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM files")
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("Failed to get file count: {}", e))?;

    Ok(count)
}

/// Get total count of files in database
///
/// Returns the number of MIDI files currently stored.
///
/// # Manager Archetype
/// - ‚úÖ Performs I/O (database query)
/// - ‚úÖ Has side effects (reads from database)
/// - ‚úÖ Handles errors properly
/// - ‚ùå No complex business logic
///
/// # Returns
///
/// * `Result<i64, String>` - Total file count or error message
///
/// # Frontend Usage
///
/// ```typescript
/// const count = await invoke<number>('get_file_count');
/// console.log(`Library contains ${count} files`);
/// ```
#[tauri::command]
pub async fn get_file_count(state: State<'_, AppState>) -> Result<i64, String> {
    get_file_count_impl(&state).await
}

/// Get file details by ID (implementation for tests and reuse)
///
/// Internal implementation that accepts &AppState for testing without Tauri context.
pub async fn get_file_details_impl(file_id: i64, state: &AppState) -> Result<MidiFile, String> {
    let pool = state.database.pool().await;
    let file = sqlx::query_as::<_, MidiFile>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.original_filename,
            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,
            f.parent_folder,
            f.file_size_bytes as file_size,
            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,
            f.created_at,
            f.updated_at,
            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,
            mm.key_signature::text as key_signature
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE f.id = $1
        "#,
    )
    .bind(file_id)
    .fetch_optional(&pool)
    .await
    .map_err(|e| format!("Failed to fetch file details: {}", e))?
    .ok_or_else(|| format!("File with ID {} not found", file_id))?;

    Ok(file)
}

/// Get file details by ID
///
/// Retrieves complete information for a single MIDI file.
///
/// # Manager Archetype
/// - ‚úÖ Performs I/O (database query)
/// - ‚úÖ Has side effects (reads from database)
/// - ‚úÖ Handles errors properly (including NotFound)
/// - ‚ùå No complex business logic
///
/// # Arguments
///
/// * `file_id` - Unique file ID to retrieve
///
/// # Returns
///
/// * `Result<MidiFile, String>` - File details or error message
///
/// # Errors
///
/// Returns error if file doesn't exist or query fails.
///
/// # Frontend Usage
///
/// ```typescript
/// const file = await invoke<MidiFile>('get_file_details', { fileId: 123 });
/// console.log(`File: ${file.filename}, BPM: ${file.bpm}`);
/// ```
#[tauri::command]
pub async fn get_file_details(
    file_id: i64,
    state: State<'_, AppState>,
) -> Result<MidiFile, String> {
    get_file_details_impl(file_id, &state).await
}

/// Get file by ID (alias for get_file_details for frontend compatibility)
///
/// # Frontend Usage
///
/// ```typescript
/// const file = await invoke<MidiFile>('get_file', { fileId: 123 });
/// ```
#[tauri::command]
pub async fn get_file(file_id: i64, state: State<'_, AppState>) -> Result<MidiFile, String> {
    get_file_details(file_id, state).await
}

/// List files with pagination (implementation for tests and reuse)
///
/// Internal implementation that accepts &AppState for testing without Tauri context.
pub async fn list_files_impl(
    limit: Option<i64>,
    offset: Option<i64>,
    state: &AppState,
) -> Result<Vec<MidiFile>, String> {
    let limit = limit.unwrap_or(50);
    let offset = offset.unwrap_or(0);

    let pool = state.database.pool().await;
    let files = sqlx::query_as::<_, MidiFile>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.original_filename,
            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,
            f.parent_folder,
            f.file_size_bytes as file_size,
            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,
            f.created_at,
            f.updated_at,
            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,
            mm.key_signature::text as key_signature
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        ORDER BY f.created_at DESC
        LIMIT $1 OFFSET $2
        "#,
    )
    .bind(limit)
    .bind(offset)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("Failed to list files: {}", e))?;

    // Debug logging
    tracing::info!(
        "list_files: Returning {} files, first file parent_folder: {:?}",
        files.len(),
        files.first().map(|f| &f.parent_folder)
    );

    Ok(files)
}

/// List files with pagination
///
/// Returns a paginated list of files ordered by creation date (newest first).
///
/// # Manager Archetype
/// - ‚úÖ Performs I/O (database query)
/// - ‚úÖ Has side effects (reads from database)
/// - ‚úÖ Handles errors properly
///
/// # Arguments
///
/// * `limit` - Maximum number of files to return (default: 50)
/// * `offset` - Number of files to skip (default: 0)
///
/// # Frontend Usage
///
/// ```typescript
/// const files = await invoke<MidiFile[]>('list_files', { limit: 50, offset: 0 });
/// ```
#[tauri::command]
pub async fn list_files(
    limit: Option<i64>,
    offset: Option<i64>,
    state: State<'_, AppState>,
) -> Result<Vec<MidiFile>, String> {
    list_files_impl(limit, offset, &state).await
}

/// Get files by category
///
/// Returns all files in a specific category.
///
/// # Arguments
///
/// * `category` - Category name (e.g., "bass", "drums", "melody")
/// * `limit` - Maximum number of files to return (default: 50)
///
/// # Frontend Usage
///
/// ```typescript
/// const files = await invoke<MidiFile[]>('get_files_by_category', {
///   category: 'bass',
///   limit: 50
/// });
/// ```
#[tauri::command]
pub async fn get_files_by_category(
    category: String,
    limit: Option<i64>,
    state: State<'_, AppState>,
) -> Result<Vec<MidiFile>, String> {
    let limit = limit.unwrap_or(50);

    let pool = state.database.pool().await;
    let files = sqlx::query_as::<_, MidiFile>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.original_filename,
            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,
            f.parent_folder,
            f.file_size_bytes as file_size,
            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,
            f.created_at,
            f.updated_at,
            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,
            mm.key_signature::text as key_signature
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE fc.primary_category::text = $1
        ORDER BY f.created_at DESC
        LIMIT $2
        "#,
    )
    .bind(category)
    .bind(limit)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("Failed to get files by category: {}", e))?;

    Ok(files)
}

/// Get recently added files
///
/// Returns the most recently imported files.
///
/// # Arguments
///
/// * `limit` - Maximum number of files to return (default: 10)
///
/// # Frontend Usage
///
/// ```typescript
/// const files = await invoke<MidiFile[]>('get_recent_files', { limit: 10 });
/// ```
#[tauri::command]
pub async fn get_recent_files(
    limit: Option<i64>,
    state: State<'_, AppState>,
) -> Result<Vec<MidiFile>, String> {
    let limit = limit.unwrap_or(10);

    let pool = state.database.pool().await;
    let files = sqlx::query_as::<_, MidiFile>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            f.original_filename,
            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,
            f.parent_folder,
            f.file_size_bytes as file_size,
            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,
            f.created_at,
            f.updated_at,
            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,
            mm.key_signature::text as key_signature
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        ORDER BY f.created_at DESC
        LIMIT $1
        "#,
    )
    .bind(limit)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("Failed to get recent files: {}", e))?;

    Ok(files)
}

/// Delete a file
///
/// Removes a file from the database (cascading deletes related records).
///
/// # Arguments
///
/// * `file_id` - ID of the file to delete
///
/// # Frontend Usage
///
/// ```typescript
/// await invoke('delete_file', { fileId: 123 });
/// ```
#[tauri::command]
pub async fn delete_file(file_id: i64, state: State<'_, AppState>) -> Result<(), String> {
    let pool = state.database.pool().await;
    sqlx::query("DELETE FROM files WHERE id = $1")
        .bind(file_id)
        .execute(&pool)
        .await
        .map_err(|e| format!("Failed to delete file: {}", e))?;

    Ok(())
}

// Update file tags moved to commands/tags.rs to use TagRepository

// =============================================================================
// TESTS - MANAGER ARCHETYPE TESTING
// =============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    /// Test that MidiFile struct has all required fields
    #[test]
    fn test_midi_file_struct() {
        let now = Utc::now();
        let file = MidiFile {
            id: 1,
            filename: "test.mid".to_string(),
            filepath: "/path/to/test.mid".to_string(),
            original_filename: "original_test.mid".to_string(),
            category: "DRUMS".to_string(),
            parent_folder: Some("drums".to_string()),
            file_size: 1024,
            bpm: Some(120.0),
            key_signature: Some("Cm".to_string()),
            duration_seconds: Some(180.0),
            created_at: now,
            updated_at: now,
        };

        assert_eq!(file.id, 1);
        assert_eq!(file.filename, "test.mid");
        assert_eq!(file.bpm, Some(120.0));
        assert_eq!(file.key_signature, Some("Cm".to_string()));
    }

    // NOTE: Advanced search functionality is in commands/search.rs

    // Integration tests require database connection and Tauri runtime
    // These tests should be run as part of E2E testing, not unit tests
    // For manual testing:
    // 1. Start database: docker-compose up -d
    // 2. Run the Tauri app and test commands from the frontend
}

```

### `midi.rs` {#midi-rs}

- **Lines**: 83 (code: 74, comments: 0, blank: 9)

#### Source Code

```rust
use crate::midi::MidiManager;
use crate::models::MidiDevice;
use std::sync::Arc;
/// MIDI hardware Tauri commands
///
/// Grown-up Scripts: Thin wrappers around MIDI manager for frontend access.
/// Delegate all business logic to Trusty Modules and MIDI manager.
use tauri::State;

/// List all available MIDI output devices
///
/// Returns a list of MIDI output devices found on the system.
#[tauri::command]
pub async fn midi_list_devices(
    midi_manager: State<'_, Arc<MidiManager>>,
) -> Result<Vec<MidiDevice>, String> {
    midi_manager.list_devices()
}

/// Connect to a specific MIDI device by name
///
/// Establishes a connection to the specified MIDI output device.
#[tauri::command]
pub async fn midi_connect(
    device_name: String,
    midi_manager: State<'_, Arc<MidiManager>>,
) -> Result<(), String> {
    midi_manager.connect(&device_name).await
}

/// Disconnect from current MIDI device
///
/// Closes the active MIDI connection if one exists.
#[tauri::command]
pub async fn midi_disconnect(midi_manager: State<'_, Arc<MidiManager>>) -> Result<(), String> {
    midi_manager.disconnect().await;
    Ok(())
}

/// Check if MIDI device is currently connected
///
/// Returns true if a MIDI device is connected, false otherwise.
#[tauri::command]
pub async fn midi_is_connected(midi_manager: State<'_, Arc<MidiManager>>) -> Result<bool, String> {
    Ok(midi_manager.is_connected().await)
}

/// Get current MIDI device info
///
/// Returns information about the currently connected device, if any.
#[tauri::command]
pub async fn midi_get_current_device(
    midi_manager: State<'_, Arc<MidiManager>>,
) -> Result<Option<MidiDevice>, String> {
    if let Some(name) = midi_manager.current_device().await {
        Ok(Some(MidiDevice { name, manufacturer: None }))
    } else {
        Ok(None)
    }
}

/// Send a test note to verify MIDI connection
///
/// Sends a note on/off pair with configurable parameters.
/// The note plays for 500ms.
#[tauri::command]
pub async fn midi_send_test_note(
    channel: u8,
    note: u8,
    velocity: u8,
    midi_manager: State<'_, Arc<MidiManager>>,
) -> Result<(), String> {
    // Send note on
    midi_manager.send_note_on(channel, note, velocity).await?;

    // Wait 500ms
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    // Send note off
    midi_manager.send_note_off(channel, note).await?;

    Ok(())
}

```

### `mixer.rs` {#mixer-rs}

- **Lines**: 355 (code: 308, comments: 0, blank: 47)

#### Source Code

```rust
use serde::{Deserialize, Serialize};
use tauri::{command, Emitter, State, Window};
use std::sync::{Arc, Mutex};
use std::time::Duration;
use tokio::time::interval;
use rand::Rng;

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct MixerChannel {
    pub track_id: u32,
    pub name: String,
    pub volume: f32,
    pub pan: f32,
    pub muted: bool,
    pub solo: bool,
    pub vu_level: (f32, f32),
    pub peak_level: (f32, f32),
    pub effects: Vec<EffectSlot>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct EffectSlot {
    pub id: u32,
    pub name: String,
    pub enabled: bool,
    pub wet_dry: f32,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct MasterChannel {
    pub volume: f32,
    pub vu_level: (f32, f32),
    pub peak_level: (f32, f32),
    pub limiter_enabled: bool,
    pub compressor_enabled: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MeterData {
    pub track_id: u32,
    pub vu_left: f32,
    pub vu_right: f32,
    pub peak_left: f32,
    pub peak_right: f32,
}

#[derive(Debug, Clone)]
pub struct MixerState {
    pub channels: Arc<Mutex<Vec<MixerChannel>>>,
    pub master: Arc<Mutex<MasterChannel>>,
    pub meter_handle: Arc<Mutex<Option<tokio::task::JoinHandle<()>>>>,
}

impl Default for MixerState {
    fn default() -> Self {
        Self {
            channels: Arc::new(Mutex::new(Vec::new())),
            master: Arc::new(Mutex::new(MasterChannel {
                volume: 0.8,
                vu_level: (-60.0, -60.0),
                peak_level: (-60.0, -60.0),
                limiter_enabled: true,
                compressor_enabled: false,
            })),
            meter_handle: Arc::new(Mutex::new(None)),
        }
    }
}

#[command]
pub async fn mixer_get_channels(state: State<'_, MixerState>) -> Result<Vec<MixerChannel>, String> {
    let channels = state.channels.lock().unwrap();
    Ok(channels.clone())
}

#[command]
pub async fn mixer_get_master(state: State<'_, MixerState>) -> Result<MasterChannel, String> {
    let master = state.master.lock().unwrap();
    Ok(master.clone())
}

#[command]
pub async fn mixer_add_channel(
    state: State<'_, MixerState>,
    window: Window,
    track_id: u32,
    name: String,
) -> Result<MixerChannel, String> {
    let mut channels = state.channels.lock().unwrap();

    let channel = MixerChannel {
        track_id,
        name: name.clone(),
        volume: 0.8,
        pan: 0.0,
        muted: false,
        solo: false,
        vu_level: (-60.0, -60.0),
        peak_level: (-60.0, -60.0),
        effects: Vec::new(),
    };

    channels.push(channel.clone());

    // Start meter update if not running
    let mut handle_guard = state.meter_handle.lock().unwrap();
    if handle_guard.is_none() {
        let window_clone = window.clone();
        let state_clone = Arc::new(state.inner().clone());
        let spawn_handle = tokio::spawn(meter_update_loop(window_clone, state_clone));
        *handle_guard = Some(spawn_handle);
    }

    Ok(channel)
}

#[command]
pub async fn mixer_remove_channel(state: State<'_, MixerState>, track_id: u32) -> Result<(), String> {
    let mut channels = state.channels.lock().unwrap();
    let initial_len = channels.len();
    channels.retain(|c| c.track_id != track_id);

    if channels.len() < initial_len {
        Ok(())
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_volume(
    state: State<'_, MixerState>,
    track_id: u32,
    volume: f32,
) -> Result<(), String> {
    let volume = volume.clamp(0.0, 1.0);
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        channel.volume = volume;
        Ok(())
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_pan(
    state: State<'_, MixerState>,
    track_id: u32,
    pan: f32,
) -> Result<(), String> {
    let pan = pan.clamp(-1.0, 1.0);
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        channel.pan = pan;
        Ok(())
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_mute(
    state: State<'_, MixerState>,
    track_id: u32,
    muted: bool,
) -> Result<(), String> {
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        channel.muted = muted;
        Ok(())
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_solo(
    state: State<'_, MixerState>,
    track_id: u32,
    solo: bool,
) -> Result<(), String> {
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        channel.solo = solo;
        Ok(())
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_master_volume(
    state: State<'_, MixerState>,
    volume: f32,
) -> Result<(), String> {
    let volume = volume.clamp(0.0, 1.0);
    let mut master = state.master.lock().unwrap();
    master.volume = volume;
    Ok(())
}

#[command]
pub async fn mixer_set_master_limiter(
    state: State<'_, MixerState>,
    enabled: bool,
) -> Result<(), String> {
    let mut master = state.master.lock().unwrap();
    master.limiter_enabled = enabled;
    Ok(())
}

#[command]
pub async fn mixer_set_master_compressor(
    state: State<'_, MixerState>,
    enabled: bool,
) -> Result<(), String> {
    let mut master = state.master.lock().unwrap();
    master.compressor_enabled = enabled;
    Ok(())
}

#[command]
pub async fn mixer_add_effect(
    state: State<'_, MixerState>,
    track_id: u32,
    effect_name: String,
) -> Result<EffectSlot, String> {
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        let effect_id = channel.effects.len() as u32 + 1;
        let effect = EffectSlot {
            id: effect_id,
            name: effect_name.clone(),
            enabled: true,
            wet_dry: 1.0,
        };

        channel.effects.push(effect.clone());
        Ok(effect)
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_remove_effect(
    state: State<'_, MixerState>,
    track_id: u32,
    effect_id: u32,
) -> Result<(), String> {
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        let initial_len = channel.effects.len();
        channel.effects.retain(|e| e.id != effect_id);

        if channel.effects.len() < initial_len {
            Ok(())
        } else {
            Err("Effect not found".to_string())
        }
    } else {
        Err("Channel not found".to_string())
    }
}

#[command]
pub async fn mixer_set_effect_enabled(
    state: State<'_, MixerState>,
    track_id: u32,
    effect_id: u32,
    enabled: bool,
) -> Result<(), String> {
    let mut channels = state.channels.lock().unwrap();

    if let Some(channel) = channels.iter_mut().find(|c| c.track_id == track_id) {
        if let Some(effect) = channel.effects.iter_mut().find(|e| e.id == effect_id) {
            effect.enabled = enabled;
            Ok(())
        } else {
            Err("Effect not found".to_string())
        }
    } else {
        Err("Channel not found".to_string())
    }
}

// Meter update loop
async fn meter_update_loop(window: Window, state: Arc<MixerState>) {
    let mut interval = interval(Duration::from_millis(50)); // 20 FPS

    loop {
        interval.tick().await;

        let mut meter_updates = Vec::new();

        {
            let mut rng = rand::thread_rng();
            let mut channels = state.channels.lock().unwrap();
            let mut master = state.master.lock().unwrap();

            // Update channels
            for channel in channels.iter_mut() {
                let activity = if channel.muted { -60.0 } else {
                    -30.0 + rng.gen_range(-20.0..20.0)
                };

                let left_level = activity + (channel.pan * -6.0).min(0.0);
                let right_level = activity + (channel.pan * 6.0).max(0.0);

                channel.vu_level = (left_level, right_level);
                channel.peak_level.0 = channel.peak_level.0.max(left_level);
                channel.peak_level.1 = channel.peak_level.1.max(right_level);

                meter_updates.push(MeterData {
                    track_id: channel.track_id,
                    vu_left: left_level,
                    vu_right: right_level,
                    peak_left: channel.peak_level.0,
                    peak_right: channel.peak_level.1,
                });
            }

            // Update master
            let master_level = if channels.is_empty() { -60.0 } else {
                channels.iter().map(|c| (c.vu_level.0 + c.vu_level.1) / 2.0).sum::<f32>() / channels.len() as f32
            };

            master.vu_level = (master_level, master_level);
            master.peak_level.0 = master.peak_level.0.max(master_level);
            master.peak_level.1 = master.peak_level.1.max(master_level);
        }

        if !meter_updates.is_empty() {
            let _ = window.emit("mixer::meter-update", meter_updates);
        }

        // Reset peaks occasionally
        if rand::thread_rng().gen_bool(0.01) {
            let mut channels = state.channels.lock().unwrap();
            let mut master = state.master.lock().unwrap();

            for channel in channels.iter_mut() {
                channel.peak_level = (-60.0, -60.0);
            }
            master.peak_level = (-60.0, -60.0);
        }
    }
}
```

### `mod.rs` {#mod-rs}

- **Lines**: 33 (code: 30, comments: 0, blank: 3)

#### Source Code

```rust
/// Tauri command handlers
///
/// All commands are Grown-up Scripts:
/// - Perform I/O (file system, database, network)
/// - Delegate business logic to Trusty Modules
/// - Handle errors and convert to frontend-friendly format
/// - Provide progress updates for long-running operations
pub mod analyze;
pub mod archive_import;
pub mod file_import;
pub mod files;
pub mod progress;
pub mod search;
pub mod split_file;
pub mod stats;
pub mod system;
pub mod tags;

// Re-export commonly used split types
pub use split_file::{split_and_import, SplitResult};

// Re-export analysis command and types
pub use analyze::{
    start_analysis,
    analyze_single_file,
    batch_insert_analyzed_files,
    AnalyzedFile,
    FileRecord,
    TrackInstrument
};

// Future command modules:
// pub mod playback;

```

### `pipeline.rs` {#pipeline-rs}

- **Lines**: 383 (code: 330, comments: 0, blank: 53)

#### Source Code

```rust
use serde::{Deserialize, Serialize};
use tauri::{command, Emitter, State, Window};
use tokio::fs;
use zip::write::FileOptions;
use zip::ZipWriter;
use std::io::Write;
use std::time::Duration;
use tokio::time::sleep;
use rand::Rng;
use rand::SeedableRng;

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct PipelineProgress {
    pub current: u32,
    pub total: u32,
    pub stage: String,
    pub current_file: Option<String>,
    pub rate: f32,
    pub eta_seconds: f32,
    pub details: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct ImportStats {
    pub files_processed: u32,
    pub files_imported: u32,
    pub files_skipped: u32,
    pub total_size: u64,
    pub duration_seconds: f64,
    pub errors: Vec<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone, Default)]
pub struct AnalysisResults {
    pub files_analyzed: u32,
    pub bpm_detected: u32,
    pub key_detected: u32,
    pub instruments_found: Vec<String>,
    pub errors: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct PipelineState {
    pub progress: std::sync::Arc<std::sync::Mutex<PipelineProgress>>,
    pub is_processing: std::sync::Arc<std::sync::Mutex<bool>>,
}

impl Default for PipelineState {
    fn default() -> Self {
        Self {
            progress: std::sync::Arc::new(std::sync::Mutex::new(PipelineProgress::default())),
            is_processing: std::sync::Arc::new(std::sync::Mutex::new(false)),
        }
    }
}

#[command]
pub async fn pipeline_import_files(
    state: State<'_, PipelineState>,
    window: Window,
    file_paths: Vec<String>,
) -> Result<ImportStats, String> {
    // Use explicit scopes to ensure MutexGuards are dropped before any await
    {
        let mut is_processing = state.is_processing.lock().unwrap();
        if *is_processing {
            return Err("Pipeline is already processing".to_string());
        }
        *is_processing = true;
    }

    {
        let mut progress = state.progress.lock().unwrap();
        *progress = PipelineProgress {
            current: 0,
            total: file_paths.len() as u32,
            stage: "importing".to_string(),
            current_file: None,
            rate: 0.0,
            eta_seconds: 0.0,
            details: "Starting import process".to_string(),
        };
    }

    let start_time = std::time::Instant::now();
    let mut files_imported = 0;
    let mut files_skipped = 0;
    let mut total_size = 0;
    let mut errors = Vec::new();
    let mut rng = rand::rngs::StdRng::from_entropy();

    for (i, file_path) in file_paths.iter().enumerate() {
        // Check cancellation
        if !*state.is_processing.lock().unwrap() {
            break;
        }

        // Update progress
        {
            let mut progress = state.progress.lock().unwrap();
            progress.current = i as u32 + 1;
            progress.current_file = Some(file_path.clone());

            let elapsed = start_time.elapsed().as_secs_f64();
            if elapsed > 0.0 {
                progress.rate = (i as f32 + 1.0) / elapsed as f32;
                progress.eta_seconds = (progress.total as f32 - progress.current as f32) / progress.rate;
            }
            let filename = std::path::Path::new(file_path)
                .file_name()
                .map(|n| n.to_string_lossy().to_string())
                .unwrap_or_else(|| "unknown".to_string());
            progress.details = format!("Processing: {}", filename);
        }

        // Emit progress
        {
            let progress = state.progress.lock().unwrap();
            let _ = window.emit("pipeline::progress", progress.clone());
        }

        // Simulate file processing
        match fs::metadata(file_path).await {
            Ok(metadata) => {
                total_size += metadata.len();
                files_imported += 1;
                // Simulate DB insert or other processing
                sleep(Duration::from_millis(rng.gen_range(50..200))).await;
            }
            Err(e) => {
                errors.push(format!("Failed to process {}: {}", file_path, e));
                files_skipped += 1;
            }
        }
    }

    // Complete
    {
        let mut progress = state.progress.lock().unwrap();
        progress.stage = "completed".to_string();
        progress.current_file = None;
        progress.details = "Import completed".to_string();
    }

    let _ = window.emit("pipeline::completed", ());

    *state.is_processing.lock().unwrap() = false;

    let stats = ImportStats {
        files_processed: file_paths.len() as u32,
        files_imported,
        files_skipped,
        total_size,
        duration_seconds: start_time.elapsed().as_secs_f64(),
        errors,
    };

    Ok(stats)
}

#[command]
pub async fn pipeline_analyze_files(
    state: State<'_, PipelineState>,
    window: Window,
    file_ids: Vec<i64>,
) -> Result<AnalysisResults, String> {
    // Use explicit scopes to ensure MutexGuards are dropped before any await
    {
        let mut is_processing = state.is_processing.lock().unwrap();
        if *is_processing {
            return Err("Pipeline is already processing".to_string());
        }
        *is_processing = true;
    }

    {
        let mut progress = state.progress.lock().unwrap();
        *progress = PipelineProgress {
            current: 0,
            total: file_ids.len() as u32,
            stage: "analyzing".to_string(),
            current_file: None,
            rate: 0.0,
            eta_seconds: 0.0,
            details: "Starting analysis process".to_string(),
        };
    }

    let start_time = std::time::Instant::now();
    let mut files_analyzed = 0;
    let mut bpm_detected = 0;
    let mut key_detected = 0;
    let mut instruments = Vec::new();
    let errors = Vec::new();
    let mut rng = rand::rngs::StdRng::from_entropy();

    for (i, &file_id) in file_ids.iter().enumerate() {
        if !*state.is_processing.lock().unwrap() {
            break;
        }

        // Update progress
        {
            let mut progress = state.progress.lock().unwrap();
            progress.current = i as u32 + 1;
            progress.current_file = Some(file_id.to_string());

            let elapsed = start_time.elapsed().as_secs_f64();
            if elapsed > 0.0 {
                progress.rate = (i as f32 + 1.0) / elapsed as f32;
                progress.eta_seconds = (progress.total as f32 - progress.current as f32) / progress.rate;
            }
            progress.details = format!("Analyzing file ID {}", file_id);
        }

        // Emit progress
        {
            let progress = state.progress.lock().unwrap();
            let _ = window.emit("pipeline::progress", progress.clone());
        }

        // Simulate analysis
        let bpm_detected_this = rng.gen_bool(0.8); // 80% success
        let key_detected_this = rng.gen_bool(0.7); // 70% success
        let instrument = if rng.gen_bool(0.5) { "piano" } else { "synth" };

        if bpm_detected_this {
            bpm_detected += 1;
        }
        if key_detected_this {
            key_detected += 1;
        }
        instruments.push(instrument.to_string());

        files_analyzed += 1;

        sleep(Duration::from_millis(rng.gen_range(100..300))).await;
    }

    // Complete
    {
        let mut progress = state.progress.lock().unwrap();
        progress.stage = "completed".to_string();
        progress.current_file = None;
        progress.details = "Analysis completed".to_string();
    }

    let _ = window.emit("pipeline::completed", ());

    *state.is_processing.lock().unwrap() = false;

    let results = AnalysisResults {
        files_analyzed,
        bpm_detected,
        key_detected,
        instruments_found: instruments,
        errors,
    };

    Ok(results)
}

#[command]
pub async fn pipeline_archive_files(
    state: State<'_, PipelineState>,
    window: Window,
    file_ids: Vec<i64>,
    archive_path: String,
) -> Result<ImportStats, String> {
    // Use explicit scopes to ensure MutexGuards are dropped before any await
    {
        let mut is_processing = state.is_processing.lock().unwrap();
        if *is_processing {
            return Err("Pipeline is already processing".to_string());
        }
        *is_processing = true;
    }

    {
        let mut progress = state.progress.lock().unwrap();
        *progress = PipelineProgress {
            current: 0,
            total: file_ids.len() as u32,
            stage: "archiving".to_string(),
            current_file: None,
            rate: 0.0,
            eta_seconds: 0.0,
            details: format!("Creating archive: {}", archive_path),
        };
    }

    let start_time = std::time::Instant::now();
    let mut files_processed = 0;
    let mut total_size: u64 = 0;
    let errors = Vec::new();
    let mut rng = rand::rngs::StdRng::from_entropy();

    // Create zip file
    let file = std::fs::File::create(&archive_path).map_err(|e| e.to_string())?;
    let mut zip = ZipWriter::new(file);
    let options = FileOptions::default()
        .compression_method(zip::CompressionMethod::Stored)
        .unix_permissions(0o755);

    for (i, &file_id) in file_ids.iter().enumerate() {
        if !*state.is_processing.lock().unwrap() {
            break;
        }

        // Update progress
        {
            let mut progress = state.progress.lock().unwrap();
            progress.current = i as u32 + 1;
            progress.current_file = Some(file_id.to_string());

            let elapsed = start_time.elapsed().as_secs_f64();
            if elapsed > 0.0 {
                progress.rate = (i as f32 + 1.0) / elapsed as f32;
                progress.eta_seconds = (progress.total as f32 - progress.current as f32) / progress.rate;
            }
            progress.details = format!("Archiving file ID {}", file_id);
        }

        // Emit progress
        {
            let progress = state.progress.lock().unwrap();
            let _ = window.emit("pipeline::progress", progress.clone());
        }

        // Simulate archiving (in real, copy files to zip)
        let size: u64 = rng.gen_range(1024..(1024*1024));
        total_size += size;
        files_processed += 1;

        // Add to zip (mock)
        let filename = format!("file_{}.mid", file_id);
        zip.start_file(&filename, options).map_err(|e| e.to_string())?;
        zip.write_all(&vec![0u8; size as usize]).map_err(|e| e.to_string())?;

        let delay_ms: u64 = rng.gen_range(50..150);
        sleep(Duration::from_millis(delay_ms)).await;
    }

    zip.finish().map_err(|e| e.to_string())?;

    // Complete
    {
        let mut progress = state.progress.lock().unwrap();
        progress.stage = "completed".to_string();
        progress.current_file = None;
        progress.details = "Archive created successfully".to_string();
    }

    let _ = window.emit("pipeline::completed", ());

    *state.is_processing.lock().unwrap() = false;

    let stats = ImportStats {
        files_processed: file_ids.len() as u32,
        files_imported: files_processed,
        files_skipped: 0,
        total_size,
        duration_seconds: start_time.elapsed().as_secs_f64(),
        errors,
    };

    Ok(stats)
}

#[command]
pub async fn pipeline_get_progress(state: State<'_, PipelineState>) -> Result<PipelineProgress, String> {
    let progress = state.progress.lock().unwrap();
    Ok(progress.clone())
}

#[command]
pub async fn pipeline_cancel(state: State<'_, PipelineState>) -> Result<(), String> {
    *state.is_processing.lock().unwrap() = false;
    let mut progress = state.progress.lock().unwrap();
    progress.stage = "cancelled".to_string();
    progress.details = "Operation cancelled".to_string();
    Ok(())
}
```

### `progress.rs` {#progress-rs}

- **Lines**: 311 (code: 263, comments: 0, blank: 48)

#### Source Code

```rust
// ARCHETYPE: MANAGER (Grown-up Script)
// Purpose: Track import progress and emit real-time updates to frontend
// Side effects: Emits Tauri events, manages mutable state

use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};
use tauri::{AppHandle, Emitter, State};

/// Progress state for file import operations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProgressState {
    pub current_file: String,
    pub current_index: usize,
    pub total_files: usize,
    pub percentage: f64,
    pub phase: String,
    pub files_per_second: f64,
    pub errors_count: usize,
    pub duplicates_found: usize,
    pub estimated_time_remaining: f64,
}

impl Default for ProgressState {
    fn default() -> Self {
        Self {
            current_file: String::new(),
            current_index: 0,
            total_files: 0,
            percentage: 0.0,
            phase: "idle".to_string(),
            files_per_second: 0.0,
            errors_count: 0,
            duplicates_found: 0,
            estimated_time_remaining: 0.0,
        }
    }
}

/// Thread-safe progress tracker
#[derive(Clone)]
pub struct ProgressTracker {
    state: Arc<Mutex<ProgressState>>,
    start_time: Arc<Mutex<Option<std::time::Instant>>>,
}

impl ProgressTracker {
    pub fn new() -> Self {
        Self {
            state: Arc::new(Mutex::new(ProgressState::default())),
            start_time: Arc::new(Mutex::new(None)),
        }
    }

    /// Get current progress state
    pub fn get_state(&self) -> ProgressState {
        self.state.lock().unwrap_or_else(|poisoned| poisoned.into_inner()).clone()
    }

    /// Update state and return the new state
    fn update_state<F>(&self, updater: F) -> ProgressState
    where
        F: FnOnce(&mut ProgressState),
    {
        let mut state = self.state.lock().unwrap_or_else(|poisoned| poisoned.into_inner());
        updater(&mut state);
        state.clone()
    }

    /// Calculate metrics based on current progress
    fn calculate_metrics(&self, current_index: usize, total_files: usize) -> (f64, f64) {
        let start_time = self.start_time.lock().unwrap_or_else(|poisoned| poisoned.into_inner());

        if let Some(start) = *start_time {
            let elapsed = start.elapsed().as_secs_f64();

            if elapsed > 0.0 && current_index > 0 {
                let files_per_second = current_index as f64 / elapsed;
                let remaining_files = total_files.saturating_sub(current_index);
                let estimated_time_remaining = if files_per_second > 0.0 {
                    remaining_files as f64 / files_per_second
                } else {
                    0.0
                };

                return (files_per_second, estimated_time_remaining);
            }
        }

        (0.0, 0.0)
    }
}

impl Default for ProgressTracker {
    fn default() -> Self {
        Self::new()
    }
}

/// Start progress tracking for a new import operation
#[tauri::command]
pub async fn start_progress_tracking(
    total: usize,
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    // Reset start time
    *tracker.start_time.lock().unwrap_or_else(|poisoned| poisoned.into_inner()) =
        Some(std::time::Instant::now());

    // Initialize state
    let state = tracker.update_state(|s| {
        s.current_file = String::new();
        s.current_index = 0;
        s.total_files = total;
        s.percentage = 0.0;
        s.phase = "scanning".to_string();
        s.files_per_second = 0.0;
        s.errors_count = 0;
        s.duplicates_found = 0;
        s.estimated_time_remaining = 0.0;
    });

    // Emit initial state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    Ok(())
}

/// Update progress with current file and phase
#[tauri::command]
pub async fn update_progress(
    current: usize,
    file: String,
    phase: String,
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    let total = {
        let state = tracker.state.lock().unwrap_or_else(|poisoned| poisoned.into_inner());
        state.total_files
    };

    // Calculate metrics
    let (files_per_second, estimated_time_remaining) = tracker.calculate_metrics(current, total);

    // Update state
    let state = tracker.update_state(|s| {
        s.current_file = file;
        s.current_index = current;
        s.phase = phase;
        s.percentage = if total > 0 {
            (current as f64 / total as f64) * 100.0
        } else {
            0.0
        };
        s.files_per_second = files_per_second;
        s.estimated_time_remaining = estimated_time_remaining;
    });

    // Emit updated state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    Ok(())
}

/// Mark an error during processing
#[tauri::command]
pub async fn increment_error_count(
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    let state = tracker.update_state(|s| {
        s.errors_count += 1;
    });

    // Emit updated state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    Ok(())
}

/// Mark a duplicate file found
#[tauri::command]
pub async fn increment_duplicate_count(
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    let state = tracker.update_state(|s| {
        s.duplicates_found += 1;
    });

    // Emit updated state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    Ok(())
}

/// Complete progress tracking
#[tauri::command]
pub async fn complete_progress(
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    let state = tracker.update_state(|s| {
        s.percentage = 100.0;
        s.phase = "complete".to_string();
        s.estimated_time_remaining = 0.0;
    });

    // Emit final state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    // Reset start time
    *tracker.start_time.lock().unwrap_or_else(|poisoned| poisoned.into_inner()) = None;

    Ok(())
}

/// Get current progress state (for polling if needed)
#[tauri::command]
pub async fn get_current_progress(
    tracker: State<'_, ProgressTracker>,
) -> Result<ProgressState, String> {
    Ok(tracker.get_state())
}

/// Reset progress to idle state
#[tauri::command]
pub async fn reset_progress(
    tracker: State<'_, ProgressTracker>,
    app: AppHandle,
) -> Result<(), String> {
    *tracker.start_time.lock().unwrap_or_else(|poisoned| poisoned.into_inner()) = None;

    let state = tracker.update_state(|s| {
        *s = ProgressState::default();
    });

    // Emit reset state
    app.emit("import-progress", &state)
        .map_err(|e| format!("Failed to emit progress: {}", e))?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_progress_state_default() {
        let state = ProgressState::default();
        assert_eq!(state.current_index, 0);
        assert_eq!(state.total_files, 0);
        assert_eq!(state.percentage, 0.0);
        assert_eq!(state.phase, "idle");
    }

    #[test]
    fn test_progress_tracker_new() {
        let tracker = ProgressTracker::new();
        let state = tracker.get_state();
        assert_eq!(state.current_index, 0);
        assert_eq!(state.total_files, 0);
    }

    #[test]
    fn test_progress_tracker_update() {
        let tracker = ProgressTracker::new();

        // Simulate starting tracking
        *tracker.start_time.lock()
            .expect("start_time mutex panicked in test - indicates logic error") = Some(std::time::Instant::now());

        let state = tracker.update_state(|s| {
            s.total_files = 100;
            s.current_index = 50;
            s.phase = "analyzing".to_string();
            s.percentage = 50.0;
        });

        assert_eq!(state.total_files, 100);
        assert_eq!(state.current_index, 50);
        assert_eq!(state.phase, "analyzing");
        assert_eq!(state.percentage, 50.0);
    }

    #[test]
    fn test_calculate_metrics() {
        let tracker = ProgressTracker::new();

        // Before start time is set
        let (fps, eta) = tracker.calculate_metrics(10, 100);
        assert_eq!(fps, 0.0);
        assert_eq!(eta, 0.0);

        // After start time is set
        *tracker.start_time.lock()
            .expect("start_time mutex panicked in test - indicates logic error") = Some(std::time::Instant::now());
        std::thread::sleep(std::time::Duration::from_millis(100));

        let (fps, eta) = tracker.calculate_metrics(10, 100);
        assert!(fps > 0.0); // Should be processing files
        assert!(eta > 0.0); // Should have estimated time
    }
}

```

### `project.rs` {#project-rs}

- **Lines**: 172 (code: 152, comments: 0, blank: 20)

#### Source Code

```rust
/// Project and track loading commands
///
/// Commands for loading multiple tracks into the sequencer from the database.
use crate::commands::AppState;
use crate::core::midi::loader::load_midi_file;
use crate::models::sequencer::Track;
use crate::sequencer::{ScheduledEvent, SequencerEngine};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tauri::State;
use tracing::{error, info, warn};

/// Track with loaded events ready for scheduling
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrackWithEvents {
    pub track: Track,
    pub events: Vec<ScheduledEvent>,
}

/// Load multiple MIDI files as sequencer tracks
///
/// This command loads multiple files from the database and prepares them
/// as sequencer tracks with their MIDI events ready for playback.
///
/// # Arguments
/// * `file_ids` - List of database file IDs to load
/// * `state` - Application state with database connection
/// * `engine` - Sequencer engine
#[tauri::command]
pub async fn load_multiple_tracks(
    file_ids: Vec<i32>,
    state: State<'_, AppState>,
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<Vec<Track>, String> {
    info!("Loading {} files as sequencer tracks", file_ids.len());

    let mut loaded_tracks = Vec::new();
    let mut failed_count = 0;

    for (idx, file_id) in file_ids.iter().enumerate() {
        // Query database for file information
        let file_result = match sqlx::query!(
            r#"
            SELECT id, filepath, filename
            FROM files
            WHERE id = $1
            "#,
            *file_id as i64
        )
        .fetch_one(state.db_pool.as_ref().ok_or_else(|| "Database not initialized".to_string())?)
        .await
        {
            Ok(result) => result,
            Err(e) => {
                error!("Failed to query file {} from database: {}", file_id, e);
                failed_count += 1;
                continue;
            },
        };

        // Load MIDI file and parse events
        let loaded_midi = match load_midi_file(&file_result.filepath) {
            Ok(midi) => midi,
            Err(e) => {
                error!(
                    "Failed to load MIDI file {} ({}): {}",
                    file_result.filename, file_result.filepath, e
                );
                failed_count += 1;
                continue;
            },
        };

        info!(
            "Loaded {} events from {} ({}/{})",
            loaded_midi.events.len(),
            file_result.filename,
            idx + 1,
            file_ids.len()
        );

        // Add track with loaded events
        let track_manager = engine.track_manager();
        let channel = (idx % 16) as u8; // Distribute across MIDI channels

        match track_manager
            .add_track(file_result.id as i32, channel, loaded_midi.events)
            .await
        {
            Ok(track) => loaded_tracks.push(track),
            Err(e) => {
                error!("Failed to add track for file {}: {}", file_id, e);
                failed_count += 1;
            },
        }
    }

    if failed_count > 0 {
        warn!(
            "Failed to load {} out of {} tracks",
            failed_count,
            file_ids.len()
        );
    }

    // Reload tracks in engine to update scheduler
    engine.load_tracks().await;

    info!(
        "Successfully loaded {} tracks into sequencer",
        loaded_tracks.len()
    );

    Ok(loaded_tracks)
}

/// Clear all tracks from the sequencer
#[tauri::command]
pub async fn clear_all_tracks(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    info!("Clearing all tracks from sequencer");

    let track_manager = engine.track_manager();
    track_manager.clear().await;

    let scheduler = engine.scheduler();
    scheduler.clear().await;

    Ok(())
}

/// Get detailed information about loaded tracks
#[tauri::command]
pub async fn get_track_details(
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<Vec<TrackDetails>, String> {
    let track_manager = engine.track_manager();
    let tracks = track_manager.get_tracks().await;

    let details: Vec<TrackDetails> = tracks
        .into_iter()
        .map(|track| {
            let event_count = track.events.len();
            TrackDetails {
                id: track.id,
                name: track.name,
                file_id: track.file_id,
                channel: track.channel,
                muted: track.muted,
                solo: track.solo,
                volume: track.volume,
                pan: track.pan,
                event_count,
            }
        })
        .collect();

    Ok(details)
}

/// Track details for frontend display
#[derive(Debug, Serialize, Deserialize)]
pub struct TrackDetails {
    pub id: i32,
    pub name: String,
    pub file_id: i32,
    pub channel: u8,
    pub muted: bool,
    pub solo: bool,
    pub volume: u8,
    pub pan: u8,
    pub event_count: usize,
}

```

### `search.rs` {#search-rs}

- **Lines**: 326 (code: 300, comments: 0, blank: 26)

#### Source Code

```rust
/// Search command handlers - GROWN-UP SCRIPT ARCHETYPE
///
/// PURPOSE: Advanced search functionality with filters and pagination
/// ARCHETYPE: Grown-up Script (I/O operations, reusable logic)
///
/// ‚úÖ CAN: Perform database I/O
/// ‚úÖ CAN: Have side effects (complex queries)
/// ‚úÖ SHOULD: Handle errors properly
/// ‚ùå NO: Complex business logic (delegate to Trusty Modules)
use crate::AppState;
use serde::{Deserialize, Serialize};
use tauri::State;

// =============================================================================
// DATA STRUCTURES
// =============================================================================

/// Search filters from frontend
#[derive(Debug, Clone, Deserialize)]
pub struct SearchFilters {
    pub category: Option<String>,
    pub min_bpm: Option<f64>,
    pub max_bpm: Option<f64>,
    pub key_signature: Option<String>,
}

/// Search result item (simplified for list view)
///
/// Note: NUMERIC columns are cast to float8 in SQL queries for simplicity
#[derive(Debug, Clone, Serialize, sqlx::FromRow)]
pub struct SearchResultItem {
    pub id: i64,
    pub filename: String,
    pub filepath: String,
    pub bpm: Option<f64>, // Cast from NUMERIC in SQL
    pub key_signature: Option<String>,
    pub duration_seconds: Option<f64>, // Cast from NUMERIC in SQL
    pub category: Option<String>,
}

/// Paginated search results
#[derive(Debug, Serialize)]
pub struct SearchResults {
    pub items: Vec<SearchResultItem>,
    pub total_count: i64,
    pub page: i32,
    pub page_size: i32,
    pub total_pages: i32,
}

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

/// Count search results for pagination
async fn count_search_results(
    query: &str,
    filters: &SearchFilters,
    pool: &sqlx::PgPool,
) -> Result<i64, sqlx::Error> {
    let count: (i64,) = sqlx::query_as(
        r#"
        SELECT COUNT(*)
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE
            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')
            AND ($2::text IS NULL OR fc.primary_category::text = $2)
            AND ($3::float8 IS NULL OR mm.bpm >= $3)
            AND ($4::float8 IS NULL OR mm.bpm <= $4)
            AND ($5::text IS NULL OR mm.key_signature::text = $5)
        "#
    )
    .bind(query)
    .bind(&filters.category)
    .bind(filters.min_bpm)
    .bind(filters.max_bpm)
    .bind(&filters.key_signature)
    .fetch_one(pool)
    .await?;

    Ok(count.0)
}

// =============================================================================
// TAURI COMMANDS
// =============================================================================

/// Search files with filters and pagination (implementation for tests and reuse)
pub async fn search_files_impl(
    query: String,
    filters: SearchFilters,
    page: i32,
    page_size: i32,
    state: &AppState,
) -> Result<SearchResults, String> {
    let pool = state.database.pool().await;

    // Validate pagination
    if page < 1 {
        return Err("Page must be >= 1".to_string());
    }
    if !(1..=100).contains(&page_size) {
        return Err("Page size must be between 1 and 100".to_string());
    }

    // Calculate offset
    let offset = (page - 1) * page_size;

    // Query with correct column names from schema
    let items = sqlx::query_as::<_, SearchResultItem>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            mm.bpm::float8 as bpm,
            mm.key_signature::text as key_signature,
            f.duration_seconds::float8 as duration_seconds,
            fc.primary_category::text as category
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        WHERE
            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')
            AND ($2::text IS NULL OR fc.primary_category::text = $2)
            AND ($3::float8 IS NULL OR mm.bpm >= $3)
            AND ($4::float8 IS NULL OR mm.bpm <= $4)
            AND ($5::text IS NULL OR mm.key_signature::text = $5)
        ORDER BY f.created_at DESC
        LIMIT $6 OFFSET $7
        "#
    )
    .bind(&query)
    .bind(&filters.category)
    .bind(filters.min_bpm)
    .bind(filters.max_bpm)
    .bind(&filters.key_signature)
    .bind(page_size as i64)
    .bind(offset as i64)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("Search error: {}", e))?;

    let total_count = count_search_results(&query, &filters, &pool)
        .await
        .map_err(|e| format!("Count error: {}", e))?;

    Ok(SearchResults {
        items,
        total_count,
        page,
        page_size,
        total_pages: ((total_count as f64) / (page_size as f64)).ceil() as i32,
    })
}

/// Search files with filters and pagination
///
/// # Manager Archetype
/// - ‚úÖ Performs I/O (complex database query)
/// - ‚úÖ Has side effects (reads from database)
/// - ‚úÖ Handles errors properly
///
/// # Arguments
///
/// * `query` - Text search query (searches filename and filepath)
/// * `filters` - Search filters (category, BPM range, key)
/// * `page` - Page number (1-indexed)
/// * `page_size` - Items per page (1-100)
///
/// # Returns
///
/// Paginated search results with total count
#[tauri::command]
pub async fn search_files(
    query: String,
    filters: SearchFilters,
    page: i32,
    page_size: i32,
    state: State<'_, AppState>,
) -> Result<SearchResults, String> {
    search_files_impl(query, filters, page, page_size, &state).await
}

/// Get all unique tags from database (implementation for tests and reuse)
pub async fn get_all_tags_impl(state: &AppState) -> Result<Vec<String>, String> {
    let tags: Vec<(String,)> = sqlx::query_as(
        r#"
        SELECT DISTINCT tag_name
        FROM file_tags
        ORDER BY tag_name ASC
        "#,
    )
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get tags: {}", e))?;

    Ok(tags.into_iter().map(|(tag,)| tag).collect())
}

/// Get all unique tags from database
///
/// Returns a list of all unique tag names used in the database.
///
/// # Frontend Usage
///
/// ```typescript
/// const tags = await invoke<string[]>('get_all_tags');
/// ```
#[tauri::command]
pub async fn get_all_tags(state: State<'_, AppState>) -> Result<Vec<String>, String> {
    get_all_tags_impl(&state).await
}

/// Get files by tag
///
/// Returns all files that have a specific tag.
///
/// # Arguments
///
/// * `tag` - Tag name to filter by
///
/// # Frontend Usage
///
/// ```typescript
/// const files = await invoke<FileMetadata[]>('get_files_by_tag', { tag: 'ambient' });
/// ```
#[tauri::command]
pub async fn get_files_by_tag(
    tag: String,
    state: State<'_, AppState>,
) -> Result<Vec<SearchResultItem>, String> {
    let files = sqlx::query_as::<_, SearchResultItem>(
        r#"
        SELECT
            f.id,
            f.filename,
            f.filepath,
            mm.bpm::float8 as bpm,
            mm.key_signature::text as key_signature,
            f.duration_seconds::float8 as duration_seconds,
            fc.primary_category::text as category
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        INNER JOIN file_tags ft ON f.id = ft.file_id
        WHERE ft.tag_name = $1
        ORDER BY f.created_at DESC
        "#,
    )
    .bind(tag)
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get files by tag: {}", e))?;

    Ok(files)
}

/// Get BPM range from database (implementation for tests and reuse)
pub async fn get_bpm_range_impl(state: &AppState) -> Result<BpmRange, String> {
    let pool = state.database.pool().await;
    let result: Option<(Option<f64>, Option<f64>)> = sqlx::query_as(
        r#"
        SELECT MIN(bpm)::float8, MAX(bpm)::float8
        FROM musical_metadata
        WHERE bpm IS NOT NULL
        "#,
    )
    .fetch_optional(&pool)
    .await
    .map_err(|e| format!("Failed to get BPM range: {}", e))?;

    match result {
        Some((Some(min), Some(max))) => Ok(BpmRange { min, max }),
        _ => Ok(BpmRange { min: 0.0, max: 300.0 }), // Default range if no data
    }
}

/// Get BPM range from database
///
/// Returns the minimum and maximum BPM values in the database.
///
/// # Frontend Usage
///
/// ```typescript
/// const range = await invoke<{min: number, max: number}>('get_bpm_range');
/// ```
#[tauri::command]
pub async fn get_bpm_range(state: State<'_, AppState>) -> Result<BpmRange, String> {
    get_bpm_range_impl(&state).await
}

/// Get all unique key signatures from database
///
/// Returns a list of all unique key signatures.
///
/// # Frontend Usage
///
/// ```typescript
/// const keys = await invoke<string[]>('get_all_keys');
/// ```
#[tauri::command]
pub async fn get_all_keys(state: State<'_, AppState>) -> Result<Vec<String>, String> {
    let keys: Vec<(String,)> = sqlx::query_as(
        r#"
        SELECT DISTINCT key_signature::text
        FROM musical_metadata
        WHERE key_signature IS NOT NULL
        ORDER BY key_signature ASC
        "#,
    )
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get keys: {}", e))?;

    Ok(keys.into_iter().map(|(key,)| key).collect())
}

/// BPM range response
#[derive(Debug, Serialize)]
pub struct BpmRange {
    pub min: f64,
    pub max: f64,
}

```

### `sequencer.rs` {#sequencer-rs}

- **Lines**: 187 (code: 162, comments: 0, blank: 25)

#### Source Code

```rust
/// Sequencer Tauri commands
///
/// Thin wrappers that expose sequencer functionality to the frontend.
use crate::commands::AppState;
use crate::core::midi::loader::load_midi_file;
use crate::models::sequencer::{PlaybackPosition, Track, TrackProperties};
use crate::sequencer::SequencerEngine;
use std::sync::Arc;
use tauri::State;
use tracing::{error, info};

/// Start sequencer playback
#[tauri::command]
pub async fn start_sequencer(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.start().await
}

/// Stop sequencer playback (resets position)
#[tauri::command]
pub async fn stop_sequencer(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.stop().await;
    Ok(())
}

/// Pause sequencer playback (maintains position)
#[tauri::command]
pub async fn pause_sequencer(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.pause().await;
    Ok(())
}

/// Resume sequencer playback from paused state
#[tauri::command]
pub async fn resume_sequencer(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.resume().await
}

/// Get current playback position
#[tauri::command]
pub async fn get_playback_position(
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<PlaybackPosition, String> {
    Ok(engine.get_position().await)
}

/// Seek to a specific position
///
/// # Arguments
/// * `bar` - Bar number (0-indexed)
/// * `beat` - Beat within bar (0-indexed)
#[tauri::command]
pub async fn seek_position(
    bar: u32,
    beat: u32,
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<(), String> {
    use crate::core::sequencer::timing::bar_beat_to_tick;

    let tick = bar_beat_to_tick(bar, beat, 480, 4); // TODO: Get these from engine
    engine.seek(tick).await;
    Ok(())
}

/// Set global tempo (BPM)
#[tauri::command]
pub async fn set_tempo(bpm: f32, engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.set_bpm(bpm).await
}

/// Get current tempo
#[tauri::command]
pub async fn get_tempo(engine: State<'_, Arc<SequencerEngine>>) -> Result<f32, String> {
    Ok(engine.get_bpm().await)
}

/// Add a track to the sequencer
///
/// # Arguments
/// * `file_id` - Database ID of the MIDI file
/// * `channel` - MIDI channel (0-15)
/// * `state` - Application state with database connection
/// * `engine` - Sequencer engine
#[tauri::command]
pub async fn add_track(
    file_id: i32,
    channel: u8,
    state: State<'_, AppState>,
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<Track, String> {
    // Query database for file information
    let file_result = sqlx::query!(
        r#"
        SELECT filepath
        FROM files
        WHERE id = $1
        "#,
        file_id as i64
    )
    .fetch_one(
        state
            .db_pool
            .as_ref()
            .ok_or_else(|| "Database pool not initialized".to_string())?,
    )
    .await
    .map_err(|e| {
        error!("Failed to query file {} from database: {}", file_id, e);
        format!("File not found: {}", file_id)
    })?;

    // Load MIDI file and parse events
    let loaded_midi = load_midi_file(&file_result.filepath).map_err(|e| {
        error!("Failed to load MIDI file {}: {}", file_result.filepath, e);
        format!("Failed to load MIDI file: {}", e)
    })?;

    info!(
        "Loaded {} events from file {} ({})",
        loaded_midi.events.len(),
        file_id,
        file_result.filepath
    );

    // Add track with loaded events
    let track_manager = engine.track_manager();
    let track = track_manager.add_track(file_id, channel, loaded_midi.events).await?;

    // Reload tracks in engine to update scheduler
    engine.load_tracks().await;

    Ok(track)
}

/// Remove a track from the sequencer
#[tauri::command]
pub async fn remove_track(
    track_id: i32,
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<(), String> {
    let track_manager = engine.track_manager();
    track_manager.remove_track(track_id).await?;

    // Remove track's events from scheduler
    let scheduler = engine.scheduler();
    scheduler.clear_track(track_id).await;

    Ok(())
}

/// Update track properties (mute, solo, volume, pan)
#[tauri::command]
pub async fn update_track(
    track_id: i32,
    properties: TrackProperties,
    engine: State<'_, Arc<SequencerEngine>>,
) -> Result<(), String> {
    let track_manager = engine.track_manager();
    track_manager.update_track(track_id, properties).await?;

    // Reload tracks to update scheduler
    engine.load_tracks().await;

    Ok(())
}

/// Get all tracks in current project
#[tauri::command]
pub async fn get_tracks(engine: State<'_, Arc<SequencerEngine>>) -> Result<Vec<Track>, String> {
    let track_manager = engine.track_manager();
    Ok(track_manager.get_tracks().await)
}

/// Load tracks into sequencer and prepare for playback
#[tauri::command]
pub async fn load_sequencer_tracks(engine: State<'_, Arc<SequencerEngine>>) -> Result<(), String> {
    engine.load_tracks().await;
    Ok(())
}

/// Check if sequencer is currently playing
#[tauri::command]
pub async fn is_sequencer_playing(engine: State<'_, Arc<SequencerEngine>>) -> Result<bool, String> {
    use crate::sequencer::engine::PlaybackState;

    let state = engine.get_state().await;
    Ok(state == PlaybackState::Playing)
}

```

### `split_file.rs` {#split-file-rs}

- **Lines**: 699 (code: 623, comments: 0, blank: 76)

#### Source Code

```rust
use crate::core::analysis::bpm_detector::detect_bpm;
use crate::core::analysis::key_detector::detect_key;
/// Track Splitting Commands - GROWN-UP SCRIPT
///
/// Architecture: Grown-up Script
/// Purpose: I/O wrapper around track_splitter Trusty Module
///
/// This module provides Tauri commands for splitting multi-track MIDI files
/// into individual single-track files. It handles:
/// - Database queries (fetch file info)
/// - File I/O (read original, write splits)
/// - Database transactions (insert splits, create relationships)
/// - Error handling and user-friendly messages
///
/// The actual splitting logic is delegated to the track_splitter Trusty Module,
/// which operates on byte arrays with no I/O.
use crate::core::hash::calculate_file_hash;
use crate::core::naming::generator::generate_production_layer_filename;
use crate::core::splitting::{split_tracks_with_repair, RepairResult, SplitError, SplitTrack};
use midi_library_shared::core::midi::parser::parse_midi_file;
use serde::{Deserialize, Serialize};
use std::path::{Path, PathBuf};
use thiserror::Error;

//=============================================================================
// ERROR TYPES
//=============================================================================

/// Errors that can occur during split and import operations
#[derive(Error, Debug)]
pub enum SplitCommandError {
    #[error("File not found in database: {0}")]
    FileNotFound(i64),

    #[error("File not found on disk: {0}")]
    FileNotFoundOnDisk(String),

    #[error("Failed to read file: {0}")]
    IoError(#[from] std::io::Error),

    #[error("Failed to split tracks: {0}")]
    SplitError(#[from] SplitError),

    #[error("Database error: {0}")]
    DatabaseError(String),

    #[error("Failed to create output directory: {0}")]
    DirectoryCreationError(String),

    #[error("Transaction failed: {0}")]
    TransactionError(String),
}

// Convert to user-friendly string for Tauri commands
impl From<SplitCommandError> for String {
    fn from(err: SplitCommandError) -> String {
        err.to_string()
    }
}

//=============================================================================
// TYPE DEFINITIONS
//=============================================================================

/// Result of a successful split operation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SplitResult {
    /// IDs of the newly created split files in the database
    pub split_file_ids: Vec<i64>,

    /// Number of tracks that were split
    pub tracks_split: usize,

    /// Directory where split files were written
    pub output_dir: PathBuf,
}

//=============================================================================
// PUBLIC API (Grown-up Script Pattern)
//=============================================================================

/// Split a multi-track MIDI file and import each track as a separate file.
///
/// This is the main entry point for track splitting operations. It:
/// 1. Queries the database for the original file's info
/// 2. Reads the original MIDI file from disk
/// 3. Calls the track_splitter Trusty Module to split tracks
/// 4. Creates output directory
/// 5. For each split track:
///    - Generates filename based on track metadata
///    - Writes MIDI bytes to disk
///    - Imports to database with full metadata
///    - Creates relationship in track_splits table
/// 6. Returns list of created file IDs
///
/// # Arguments
///
/// * `file_id` - Database ID of the parent file to split
/// * `output_dir` - Directory where split files will be written
/// * `pool` - Database connection pool
///
/// # Returns
///
/// `SplitResult` containing IDs of created files and statistics
///
/// # Errors
///
/// Returns error if:
/// - File not found in database
/// - File not found on disk
/// - Failed to read/parse MIDI file
/// - Failed to split tracks (e.g., only tempo track)
/// - Failed to create output directory
/// - Database transaction fails
///
/// # Examples
///
/// ```no_run
/// use pipeline::commands::split_file::split_and_import;
/// use std::path::PathBuf;
///
/// # async fn example(pool: sqlx::PgPool) -> Result<(), Box<dyn std::error::Error>> {
/// let result = split_and_import(
///     42,
///     PathBuf::from("/output/splits"),
///     &pool
/// ).await?;
///
/// println!("Split {} tracks into {} files",
///     result.tracks_split,
///     result.split_file_ids.len()
/// );
/// # Ok(())
/// # }
/// ```
pub async fn split_and_import(
    file_id: i64,
    output_dir: PathBuf,
    pool: &sqlx::PgPool,
) -> Result<SplitResult, SplitCommandError> {
    // 1. Query database for parent file info with metadata for Production naming
    let parent_file = sqlx::query!(
        r#"
        SELECT f.id, f.filename, f.original_filename, f.filepath, f.parent_folder,
               m.bpm, m.key_signature::text as "key_signature?"
        FROM files f
        LEFT JOIN musical_metadata m ON f.id = m.file_id
        WHERE f.id = $1
        "#,
        file_id
    )
    .fetch_optional(pool)
    .await
    .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?
    .ok_or(SplitCommandError::FileNotFound(file_id))?;

    // 2. Read original file from disk
    let file_path = Path::new(&parent_file.filepath);
    if !file_path.exists() {
        return Err(SplitCommandError::FileNotFoundOnDisk(
            parent_file.filepath.clone(),
        ));
    }

    let original_bytes = tokio::fs::read(file_path).await?;

    // 2b. Parse MIDI to extract time signature for Production naming
    let midi_data = parse_midi_file(&original_bytes)
        .map_err(|e| SplitCommandError::DatabaseError(format!("Failed to parse MIDI: {}", e)))?;

    // Extract time signature from events (default to 4-4)
    let time_signature = extract_time_signature_from_midi(&midi_data).unwrap_or_else(|| "4-4".to_string());

    // 3. Call Trusty Module to split tracks with automatic repair
    let (split_tracks, repair_result) = split_tracks_with_repair(&original_bytes)
        .map_err(|e| SplitCommandError::SplitError(SplitError::ParseError(e.to_string())))?;

    // Log repair if it occurred
    match &repair_result {
        RepairResult::Valid => {
            // File was valid, no repair needed
        }
        RepairResult::Repaired { fix_description, .. } => {
            eprintln!("üîß REPAIRED: {} - {}", parent_file.filename, fix_description);
        }
        RepairResult::Corrupt { reason } => {
            eprintln!("‚ùå CORRUPT: {} - {}", parent_file.filename, reason);
        }
    }

    if split_tracks.is_empty() {
        return Err(SplitCommandError::SplitError(SplitError::NoTracksToSplit));
    }

    // 4. Create output directory if it doesn't exist
    if !output_dir.exists() {
        tokio::fs::create_dir_all(&output_dir)
            .await
            .map_err(|e| SplitCommandError::DirectoryCreationError(e.to_string()))?;
    }

    // 5. Process each split track with Production naming
    let mut split_file_ids = Vec::new();

    // Extract metadata for Production template
    // Query musical_metadata for category if available
    // query_scalar with fetch_optional returns Result<Option<Option<String>>>
    // We unwrap the Result, then flatten the nested Options to get Option<String>,
    // then unwrap_or to get the final String value
    let category = sqlx::query_scalar::<_, Option<String>>(
        "SELECT category FROM musical_metadata WHERE file_id = $1"
    )
    .bind(parent_file.id)
    .fetch_optional(pool)
    .await
    .ok()
    .flatten()  // Flattens Option<Option<Option<String>>> to Option<Option<String>>
    .flatten()  // Flattens Option<Option<String>> to Option<String>
    .unwrap_or_else(|| "MIDI".to_string());

    let pack_name = parent_file.parent_folder.clone().unwrap_or_else(|| "Unknown".to_string());
    let file_id_str = format!("{:06}", parent_file.id);

    // Convert Option<BigDecimal> to f64 for BPM
    let bpm = parent_file.bpm
        .as_ref()
        .and_then(|bd| bd.to_string().parse::<f64>().ok())
        .unwrap_or(120.0);

    let key_signature = parent_file.key_signature.clone().unwrap_or_else(|| "C".to_string());

    for (layer_idx, split_track) in split_tracks.iter().enumerate() {
        // Extract layer name from instrument or track name
        let layer_name = if let Some(ref instrument) = split_track.instrument {
            instrument.clone()
        } else if let Some(ref track_name) = split_track.track_name {
            track_name.clone()
        } else {
            format!("Track{:02}", split_track.track_number)
        };

        // Generate Production filename: {CATEGORY}_{TIMESIG}_{BPM}BPM_{KEY}_{ID}_{PACK}_{LAYER}_L{NUM}.mid
        let filename = generate_production_layer_filename(
            category.as_str(), // Convert String to &str for function parameter
            bpm,
            &key_signature,
            &file_id_str,
            &time_signature,
            &pack_name,
            &layer_name,
            layer_idx + 1, // 1-based layer numbering
        );

        // Full path for split file
        let split_path = output_dir.join(&filename);

        // Write MIDI bytes to disk
        tokio::fs::write(&split_path, &split_track.midi_bytes).await?;

        // Import split file to database with full metadata
        let split_file_id =
            import_split_track(&split_path, &filename, &split_track.midi_bytes, pool)
                .await
                .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?;

        // Create relationship in track_splits table
        insert_track_split_relationship(file_id, split_file_id, split_track, pool)
            .await
            .map_err(|e| SplitCommandError::TransactionError(e.to_string()))?;

        split_file_ids.push(split_file_id);
    }

    Ok(SplitResult { split_file_ids, tracks_split: split_tracks.len(), output_dir })
}

//=============================================================================
// HELPER FUNCTIONS (Grown-up Script - I/O Operations)
//=============================================================================

/// Import a split track file to the database with full metadata.
///
/// Performs a complete import operation including:
/// - Hash calculation for deduplication
/// - MIDI parsing for metadata extraction
/// - BPM and key detection
/// - Transaction-safe insertion to files and musical_metadata tables
///
/// # Arguments
///
/// * `filepath` - Path to the split MIDI file on disk
/// * `filename` - Filename to store in database
/// * `file_data` - MIDI file bytes (already in memory)
/// * `pool` - Database connection pool
///
/// # Returns
///
/// Database ID of the newly inserted file
///
/// # Errors
///
/// Returns error if database insertion fails or file already exists (duplicate hash)
async fn import_split_track(
    filepath: &Path,
    filename: &str,
    file_data: &[u8],
    pool: &sqlx::PgPool,
) -> Result<i64, Box<dyn std::error::Error + Send + Sync>> {
    // Calculate hash for deduplication (BLAKE3)
    let hash_bytes = calculate_file_hash(filepath)?;
    let content_hash: Vec<u8> = hash_bytes.to_vec();

    // Parse MIDI for metadata
    let midi_data = parse_midi_file(file_data)?;

    // Detect BPM
    let bpm_result = detect_bpm(&midi_data);
    let bpm = if bpm_result.confidence > 0.5 {
        Some(bpm_result.bpm)
    } else {
        None
    };

    // Detect key signature
    let key_result = detect_key(&midi_data);
    let key_signature = if key_result.confidence > 0.5 {
        Some(key_result.key.clone())
    } else {
        None
    };

    // Get file size
    let file_size_bytes = file_data.len() as i64;
    let filepath_str = filepath.to_str().ok_or("Invalid file path")?;

    // Begin transaction
    let mut tx = pool.begin().await?;

    // Insert file record
    let file_id = sqlx::query_scalar::<_, i64>(
        r#"
        INSERT INTO files (
            filename,
            original_filename,
            filepath,
            content_hash,
            file_size_bytes,
            num_tracks,
            created_at
        ) VALUES ($1, $2, $3, $4, $5, 1, NOW())
        ON CONFLICT (content_hash) DO NOTHING
        RETURNING id
        "#,
    )
    .bind(filename)
    .bind(filename) // Original filename is same as filename for splits
    .bind(filepath_str)
    .bind(&content_hash)
    .bind(file_size_bytes)
    .fetch_optional(&mut *tx)
    .await?
    .ok_or("File already exists (duplicate hash)")?;

    // Insert musical metadata if available
    if bpm.is_some() || key_signature.is_some() {
        sqlx::query(
            r#"
            INSERT INTO musical_metadata (
                file_id,
                bpm,
                key_signature,
                time_signature_numerator,
                time_signature_denominator
            ) VALUES ($1, $2, $3::musical_key, 4, 4)
            ON CONFLICT (file_id) DO UPDATE SET
                bpm = EXCLUDED.bpm,
                key_signature = EXCLUDED.key_signature
            "#,
        )
        .bind(file_id)
        .bind(bpm)
        .bind(key_signature.as_deref())
        .execute(&mut *tx)
        .await?;
    }

    // Commit transaction
    tx.commit().await?;

    Ok(file_id)
}

/// Insert relationship between parent file and split track into track_splits table.
///
/// Creates a record linking the parent multi-track file to the split single-track file
/// with metadata about the track (number, name, instrument, note count).
///
/// # Arguments
///
/// * `parent_file_id` - Database ID of the parent file
/// * `split_file_id` - Database ID of the split file
/// * `split_track` - Metadata about the split track
/// * `pool` - Database connection pool
///
/// # Errors
///
/// Returns error if insertion fails or relationship already exists
async fn insert_track_split_relationship(
    parent_file_id: i64,
    split_file_id: i64,
    split_track: &SplitTrack,
    pool: &sqlx::PgPool,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    sqlx::query!(
        r#"
        INSERT INTO track_splits (
            parent_file_id,
            split_file_id,
            track_number,
            track_name,
            instrument,
            note_count,
            created_at
        ) VALUES ($1, $2, $3, $4, $5, $6, NOW())
        "#,
        parent_file_id,
        split_file_id,
        split_track.track_number as i32,
        split_track.track_name.as_deref(),
        split_track.instrument.as_deref(),
        split_track.note_count as i32,
    )
    .execute(pool)
    .await?;

    Ok(())
}

//=============================================================================
// UTILITY FUNCTIONS (Pure - Could be Trusty Module)
//=============================================================================

/// Generate a filename for a split track based on metadata.
///
/// Format: `{base}_track_{num:02}_{instrument}.mid`
///
/// If instrument is not available, uses track name. If neither available,
/// uses just track number.
///
/// Sanitizes all components to ensure valid filenames.
///
/// # Arguments
///
/// * `base_filename` - Base filename from the parent file (without extension)
/// * `split_track` - Metadata about the split track
///
/// # Returns
///
/// Sanitized filename with .mid extension
///
/// # Examples
///
/// ```
/// use pipeline::commands::split_file::generate_split_filename;
/// use pipeline::core::splitting::track_splitter::SplitTrack;
///
/// let track = SplitTrack {
///     track_number: 1,
///     track_name: Some("Piano".to_string()),
///     channel: Some(0),
///     instrument: Some("Acoustic Grand Piano".to_string()),
///     note_count: 100,
///     midi_bytes: vec![],
/// };
///
/// let filename = generate_split_filename("my_song", &track);
/// assert_eq!(filename, "my_song_track_01_Acoustic_Grand_Piano.mid");
/// ```
pub fn generate_split_filename(base_filename: &str, split_track: &SplitTrack) -> String {
    let base = sanitize_filename(base_filename);
    let track_num = format!("{:02}", split_track.track_number);

    // Build suffix: prefer instrument, fall back to track name, then just number
    let suffix = if let Some(ref instrument) = split_track.instrument {
        sanitize_filename(instrument)
    } else if let Some(ref track_name) = split_track.track_name {
        sanitize_filename(track_name)
    } else {
        String::new()
    };

    if suffix.is_empty() {
        format!("{}_track_{}.mid", base, track_num)
    } else {
        format!("{}_track_{}_{}.mid", base, track_num, suffix)
    }
}

/// Sanitize a string to be used as a filename component.
///
/// Removes or replaces problematic characters:
/// - Replaces spaces with underscores
/// - Removes: / \ : * ? " < > | (filesystem-unsafe characters)
/// - Removes: control characters, non-ASCII if problematic
/// - Collapses multiple underscores to single underscore
/// - Trims underscores from start and end
///
/// # Arguments
///
/// * `name` - String to sanitize
///
/// # Returns
///
/// Sanitized string safe for use in filenames
///
/// # Examples
///
/// ```
/// use pipeline::commands::split_file::sanitize_filename;
///
/// assert_eq!(sanitize_filename("Piano Track"), "Piano_Track");
/// assert_eq!(sanitize_filename("Track: 1 (Lead)"), "Track_1_Lead");
/// assert_eq!(sanitize_filename("Bass/Guitar"), "BassGuitar");
/// assert_eq!(sanitize_filename("  Piano  "), "Piano");
/// ```
pub fn sanitize_filename(name: &str) -> String {
    name.chars()
        .map(|c| match c {
            // Replace spaces with underscores
            ' ' => '_',
            // Remove problematic characters
            '/' | '\\' | ':' | '*' | '?' | '"' | '<' | '>' | '|' => '_',
            // Keep alphanumeric, underscore, hyphen, period, parentheses
            c if c.is_alphanumeric() || c == '_' || c == '-' || c == '.' || c == '(' || c == ')' => c,
            // Replace everything else with underscore
            _ => '_',
        })
        .collect::<String>()
        // Collapse multiple underscores
        .split('_')
        .filter(|s| !s.is_empty())
        .collect::<Vec<_>>()
        .join("_")
}

/// Extract time signature from MIDI file events
/// Returns format like "4-4" for 4/4 time, or None if not found
fn extract_time_signature_from_midi(midi: &midi_library_shared::core::midi::types::MidiFile) -> Option<String> {
    use midi_library_shared::core::midi::types::Event;

    // Search all tracks for TimeSignature event
    for track in &midi.tracks {
        for timed_event in &track.events {
            if let Event::TimeSignature { numerator, denominator, .. } = &timed_event.event {
                // Convert denominator from power-of-2 format (e.g., 2 = quarter note = 4)
                let denom_value = 2_u8.pow(*denominator as u32);
                return Some(format!("{}-{}", numerator, denom_value));
            }
        }
    }

    None // No time signature found
}

//=============================================================================
// TESTS
//=============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sanitize_filename_spaces() {
        assert_eq!(sanitize_filename("Piano Track"), "Piano_Track");
        assert_eq!(sanitize_filename("My Song Name"), "My_Song_Name");
    }

    #[test]
    fn test_sanitize_filename_special_chars() {
        assert_eq!(sanitize_filename("Track: 1"), "Track_1");
        assert_eq!(sanitize_filename("Bass/Guitar"), "Bass_Guitar");
        assert_eq!(sanitize_filename("Lead (Synth)"), "Lead_(Synth)");
        assert_eq!(sanitize_filename("File*Name?"), "File_Name");
        assert_eq!(sanitize_filename("Path\\To\\File"), "Path_To_File");
    }

    #[test]
    fn test_sanitize_filename_multiple_underscores() {
        assert_eq!(sanitize_filename("Track___1"), "Track_1");
        assert_eq!(sanitize_filename("__Piano__"), "Piano");
        assert_eq!(sanitize_filename("A___B___C"), "A_B_C");
    }

    #[test]
    fn test_sanitize_filename_edge_cases() {
        assert_eq!(sanitize_filename(""), "");
        assert_eq!(sanitize_filename("   "), "");
        assert_eq!(sanitize_filename("___"), "");
        assert_eq!(sanitize_filename("ValidName123"), "ValidName123");
    }

    #[test]
    fn test_sanitize_filename_unicode() {
        // Keep alphanumeric Unicode (includes accented characters)
        assert_eq!(sanitize_filename("Caf√©"), "Caf√©");
        assert_eq!(sanitize_filename("Track‚ô™1"), "Track_1");
    }

    #[test]
    fn test_generate_split_filename_with_instrument() {
        let track = SplitTrack {
            track_number: 1,
            track_name: Some("Piano Part".to_string()),
            channel: Some(0),
            instrument: Some("Acoustic Grand Piano".to_string()),
            note_count: 100,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("my_song", &track);
        assert_eq!(filename, "my_song_track_01_Acoustic_Grand_Piano.mid");
    }

    #[test]
    fn test_generate_split_filename_with_track_name_only() {
        let track = SplitTrack {
            track_number: 2,
            track_name: Some("Bass Line".to_string()),
            channel: Some(1),
            instrument: None,
            note_count: 50,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("song", &track);
        assert_eq!(filename, "song_track_02_Bass_Line.mid");
    }

    #[test]
    fn test_generate_split_filename_no_metadata() {
        let track = SplitTrack {
            track_number: 0,
            track_name: None,
            channel: None,
            instrument: None,
            note_count: 10,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("minimal", &track);
        assert_eq!(filename, "minimal_track_00.mid");
    }

    #[test]
    fn test_generate_split_filename_sanitizes_base() {
        let track = SplitTrack {
            track_number: 5,
            track_name: None,
            channel: None,
            instrument: Some("Guitar".to_string()),
            note_count: 75,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("My/Bad\\Filename:1", &track);
        assert_eq!(filename, "My_Bad_Filename_1_track_05_Guitar.mid");
    }

    #[test]
    fn test_generate_split_filename_sanitizes_instrument() {
        let track = SplitTrack {
            track_number: 3,
            track_name: None,
            channel: None,
            instrument: Some("Electric Piano (DX7)".to_string()),
            note_count: 80,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("track", &track);
        assert_eq!(filename, "track_track_03_Electric_Piano_(DX7).mid");
    }

    #[test]
    fn test_generate_split_filename_high_track_numbers() {
        let track = SplitTrack {
            track_number: 99,
            track_name: None,
            channel: None,
            instrument: Some("Drums".to_string()),
            note_count: 200,
            midi_bytes: vec![],
        };

        let filename = generate_split_filename("orchestra", &track);
        assert_eq!(filename, "orchestra_track_99_Drums.mid");
    }
}

```

### `stats.rs` {#stats-rs}

- **Lines**: 239 (code: 220, comments: 0, blank: 19)

#### Source Code

```rust
/// Statistics command handlers - GROWN-UP SCRIPT ARCHETYPE
///
/// PURPOSE: Database statistics and metrics
/// ARCHETYPE: Grown-up Script (I/O operations)
///
/// ‚úÖ CAN: Perform database I/O
/// ‚úÖ CAN: Have side effects (complex queries)
/// ‚úÖ SHOULD: Handle errors properly
/// ‚ùå NO: Complex business logic (delegate to Trusty Modules)
use crate::AppState;
use std::collections::HashMap;
use tauri::State;

// =============================================================================
// TAURI COMMANDS
// =============================================================================

/// Get file count breakdown by category (implementation for tests and reuse)
pub async fn get_category_stats_impl(state: &AppState) -> Result<HashMap<String, i64>, String> {
    let results: Vec<(Option<String>, i64)> = sqlx::query_as(
        r#"
        SELECT fc.primary_category::text as category, COUNT(*) as count
        FROM files f
        LEFT JOIN file_categories fc ON f.id = fc.file_id
        GROUP BY fc.primary_category
        ORDER BY count DESC
        "#,
    )
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get category stats: {}", e))?;

    let mut stats = HashMap::new();
    for (category, count) in results {
        let category_name = category.unwrap_or_else(|| "Uncategorized".to_string());
        stats.insert(category_name, count);
    }

    Ok(stats)
}

/// Get file count breakdown by category
///
/// Returns a map of category names to file counts.
///
/// # Frontend Usage
///
/// ```typescript
/// const stats = await invoke<Record<string, number>>('get_category_stats');
/// // { "bass": 150, "drums": 200, "melody": 100 }
/// ```
#[tauri::command]
pub async fn get_category_stats(
    state: State<'_, AppState>,
) -> Result<HashMap<String, i64>, String> {
    get_category_stats_impl(&state).await
}

/// Get file count breakdown by manufacturer
///
/// Returns a map of manufacturer names to file counts.
///
/// # Frontend Usage
///
/// ```typescript
/// const stats = await invoke<Record<string, number>>('get_manufacturer_stats');
/// ```
#[tauri::command]
pub async fn get_manufacturer_stats(
    state: State<'_, AppState>,
) -> Result<HashMap<String, i64>, String> {
    let results: Vec<(Option<String>, i64)> = sqlx::query_as(
        r#"
        SELECT mm.manufacturer::text as manufacturer, COUNT(*) as count
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        WHERE mm.manufacturer IS NOT NULL
        GROUP BY mm.manufacturer
        ORDER BY count DESC
        "#,
    )
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get manufacturer stats: {}", e))?;

    let mut stats = HashMap::new();
    for (manufacturer, count) in results {
        if let Some(mfr) = manufacturer {
            stats.insert(mfr, count);
        }
    }

    Ok(stats)
}

/// Get file count breakdown by key signature
///
/// Returns a map of key signatures to file counts.
///
/// # Frontend Usage
///
/// ```typescript
/// const stats = await invoke<Record<string, number>>('get_key_signature_stats');
/// ```
#[tauri::command]
pub async fn get_key_signature_stats(
    state: State<'_, AppState>,
) -> Result<HashMap<String, i64>, String> {
    let results: Vec<(Option<String>, i64)> = sqlx::query_as(
        r#"
        SELECT mm.key_signature::text as key_sig, COUNT(*) as count
        FROM files f
        LEFT JOIN musical_metadata mm ON f.id = mm.file_id
        WHERE mm.key_signature IS NOT NULL
        GROUP BY mm.key_signature
        ORDER BY count DESC
        "#,
    )
    .fetch_all(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get key signature stats: {}", e))?;

    let mut stats = HashMap::new();
    for (key_sig, count) in results {
        if let Some(key) = key_sig {
            stats.insert(key, count);
        }
    }

    Ok(stats)
}

/// Get count of recently added files (last 7 days)
///
/// # Frontend Usage
///
/// ```typescript
/// const count = await invoke<number>('get_recently_added_count');
/// ```
#[tauri::command]
pub async fn get_recently_added_count(state: State<'_, AppState>) -> Result<i64, String> {
    let count: (i64,) = sqlx::query_as(
        r#"
        SELECT COUNT(*)
        FROM files
        WHERE created_at >= NOW() - INTERVAL '7 days'
        "#,
    )
    .fetch_one(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get recently added count: {}", e))?;

    Ok(count.0)
}

/// Get count of duplicate files
///
/// Files are considered duplicates if they have the same content hash.
///
/// # Frontend Usage
///
/// ```typescript
/// const count = await invoke<number>('get_duplicate_count');
/// ```
#[tauri::command]
pub async fn get_duplicate_count(state: State<'_, AppState>) -> Result<i64, String> {
    let count: (i64,) = sqlx::query_as(
        r#"
        SELECT COUNT(*)
        FROM (
            SELECT content_hash
            FROM files
            GROUP BY content_hash
            HAVING COUNT(*) > 1
        ) as duplicates
        "#,
    )
    .fetch_one(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get duplicate count: {}", e))?;

    Ok(count.0)
}

/// Get database size as formatted string (implementation for tests and reuse)
pub async fn get_database_size_impl(state: &AppState) -> Result<String, String> {
    let size: (Option<String>,) = sqlx::query_as(
        r#"
        SELECT pg_size_pretty(pg_database_size(current_database()))
        "#,
    )
    .fetch_one(&state.database.pool().await)
    .await
    .map_err(|e| format!("Failed to get database size: {}", e))?;

    Ok(size.0.unwrap_or_else(|| "Unknown".to_string()))
}

/// Get database size as formatted string
///
/// Returns the total size of the database in a human-readable format.
///
/// # Frontend Usage
///
/// ```typescript
/// const size = await invoke<string>('get_database_size');
/// // "125.4 MB"
/// ```
#[tauri::command]
pub async fn get_database_size(state: State<'_, AppState>) -> Result<String, String> {
    get_database_size_impl(&state).await
}

/// Check database health status
///
/// Returns health status based on connection and basic query tests.
///
/// # Frontend Usage
///
/// ```typescript
/// const health = await invoke<'good' | 'warning' | 'error'>('check_database_health');
/// ```
#[tauri::command]
pub async fn check_database_health(state: State<'_, AppState>) -> Result<String, String> {
    // Try a simple query
    match state.database.test_connection().await {
        Ok(_) => {
            // Check if we can count files
            match sqlx::query_scalar::<_, i64>("SELECT COUNT(*) FROM files")
                .fetch_one(&state.database.pool().await)
                .await
            {
                Ok(_) => Ok("good".to_string()),
                Err(_) => Ok("warning".to_string()),
            }
        },
        Err(_) => Ok("error".to_string()),
    }
}

```

### `system.rs` {#system-rs}

- **Lines**: 63 (code: 58, comments: 0, blank: 5)

#### Source Code

```rust
use crate::AppState;
/// System command handlers - GROWN-UP SCRIPT ARCHETYPE
///
/// PURPOSE: System-level operations and information
/// ARCHETYPE: Grown-up Script (I/O operations)
///
/// ‚úÖ CAN: Perform system I/O
/// ‚úÖ CAN: Have side effects
/// ‚úÖ SHOULD: Handle errors properly
/// ‚ùå NO: Complex business logic
use serde::Serialize;
use tauri::State;

// =============================================================================
// DATA STRUCTURES
// =============================================================================

/// System information response
#[derive(Debug, Serialize)]
pub struct SystemInfo {
    pub version: String,
    pub platform: String,
}

// =============================================================================
// TAURI COMMANDS
// =============================================================================

/// Get system information
///
/// Returns the application version and platform information.
///
/// # Frontend Usage
///
/// ```typescript
/// const info = await invoke<{version: string, platform: string}>('get_system_info');
/// // { version: "0.1.0", platform: "linux" }
/// ```
#[tauri::command]
pub async fn get_system_info() -> Result<SystemInfo, String> {
    Ok(SystemInfo {
        version: env!("CARGO_PKG_VERSION").to_string(),
        platform: std::env::consts::OS.to_string(),
    })
}

/// Initialize database connection on first use
///
/// This allows Tauri to start up without blocking, then connects
/// to database on first command. If already connected, returns ok.
///
/// # Frontend Usage
///
/// ```typescript
/// await invoke('initialize_database');
/// // Now all database commands will work
/// ```
#[tauri::command]
pub async fn initialize_database(_state: State<'_, AppState>) -> Result<(), String> {
    // Database is eagerly initialized in main.rs, so this is a no-op
    // This command exists for completeness if we switch to lazy initialization
    Ok(())
}

```

### `tags.rs` {#tags-rs}

- **Lines**: 298 (code: 251, comments: 0, blank: 47)

#### Source Code

```rust
use crate::db::repositories::tag_repository::{DbTag, TagRepository, TagWithCount};
/// Tag Commands - Tauri commands for tag operations
///
/// This module provides frontend-facing commands for:
/// - Retrieving tags for files
/// - Getting popular tags (for tag cloud)
/// - Searching tags (for autocomplete)
/// - Updating file tags
use crate::AppState;
use serde::{Deserialize, Serialize};
use tauri::State;

// =============================================================================
// TYPE DEFINITIONS
// =============================================================================

/// Tag for JSON serialization (frontend-friendly)
#[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]
pub struct TagResponse {
    pub id: i32,
    pub name: String,
    pub category: Option<String>,
    pub usage_count: i32,
}

impl From<DbTag> for TagResponse {
    fn from(db_tag: DbTag) -> Self {
        Self {
            id: db_tag.id,
            name: db_tag.name,
            category: db_tag.category,
            usage_count: db_tag.usage_count,
        }
    }
}

impl From<TagWithCount> for TagResponse {
    fn from(tag: TagWithCount) -> Self {
        Self { id: tag.id, name: tag.name, category: tag.category, usage_count: tag.usage_count }
    }
}

impl PartialEq<str> for TagResponse {
    fn eq(&self, other: &str) -> bool {
        self.name == other
    }
}

impl PartialEq<&str> for TagResponse {
    fn eq(&self, other: &&str) -> bool {
        self.name == *other
    }
}

// =============================================================================
// TAURI COMMANDS
// =============================================================================

/// Get all tags for a specific file (implementation for tests and reuse)
pub async fn get_file_tags_impl(
    file_id: i64,
    state: &AppState,
) -> Result<Vec<TagResponse>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let tags = repo
        .get_file_tags(file_id)
        .await
        .map_err(|e| format!("Failed to get file tags: {}", e))?;

    Ok(tags.into_iter().map(TagResponse::from).collect())
}

/// Get all tags for a specific file
#[tauri::command]
pub async fn get_file_tags(
    file_id: i64,
    state: State<'_, AppState>,
) -> Result<Vec<TagResponse>, String> {
    get_file_tags_impl(file_id, &state).await
}

/// Get popular tags with usage counts (implementation for tests and reuse)
pub async fn get_popular_tags_impl(
    limit: Option<i32>,
    state: &AppState,
) -> Result<Vec<TagResponse>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let limit = limit.unwrap_or(50);

    let tags = repo
        .get_popular_tags(limit)
        .await
        .map_err(|e| format!("Failed to get popular tags: {}", e))?;

    Ok(tags.into_iter().map(TagResponse::from).collect())
}

/// Get popular tags with usage counts (for tag cloud)
///
/// # Arguments
/// * `limit` - Maximum number of tags to return (default: 50)
#[tauri::command]
pub async fn get_popular_tags(
    limit: Option<i32>,
    state: State<'_, AppState>,
) -> Result<Vec<TagResponse>, String> {
    get_popular_tags_impl(limit, &state).await
}

/// Search tags by name prefix (implementation for tests and reuse)
pub async fn search_tags_impl(
    query: String,
    limit: Option<i32>,
    state: &AppState,
) -> Result<Vec<TagResponse>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let limit = limit.unwrap_or(10);

    let tags = repo
        .search_tags(&query, limit)
        .await
        .map_err(|e| format!("Failed to search tags: {}", e))?;

    Ok(tags.into_iter().map(TagResponse::from).collect())
}

/// Search tags by name prefix (for autocomplete)
///
/// # Arguments
/// * `query` - Search query (prefix match)
/// * `limit` - Maximum number of results (default: 10)
#[tauri::command]
pub async fn search_tags(
    query: String,
    limit: Option<i32>,
    state: State<'_, AppState>,
) -> Result<Vec<TagResponse>, String> {
    search_tags_impl(query, limit, &state).await
}

/// Get all unique tag categories
#[tauri::command]
pub async fn get_tag_categories(state: State<'_, AppState>) -> Result<Vec<String>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let categories = repo
        .get_tag_categories()
        .await
        .map_err(|e| format!("Failed to get tag categories: {}", e))?;

    Ok(categories)
}

/// Get tags by category
#[tauri::command]
pub async fn get_tags_by_category(
    category: String,
    state: State<'_, AppState>,
) -> Result<Vec<TagResponse>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let tags = repo
        .get_tags_by_category(&category)
        .await
        .map_err(|e| format!("Failed to get tags by category: {}", e))?;

    Ok(tags.into_iter().map(TagResponse::from).collect())
}

/// Update tags for a file (replace all existing tags)
///
/// # Arguments
/// * `file_id` - File ID
/// * `tag_names` - Array of tag names to set
#[tauri::command]
pub async fn update_file_tags(
    file_id: i64,
    tag_names: Vec<String>,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    // Get or create tags and get their IDs
    let tag_data: Vec<(String, Option<String>)> = tag_names
        .into_iter()
        .map(|name| (name, None)) // No category for user-added tags
        .collect();

    let tag_ids = repo
        .get_or_create_tags_batch(&tag_data)
        .await
        .map_err(|e| format!("Failed to create tags: {}", e))?;

    // Update file tags
    repo.update_file_tags(file_id, &tag_ids)
        .await
        .map_err(|e| format!("Failed to update file tags: {}", e))?;

    Ok(())
}

/// Add tags to a file (implementation for tests and reuse)
pub async fn add_tags_to_file_impl(
    file_id: i64,
    tag_names: Vec<String>,
    state: &AppState,
) -> Result<(), String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    // Get or create tags and get their IDs
    let tag_data: Vec<(String, Option<String>)> =
        tag_names.into_iter().map(|name| (name, None)).collect();

    let tag_ids = repo
        .get_or_create_tags_batch(&tag_data)
        .await
        .map_err(|e| format!("Failed to create tags: {}", e))?;

    // Add tags to file
    repo.add_tags_to_file(file_id, &tag_ids)
        .await
        .map_err(|e| format!("Failed to add tags to file: {}", e))?;

    Ok(())
}

/// Add tags to a file (without removing existing tags)
#[tauri::command]
pub async fn add_tags_to_file(
    file_id: i64,
    tag_names: Vec<String>,
    state: State<'_, AppState>,
) -> Result<(), String> {
    add_tags_to_file_impl(file_id, tag_names, &state).await
}

/// Remove a specific tag from a file
#[tauri::command]
pub async fn remove_tag_from_file(
    file_id: i64,
    tag_id: i32,
    state: State<'_, AppState>,
) -> Result<(), String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    repo.remove_tag_from_file(file_id, tag_id)
        .await
        .map_err(|e| format!("Failed to remove tag from file: {}", e))?;

    Ok(())
}

/// Get files by tags (for filtering)
///
/// # Arguments
/// * `tag_names` - Array of tag names to filter by
/// * `match_all` - If true, file must have ALL tags (AND logic). If false, file must have at least one tag (OR logic)
#[tauri::command]
pub async fn get_files_by_tags(
    tag_names: Vec<String>,
    match_all: bool,
    state: State<'_, AppState>,
) -> Result<Vec<i64>, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let file_ids = repo
        .get_files_by_tags(&tag_names, match_all)
        .await
        .map_err(|e| format!("Failed to get files by tags: {}", e))?;

    Ok(file_ids)
}

/// Get usage statistics for a tag
#[tauri::command]
pub async fn get_tag_stats(tag_id: i32, state: State<'_, AppState>) -> Result<i64, String> {
    let pool = state.database.pool().await;
    let repo = TagRepository::new(pool);

    let count = repo
        .get_tag_file_count(tag_id)
        .await
        .map_err(|e| format!("Failed to get tag stats: {}", e))?;

    Ok(count)
}

```

### `window.rs` {#window-rs}

- **Lines**: 578 (code: 495, comments: 0, blank: 83)

#### Source Code

```rust
/// Tauri command handlers for DAW windows
///
/// Grown-up Scripts: Expose DAW window operations to frontend.
/// All commands use proper error handling with Result<T, String>.
use crate::windows::{
    DAWWindowState, MixerWindowState, PlaybackPosition, PlaybackState, TrackInfo,
};
use std::sync::Arc;
use tokio::sync::RwLock;

/// Shared state for DAW windows
///
/// Managed by Tauri and shared across all window commands.
pub struct DAWState {
    /// DAW window state (transport, tracks, playback)
    pub daw: Arc<RwLock<DAWWindowState>>,
    /// Mixer window state (channels, volume, pan)
    pub mixer: Arc<RwLock<MixerWindowState>>,
}

impl DAWState {
    /// Create new DAW state
    pub fn new() -> Self {
        DAWState {
            daw: Arc::new(RwLock::new(DAWWindowState::new())),
            mixer: Arc::new(RwLock::new(MixerWindowState::new())),
        }
    }
}

impl Default for DAWState {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// Transport Commands
// ============================================================================

/// Start playback
#[tauri::command]
pub async fn play_transport(state: tauri::State<'_, DAWState>) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    daw.playback_state = PlaybackState::Playing;
    Ok(())
}

/// Stop playback (reset position to start)
#[tauri::command]
pub async fn stop_transport(state: tauri::State<'_, DAWState>) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    daw.playback_state = PlaybackState::Stopped;
    daw.transport.position = PlaybackPosition::default();
    Ok(())
}

/// Pause playback (keep current position)
#[tauri::command]
pub async fn pause_transport(state: tauri::State<'_, DAWState>) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    if !daw.playback_state.can_pause() {
        return Err("Cannot pause when not playing".to_string());
    }
    daw.playback_state = PlaybackState::Paused;
    Ok(())
}

/// Set playback position
#[tauri::command]
pub async fn set_playback_position(
    state: tauri::State<'_, DAWState>,
    bar: i32,
    beat: i32,
    tick: i32,
) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    let position = PlaybackPosition::new(bar, beat, tick);

    if !position.is_valid() {
        return Err(format!(
            "Invalid position: bar={}, beat={}, tick={}",
            bar, beat, tick
        ));
    }

    daw.transport.position = position;
    Ok(())
}

/// Get current playback state
#[tauri::command]
pub async fn get_playback_state(
    state: tauri::State<'_, DAWState>,
) -> Result<PlaybackState, String> {
    let daw = state.daw.read().await;
    Ok(daw.playback_state)
}

// ============================================================================
// Tempo and Key Commands
// ============================================================================

/// Set tempo (BPM)
#[tauri::command]
pub async fn set_bpm(state: tauri::State<'_, DAWState>, bpm: f32) -> Result<(), String> {
    if !(20.0..=999.0).contains(&bpm) {
        return Err(format!("BPM {} out of range (20-999)", bpm));
    }

    let mut daw = state.daw.write().await;
    daw.transport.bpm = bpm;
    Ok(())
}

/// Get current tempo
#[tauri::command]
pub async fn get_bpm(state: tauri::State<'_, DAWState>) -> Result<f32, String> {
    let daw = state.daw.read().await;
    Ok(daw.transport.bpm)
}

/// Set time signature
#[tauri::command]
pub async fn set_time_signature(
    state: tauri::State<'_, DAWState>,
    numerator: u8,
    denominator: u8,
) -> Result<(), String> {
    if !(1..=32).contains(&numerator) {
        return Err(format!("Invalid numerator: {}", numerator));
    }

    if !matches!(denominator, 1 | 2 | 4 | 8 | 16 | 32) {
        return Err(format!("Invalid denominator: {}", denominator));
    }

    let mut daw = state.daw.write().await;
    daw.transport.time_signature_numerator = numerator;
    daw.transport.time_signature_denominator = denominator;
    Ok(())
}

/// Get current time signature
#[tauri::command]
pub async fn get_time_signature(state: tauri::State<'_, DAWState>) -> Result<(u8, u8), String> {
    let daw = state.daw.read().await;
    Ok((
        daw.transport.time_signature_numerator,
        daw.transport.time_signature_denominator,
    ))
}

/// Set key signature
#[tauri::command]
pub async fn set_key_signature(
    state: tauri::State<'_, DAWState>,
    key: String,
) -> Result<(), String> {
    // Validate key signature format (basic check)
    if key.is_empty() || key.len() > 3 {
        return Err(format!("Invalid key signature: {}", key));
    }

    let mut daw = state.daw.write().await;
    daw.transport.key_signature = key;
    Ok(())
}

/// Get current key signature
#[tauri::command]
pub async fn get_key_signature(state: tauri::State<'_, DAWState>) -> Result<String, String> {
    let daw = state.daw.read().await;
    Ok(daw.transport.key_signature.clone())
}

// ============================================================================
// Track Commands
// ============================================================================

/// Add a new track to DAW window
#[tauri::command]
pub async fn add_window_track(
    state: tauri::State<'_, DAWState>,
    label: String,
) -> Result<i32, String> {
    if label.is_empty() {
        return Err("Track label cannot be empty".to_string());
    }

    let mut daw = state.daw.write().await;
    let track_id = daw.add_track(label.clone());

    // Sync with mixer
    let track = daw.get_track(track_id).ok_or("Track not found")?;
    let mut mixer = state.mixer.write().await;
    mixer.add_channel_from_track(track);

    Ok(track_id)
}

/// Remove a track from DAW window
#[tauri::command]
pub async fn remove_window_track(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    daw.remove_track(track_id)
        .ok_or_else(|| format!("Track {} not found", track_id))?;

    // Remove from mixer
    let mut mixer = state.mixer.write().await;
    mixer.remove_channel(track_id);

    Ok(())
}

/// Get all tracks from DAW window
#[tauri::command]
pub async fn get_all_window_tracks(
    state: tauri::State<'_, DAWState>,
) -> Result<Vec<TrackInfo>, String> {
    let daw = state.daw.read().await;
    Ok(daw.get_all_tracks())
}

/// Set track visibility
#[tauri::command]
pub async fn set_track_visible(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
    visible: bool,
) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    let track = daw
        .get_track_mut(track_id)
        .ok_or_else(|| format!("Track {} not found", track_id))?;
    track.visible = visible;
    Ok(())
}

/// Set track muted
#[tauri::command]
pub async fn set_track_muted(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
    muted: bool,
) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    let track = daw
        .get_track_mut(track_id)
        .ok_or_else(|| format!("Track {} not found", track_id))?;
    track.muted = muted;

    // Sync with mixer
    let mut mixer = state.mixer.write().await;
    if let Some(channel) = mixer.get_channel_mut(track_id) {
        channel.muted = muted;
    }

    Ok(())
}

/// Set track soloed
#[tauri::command]
pub async fn set_track_soloed(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
    soloed: bool,
) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    let track = daw
        .get_track_mut(track_id)
        .ok_or_else(|| format!("Track {} not found", track_id))?;
    track.soloed = soloed;

    // Sync with mixer
    let mut mixer = state.mixer.write().await;
    if let Some(channel) = mixer.get_channel_mut(track_id) {
        channel.soloed = soloed;
    }

    Ok(())
}

/// Get track info by ID
#[tauri::command]
pub async fn get_track_info(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
) -> Result<TrackInfo, String> {
    let daw = state.daw.read().await;
    daw.get_track(track_id)
        .cloned()
        .ok_or_else(|| format!("Track {} not found", track_id))
}

/// Update track label
#[tauri::command]
pub async fn update_track_label(
    state: tauri::State<'_, DAWState>,
    track_id: i32,
    label: String,
) -> Result<(), String> {
    if label.is_empty() {
        return Err("Track label cannot be empty".to_string());
    }

    let mut daw = state.daw.write().await;
    let track = daw
        .get_track_mut(track_id)
        .ok_or_else(|| format!("Track {} not found", track_id))?;
    track.label = label.clone();

    // Sync with mixer
    let mut mixer = state.mixer.write().await;
    if let Some(channel) = mixer.get_channel_mut(track_id) {
        channel.label = label;
    }

    Ok(())
}

// ============================================================================
// Mixer Commands
// ============================================================================

/// Get complete mixer state
#[tauri::command]
pub async fn get_mixer_state(
    state: tauri::State<'_, DAWState>,
) -> Result<MixerWindowState, String> {
    let mixer = state.mixer.read().await;
    Ok(mixer.clone())
}

/// Set channel volume
#[tauri::command]
pub async fn set_channel_volume(
    state: tauri::State<'_, DAWState>,
    channel_id: i32,
    volume: f32,
) -> Result<(), String> {
    if !(0.0..=1.0).contains(&volume) {
        return Err(format!("Volume {} out of range (0.0-1.0)", volume));
    }

    let mut mixer = state.mixer.write().await;

    if channel_id == -1 {
        mixer.master.volume = volume;
    } else {
        let channel = mixer
            .get_channel_mut(channel_id)
            .ok_or_else(|| format!("Channel {} not found", channel_id))?;
        channel.volume = volume;
    }

    Ok(())
}

/// Set channel pan
#[tauri::command]
pub async fn set_channel_pan(
    state: tauri::State<'_, DAWState>,
    channel_id: i32,
    pan: f32,
) -> Result<(), String> {
    if !(-1.0..=1.0).contains(&pan) {
        return Err(format!("Pan {} out of range (-1.0 to 1.0)", pan));
    }

    let mut mixer = state.mixer.write().await;

    if channel_id == -1 {
        mixer.master.pan = pan;
    } else {
        let channel = mixer
            .get_channel_mut(channel_id)
            .ok_or_else(|| format!("Channel {} not found", channel_id))?;
        channel.pan = pan;
    }

    Ok(())
}

/// Set channel mute
#[tauri::command]
pub async fn set_channel_mute(
    state: tauri::State<'_, DAWState>,
    channel_id: i32,
    muted: bool,
) -> Result<(), String> {
    let mut mixer = state.mixer.write().await;

    if channel_id == -1 {
        mixer.master.muted = muted;
    } else {
        let channel = mixer
            .get_channel_mut(channel_id)
            .ok_or_else(|| format!("Channel {} not found", channel_id))?;
        channel.muted = muted;
    }

    // Sync with DAW tracks
    if channel_id != -1 {
        let mut daw = state.daw.write().await;
        if let Some(track) = daw.get_track_mut(channel_id) {
            track.muted = muted;
        }
    }

    Ok(())
}

/// Set channel solo
#[tauri::command]
pub async fn set_channel_solo(
    state: tauri::State<'_, DAWState>,
    channel_id: i32,
    soloed: bool,
) -> Result<(), String> {
    let mut mixer = state.mixer.write().await;

    let channel = mixer
        .get_channel_mut(channel_id)
        .ok_or_else(|| format!("Channel {} not found", channel_id))?;
    channel.soloed = soloed;

    // Sync with DAW tracks
    let mut daw = state.daw.write().await;
    if let Some(track) = daw.get_track_mut(channel_id) {
        track.soloed = soloed;
    }

    Ok(())
}

// ============================================================================
// State Commands
// ============================================================================

/// Get complete DAW state
#[tauri::command]
pub async fn get_daw_state(state: tauri::State<'_, DAWState>) -> Result<DAWWindowState, String> {
    let daw = state.daw.read().await;
    Ok(daw.clone())
}

/// Reset DAW state to defaults
#[tauri::command]
pub async fn reset_daw_state(state: tauri::State<'_, DAWState>) -> Result<(), String> {
    let mut daw = state.daw.write().await;
    *daw = DAWWindowState::new();

    let mut mixer = state.mixer.write().await;
    *mixer = MixerWindowState::new();

    Ok(())
}

#[cfg(test)]
mod tests {
    // Temporarily disabled - Tauri State mocking needs proper setup
    /*
    fn create_test_state() -> DAWState {
        DAWState::new()
    }

    #[tokio::test]
    async fn test_transport_commands() {
        let state = create_test_state();

        // Start playback
        play_transport(tauri::State::from(&state))
            .await
            .unwrap();
        let playback_state = get_playback_state(tauri::State::from(&state))
            .await
            .unwrap();
        assert_eq!(playback_state, PlaybackState::Playing);

        // Pause
        pause_transport(tauri::State::from(&state))
            .await
            .unwrap();
        let playback_state = get_playback_state(tauri::State::from(&state))
            .await
            .unwrap();
        assert_eq!(playback_state, PlaybackState::Paused);

        // Stop
        stop_transport(tauri::State::from(&state)).await.unwrap();
        let playback_state = get_playback_state(tauri::State::from(&state))
            .await
            .unwrap();
        assert_eq!(playback_state, PlaybackState::Stopped);
    }

    #[tokio::test]
    async fn test_bpm_commands() {
        let state = create_test_state();

        set_bpm(tauri::State::from(&state), 140.0)
            .await
            .unwrap();
        let bpm = get_bpm(tauri::State::from(&state)).await.unwrap();
        assert_eq!(bpm, 140.0);

        // Test invalid BPM
        let result = set_bpm(tauri::State::from(&state), 1000.0).await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_track_commands() {
        let state = create_test_state();

        // Add track
        let track_id = add_window_track(tauri::State::from(&state), "Piano".to_string())
            .await
            .unwrap();
        assert_eq!(track_id, 1);

        // Get tracks
        let tracks = get_all_window_tracks(tauri::State::from(&state))
            .await
            .unwrap();
        assert_eq!(tracks.len(), 1);
        assert_eq!(tracks[0].label, "Piano");

        // Set track muted
        set_track_muted(tauri::State::from(&state), track_id, true)
            .await
            .unwrap();
        let track = get_track_info(tauri::State::from(&state), track_id)
            .await
            .unwrap();
        assert!(track.muted);

        // Remove track
        remove_window_track(tauri::State::from(&state), track_id)
            .await
            .unwrap();
        let tracks = get_all_window_tracks(tauri::State::from(&state))
            .await
            .unwrap();
        assert_eq!(tracks.len(), 0);
    }

    #[tokio::test]
    async fn test_mixer_sync() {
        let state = create_test_state();

        // Add track
        let track_id = add_window_track(tauri::State::from(&state), "Piano".to_string())
            .await
            .unwrap();

        // Check mixer has channel
        let mixer_state = get_mixer_state(tauri::State::from(&state))
            .await
            .unwrap();
        assert!(mixer_state.channels.contains_key(&track_id));

        // Set channel volume
        set_channel_volume(tauri::State::from(&state), track_id, 0.5)
            .await
            .unwrap();
        let mixer_state = get_mixer_state(tauri::State::from(&state))
            .await
            .unwrap();
        let channel = mixer_state.channels.get(&track_id).unwrap();
        assert_eq!(channel.volume, 0.5);
    }
    */
}

```

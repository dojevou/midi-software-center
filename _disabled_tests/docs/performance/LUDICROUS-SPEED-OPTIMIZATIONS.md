# üöÄ LUDICROUS SPEED Import Optimizations

**Complete guide to ALL Rust and SQL optimizations for maximum import speed**

Created: 2025-11-17
Target Speed: 1500-2000+ files/sec (3-5x faster than normal)
Est. Time Savings: 6+ hours on 4M+ file import

---

## üìä Performance Comparison

| Mode | Speed | ETA (4M files) | Optimizations |
|------|-------|----------------|---------------|
| **Normal** | 388 files/sec | ~9 hours | Standard settings, all indexes |
| **Fast** | 800 files/sec | ~4.5 hours | Indexes dropped, fsync off |
| **LUDICROUS** | 1500+ files/sec | ~2-3 hours | ALL optimizations enabled |

---

## üîß PostgreSQL (SQL) Optimizations

### Level 1: Basic Speed Boost (2x faster)
```sql
-- Disable synchronous commits (async writes)
ALTER SYSTEM SET synchronous_commit = 'off';

-- Increase memory buffers
ALTER SYSTEM SET maintenance_work_mem = '2GB';
ALTER SYSTEM SET work_mem = '256MB';

-- Larger WAL
ALTER SYSTEM SET max_wal_size = '4GB';
ALTER SYSTEM SET wal_buffers = '16MB';

SELECT pg_reload_conf();
```

### Level 2: Drop Indexes (3x faster)
```bash
# Backup all indexes first
docker exec midi-library-postgres pg_dump -U midiuser -d midi_library \
  --schema-only --table=files --table=musical_metadata | \
  grep "CREATE INDEX" > database/INDEX_BACKUP.sql

# Drop 39 non-essential indexes
docker exec midi-library-postgres psql -U midiuser -d midi_library <<SQL
DROP INDEX IF EXISTS idx_files_batch CASCADE;
DROP INDEX IF EXISTS idx_files_collection CASCADE;
-- ... (see scripts/LUDICROUS-SPEED-import.sh for full list)
SQL
```

### Level 3: LUDICROUS MODE (5x faster!)
```sql
-- DANGER: Disable fsync (no crash safety!)
ALTER SYSTEM SET fsync = 'off';
ALTER SYSTEM SET full_page_writes = 'off';
ALTER SYSTEM SET wal_level = 'minimal';

-- Convert to UNLOGGED tables (10x faster writes!)
ALTER TABLE files SET UNLOGGED;
ALTER TABLE musical_metadata SET UNLOGGED;

-- Disable autovacuum during import
ALTER SYSTEM SET autovacuum = 'off';

-- Maximum parallel workers
ALTER SYSTEM SET max_parallel_workers = 64;
ALTER SYSTEM SET max_parallel_workers_per_gather = 32;

SELECT pg_reload_conf();
```

---

## ü¶Ä Rust (App) Optimizations

### Level 1: Parallel Processing
```toml
# Cargo.toml dependencies
[dependencies]
rayon = "1.8"  # CPU-parallel file processing
tokio = { version = "1.35", features = ["rt-multi-thread"] }  # Async runtime
crossbeam = "0.8"  # Lock-free channels
dashmap = "5.5"  # Concurrent hash map
```

```rust
// Use all CPU cores
use rayon::prelude::*;

files.par_iter()
    .map(|file| process_midi(file))
    .collect()
```

### Level 2: Batch Database Operations
```rust
// Large batch inserts with SQL unnest()
const BATCH_SIZE: usize = 3_200;  // 3,200 records per transaction

sqlx::query(r#"
    INSERT INTO files (filename, filepath, ...)
    SELECT * FROM unnest($1::text[], $2::text[], ...)
"#)
.bind(&filenames)
.bind(&filepaths)
.execute(&pool)
.await?;
```

### Level 3: Advanced Extraction
```toml
# Ultra-fast parallel decompression
[dependencies]
flate2 = { version = "1.0", features = ["zlib-ng"] }  # 2x faster zlib
async-compression = { version = "0.4", features = ["tokio", "gzip", "bzip2", "xz", "zstd"] }
memmap2 = "0.9"  # Memory-mapped I/O (zero-copy)
```

### Level 4: Compiler Optimizations
```toml
# .cargo/config.toml
[profile.release]
opt-level = 3
lto = "fat"  # Full link-time optimization
codegen-units = 1  # Single codegen unit
panic = "abort"
strip = true

[build]
rustflags = [
    "-C", "target-cpu=native",  # Use ALL CPU instructions
    "-C", "target-feature=+avx2,+fma",  # Enable AVX2 + FMA
]
```

---

## üíæ System-Level Optimizations

### 1. Parallel Archive Extraction
```bash
# Install parallel decompression tools
sudo apt-get install -y pigz pbzip2 pixz pzstd parallel

# Extract 8 archives simultaneously
./scripts/parallel-extract-all.sh
```

**Tools:**
- `pigz`: Parallel gzip (uses all cores)
- `pbzip2`: Parallel bzip2 (4x faster)
- `pixz`: Parallel xz (8x faster)
- `GNU parallel`: Job controller

### 2. System Tuning
```bash
# Increase file descriptors
ulimit -n 65536

# CPU performance mode
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# Disable swap (prevents I/O stalls)
sudo swapoff -a

# Enable transparent huge pages
echo always | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
```

---

## üéØ Complete LUDICROUS SPEED Workflow

### Step 1: Backup & Prepare
```bash
# Backup indexes
docker exec midi-library-postgres pg_dump -U midiuser -d midi_library \
  --schema-only --table=files --table=musical_metadata | \
  grep "CREATE INDEX" > database/INDEX_BACKUP.sql
```

### Step 2: Run LUDICROUS SPEED Import
```bash
chmod +x scripts/LUDICROUS-SPEED-import.sh
./scripts/LUDICROUS-SPEED-import.sh

# Monitor progress
tail -f /tmp/ludicrous_import.log

# Watch speed in real-time
watch -n 2 'tail -3 /tmp/ludicrous_import.log'
```

### Step 3: Restore Safety Features
```bash
# After import completes
./scripts/restore-safety.sh

# Convert tables back to LOGGED
# Restore fsync, synchronous_commit, etc.
```

### Step 4: Rebuild Indexes
```bash
./scripts/rebuild-indexes.sh

# Rebuilds all 39 indexes from backup
# Runs ANALYZE to update statistics
```

---

## üìà Expected Performance

### Import Speed Progression
1. **Initial**: 50-100 files/sec (warming up)
2. **Ramp-up**: 200-400 files/sec (cache warming)
3. **Steady State**: 800-1200 files/sec (normal LUDICROUS)
4. **Peak**: 1500-2000+ files/sec (UNLOGGED + no indexes)

### Bottlenecks by Phase
| Phase | Bottleneck | Solution |
|-------|-----------|----------|
| Archive extraction | CPU decompression | Use pigz/pbzip2 parallel extraction |
| MIDI parsing | CPU processing | 64 Rayon workers + Rust optimizations |
| Database inserts | Index updates | Drop indexes, use UNLOGGED tables |
| Disk I/O | Write throughput | fsync=off, larger WAL buffers |

---

## ‚ö†Ô∏è Safety Warnings

### LUDICROUS MODE Risks
- **fsync=off**: Data loss if crash during import
- **UNLOGGED tables**: All data lost if PostgreSQL crashes
- **No indexes**: Queries will be SLOW until rebuilt

### Recommended Precautions
1. ‚úÖ Backup database before starting
2. ‚úÖ Use UPS (prevent power loss)
3. ‚úÖ Don't run on production server
4. ‚úÖ Monitor disk space (10GB+ WAL)
5. ‚úÖ Restore safety features immediately after import

---

## üîç Monitoring & Debugging

### Check Current Speed
```bash
tail -5 /tmp/ludicrous_import.log
```

### Database Statistics
```bash
docker exec midi-library-postgres psql -U midiuser -d midi_library -c \
  "SELECT COUNT(*) as files_imported FROM files"
```

### Index Status
```bash
docker exec midi-library-postgres psql -U midiuser -d midi_library -c \
  "SELECT count(*) FROM pg_indexes WHERE tablename IN ('files', 'musical_metadata')"
```

### PostgreSQL Settings
```bash
docker exec midi-library-postgres psql -U midiuser -d midi_library -c \
  "SHOW synchronous_commit; SHOW fsync; SHOW autovacuum;"
```

---

## üìù Scripts Reference

### Created Scripts
1. `scripts/LUDICROUS-SPEED-import.sh` - Main ultra-fast import
2. `scripts/restore-safety.sh` - Restore PostgreSQL safety
3. `scripts/rebuild-indexes.sh` - Rebuild all 39 indexes
4. `scripts/parallel-extract-all.sh` - Parallel archive extraction

### Database Files
1. `database/INDEX_BACKUP.sql` - All 39 index definitions

### Configuration Files
1. `.cargo/config.toml` - Rust compiler optimizations

---

## üí° Additional Optimizations to Consider

### Future Enhancements
1. **SSD Caching**: Use bcache or LVM cache
2. **RAID 0**: Stripe writes across multiple disks
3. **tmpfs**: Extract to RAM filesystem
4. **Async COPY**: Use PostgreSQL COPY instead of INSERT
5. **Compiled Rust**: Pre-build with PGO (Profile-Guided Optimization)

### Rust Crates to Add
```toml
# Even faster extraction
zstd = "0.13"  # Zstandard compression (fastest)
lz4 = "1.24"  # LZ4 compression (very fast)

# Lock-free data structures
lockfree = "0.5"
parking_lot = "0.12"  # Faster mutexes

# SIMD acceleration
simdeez = "1.0"  # SIMD utilities
```

---

## üéâ Summary

**Total Speed Improvement: 3-5x faster**

| Optimization | Speed Gain | Effort | Risk |
|-------------|------------|--------|------|
| Drop indexes | 2-3x | Low | None (rebuildable) |
| fsync=off | 3-5x | Low | High (data loss) |
| UNLOGGED tables | 10x writes | Low | High (data loss) |
| Parallel extraction | 8x | Medium | None |
| Rust optimizations | 1.5-2x | Medium | None |
| System tuning | 1.2-1.5x | Low | Low |

**Combined Effect:** 388 files/sec ‚Üí 1500+ files/sec (**~4x total**)

**Time Saved:** 9 hours ‚Üí 2-3 hours (**~6 hours saved!**)

---

Generated: 2025-11-17
Import Log: `/tmp/ludicrous_import.log`
Monitor: `tail -f /tmp/ludicrous_import.log`

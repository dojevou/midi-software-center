<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>:root {
  --color: black;
  --bg: white;
  --head-bg: white;
  --link: #338;

  --blue: #ccf;
  --red: #fcc;
  --yellow: #ffc;
  --green: #cfc;
}

[data-theme='dark'] {
  --color: white;
  --bg: black;
  --head-bg: #333;
  --link: #aaf;

  --blue: #225;
  --red: #522;
  --yellow: #552;
  --green: #252;
}

html,
body {
  margin: 0;
  padding: 0;
  color: var(--color);
  background: var(--bg);
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: var(--head-bg);
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: var(--blue);
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: var(--red);
}
.files-list__file_medium {
  background: var(--yellow);
}
.files-list__file_high {
  background: var(--green);
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: var(--bg);
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: var(--link);
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
  content: counter(line);
  margin-right: 10px;
}
.code-line {
  margin: 0;
  padding: 0.3em;
  height: 1em;
  counter-increment: line;
}
.code-line_covered {
  background: var(--green);
}
.code-line_uncovered {
  background: var(--red);
}

#theme-toggle-label {
  margin-left: 1ch;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","build.rs"],"content":"fn main() {\n    tauri_build::build()\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","analysis.rs"],"content":"//! Analysis Tauri commands\n//!\n//! Grown-up Script: I/O wrapper for musical analysis and compatibility matching.\n//! Updated to use proper JOINs with actual database schema.\n\nuse crate::commands::AppState;\nuse crate::core::compatibility;\nuse crate::models::analysis::CompatibleFile;\nuse crate::models::midi_file::MidiFile;\nuse tauri::State;\nuse tracing::{debug, error};\n\n/// Find files that are musically compatible with a given file\n///\n/// Returns files sorted by compatibility score (highest first).\n/// Considers key signature, BPM, and time signature.\n///\n/// # Arguments\n/// * `file_id` - The reference file to find compatible files for\n/// * `max_results` - Maximum number of results to return (default: 20, max: 100)\n#[tauri::command]\npub async fn find_compatible_files(\n    file_id: i32,\n    max_results: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cCompatibleFile\u003e, String\u003e {\n    debug!(\"Finding compatible files for file ID: {}\", file_id);\n\n    let max = max_results.unwrap_or(20).min(100);\n\n    // Get reference file with proper JOINs\n    let ref_file = sqlx::query_as!(\n        MidiFile,\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.content_hash as \"content_hash!\",\n            f.is_multi_track as \"is_multi_track!\",\n            f.parent_file_id as \"parent_file_id?\",\n            f.track_number as \"track_number?\",\n            f.total_tracks as \"total_tracks?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"folder_tags!\",\n            f.parent_folder as \"parent_folder?\",\n            f.num_tracks,\n            f.created_at as \"created_at!\",\n            f.analyzed_at as \"analyzed_at?\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) as \"total_notes!\",\n            fc.primary_category::TEXT as \"primary_category?\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to get reference file: {}\", e);\n        format!(\"Failed to get reference file: {}\", e)\n    })?;\n\n    let ref_file = ref_file.ok_or_else(|| format!(\"File with ID {} not found\", file_id))?;\n\n    debug!(\n        \"Reference file - BPM: {:?}, Key: {:?}, Time sig: {:?}\",\n        ref_file.bpm, ref_file.key_signature, ref_file.time_signature\n    );\n\n    // Get all other files with proper JOINs\n    let candidate_files = sqlx::query_as!(\n        MidiFile,\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.content_hash as \"content_hash!\",\n            f.is_multi_track as \"is_multi_track!\",\n            f.parent_file_id as \"parent_file_id?\",\n            f.track_number as \"track_number?\",\n            f.total_tracks as \"total_tracks?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"folder_tags!\",\n            f.parent_folder as \"parent_folder?\",\n            f.num_tracks,\n            f.created_at as \"created_at!\",\n            f.analyzed_at as \"analyzed_at?\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) as \"total_notes!\",\n            fc.primary_category::TEXT as \"primary_category?\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id != $1\n        LIMIT 500\n        \"#,\n        file_id as i64\n    )\n    .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to fetch candidate files: {}\", e);\n        format!(\"Failed to fetch files: {}\", e)\n    })?;\n\n    let mut compatible_files: Vec\u003cCompatibleFile\u003e = candidate_files\n        .iter()\n        .map(|candidate| {\n            // Use Trusty Module to calculate compatibility (pure function)\n            let score = compatibility::calculate_compatibility(\u0026ref_file, candidate);\n\n            // Calculate BPM-based time stretch suggestion\n            let suggested_bpm_multiplier = if let (Some(ref_bpm), Some(cand_bpm)) = (ref_file.bpm, candidate.bpm) {\n                let ratio = cand_bpm / ref_bpm;\n                // Suggest multiplier if it's a simple ratio\n                if (ratio - 0.5).abs() \u003c 0.05 { Some(0.5) }\n                else if (ratio - 2.0).abs() \u003c 0.1 { Some(2.0) }\n                else if (ratio - 1.5).abs() \u003c 0.1 { Some(1.5) }\n                else if (ratio - 0.75).abs() \u003c 0.05 { Some(0.75) }\n                else { None }\n            } else {\n                None\n            };\n\n            CompatibleFile {\n                id: candidate.id as i32,\n                file_name: candidate.filename.clone(),\n                compatibility_score: score.total_score as i32, // Convert f32 to i32\n                key_match: ref_file.key_signature == candidate.key_signature,\n                bpm_difference: if let (Some(ref_bpm), Some(cand_bpm)) = (ref_file.bpm, candidate.bpm) {\n                    Some((ref_bpm - cand_bpm).abs() as f32)\n                } else {\n                    None\n                },\n                time_signature_match: ref_file.time_signature == candidate.time_signature,\n                suggested_bpm_multiplier,\n                category: candidate.primary_category.clone(),\n            }\n        })\n        .collect();\n\n    // Sort by compatibility score (descending)\n    compatible_files.sort_by(|a, b| b.compatibility_score.cmp(\u0026a.compatibility_score));\n\n    // Take top N results\n    compatible_files.truncate(max as usize);\n\n    debug!(\n        \"Returning {} compatible files (top score: {})\",\n        compatible_files.len(),\n        compatible_files.first().map(|f| f.compatibility_score).unwrap_or(0)\n    );\n\n    Ok(compatible_files)\n}\n\n/// Add file to favorites\n#[tauri::command]\npub async fn add_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Adding file {} to favorites\", file_id);\n\n    // Insert into favorites table (ON CONFLICT DO NOTHING to handle duplicates)\n    sqlx::query!(\n        \"INSERT INTO favorites (file_id) VALUES ($1) ON CONFLICT (file_id) DO NOTHING\",\n        file_id as i64\n    )\n    .execute(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to add favorite: {}\", e);\n        format!(\"Failed to add favorite: {}\", e)\n    })?;\n\n    debug!(\"Successfully added file {} to favorites\", file_id);\n    Ok(())\n}\n\n/// Remove file from favorites\n#[tauri::command]\npub async fn remove_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Removing file {} from favorites\", file_id);\n\n    sqlx::query!(\n        \"DELETE FROM favorites WHERE file_id = $1\",\n        file_id as i64\n    )\n    .execute(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to remove favorite: {}\", e);\n        format!(\"Failed to remove favorite: {}\", e)\n    })?;\n\n    debug!(\"Successfully removed file {} from favorites\", file_id);\n    Ok(())\n}\n\n/// Check if a file is favorited\n#[tauri::command]\npub async fn is_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    let result = sqlx::query!(\n        \"SELECT EXISTS(SELECT 1 FROM favorites WHERE file_id = $1) as is_fav\",\n        file_id as i64\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to check favorite status: {}\", e))?;\n\n    Ok(result.is_fav.unwrap_or(false))\n}\n\n/// Get all favorite files with full details\n#[tauri::command]\npub async fn get_favorites(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003ccrate::models::midi_file::FileDetails\u003e, String\u003e {\n    debug!(\"Getting all favorite files\");\n\n    let favorites = sqlx::query_as!(\n        crate::models::midi_file::FileDetails,\n        r#\"\n        SELECT\n            f.id as \"id!\",\n            f.filename as \"filename!\",\n            f.filepath as \"filepath!\",\n            f.file_size_bytes as \"file_size_bytes!\",\n            f.num_tracks as \"track_count!\",\n            f.content_hash as \"content_hash!\",\n            f.parent_folder as \"parent_folder?\",\n            f.created_at as \"created_at!\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) \u003e 0 as \"has_notes!\",\n            mm.total_notes as \"total_notes?\",\n            mm.is_percussive as \"has_drums?\",\n            fc.primary_category::TEXT as \"primary_category?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"tags!\",\n            true as \"is_favorite!\"\n        FROM favorites fav\n        INNER JOIN files f ON fav.file_id = f.id\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY fav.created_at DESC\n        \"#\n    )\n    .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to fetch favorites: {}\", e);\n        format!(\"Failed to fetch favorites: {}\", e)\n    })?;\n\n    debug!(\"Retrieved {} favorite files\", favorites.len());\n    Ok(favorites)\n}\n\n/// Get usage statistics\n#[tauri::command]\npub async fn get_usage_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    debug!(\"Getting usage statistics\");\n\n    // Gather various statistics using proper table and column names\n    let total_files: i64 = sqlx::query_scalar(\"SELECT COUNT(*) FROM files\")\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| format!(\"Failed to count files: {}\", e))?;\n\n    let total_duration: Option\u003cf64\u003e = sqlx::query_scalar(\n        \"SELECT SUM(duration_seconds) FROM files WHERE duration_seconds IS NOT NULL\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to sum duration: {}\", e))?;\n\n    let total_notes: Option\u003ci64\u003e = sqlx::query_scalar(\n        \"SELECT SUM(total_notes) FROM musical_metadata\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to sum notes: {}\", e))?;\n\n    let avg_bpm: Option\u003cf64\u003e = sqlx::query_scalar(\n        \"SELECT AVG(bpm) FROM musical_metadata WHERE bpm IS NOT NULL\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to calculate average BPM: {}\", e))?;\n\n    // Most common key\n    let most_common_key: Option\u003c(String,)\u003e = sqlx::query_as(\n        \"SELECT key_signature::TEXT\n         FROM musical_metadata\n         WHERE key_signature IS NOT NULL\n         GROUP BY key_signature\n         ORDER BY COUNT(*) DESC\n         LIMIT 1\"\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to find most common key: {}\", e))?;\n\n    // Most common time signature\n    let most_common_time: Option\u003c(String,)\u003e = sqlx::query_as(\n        \"SELECT time_signature_numerator::TEXT || '/' || time_signature_denominator::TEXT\n         FROM musical_metadata\n         WHERE time_signature_numerator IS NOT NULL\n           AND time_signature_denominator IS NOT NULL\n         GROUP BY time_signature_numerator, time_signature_denominator\n         ORDER BY COUNT(*) DESC\n         LIMIT 1\"\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to find most common time signature: {}\", e))?;\n\n    // Format as JSON\n    let stats = serde_json::json!({\n        \"total_files\": total_files,\n        \"total_duration_hours\": total_duration.unwrap_or(0.0) / 3600.0,\n        \"total_notes\": total_notes.unwrap_or(0),\n        \"average_bpm\": avg_bpm.unwrap_or(0.0),\n        \"most_common_key\": most_common_key.map(|(k,)| k),\n        \"most_common_time_signature\": most_common_time.map(|(t,)| t),\n    });\n\n    Ok(stats.to_string())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","export.rs"],"content":"//! Export Tauri commands\n//!\n//! Grown-up Script: Handles exporting sequencer projects and MIDI data.\n//! Delegates MIDI file generation to Trusty Modules (pure functions).\n\nuse crate::core::midi::writer;\nuse crate::models::midi::{MidiEvent, MidiEventType};\nuse tracing::{debug, error, info};\nuse std::path::PathBuf;\n\n/// Export project as MIDI file\n///\n/// Uses MIDI writer Trusty Module (pure function) to generate MIDI data.\n///\n/// TODO for full implementation:\n/// - Get events from sequencer engine\n/// - Merge all tracks into event list\n/// - Apply track properties (volume, pan as MIDI CC)\n/// - Support tempo map changes\n///\n/// Current implementation creates a demonstration MIDI file.\n#[tauri::command]\npub async fn export_project_midi(\n    output_path: String,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Exporting project to MIDI file: {}\", output_path);\n\n    let path = PathBuf::from(\u0026output_path);\n\n    // Validate path\n    if let Some(parent) = path.parent() {\n        if !parent.exists() {\n            return Err(format!(\"Parent directory does not exist: {}\", parent.display()));\n        }\n    }\n\n    // Validate extension\n    if path.extension().and_then(|s| s.to_str()) != Some(\"mid\") \u0026\u0026\n       path.extension().and_then(|s| s.to_str()) != Some(\"midi\") {\n        return Err(\"Output file must have .mid or .midi extension\".to_string());\n    }\n\n    // TODO: Get events from sequencer engine\n    // For now, create a simple demonstration pattern\n    let events = create_demo_events();\n\n    // Use Trusty Module (pure function) to generate MIDI file\n    let midi_data = writer::write_midi_file(\u0026events, 480, 120.0)\n        .map_err(|e| {\n            error!(\"Failed to generate MIDI data: {}\", e);\n            format!(\"Failed to generate MIDI: {}\", e)\n        })?;\n\n    // I/O operation (Grown-up Script responsibility)\n    std::fs::write(\u0026path, midi_data)\n        .map_err(|e| {\n            error!(\"Failed to write MIDI file: {}\", e);\n            format!(\"Failed to write file: {}\", e)\n        })?;\n\n    info!(\"Exported project to: {}\", output_path);\n    Ok(())\n}\n\n/// Create demonstration MIDI events\n///\n/// This is a placeholder for integration with the sequencer.\n/// A real implementation would:\n/// 1. Get all tracks from the sequencer engine\n/// 2. Merge events from all enabled tracks\n/// 3. Apply track properties (mute, solo, volume, pan)\n/// 4. Sort events by timestamp\n///\n/// Current implementation creates a simple C major arpeggio pattern.\nfn create_demo_events() -\u003e Vec\u003cMidiEvent\u003e {\n    vec![\n        // C major arpeggio (C-E-G-C)\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 0,\n            channel: 0,\n            note: Some(60), // C\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 480, // 1 beat later\n            channel: 0,\n            note: Some(60),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 480,\n            channel: 0,\n            note: Some(64), // E\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 960, // 2 beats\n            channel: 0,\n            note: Some(64),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 960,\n            channel: 0,\n            note: Some(67), // G\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 1440, // 3 beats\n            channel: 0,\n            note: Some(67),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 1440,\n            channel: 0,\n            note: Some(72), // C (octave higher)\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 1920, // 4 beats (1 bar)\n            channel: 0,\n            note: Some(72),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n    ]\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_create_demo_events() {\n        let events = create_demo_events();\n\n        // Should create 8 events (4 note on + 4 note off)\n        assert_eq!(events.len(), 8);\n\n        // First event should be Note On at tick 0\n        assert_eq!(events[0].event_type, MidiEventType::NoteOn);\n        assert_eq!(events[0].tick, 0);\n        assert_eq!(events[0].note, Some(60)); // Middle C\n\n        // Last event should be Note Off at tick 1920 (1 bar)\n        assert_eq!(events[7].event_type, MidiEventType::NoteOff);\n        assert_eq!(events[7].tick, 1920);\n        assert_eq!(events[7].note, Some(72)); // High C\n    }\n\n    #[test]\n    fn test_export_uses_trusty_module() {\n        // Verify we're using the MIDI writer Trusty Module\n        let events = create_demo_events();\n        let result = writer::write_midi_file(\u0026events, 480, 120.0);\n\n        assert!(result.is_ok());\n        let midi_data = result.unwrap();\n\n        // Verify MIDI header\n        assert_eq!(\u0026midi_data[0..4], b\"MThd\");\n        // Verify track chunk\n        assert_eq!(\u0026midi_data[14..18], b\"MTrk\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","midi.rs"],"content":"//! MIDI hardware Tauri commands\n//!\n//! Grown-up Scripts: Thin wrappers around MIDI manager for frontend access.\n//! Delegate all business logic to Trusty Modules and MIDI manager.\n\nuse tauri::State;\nuse std::sync::Arc;\nuse crate::midi::MidiManager;\nuse crate::models::MidiDevice;\n\n/// List all available MIDI output devices\n///\n/// Returns a list of MIDI output devices found on the system.\n#[tauri::command]\npub async fn midi_list_devices(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cVec\u003cMidiDevice\u003e, String\u003e {\n    midi_manager.list_devices()\n}\n\n/// Connect to a specific MIDI device by name\n///\n/// Establishes a connection to the specified MIDI output device.\n#[tauri::command]\npub async fn midi_connect(\n    device_name: String,\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    midi_manager.connect(\u0026device_name).await\n}\n\n/// Disconnect from current MIDI device\n///\n/// Closes the active MIDI connection if one exists.\n#[tauri::command]\npub async fn midi_disconnect(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    midi_manager.disconnect().await;\n    Ok(())\n}\n\n/// Check if MIDI device is currently connected\n///\n/// Returns true if a MIDI device is connected, false otherwise.\n#[tauri::command]\npub async fn midi_is_connected(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    Ok(midi_manager.is_connected().await)\n}\n\n/// Get current MIDI device info\n///\n/// Returns information about the currently connected device, if any.\n#[tauri::command]\npub async fn midi_get_current_device(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cOption\u003cMidiDevice\u003e, String\u003e {\n    if let Some(name) = midi_manager.current_device().await {\n        Ok(Some(MidiDevice {\n            name,\n            manufacturer: None,\n        }))\n    } else {\n        Ok(None)\n    }\n}\n\n/// Send a test note to verify MIDI connection\n///\n/// Sends a note on/off pair with configurable parameters.\n/// The note plays for 500ms.\n#[tauri::command]\npub async fn midi_send_test_note(\n    channel: u8,\n    note: u8,\n    velocity: u8,\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    // Send note on\n    midi_manager.send_note_on(channel, note, velocity).await?;\n\n    // Wait 500ms\n    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;\n\n    // Send note off\n    midi_manager.send_note_off(channel, note).await?;\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","mod.rs"],"content":"//! Tauri command handlers\n//!\n//! Grown-up Scripts: Thin wrappers that expose backend functionality to frontend.\n//! All commands delegate business logic to Trusty Modules or Grown-up Scripts.\n\npub mod midi;\npub mod sequencer;\npub mod search;\npub mod analysis;\npub mod export;\npub mod project;\n\n/// Shared application state across all commands\n///\n/// Contains database pool for read-only access to MIDI file metadata.\npub struct AppState {\n    pub db_pool: Option\u003csqlx::PgPool\u003e,\n}\n\n#[tauri::command]\npub async fn initialize_database(state: tauri::State\u003c'_, AppState\u003e) -\u003e Result\u003c(), String\u003e {\n    // Get database connection pool\n    let pool = state.db_pool.as_ref().ok_or_else(|| {\n        \"Database connection not available. Please set DATABASE_URL environment variable.\".to_string()\n    })?;\n\n    // Test the connection with a simple query\n    sqlx::query(\"SELECT COUNT(*) FROM files\")\n        .execute(pool)\n        .await\n        .map_err(|e| format!(\"Database connection test failed: {}\", e))?;\n\n    Ok(())\n}\n\n// Re-export all command functions for easy registration\n#[allow(unused_imports)]\npub use midi::{\n    midi_list_devices, midi_connect, midi_disconnect,\n    midi_is_connected, midi_get_current_device, midi_send_test_note,\n};\n\n#[allow(unused_imports)]\npub use sequencer::{\n    start_sequencer, stop_sequencer, pause_sequencer, resume_sequencer,\n    get_playback_position, seek_position, set_tempo, get_tempo,\n    add_track, remove_track, update_track, get_tracks,\n    load_sequencer_tracks, is_sequencer_playing,\n};\n\n#[allow(unused_imports)]\npub use search::{\n    search_files, get_file_details, get_search_suggestions,\n};\n\n#[allow(unused_imports)]\npub use analysis::{\n    find_compatible_files, add_favorite, remove_favorite,\n    is_favorite, get_favorites, get_usage_stats,\n};\n\n#[allow(unused_imports)]\npub use export::{\n    export_project_midi,\n};\n\n#[allow(unused_imports)]\npub use project::{\n    load_multiple_tracks, clear_all_tracks, get_track_details,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","project.rs"],"content":"//! Project and track loading commands\n//!\n//! Commands for loading multiple tracks into the sequencer from the database.\n\nuse crate::commands::AppState;\nuse crate::core::midi::loader::load_midi_file;\nuse crate::models::sequencer::Track;\nuse crate::sequencer::{ScheduledEvent, SequencerEngine};\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\nuse tauri::State;\nuse tracing::{error, info, warn};\n\n/// Track with loaded events ready for scheduling\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TrackWithEvents {\n    pub track: Track,\n    pub events: Vec\u003cScheduledEvent\u003e,\n}\n\n/// Load multiple MIDI files as sequencer tracks\n///\n/// This command loads multiple files from the database and prepares them\n/// as sequencer tracks with their MIDI events ready for playback.\n///\n/// # Arguments\n/// * `file_ids` - List of database file IDs to load\n/// * `state` - Application state with database connection\n/// * `engine` - Sequencer engine\n#[tauri::command]\npub async fn load_multiple_tracks(\n    file_ids: Vec\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrack\u003e, String\u003e {\n    info!(\"Loading {} files as sequencer tracks\", file_ids.len());\n\n    let mut loaded_tracks = Vec::new();\n    let mut failed_count = 0;\n\n    for (idx, file_id) in file_ids.iter().enumerate() {\n        // Query database for file information\n        let file_result = match sqlx::query!(\n            r#\"\n            SELECT id, filepath, filename\n            FROM files\n            WHERE id = $1\n            \"#,\n            *file_id as i64\n        )\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        {\n            Ok(result) =\u003e result,\n            Err(e) =\u003e {\n                error!(\"Failed to query file {} from database: {}\", file_id, e);\n                failed_count += 1;\n                continue;\n            }\n        };\n\n        // Load MIDI file and parse events\n        let loaded_midi = match load_midi_file(\u0026file_result.filepath) {\n            Ok(midi) =\u003e midi,\n            Err(e) =\u003e {\n                error!(\n                    \"Failed to load MIDI file {} ({}): {}\",\n                    file_result.filename, file_result.filepath, e\n                );\n                failed_count += 1;\n                continue;\n            }\n        };\n\n        info!(\n            \"Loaded {} events from {} ({}/{})\",\n            loaded_midi.events.len(),\n            file_result.filename,\n            idx + 1,\n            file_ids.len()\n        );\n\n        // Add track with loaded events\n        let track_manager = engine.track_manager();\n        let channel = (idx % 16) as u8; // Distribute across MIDI channels\n\n        match track_manager\n            .add_track(file_result.id as i32, channel, loaded_midi.events)\n            .await\n        {\n            Ok(track) =\u003e loaded_tracks.push(track),\n            Err(e) =\u003e {\n                error!(\"Failed to add track for file {}: {}\", file_id, e);\n                failed_count += 1;\n            }\n        }\n    }\n\n    if failed_count \u003e 0 {\n        warn!(\n            \"Failed to load {} out of {} tracks\",\n            failed_count,\n            file_ids.len()\n        );\n    }\n\n    // Reload tracks in engine to update scheduler\n    engine.load_tracks().await;\n\n    info!(\n        \"Successfully loaded {} tracks into sequencer\",\n        loaded_tracks.len()\n    );\n\n    Ok(loaded_tracks)\n}\n\n/// Clear all tracks from the sequencer\n#[tauri::command]\npub async fn clear_all_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    info!(\"Clearing all tracks from sequencer\");\n\n    let track_manager = engine.track_manager();\n    track_manager.clear().await;\n\n    let scheduler = engine.scheduler();\n    scheduler.clear().await;\n\n    Ok(())\n}\n\n/// Get detailed information about loaded tracks\n#[tauri::command]\npub async fn get_track_details(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrackDetails\u003e, String\u003e {\n    let track_manager = engine.track_manager();\n    let tracks = track_manager.get_tracks().await;\n\n    let details: Vec\u003cTrackDetails\u003e = tracks\n        .into_iter()\n        .map(|track| {\n            let event_count = track.events.len();\n            TrackDetails {\n                id: track.id,\n                name: track.name,\n                file_id: track.file_id,\n                channel: track.channel,\n                muted: track.muted,\n                solo: track.solo,\n                volume: track.volume,\n                pan: track.pan,\n                event_count,\n            }\n        })\n        .collect();\n\n    Ok(details)\n}\n\n/// Track details for frontend display\n#[derive(Debug, Serialize, Deserialize)]\npub struct TrackDetails {\n    pub id: i32,\n    pub name: String,\n    pub file_id: i32,\n    pub channel: u8,\n    pub muted: bool,\n    pub solo: bool,\n    pub volume: u8,\n    pub pan: u8,\n    pub event_count: usize,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","search.rs"],"content":"//! Search Tauri commands\n//!\n//! Thin wrappers that expose search functionality to the frontend.\n//! Queries the PostgreSQL database for MIDI files with filtering and sorting.\n//! Updated to use proper JOINs with actual database schema.\n\nuse crate::commands::AppState;\nuse crate::models::midi_file::FileDetails;\nuse crate::models::search::{SearchFilters, SearchResponse, Suggestion};\nuse sqlx::Row;\nuse tauri::State;\nuse tracing::{debug, error};\n\n/// Search for MIDI files with filters\n///\n/// Supports filtering by:\n/// - BPM range\n/// - Key signature\n/// - Time signature\n/// - Category\n/// - Note count range\n/// - Duration range\n/// - Full-text search in filename\n#[tauri::command]\npub async fn search_files(\n    filters: SearchFilters,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cSearchResponse, String\u003e {\n    debug!(\"Searching files with filters: {:?}\", filters);\n\n    // Build base query with proper JOINs and type casts\n    let mut query = String::from(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.parent_folder,\n            f.created_at,\n            f.content_hash,\n            f.num_tracks,\n            f.manufacturer,\n            f.collection_name,\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as folder_tags,\n            mm.bpm::FLOAT8 as bpm,\n            mm.key_signature::TEXT as key_signature,\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as time_signature,\n            f.duration_seconds::FLOAT8 as duration_seconds,\n            mm.total_notes,\n            mm.is_percussive as has_drums,\n            fc.primary_category::TEXT as primary_category,\n            CASE WHEN fav.file_id IS NOT NULL THEN true ELSE false END as is_favorite\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        LEFT JOIN favorites fav ON f.id = fav.file_id\n        WHERE 1=1\n        \"#\n    );\n\n    let mut conditions = Vec::new();\n\n    // BPM filter\n    if let Some(min_bpm) = filters.min_bpm {\n        conditions.push(format!(\"mm.bpm \u003e= {}\", min_bpm));\n    }\n    if let Some(max_bpm) = filters.max_bpm {\n        conditions.push(format!(\"mm.bpm \u003c= {}\", max_bpm));\n    }\n\n    // Key signature filter\n    if let Some(ref key) = filters.key_signature {\n        conditions.push(format!(\"mm.key_signature = '{}'\", key.replace(\"'\", \"''\")));\n    }\n\n    // Time signature filter (need to match formatted string)\n    if let Some(ref time_sig) = filters.time_signature {\n        let parts: Vec\u003c\u0026str\u003e = time_sig.split('/').collect();\n        if parts.len() == 2 {\n            conditions.push(format!(\n                \"mm.time_signature_numerator = {} AND mm.time_signature_denominator = {}\",\n                parts[0], parts[1]\n            ));\n        }\n    }\n\n    // Category filter (check primary_category in file_categories table)\n    if let Some(ref category) = filters.category {\n        conditions.push(format!(\n            \"fc.primary_category::TEXT ILIKE '%{}%'\",\n            category.replace(\"'\", \"''\")\n        ));\n    }\n\n    // Note count range\n    if let Some(min_notes) = filters.min_notes {\n        conditions.push(format!(\"mm.total_notes \u003e= {}\", min_notes));\n    }\n    if let Some(max_notes) = filters.max_notes {\n        conditions.push(format!(\"mm.total_notes \u003c= {}\", max_notes));\n    }\n\n    // Duration range\n    if let Some(min_duration) = filters.min_duration {\n        conditions.push(format!(\"f.duration_seconds \u003e= {}\", min_duration));\n    }\n    if let Some(max_duration) = filters.max_duration {\n        conditions.push(format!(\"f.duration_seconds \u003c= {}\", max_duration));\n    }\n\n    // Text search in filename\n    if let Some(ref search_text) = filters.search_text {\n        if !search_text.is_empty() {\n            conditions.push(format!(\"f.filename ILIKE '%{}%'\", search_text.replace(\"'\", \"''\")));\n        }\n    }\n\n    // Add all conditions to query\n    for condition in \u0026conditions {\n        query.push_str(\u0026format!(\" AND {}\", condition));\n    }\n\n    // Add sorting - map frontend field names to actual DB columns\n    let sort_by = match filters.sort_by.as_deref().unwrap_or(\"created_at\") {\n        \"file_name\" =\u003e \"f.filename\",\n        \"bpm\" =\u003e \"mm.bpm\",\n        \"key_signature\" =\u003e \"mm.key_signature\",\n        \"duration_seconds\" =\u003e \"f.duration_seconds\",\n        \"note_count\" =\u003e \"mm.total_notes\",\n        \"created_at\" =\u003e \"f.created_at\",\n        _ =\u003e \"f.created_at\",\n    };\n\n    let sort_order = if filters.sort_desc.unwrap_or(false) {\n        \"DESC\"\n    } else {\n        \"ASC\"\n    };\n    query.push_str(\u0026format!(\" ORDER BY {} {}\", sort_by, sort_order));\n\n    // Add pagination\n    let limit = filters.limit.unwrap_or(50).min(500); // Cap at 500\n    let offset = filters.offset.unwrap_or(0);\n    query.push_str(\u0026format!(\" LIMIT {} OFFSET {}\", limit, offset));\n\n    debug!(\"Executing query: {}\", query);\n\n    // Execute query\n    let rows = sqlx::query(\u0026query)\n        .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| {\n            error!(\"Database query failed: {}\", e);\n            format!(\"Failed to search files: {}\", e)\n        })?;\n\n    // Convert rows to FileDetails structs\n    let files: Vec\u003cFileDetails\u003e = rows\n        .iter()\n        .map(|row| FileDetails {\n            id: row.get(\"id\"),\n            filename: row.get(\"filename\"),\n            filepath: row.get(\"filepath\"),\n            file_size_bytes: row.get(\"file_size_bytes\"),\n            bpm: row.try_get(\"bpm\").ok(),\n            key_signature: row.try_get(\"key_signature\").ok(),\n            time_signature: row.try_get(\"time_signature\").ok(),\n            duration_seconds: row.try_get(\"duration_seconds\").ok(),\n            total_notes: row.try_get(\"total_notes\").ok(),\n            primary_category: row.try_get(\"primary_category\").ok(),\n            parent_folder: row.try_get(\"parent_folder\").ok(),\n            created_at: row.get(\"created_at\"),\n            is_favorite: row.try_get(\"is_favorite\").unwrap_or(false),\n            tags: row.try_get(\"folder_tags\").unwrap_or_default(),\n            manufacturer: row.try_get(\"manufacturer\").ok(),\n            collection_name: row.try_get(\"collection_name\").ok(),\n            track_count: row.try_get(\"num_tracks\").unwrap_or(0),\n            has_notes: row.try_get::\u003cOption\u003ci32\u003e, _\u003e(\"total_notes\").ok().flatten().unwrap_or(0) \u003e 0,\n            has_drums: row.try_get(\"has_drums\").ok(),\n            content_hash: row.try_get(\"content_hash\").unwrap_or_default(),\n        })\n        .collect();\n\n    // Get total count (without pagination) - must include all JOINs for WHERE conditions\n    let mut count_query = String::from(\n        \"SELECT COUNT(*) FROM files f \\\n         LEFT JOIN musical_metadata mm ON f.id = mm.file_id \\\n         LEFT JOIN file_categories fc ON f.id = fc.file_id \\\n         LEFT JOIN favorites fav ON f.id = fav.file_id \\\n         WHERE 1=1\"\n    );\n    for condition in \u0026conditions {\n        count_query.push_str(\u0026format!(\" AND {}\", condition));\n    }\n\n    let total: i64 = sqlx::query_scalar(\u0026count_query)\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| {\n            error!(\"Count query failed: {}\", e);\n            format!(\"Failed to count results: {}\", e)\n        })?;\n\n    debug!(\"Found {} total results, returning {} files\", total, files.len());\n\n    Ok(SearchResponse {\n        files,\n        total: total as i32,\n    })\n}\n\n/// Get detailed information about a specific file\n#[tauri::command]\npub async fn get_file_details(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cFileDetails, String\u003e {\n    debug!(\"Getting details for file ID: {}\", file_id);\n\n    let file = sqlx::query_as!(\n        FileDetails,\n        r#\"\n        SELECT\n            f.id as \"id!\",\n            f.filename as \"filename!\",\n            f.filepath as \"filepath!\",\n            f.file_size_bytes as \"file_size_bytes!\",\n            f.parent_folder as \"parent_folder?\",\n            f.created_at as \"created_at!\",\n            f.content_hash as \"content_hash!\",\n            f.num_tracks as \"track_count!\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"tags!\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) \u003e 0 as \"has_notes!\",\n            mm.total_notes as \"total_notes?\",\n            mm.is_percussive as \"has_drums?\",\n            fc.primary_category::TEXT as \"primary_category?\",\n            CASE WHEN fav.file_id IS NOT NULL THEN true ELSE false END as \"is_favorite!\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        LEFT JOIN favorites fav ON f.id = fav.file_id\n        WHERE f.id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Database query failed: {}\", e);\n        format!(\"Failed to get file details: {}\", e)\n    })?;\n\n    file.ok_or_else(|| format!(\"File with ID {} not found\", file_id))\n}\n\n/// Get autocomplete suggestions for search\n///\n/// Provides suggestions for:\n/// - Categories\n/// - Key signatures\n/// - Time signatures\n#[tauri::command]\npub async fn get_search_suggestions(\n    query: String,\n    field: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cSuggestion\u003e, String\u003e {\n    debug!(\"Getting suggestions for field '{}' with query '{}'\", field, query);\n\n    let suggestions: Vec\u003cSuggestion\u003e = match field.as_str() {\n        \"category\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT primary_category::TEXT as category FROM file_categories\n                 WHERE primary_category IS NOT NULL\n                 ORDER BY category LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get category suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        \"key_signature\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT key_signature::TEXT FROM musical_metadata\n                 WHERE key_signature IS NOT NULL AND key_signature::TEXT ILIKE $1\n                 ORDER BY key_signature LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get key suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        \"time_signature\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT\n                    time_signature_numerator::TEXT || '/' || time_signature_denominator::TEXT as time_sig\n                 FROM musical_metadata\n                 WHERE time_signature_numerator IS NOT NULL\n                   AND time_signature_denominator IS NOT NULL\n                 ORDER BY time_sig LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get time signature suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        _ =\u003e {\n            return Err(format!(\"Unknown field for suggestions: {}\", field));\n        }\n    };\n\n    debug!(\"Returning {} suggestions\", suggestions.len());\n    Ok(suggestions)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","sequencer.rs"],"content":"//! Sequencer Tauri commands\n//!\n//! Thin wrappers that expose sequencer functionality to the frontend.\n\nuse crate::commands::AppState;\nuse crate::core::midi::loader::load_midi_file;\nuse crate::models::sequencer::{PlaybackPosition, Track, TrackProperties};\nuse crate::sequencer::SequencerEngine;\nuse std::sync::Arc;\nuse tauri::State;\nuse tracing::{error, info};\n\n/// Start sequencer playback\n#[tauri::command]\npub async fn start_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.start().await\n}\n\n/// Stop sequencer playback (resets position)\n#[tauri::command]\npub async fn stop_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.stop().await;\n    Ok(())\n}\n\n/// Pause sequencer playback (maintains position)\n#[tauri::command]\npub async fn pause_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.pause().await;\n    Ok(())\n}\n\n/// Resume sequencer playback from paused state\n#[tauri::command]\npub async fn resume_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.resume().await\n}\n\n/// Get current playback position\n#[tauri::command]\npub async fn get_playback_position(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cPlaybackPosition, String\u003e {\n    Ok(engine.get_position().await)\n}\n\n/// Seek to a specific position\n///\n/// # Arguments\n/// * `bar` - Bar number (0-indexed)\n/// * `beat` - Beat within bar (0-indexed)\n#[tauri::command]\npub async fn seek_position(\n    bar: u32,\n    beat: u32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    use crate::core::sequencer::timing::bar_beat_to_tick;\n\n    let tick = bar_beat_to_tick(bar, beat, 480, 4); // TODO: Get these from engine\n    engine.seek(tick).await;\n    Ok(())\n}\n\n/// Set global tempo (BPM)\n#[tauri::command]\npub async fn set_tempo(\n    bpm: f32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.set_bpm(bpm).await\n}\n\n/// Get current tempo\n#[tauri::command]\npub async fn get_tempo(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cf32, String\u003e {\n    Ok(engine.get_bpm().await)\n}\n\n/// Add a track to the sequencer\n///\n/// # Arguments\n/// * `file_id` - Database ID of the MIDI file\n/// * `channel` - MIDI channel (0-15)\n/// * `state` - Application state with database connection\n/// * `engine` - Sequencer engine\n#[tauri::command]\npub async fn add_track(\n    file_id: i32,\n    channel: u8,\n    state: State\u003c'_, AppState\u003e,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cTrack, String\u003e {\n    // Query database for file information\n    let file_result = sqlx::query!(\n        r#\"\n        SELECT filepath\n        FROM files\n        WHERE id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database pool not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to query file {} from database: {}\", file_id, e);\n        format!(\"File not found: {}\", file_id)\n    })?;\n\n    // Load MIDI file and parse events\n    let loaded_midi = load_midi_file(\u0026file_result.filepath)\n        .map_err(|e| {\n            error!(\"Failed to load MIDI file {}: {}\", file_result.filepath, e);\n            format!(\"Failed to load MIDI file: {}\", e)\n        })?;\n\n    info!(\n        \"Loaded {} events from file {} ({})\",\n        loaded_midi.events.len(),\n        file_id,\n        file_result.filepath\n    );\n\n    // Add track with loaded events\n    let track_manager = engine.track_manager();\n    let track = track_manager.add_track(file_id, channel, loaded_midi.events).await?;\n\n    // Reload tracks in engine to update scheduler\n    engine.load_tracks().await;\n\n    Ok(track)\n}\n\n/// Remove a track from the sequencer\n#[tauri::command]\npub async fn remove_track(\n    track_id: i32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let track_manager = engine.track_manager();\n    track_manager.remove_track(track_id).await?;\n\n    // Remove track's events from scheduler\n    let scheduler = engine.scheduler();\n    scheduler.clear_track(track_id).await;\n\n    Ok(())\n}\n\n/// Update track properties (mute, solo, volume, pan)\n#[tauri::command]\npub async fn update_track(\n    track_id: i32,\n    properties: TrackProperties,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let track_manager = engine.track_manager();\n    track_manager.update_track(track_id, properties).await?;\n\n    // Reload tracks to update scheduler\n    engine.load_tracks().await;\n\n    Ok(())\n}\n\n/// Get all tracks in current project\n#[tauri::command]\npub async fn get_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrack\u003e, String\u003e {\n    let track_manager = engine.track_manager();\n    Ok(track_manager.get_tracks().await)\n}\n\n/// Load tracks into sequencer and prepare for playback\n#[tauri::command]\npub async fn load_sequencer_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.load_tracks().await;\n    Ok(())\n}\n\n/// Check if sequencer is currently playing\n#[tauri::command]\npub async fn is_sequencer_playing(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    use crate::sequencer::engine::PlaybackState;\n\n    let state = engine.get_state().await;\n    Ok(state == PlaybackState::Playing)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","mod.rs"],"content":"//! Compatibility module - Musical matching algorithms\n//!\n//! Trusty Module: Pure functions for calculating compatibility between MIDI files.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod music;\npub mod scoring;\npub mod types;\n\n// Re-export commonly used items\n#[allow(unused_imports)]\npub use music::{\n    bpm_compatibility_score, bpm_time_stretchable, is_relative_key, key_compatibility_score,\n    key_distance, keys_compatible,\n};\n#[allow(unused_imports)]\npub use scoring::{calculate_compatibility, explain_compatibility};\n#[allow(unused_imports)]\npub use types::{CompatibilityScore, Key, KeySignature, Mode};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","music.rs"],"content":"//! Music theory utilities - Pure functions for musical analysis\n//!\n//! Trusty Module: All functions are pure - no I/O, fully deterministic.\n\nuse super::types::{Key, KeySignature, Mode};\n\n/// Calculate distance between two keys in semitones\n///\n/// Returns the minimum distance around the circle of fifths (0-6).\n/// Example: C to G is 5 semitones (perfect fifth).\n///\n/// # Arguments\n/// * `key1` - First key\n/// * `key2` - Second key\n///\n/// # Returns\n/// Minimum distance (0-6 semitones)\npub fn key_distance(key1: Key, key2: Key) -\u003e i32 {\n    let diff = (key1.semitone() - key2.semitone()).abs();\n    // Return minimum distance around circle of fifths\n    diff.min(12 - diff)\n}\n\n/// Check if two key signatures are compatible\n///\n/// Keys are compatible if they:\n/// - Are the same key\n/// - Are relative major/minor (share the same notes)\n/// - Are a perfect fifth apart (circle of fifths)\npub fn keys_compatible(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e bool {\n    // Same key = perfect match\n    if ks1.key == ks2.key \u0026\u0026 ks1.mode == ks2.mode {\n        return true;\n    }\n\n    // Relative major/minor (e.g., C major and A minor)\n    if is_relative_key(ks1, ks2) {\n        return true;\n    }\n\n    // Perfect fifth apart (very compatible)\n    let distance = key_distance(ks1.key, ks2.key);\n    if distance == 5 {\n        return true;\n    }\n\n    false\n}\n\n/// Check if two keys are relative (share the same notes)\n///\n/// Relative keys have different modes but share the same notes.\n/// Example: C Major and A Minor are relative keys.\n///\n/// # Arguments\n/// * `ks1` - First key signature\n/// * `ks2` - Second key signature\n///\n/// # Returns\n/// True if keys are relative (e.g., C Major and A Minor)\npub fn is_relative_key(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e bool {\n    if ks1.mode == ks2.mode {\n        return false;\n    }\n\n    // A minor is relative to C major (3 semitones down from major to minor)\n    let major = if ks1.mode == Mode::Major { ks1 } else { ks2 };\n    let minor = if ks1.mode == Mode::Minor { ks1 } else { ks2 };\n\n    let diff = (major.key.semitone() - minor.key.semitone() + 12) % 12;\n    diff == 3 // Minor is 3 semitones below its relative major\n}\n\n/// Get compatibility score for two key signatures (0-100)\n///\n/// Scoring:\n/// - 100: Same key and mode (perfect match)\n/// - 95: Relative major/minor (share notes)\n/// - 85: Perfect fifth apart (circle of fifths)\n/// - 70: Major/minor third apart\n/// - 55: Whole tone apart\n/// - 40: Semitone apart\n/// - 20: Tritone (augmented fourth)\npub fn key_compatibility_score(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e f32 {\n    // Perfect match\n    if ks1.key == ks2.key \u0026\u0026 ks1.mode == ks2.mode {\n        return 100.0;\n    }\n\n    // Relative keys (share notes)\n    if is_relative_key(ks1, ks2) {\n        return 95.0;\n    }\n\n    let distance = key_distance(ks1.key, ks2.key);\n\n    // Perfect fifth (7 semitones) - very compatible\n    if distance == 5 {\n        return 85.0;\n    }\n\n    // Major/minor third (3-4 semitones) - compatible\n    if distance == 3 || distance == 4 {\n        return 70.0;\n    }\n\n    // Whole tone (2 semitones) - somewhat compatible\n    if distance == 2 {\n        return 55.0;\n    }\n\n    // Adjacent keys (1 semitone) - less compatible\n    if distance == 1 {\n        return 40.0;\n    }\n\n    // Tritone (6 semitones) - least compatible\n    if distance == 6 {\n        return 20.0;\n    }\n\n    50.0 // Default\n}\n\n/// Calculate BPM compatibility score (0-100)\n///\n/// Scores tempo similarity for DJ mixing and mashups.\n///\n/// # Arguments\n/// * `bpm1` - First tempo in BPM\n/// * `bpm2` - Second tempo in BPM\n///\n/// # Returns\n/// Compatibility score (0-100)\npub fn bpm_compatibility_score(bpm1: f32, bpm2: f32) -\u003e f32 {\n    let diff = (bpm1 - bpm2).abs();\n\n    // Perfect match\n    if diff \u003c 1.0 {\n        return 100.0;\n    }\n\n    // Very close (within 5 BPM)\n    if diff \u003c 5.0 {\n        return 95.0 - (diff * 1.0);\n    }\n\n    // Close (within 10 BPM)\n    if diff \u003c 10.0 {\n        return 90.0 - (diff * 0.5);\n    }\n\n    // Within 20 BPM\n    if diff \u003c 20.0 {\n        return 80.0 - (diff * 0.3);\n    }\n\n    // Within 40 BPM\n    if diff \u003c 40.0 {\n        return 70.0 - (diff * 0.2);\n    }\n\n    // Too different\n    30.0\n}\n\n/// Check if BPMs can be time-stretched to match\n///\n/// Returns true if the tempo ratio matches common musical ratios:\n/// - 2:1 (double-time)\n/// - 3:2 (sesquialtera)\n/// - 4:3 (perfect fourth)\n/// - And their inverses\n///\n/// # Arguments\n/// * `bpm1` - First tempo\n/// * `bpm2` - Second tempo\n///\n/// # Returns\n/// True if tempos can be time-stretched with minimal artifacts\npub fn bpm_time_stretchable(bpm1: f32, bpm2: f32) -\u003e bool {\n    let ratio = bpm1 / bpm2;\n    // Check if ratio is close to 2:1, 3:2, 4:3 (common musical ratios)\n    let ratios = [2.0, 1.5, 1.333, 0.5, 0.667, 0.75];\n\n    for target_ratio in ratios {\n        if (ratio - target_ratio).abs() \u003c 0.1 {\n            return true;\n        }\n    }\n\n    false\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_distance_same() {\n        assert_eq!(key_distance(Key::C, Key::C), 0);\n        assert_eq!(key_distance(Key::A, Key::A), 0);\n    }\n\n    #[test]\n    fn test_key_distance_fifth() {\n        // C to G is a perfect fifth (5 semitones forward, 7 back)\n        assert_eq!(key_distance(Key::C, Key::G), 5);\n        // Going the other way should be the same\n        assert_eq!(key_distance(Key::G, Key::C), 5);\n    }\n\n    #[test]\n    fn test_key_distance_tritone() {\n        // C to F# is a tritone (6 semitones - maximum distance)\n        assert_eq!(key_distance(Key::C, Key::FSharp), 6);\n    }\n\n    #[test]\n    fn test_key_distance_wraparound() {\n        // A to C is 3 semitones forward (A=9, C=0: (9-0).abs().min(12-9) = 3)\n        assert_eq!(key_distance(Key::A, Key::C), 3);\n    }\n\n    #[test]\n    fn test_relative_keys() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let a_minor = KeySignature {\n            key: Key::A,\n            mode: Mode::Minor,\n        };\n\n        assert!(is_relative_key(\u0026c_major, \u0026a_minor));\n        assert!(is_relative_key(\u0026a_minor, \u0026c_major));\n    }\n\n    #[test]\n    fn test_not_relative_keys() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let c_minor = KeySignature {\n            key: Key::C,\n            mode: Mode::Minor,\n        };\n\n        assert!(!is_relative_key(\u0026c_major, \u0026c_minor));\n    }\n\n    #[test]\n    fn test_keys_compatible() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let g_major = KeySignature {\n            key: Key::G,\n            mode: Mode::Major,\n        };\n\n        assert!(keys_compatible(\u0026c_major, \u0026c_major)); // Same key\n        assert!(keys_compatible(\u0026c_major, \u0026g_major)); // Perfect fifth\n    }\n\n    #[test]\n    fn test_key_compatibility_perfect_match() {\n        let key = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026key, \u0026key), 100.0);\n    }\n\n    #[test]\n    fn test_key_compatibility_relative() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let a_minor = KeySignature {\n            key: Key::A,\n            mode: Mode::Minor,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026c_major, \u0026a_minor), 95.0);\n    }\n\n    #[test]\n    fn test_key_compatibility_fifth() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let g_major = KeySignature {\n            key: Key::G,\n            mode: Mode::Major,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026c_major, \u0026g_major), 85.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_exact_match() {\n        assert_eq!(bpm_compatibility_score(120.0, 120.0), 100.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_close() {\n        let score = bpm_compatibility_score(120.0, 122.0);\n        assert!(score \u003e 90.0);\n        assert!(score \u003c 100.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_far() {\n        let score = bpm_compatibility_score(120.0, 180.0);\n        assert!(score \u003c 50.0);\n    }\n\n    #[test]\n    fn test_bpm_time_stretchable() {\n        // Double tempo should be stretchable\n        assert!(bpm_time_stretchable(120.0, 240.0));\n\n        // 3:2 ratio should be stretchable\n        assert!(bpm_time_stretchable(120.0, 180.0));\n\n        // Random ratio should not be\n        assert!(!bpm_time_stretchable(120.0, 137.0));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","scoring.rs"],"content":"//! Compatibility scoring - Overall compatibility calculation\n//!\n//! Trusty Module: Pure function that calculates compatibility scores.\n//! NO database access - receives file data as parameters.\n\nuse crate::models::midi_file::MidiFile;\nuse super::music::{bpm_compatibility_score, bpm_time_stretchable, key_compatibility_score};\nuse super::types::{CompatibilityScore, KeySignature};\n\n/// Calculate overall compatibility score between two MIDI files\n///\n/// This is the main entry point for compatibility calculation.\n/// It combines multiple factors with weighted scoring:\n/// - 40% Key compatibility (harmonic compatibility)\n/// - 40% BPM compatibility (tempo matching)\n/// - 20% Category compatibility (style/instrument matching)\n///\n/// # Arguments\n/// * `source` - The source file to compare against\n/// * `candidate` - The candidate file to score\n///\n/// # Returns\n/// CompatibilityScore with detailed breakdown\npub fn calculate_compatibility(\n    source: \u0026MidiFile,\n    candidate: \u0026MidiFile,\n) -\u003e CompatibilityScore {\n    let mut total_score = 0.0;\n    let mut explanations = Vec::new();\n\n    // Key compatibility (40% weight)\n    let key_score = if let (Some(key1_str), Some(key2_str)) =\n        (\u0026source.key_signature, \u0026candidate.key_signature)\n    {\n        if let (Some(key1), Some(key2)) = (\n            KeySignature::from_str(key1_str),\n            KeySignature::from_str(key2_str),\n        ) {\n            let score = key_compatibility_score(\u0026key1, \u0026key2);\n\n            if score \u003e= 95.0 {\n                explanations.push(\"Perfect key match\".to_string());\n            } else if score \u003e= 85.0 {\n                explanations.push(\"Excellent key compatibility\".to_string());\n            } else if score \u003e= 70.0 {\n                explanations.push(\"Good key compatibility\".to_string());\n            } else if score \u003c 50.0 {\n                explanations.push(\"Keys may clash\".to_string());\n            }\n\n            total_score += score * 0.4;\n            score\n        } else {\n            50.0 // Unknown keys\n        }\n    } else {\n        50.0 // Missing key information\n    };\n\n    // BPM compatibility (40% weight)\n    let bpm_score = if let (Some(bpm1), Some(bpm2)) = (source.bpm, candidate.bpm) {\n        // Cast f64 to f32 for compatibility functions\n        let score = bpm_compatibility_score(bpm1 as f32, bpm2 as f32);\n\n        if score \u003e= 95.0 {\n            explanations.push(\"Nearly identical tempo\".to_string());\n        } else if score \u003e= 80.0 {\n            explanations.push(\"Similar tempo\".to_string());\n        } else if bpm_time_stretchable(bpm1 as f32, bpm2 as f32) {\n            explanations.push(\"Tempo can be time-stretched\".to_string());\n        } else if score \u003c 50.0 {\n            explanations.push(\"Very different tempos\".to_string());\n        }\n\n        total_score += score * 0.4;\n        score\n    } else {\n        50.0 // Missing BPM information\n    };\n\n    // Category compatibility (20% weight)\n    let category_score = if let (Some(cat1), Some(cat2)) =\n        (\u0026source.primary_category, \u0026candidate.primary_category)\n    {\n        let score = if cat1 == cat2 {\n            100.0\n        } else {\n            category_compatibility(cat1, cat2)\n        };\n\n        if score \u003e= 90.0 {\n            explanations.push(\"Same or complementary category\".to_string());\n        }\n\n        total_score += score * 0.2;\n        score\n    } else {\n        50.0\n    };\n\n    // Build explanation\n    let explanation = if explanations.is_empty() {\n        \"Limited metadata available\".to_string()\n    } else {\n        explanations.join(\". \")\n    };\n\n    CompatibilityScore {\n        total_score,\n        key_score,\n        bpm_score,\n        category_score,\n        explanation,\n    }\n}\n\n/// Determine category compatibility\n///\n/// Scores how well two categories work together musically.\n/// Same category = 100, complementary categories = 80, different = 50.\nfn category_compatibility(cat1: \u0026str, cat2: \u0026str) -\u003e f32 {\n    // Normalize categories\n    let cat1 = cat1.to_lowercase();\n    let cat2 = cat2.to_lowercase();\n\n    // Same category = perfect\n    if cat1 == cat2 {\n        return 100.0;\n    }\n\n    // Define complementary categories (work well together)\n    let complementary_pairs = vec![\n        (\"kick\", \"bass\"),\n        (\"kick\", \"drum\"),\n        (\"snare\", \"hihat\"),\n        (\"bass\", \"chord\"),\n        (\"chord\", \"lead\"),\n        (\"pad\", \"lead\"),\n        (\"melody\", \"chord\"),\n        (\"drum\", \"percussion\"),\n    ];\n\n    for (a, b) in complementary_pairs {\n        if (cat1.contains(a) \u0026\u0026 cat2.contains(b)) || (cat1.contains(b) \u0026\u0026 cat2.contains(a)) {\n            return 80.0;\n        }\n    }\n\n    // Different but compatible\n    50.0\n}\n\n/// Generate human-readable explanation for compatibility score\n///\n/// Creates a summary explanation based on the overall score.\n///\n/// # Arguments\n/// * `source` - Source file (not currently used, but available for context)\n/// * `candidate` - Candidate file (not currently used, but available for context)\n/// * `score` - The compatibility score to explain\n///\n/// # Returns\n/// Human-readable explanation string\npub fn explain_compatibility(\n    _source: \u0026MidiFile,\n    _candidate: \u0026MidiFile,\n    score: \u0026CompatibilityScore,\n) -\u003e String {\n    let mut parts = Vec::new();\n\n    if score.total_score \u003e= 90.0 {\n        parts.push(\"Highly compatible\".to_string());\n    } else if score.total_score \u003e= 75.0 {\n        parts.push(\"Very compatible\".to_string());\n    } else if score.total_score \u003e= 60.0 {\n        parts.push(\"Compatible\".to_string());\n    } else if score.total_score \u003e= 50.0 {\n        parts.push(\"Somewhat compatible\".to_string());\n    } else {\n        parts.push(\"Limited compatibility\".to_string());\n    }\n\n    parts.push(score.explanation.clone());\n\n    parts.join(\". \")\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_category_compatibility_same() {\n        assert_eq!(category_compatibility(\"kick\", \"kick\"), 100.0);\n        assert_eq!(category_compatibility(\"bass\", \"bass\"), 100.0);\n    }\n\n    #[test]\n    fn test_category_compatibility_complementary() {\n        assert_eq!(category_compatibility(\"kick\", \"bass\"), 80.0);\n        assert_eq!(category_compatibility(\"bass\", \"kick\"), 80.0);\n        assert_eq!(category_compatibility(\"lead\", \"pad\"), 80.0);\n        assert_eq!(category_compatibility(\"chord\", \"melody\"), 80.0);\n    }\n\n    #[test]\n    fn test_category_compatibility_different() {\n        let score = category_compatibility(\"kick\", \"melody\");\n        assert!(score \u003c 80.0);\n        assert!(score \u003e= 50.0);\n    }\n\n    #[test]\n    fn test_explain_compatibility_high_score() {\n        let score = CompatibilityScore {\n            total_score: 92.0,\n            key_score: 95.0,\n            bpm_score: 90.0,\n            category_score: 90.0,\n            explanation: \"Perfect key match. Similar tempo\".to_string(),\n        };\n\n        let file = create_test_file();\n        let explanation = explain_compatibility(\u0026file, \u0026file, \u0026score);\n\n        assert!(explanation.contains(\"Highly compatible\"));\n        assert!(explanation.contains(\"Perfect key match\"));\n    }\n\n    #[test]\n    fn test_explain_compatibility_low_score() {\n        let score = CompatibilityScore {\n            total_score: 45.0,\n            key_score: 40.0,\n            bpm_score: 50.0,\n            category_score: 50.0,\n            explanation: \"Keys may clash. Very different tempos\".to_string(),\n        };\n\n        let file = create_test_file();\n        let explanation = explain_compatibility(\u0026file, \u0026file, \u0026score);\n\n        assert!(explanation.contains(\"Limited compatibility\"));\n    }\n\n    // Helper function to create test MidiFile\n    fn create_test_file() -\u003e MidiFile {\n        MidiFile {\n            id: 1,\n            filename: \"test.mid\".to_string(),\n            filepath: \"/test/test.mid\".to_string(),\n            file_size_bytes: 1024,\n            content_hash: vec![],\n            is_multi_track: false,\n            parent_file_id: None,\n            track_number: None,\n            total_tracks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: vec![],\n            parent_folder: None,\n            num_tracks: 1,\n            created_at: chrono::Utc::now(),\n            analyzed_at: None,\n            bpm: Some(120.0),\n            key_signature: Some(\"C\".to_string()),\n            time_signature: Some(\"4/4\".to_string()),\n            duration_seconds: Some(10.0),\n            total_notes: 100,\n            primary_category: Some(\"bass\".to_string()),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","types.rs"],"content":"//! Compatibility types - Music theory data structures\n//!\n//! Trusty Module: Pure data types for compatibility calculations.\n\nuse serde::{Deserialize, Serialize};\n\n/// Musical key\n///\n/// Represents the 12 chromatic pitches using semitone numbering (0-11).\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub enum Key {\n    C = 0,\n    CSharp = 1,\n    D = 2,\n    DSharp = 3,\n    E = 4,\n    F = 5,\n    FSharp = 6,\n    G = 7,\n    GSharp = 8,\n    A = 9,\n    ASharp = 10,\n    B = 11,\n}\n\nimpl Key {\n    /// Parse key from string (e.g., \"C\", \"C#\", \"Db\")\n    ///\n    /// Supports both sharp and flat notation (enharmonic equivalents).\n    pub fn from_str(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let normalized = s.to_uppercase().replace(\" \", \"\");\n\n        match normalized.as_str() {\n            \"C\" =\u003e Some(Key::C),\n            \"C#\" | \"DB\" =\u003e Some(Key::CSharp),\n            \"D\" =\u003e Some(Key::D),\n            \"D#\" | \"EB\" =\u003e Some(Key::DSharp),\n            \"E\" =\u003e Some(Key::E),\n            \"F\" =\u003e Some(Key::F),\n            \"F#\" | \"GB\" =\u003e Some(Key::FSharp),\n            \"G\" =\u003e Some(Key::G),\n            \"G#\" | \"AB\" =\u003e Some(Key::GSharp),\n            \"A\" =\u003e Some(Key::A),\n            \"A#\" | \"BB\" =\u003e Some(Key::ASharp),\n            \"B\" =\u003e Some(Key::B),\n            _ =\u003e None,\n        }\n    }\n\n    /// Get semitone value (0-11)\n    pub fn semitone(\u0026self) -\u003e i32 {\n        *self as i32\n    }\n\n    /// Get key name as string\n    pub fn name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Key::C =\u003e \"C\",\n            Key::CSharp =\u003e \"C#\",\n            Key::D =\u003e \"D\",\n            Key::DSharp =\u003e \"D#\",\n            Key::E =\u003e \"E\",\n            Key::F =\u003e \"F\",\n            Key::FSharp =\u003e \"F#\",\n            Key::G =\u003e \"G\",\n            Key::GSharp =\u003e \"G#\",\n            Key::A =\u003e \"A\",\n            Key::ASharp =\u003e \"A#\",\n            Key::B =\u003e \"B\",\n        }\n    }\n}\n\n/// Musical mode (major or minor)\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Mode {\n    Major,\n    Minor,\n}\n\nimpl Mode {\n    /// Parse mode from string\n    ///\n    /// Detects 'm' or 'min' for minor, defaults to major.\n    pub fn from_str(s: \u0026str) -\u003e Self {\n        let lower = s.to_lowercase();\n        if lower.contains('m') \u0026\u0026 !lower.contains(\"maj\") {\n            Mode::Minor\n        } else {\n            Mode::Major\n        }\n    }\n}\n\n/// Complete key signature (key + mode)\n///\n/// Represents the tonality of a piece (e.g., \"C Major\", \"Am\").\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub struct KeySignature {\n    pub key: Key,\n    pub mode: Mode,\n}\n\nimpl KeySignature {\n    /// Parse from string (e.g., \"C\", \"Am\", \"F# Major\")\n    pub fn from_str(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let mode = Mode::from_str(s);\n\n        // Extract key name (first part before mode indicator)\n        let key_part = s\n            .split_whitespace()\n            .next()\n            .unwrap_or(s)\n            .trim_end_matches('m');\n\n        let key = Key::from_str(key_part)?;\n\n        Some(KeySignature { key, mode })\n    }\n\n    /// Get human-readable name (e.g., \"C Major\", \"Am\")\n    pub fn name(\u0026self) -\u003e String {\n        match self.mode {\n            Mode::Major =\u003e format!(\"{} Major\", self.key.name()),\n            Mode::Minor =\u003e format!(\"{}m\", self.key.name()),\n        }\n    }\n}\n\n/// Compatibility score with detailed breakdown\n///\n/// All scores are 0-100 (percentage compatibility).\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CompatibilityScore {\n    pub total_score: f32,      // Overall compatibility (0-100)\n    pub key_score: f32,         // Key/harmony compatibility (0-100)\n    pub bpm_score: f32,         // Tempo compatibility (0-100)\n    pub category_score: f32,    // Category/style compatibility (0-100)\n    pub explanation: String,    // Human-readable explanation\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_from_str() {\n        assert_eq!(Key::from_str(\"C\").unwrap(), Key::C);\n        assert_eq!(Key::from_str(\"C#\").unwrap(), Key::CSharp);\n        assert_eq!(Key::from_str(\"Db\").unwrap(), Key::CSharp); // Enharmonic\n        assert_eq!(Key::from_str(\"G\").unwrap(), Key::G);\n        assert!(Key::from_str(\"invalid\").is_none());\n    }\n\n    #[test]\n    fn test_key_semitone() {\n        assert_eq!(Key::C.semitone(), 0);\n        assert_eq!(Key::CSharp.semitone(), 1);\n        assert_eq!(Key::B.semitone(), 11);\n    }\n\n    #[test]\n    fn test_mode_from_str() {\n        assert_eq!(Mode::from_str(\"Major\"), Mode::Major);\n        assert_eq!(Mode::from_str(\"Minor\"), Mode::Minor);\n        assert_eq!(Mode::from_str(\"m\"), Mode::Minor);\n        assert_eq!(Mode::from_str(\"\"), Mode::Major); // Default\n    }\n\n    #[test]\n    fn test_key_signature_from_str() {\n        let c_maj = KeySignature::from_str(\"C\").unwrap();\n        assert_eq!(c_maj.key, Key::C);\n        assert_eq!(c_maj.mode, Mode::Major);\n\n        let a_min = KeySignature::from_str(\"Am\").unwrap();\n        assert_eq!(a_min.key, Key::A);\n        assert_eq!(a_min.mode, Mode::Minor);\n\n        let g_maj = KeySignature::from_str(\"G Major\").unwrap();\n        assert_eq!(g_maj.key, Key::G);\n        assert_eq!(g_maj.mode, Mode::Major);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","loader.rs"],"content":"//! MIDI file loading and parsing\n//!\n//! Trusty Module: Pure functions for loading and parsing MIDI files.\n//! Uses midly crate for efficient MIDI parsing.\n\nuse midly::{Smf, Timing, TrackEventKind, MidiMessage as MidlyMessage};\nuse std::fs;\nuse std::path::Path;\nuse crate::models::midi::{MidiEvent, MidiEventType};\nuse tracing::debug;\n\n/// Load and parse a MIDI file from disk\n///\n/// Returns all MIDI events with absolute tick positions.\n///\n/// # Arguments\n/// * `filepath` - Path to the MIDI file\n///\n/// # Returns\n/// Result containing vector of parsed MIDI events with timing information\npub fn load_midi_file(filepath: \u0026str) -\u003e Result\u003cLoadedMidiFile, String\u003e {\n    let path = Path::new(filepath);\n\n    if !path.exists() {\n        return Err(format!(\"MIDI file not found: {}\", filepath));\n    }\n\n    // Read file bytes\n    let bytes = fs::read(path)\n        .map_err(|e| format!(\"Failed to read MIDI file {}: {}\", filepath, e))?;\n\n    // Parse MIDI file\n    let smf = Smf::parse(\u0026bytes)\n        .map_err(|e| format!(\"Failed to parse MIDI file {}: {}\", filepath, e))?;\n\n    // Extract timing information\n    let ticks_per_quarter = match smf.header.timing {\n        Timing::Metrical(tpq) =\u003e tpq.as_int() as u32,\n        Timing::Timecode(fps, sub) =\u003e {\n            // Convert timecode to ticks per quarter note (approximate)\n            let ticks_per_second = fps.as_f32() * sub as f32;\n            (ticks_per_second * 0.5) as u32 // Assume 120 BPM default\n        }\n    };\n\n    let format_num = match smf.header.format {\n        midly::Format::SingleTrack =\u003e 0,\n        midly::Format::Parallel =\u003e 1,\n        midly::Format::Sequential =\u003e 2,\n    };\n\n    debug!(\n        \"Loaded MIDI file: {} (format {}, {} tracks, {} ticks/quarter)\",\n        filepath,\n        format_num,\n        smf.tracks.len(),\n        ticks_per_quarter\n    );\n\n    // Parse events from all tracks\n    let mut all_events = Vec::new();\n    for (track_idx, track) in smf.tracks.iter().enumerate() {\n        let track_events = parse_track_events(track, track_idx as u8, ticks_per_quarter)?;\n        all_events.extend(track_events);\n    }\n\n    // Sort events by tick\n    all_events.sort_by_key(|e| e.tick);\n\n    Ok(LoadedMidiFile {\n        events: all_events,\n        ticks_per_quarter,\n        num_tracks: smf.tracks.len() as u16,\n        format: format_num,\n    })\n}\n\n/// Loaded MIDI file with metadata\n#[derive(Debug, Clone)]\npub struct LoadedMidiFile {\n    pub events: Vec\u003cMidiEvent\u003e,\n    pub ticks_per_quarter: u32,\n    pub num_tracks: u16,\n    pub format: u16,\n}\n\n/// Parse events from a single MIDI track\nfn parse_track_events(\n    track: \u0026midly::Track,\n    default_channel: u8,\n    ticks_per_quarter: u32,\n) -\u003e Result\u003cVec\u003cMidiEvent\u003e, String\u003e {\n    let mut events = Vec::new();\n    let mut absolute_tick: u64 = 0;\n    let mut current_channel = default_channel;\n\n    for event in track.iter() {\n        // Update absolute tick position\n        absolute_tick += event.delta.as_int() as u64;\n\n        match event.kind {\n            TrackEventKind::Midi { channel, message } =\u003e {\n                current_channel = channel.as_int();\n\n                if let Some(midi_event) = convert_midi_message(\n                    message,\n                    current_channel,\n                    absolute_tick,\n                    ticks_per_quarter,\n                ) {\n                    events.push(midi_event);\n                }\n            }\n            TrackEventKind::Meta(_) =\u003e {\n                // Skip meta events for now (tempo, time signature, etc.)\n                // These could be parsed in future for more accurate playback\n            }\n            TrackEventKind::SysEx(_) =\u003e {\n                // Skip SysEx events\n            }\n            TrackEventKind::Escape(_) =\u003e {\n                // Skip escape events\n            }\n        }\n    }\n\n    debug!(\"Parsed {} events from track (channel {})\", events.len(), current_channel);\n    Ok(events)\n}\n\n/// Convert midly MIDI message to our MidiEvent format\nfn convert_midi_message(\n    message: MidlyMessage,\n    channel: u8,\n    tick: u64,\n    _ticks_per_quarter: u32,\n) -\u003e Option\u003cMidiEvent\u003e {\n    match message {\n        MidlyMessage::NoteOff { key, vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick,\n            channel,\n            note: Some(key.as_int()),\n            velocity: Some(vel.as_int()),\n            controller: None,\n            value: None,\n            program: None,\n        }),\n        MidlyMessage::NoteOn { key, vel } =\u003e {\n            // Note: velocity 0 should be treated as Note Off\n            let event_type = if vel.as_int() == 0 {\n                MidiEventType::NoteOff\n            } else {\n                MidiEventType::NoteOn\n            };\n\n            Some(MidiEvent {\n                event_type,\n                tick,\n                channel,\n                note: Some(key.as_int()),\n                velocity: Some(vel.as_int()),\n                controller: None,\n                value: None,\n                program: None,\n            })\n        }\n        MidlyMessage::Aftertouch { key, vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::Aftertouch,\n            tick,\n            channel,\n            note: Some(key.as_int()),\n            value: Some(vel.as_int()),\n            velocity: None,\n            controller: None,\n            program: None,\n        }),\n        MidlyMessage::Controller { controller, value } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::ControlChange,\n            tick,\n            channel,\n            controller: Some(controller.as_int()),\n            value: Some(value.as_int()),\n            note: None,\n            velocity: None,\n            program: None,\n        }),\n        MidlyMessage::ProgramChange { program } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::ProgramChange,\n            tick,\n            channel,\n            program: Some(program.as_int()),\n            note: None,\n            velocity: None,\n            controller: None,\n            value: None,\n        }),\n        MidlyMessage::ChannelAftertouch { vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::Aftertouch,\n            tick,\n            channel,\n            value: Some(vel.as_int()),\n            note: None,\n            velocity: None,\n            controller: None,\n            program: None,\n        }),\n        MidlyMessage::PitchBend { bend } =\u003e {\n            // Convert 14-bit pitch bend to two 7-bit values\n            let bend_value = bend.as_int() as u16;\n            Some(MidiEvent {\n                event_type: MidiEventType::PitchBend,\n                tick,\n                channel,\n                value: Some((bend_value \u0026 0x7F) as u8), // LSB\n                velocity: Some(((bend_value \u003e\u003e 7) \u0026 0x7F) as u8), // MSB\n                note: None,\n                controller: None,\n                program: None,\n            })\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_load_nonexistent_file() {\n        let result = load_midi_file(\"/nonexistent/path/file.mid\");\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"not found\"));\n    }\n\n    #[test]\n    fn test_convert_note_on() {\n        let message = MidlyMessage::NoteOn {\n            key: 60.into(),\n            vel: 100.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        assert_eq!(event.event_type, MidiEventType::NoteOn);\n        assert_eq!(event.note, Some(60));\n        assert_eq!(event.velocity, Some(100));\n    }\n\n    #[test]\n    fn test_convert_note_on_zero_velocity() {\n        let message = MidlyMessage::NoteOn {\n            key: 60.into(),\n            vel: 0.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        // Zero velocity Note On should become Note Off\n        assert_eq!(event.event_type, MidiEventType::NoteOff);\n    }\n\n    #[test]\n    fn test_convert_control_change() {\n        let message = MidlyMessage::Controller {\n            controller: 7.into(), // Volume\n            value: 100.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        assert_eq!(event.event_type, MidiEventType::ControlChange);\n        assert_eq!(event.controller, Some(7));\n        assert_eq!(event.value, Some(100));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","mod.rs"],"content":"//! MIDI Core - Trusty Modules\n//!\n//! Pure functions for MIDI event encoding, decoding, and validation.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod parser;\npub mod types;\npub mod validator;\npub mod writer;\npub mod loader;\n\n#[allow(unused_imports)]\npub use parser::{parse_midi, ParseError};\n#[allow(unused_imports)]\npub use types::{MidiMessage, MidiEventType};\n#[allow(unused_imports)]\npub use validator::{\n    validate_channel, validate_note, validate_velocity,\n    validate_control_value, validate_message\n};\n#[allow(unused_imports)]\npub use writer::write_midi_file;\n#[allow(unused_imports)]\npub use loader::{load_midi_file, LoadedMidiFile};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","parser.rs"],"content":"//! MIDI File Parser - Trusty Module\n//!\n//! Pure functions for parsing MIDI files into data structures.\n//! NO I/O - caller reads file and passes bytes.\n\nuse crate::models::midi::{MidiEvent, MidiEventType, MidiPattern};\n\n/// Parse error types\n#[derive(Debug, thiserror::Error)]\npub enum ParseError {\n    #[error(\"Invalid MIDI file format: {0}\")]\n    InvalidFormat(String),\n\n    #[error(\"Unsupported MIDI format: {0}\")]\n    UnsupportedFormat(String),\n\n    #[error(\"Incomplete data at position {0}\")]\n    IncompleteData(usize),\n\n    #[error(\"Invalid track data: {0}\")]\n    InvalidTrack(String),\n}\n\n/// Parse complete MIDI file\npub fn parse_midi(data: \u0026[u8]) -\u003e Result\u003cMidiPattern, ParseError\u003e {\n    if data.is_empty() {\n        return Err(ParseError::IncompleteData(0));\n    }\n\n    let mut reader = MidiReader::new(data);\n\n    // Parse header\n    let header = parse_header(\u0026mut reader)?;\n\n    // Parse tracks\n    let mut all_events = Vec::new();\n\n    for _ in 0..header.num_tracks {\n        let track_events = parse_track(\u0026mut reader)?;\n        all_events.extend(track_events);\n    }\n\n    // Sort events by tick\n    all_events.sort_by_key(|e| e.tick);\n\n    let total_ticks = all_events.last().map(|e| e.tick).unwrap_or(0);\n\n    Ok(MidiPattern {\n        events: all_events,\n        ticks_per_quarter_note: header.ticks_per_quarter_note,\n        total_ticks,\n    })\n}\n\n/// MIDI file header\n#[derive(Debug)]\nstruct MidiHeader {\n    num_tracks: u16,\n    ticks_per_quarter_note: u16,\n}\n\n/// Parse MIDI header (MThd chunk)\nfn parse_header(reader: \u0026mut MidiReader) -\u003e Result\u003cMidiHeader, ParseError\u003e {\n    // Read \"MThd\"\n    let chunk_type = reader.read_bytes(4)?;\n    if chunk_type != b\"MThd\" {\n        return Err(ParseError::InvalidFormat(\"Expected MThd header\".to_string()));\n    }\n\n    // Read header length (should be 6)\n    let length = reader.read_u32()?;\n    if length != 6 {\n        return Err(ParseError::InvalidFormat(format!(\n            \"Invalid header length: {}\",\n            length\n        )));\n    }\n\n    // Read format (0, 1, or 2)\n    let format = reader.read_u16()?;\n    if format \u003e 2 {\n        return Err(ParseError::UnsupportedFormat(format!(\n            \"MIDI format {}\",\n            format\n        )));\n    }\n\n    // Read number of tracks\n    let num_tracks = reader.read_u16()?;\n\n    // Read ticks per quarter note\n    let ticks_per_quarter_note = reader.read_u16()?;\n\n    Ok(MidiHeader {\n        num_tracks,\n        ticks_per_quarter_note,\n    })\n}\n\n/// Parse a single track (MTrk chunk)\nfn parse_track(reader: \u0026mut MidiReader) -\u003e Result\u003cVec\u003cMidiEvent\u003e, ParseError\u003e {\n    // Read \"MTrk\"\n    let chunk_type = reader.read_bytes(4)?;\n    if chunk_type != b\"MTrk\" {\n        return Err(ParseError::InvalidTrack(\"Expected MTrk header\".to_string()));\n    }\n\n    // Read track length\n    let track_length = reader.read_u32()? as usize;\n    let track_end = reader.position() + track_length;\n\n    let mut events = Vec::new();\n    let mut current_tick: u64 = 0;\n    let mut running_status: Option\u003cu8\u003e = None;\n\n    while reader.position() \u003c track_end {\n        // Read delta time (variable length)\n        let delta_time = reader.read_variable_length()?;\n        current_tick += delta_time;\n\n        // Peek at next byte to determine if we need running status\n        let status_byte = reader.peek_u8()?;\n\n        let status = if status_byte \u0026 0x80 == 0 {\n            // Running status - reuse previous status\n            running_status.ok_or(ParseError::InvalidTrack(\n                \"No running status available\".to_string(),\n            ))?\n        } else {\n            let s = reader.read_u8()?;\n            if s != 0xFF \u0026\u0026 s != 0xF0 \u0026\u0026 s != 0xF7 {\n                // Not a meta event or sysex, save as running status\n                running_status = Some(s);\n            }\n            s\n        };\n\n        // Parse event based on status\n        if status == 0xFF {\n            // Meta event - skip it\n            let _meta_type = reader.read_u8()?;\n            let length = reader.read_variable_length()?;\n            reader.skip(length as usize)?;\n        } else if status == 0xF0 || status == 0xF7 {\n            // SysEx event - skip it\n            let length = reader.read_variable_length()?;\n            reader.skip(length as usize)?;\n        } else {\n            // Channel event\n            let command = status \u0026 0xF0;\n            let channel = status \u0026 0x0F;\n\n            let event = match command {\n                0x90 =\u003e {\n                    // Note On\n                    let note = reader.read_u8()?;\n                    let velocity = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::NoteOn,\n                        tick: current_tick,\n                        channel,\n                        note: Some(note),\n                        velocity: Some(velocity),\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0x80 =\u003e {\n                    // Note Off\n                    let note = reader.read_u8()?;\n                    let _velocity = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::NoteOff,\n                        tick: current_tick,\n                        channel,\n                        note: Some(note),\n                        velocity: Some(0),\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0xB0 =\u003e {\n                    // Control Change\n                    let controller = reader.read_u8()?;\n                    let value = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::ControlChange,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: Some(controller),\n                        value: Some(value),\n                        program: None,\n                    })\n                }\n                0xC0 =\u003e {\n                    // Program Change\n                    let program = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::ProgramChange,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: Some(program),\n                    })\n                }\n                0xE0 =\u003e {\n                    // Pitch Bend\n                    let _lsb = reader.read_u8()?;\n                    let _msb = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::PitchBend,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0xD0 =\u003e {\n                    // Aftertouch\n                    let _value = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::Aftertouch,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                _ =\u003e None,\n            };\n\n            if let Some(e) = event {\n                events.push(e);\n            }\n        }\n    }\n\n    Ok(events)\n}\n\n/// Helper for reading MIDI binary data\nstruct MidiReader\u003c'a\u003e {\n    data: \u0026'a [u8],\n    pos: usize,\n}\n\nimpl\u003c'a\u003e MidiReader\u003c'a\u003e {\n    fn new(data: \u0026'a [u8]) -\u003e Self {\n        Self { data, pos: 0 }\n    }\n\n    fn position(\u0026self) -\u003e usize {\n        self.pos\n    }\n\n    fn read_u8(\u0026mut self) -\u003e Result\u003cu8, ParseError\u003e {\n        if self.pos \u003e= self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        let value = self.data[self.pos];\n        self.pos += 1;\n        Ok(value)\n    }\n\n    fn peek_u8(\u0026self) -\u003e Result\u003cu8, ParseError\u003e {\n        if self.pos \u003e= self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        Ok(self.data[self.pos])\n    }\n\n    fn read_u16(\u0026mut self) -\u003e Result\u003cu16, ParseError\u003e {\n        let b1 = self.read_u8()? as u16;\n        let b2 = self.read_u8()? as u16;\n        Ok((b1 \u003c\u003c 8) | b2)\n    }\n\n    fn read_u32(\u0026mut self) -\u003e Result\u003cu32, ParseError\u003e {\n        let b1 = self.read_u8()? as u32;\n        let b2 = self.read_u8()? as u32;\n        let b3 = self.read_u8()? as u32;\n        let b4 = self.read_u8()? as u32;\n        Ok((b1 \u003c\u003c 24) | (b2 \u003c\u003c 16) | (b3 \u003c\u003c 8) | b4)\n    }\n\n    fn read_bytes(\u0026mut self, count: usize) -\u003e Result\u003c\u0026'a [u8], ParseError\u003e {\n        if self.pos + count \u003e self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        let bytes = \u0026self.data[self.pos..self.pos + count];\n        self.pos += count;\n        Ok(bytes)\n    }\n\n    fn read_variable_length(\u0026mut self) -\u003e Result\u003cu64, ParseError\u003e {\n        let mut value: u64;\n        let mut byte = self.read_u8()?;\n\n        value = (byte \u0026 0x7F) as u64;\n\n        while byte \u0026 0x80 != 0 {\n            byte = self.read_u8()?;\n            value = (value \u003c\u003c 7) | ((byte \u0026 0x7F) as u64);\n        }\n\n        Ok(value)\n    }\n\n    fn skip(\u0026mut self, count: usize) -\u003e Result\u003c(), ParseError\u003e {\n        if self.pos + count \u003e self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        self.pos += count;\n        Ok(())\n    }\n}\n","traces":[{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":42},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","types.rs"],"content":"//! MIDI types and message encoding/decoding\n//!\n//! Trusty Module: Pure data structures and conversion functions.\n//! No I/O operations - all functions are pure and deterministic.\n\n// Re-export from models for convenience\npub use crate::models::MidiEventType;\n\n/// MIDI message with raw data\n///\n/// Internal representation used for encoding/decoding MIDI messages.\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct MidiMessage {\n    pub event_type: MidiEventType,\n    pub channel: u8,\n    pub data1: u8,\n    pub data2: u8,\n    pub timestamp: u64,\n}\n\nimpl MidiMessage {\n    /// Convert to raw MIDI bytes\n    ///\n    /// Pure function - converts MIDI message to bytes for transmission.\n    pub fn to_bytes(\u0026self) -\u003e Vec\u003cu8\u003e {\n        match self.event_type {\n            MidiEventType::NoteOn =\u003e {\n                vec![\n                    0x90 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    self.data2 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::NoteOff =\u003e {\n                vec![\n                    0x80 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    0x00,\n                ]\n            }\n            MidiEventType::ControlChange =\u003e {\n                vec![\n                    0xB0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    self.data2 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::ProgramChange =\u003e {\n                vec![\n                    0xC0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::PitchBend =\u003e {\n                let value = ((self.data2 as u16) \u003c\u003c 7) | (self.data1 as u16);\n                vec![\n                    0xE0 | (self.channel \u0026 0x0F),\n                    (value \u0026 0x7F) as u8,\n                    ((value \u003e\u003e 7) \u0026 0x7F) as u8,\n                ]\n            }\n            MidiEventType::Aftertouch =\u003e {\n                vec![\n                    0xD0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                ]\n            }\n        }\n    }\n\n    /// Parse from raw MIDI bytes\n    ///\n    /// Pure function - converts raw bytes to MIDI message.\n    pub fn from_bytes(bytes: \u0026[u8]) -\u003e Result\u003cSelf, String\u003e {\n        if bytes.is_empty() {\n            return Err(\"Empty MIDI message\".to_string());\n        }\n\n        let status = bytes[0];\n        let channel = status \u0026 0x0F;\n        let command = status \u0026 0xF0;\n\n        let (event_type, data1, data2) = match command {\n            0x90 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Note On message\".to_string());\n                }\n                (MidiEventType::NoteOn, bytes[1], bytes[2])\n            }\n            0x80 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Note Off message\".to_string());\n                }\n                (MidiEventType::NoteOff, bytes[1], bytes[2])\n            }\n            0xB0 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Control Change message\".to_string());\n                }\n                (MidiEventType::ControlChange, bytes[1], bytes[2])\n            }\n            0xC0 =\u003e {\n                if bytes.len() \u003c 2 {\n                    return Err(\"Incomplete Program Change message\".to_string());\n                }\n                (MidiEventType::ProgramChange, bytes[1], 0)\n            }\n            0xE0 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Pitch Bend message\".to_string());\n                }\n                (MidiEventType::PitchBend, bytes[1], bytes[2])\n            }\n            0xD0 =\u003e {\n                if bytes.len() \u003c 2 {\n                    return Err(\"Incomplete Aftertouch message\".to_string());\n                }\n                (MidiEventType::Aftertouch, bytes[1], 0)\n            }\n            _ =\u003e return Err(format!(\"Unknown MIDI command: {:#X}\", command)),\n        };\n\n        Ok(MidiMessage {\n            event_type,\n            channel,\n            data1,\n            data2,\n            timestamp: 0,\n        })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_note_on_encoding() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 60, // Middle C\n            data2: 100, // Velocity\n            timestamp: 0,\n        };\n\n        let bytes = msg.to_bytes();\n        assert_eq!(bytes, vec![0x90, 60, 100]);\n    }\n\n    #[test]\n    fn test_note_off_encoding() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOff,\n            channel: 0,\n            data1: 60,\n            data2: 0,\n            timestamp: 0,\n        };\n\n        let bytes = msg.to_bytes();\n        assert_eq!(bytes, vec![0x80, 60, 0]);\n    }\n\n    #[test]\n    fn test_message_parsing() {\n        let bytes = vec![0x90, 60, 100];\n        let msg = MidiMessage::from_bytes(\u0026bytes).unwrap();\n\n        assert_eq!(msg.event_type, MidiEventType::NoteOn);\n        assert_eq!(msg.channel, 0);\n        assert_eq!(msg.data1, 60);\n        assert_eq!(msg.data2, 100);\n    }\n\n    #[test]\n    fn test_invalid_message() {\n        let bytes = vec![];\n        let result = MidiMessage::from_bytes(\u0026bytes);\n        assert!(result.is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","validator.rs"],"content":"//! MIDI message validation\n//!\n//! Trusty Module: Pure validation functions for MIDI data.\n//! No I/O operations - all functions are deterministic and testable.\n\nuse super::types::{MidiMessage, MidiEventType};\n\n/// Validate MIDI channel (0-15)\n///\n/// MIDI channels are 0-indexed (0-15 represent MIDI channels 1-16).\npub fn validate_channel(channel: u8) -\u003e Result\u003cu8, String\u003e {\n    if channel \u003e 15 {\n        Err(format!(\n            \"Invalid MIDI channel: {}. Must be 0-15\",\n            channel\n        ))\n    } else {\n        Ok(channel)\n    }\n}\n\n/// Validate MIDI note (0-127)\n///\n/// MIDI note numbers range from 0 to 127 (C-1 to G9).\npub fn validate_note(note: u8) -\u003e Result\u003cu8, String\u003e {\n    if note \u003e 127 {\n        Err(format!(\"Invalid MIDI note: {}. Must be 0-127\", note))\n    } else {\n        Ok(note)\n    }\n}\n\n/// Validate MIDI velocity (0-127)\n///\n/// Velocity 0 is treated as note off in some contexts.\npub fn validate_velocity(velocity: u8) -\u003e Result\u003cu8, String\u003e {\n    if velocity \u003e 127 {\n        Err(format!(\n            \"Invalid velocity: {}. Must be 0-127\",\n            velocity\n        ))\n    } else {\n        Ok(velocity)\n    }\n}\n\n/// Validate MIDI control value (0-127)\n///\n/// Used for control change messages and other data values.\npub fn validate_control_value(value: u8) -\u003e Result\u003cu8, String\u003e {\n    if value \u003e 127 {\n        Err(format!(\n            \"Invalid control value: {}. Must be 0-127\",\n            value\n        ))\n    } else {\n        Ok(value)\n    }\n}\n\n/// Validate complete MIDI message\n///\n/// Performs comprehensive validation of all message fields.\npub fn validate_message(msg: \u0026MidiMessage) -\u003e Result\u003c(), String\u003e {\n    validate_channel(msg.channel)?;\n\n    match msg.event_type {\n        MidiEventType::NoteOn | MidiEventType::NoteOff =\u003e {\n            validate_note(msg.data1)?;\n            validate_velocity(msg.data2)?;\n        }\n        MidiEventType::ControlChange =\u003e {\n            validate_control_value(msg.data1)?;\n            validate_control_value(msg.data2)?;\n        }\n        MidiEventType::ProgramChange =\u003e {\n            validate_control_value(msg.data1)?;\n        }\n        MidiEventType::Aftertouch =\u003e {\n            validate_control_value(msg.data1)?;\n        }\n        MidiEventType::PitchBend =\u003e {\n            // Pitch bend uses 14-bit value split across data1 and data2\n            // Each byte is 7-bit (0-127), so no additional validation needed\n        }\n    }\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_validate_channel() {\n        assert!(validate_channel(0).is_ok());\n        assert!(validate_channel(15).is_ok());\n        assert!(validate_channel(16).is_err());\n        assert!(validate_channel(255).is_err());\n    }\n\n    #[test]\n    fn test_validate_note() {\n        assert!(validate_note(0).is_ok());\n        assert!(validate_note(127).is_ok());\n        assert!(validate_note(128).is_err());\n        assert!(validate_note(255).is_err());\n    }\n\n    #[test]\n    fn test_validate_velocity() {\n        assert!(validate_velocity(0).is_ok());\n        assert!(validate_velocity(127).is_ok());\n        assert!(validate_velocity(128).is_err());\n    }\n\n    #[test]\n    fn test_validate_control_value() {\n        assert!(validate_control_value(0).is_ok());\n        assert!(validate_control_value(127).is_ok());\n        assert!(validate_control_value(128).is_err());\n    }\n\n    #[test]\n    fn test_validate_message_note_on() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 60,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_ok());\n    }\n\n    #[test]\n    fn test_validate_message_invalid_channel() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 16,\n            data1: 60,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_err());\n    }\n\n    #[test]\n    fn test_validate_message_invalid_note() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 128,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","writer.rs"],"content":"//! MIDI File Writer - Trusty Module\n//!\n//! Pure functions for writing MIDI files from event data structures.\n//! NO I/O - caller receives bytes and writes to file.\n\nuse crate::models::midi::{MidiEvent, MidiEventType};\n\n/// Write MIDI file from events\n///\n/// Pure function that generates MIDI file bytes from event data.\n/// Takes events, timing resolution, and tempo as input.\n///\n/// # Arguments\n///\n/// * `events` - Slice of MIDI events to write\n/// * `ticks_per_quarter` - Timing resolution (typically 480 or 960)\n/// * `tempo_bpm` - Tempo in beats per minute (e.g., 120.0)\n///\n/// # Returns\n///\n/// * `Ok(Vec\u003cu8\u003e)` - Complete MIDI file as bytes\n/// * `Err(String)` - Error message if generation fails\n///\npub fn write_midi_file(\n    events: \u0026[MidiEvent],\n    ticks_per_quarter: u16,\n    tempo_bpm: f32,\n) -\u003e Result\u003cVec\u003cu8\u003e, String\u003e {\n    let mut data = Vec::new();\n\n    // Write header (format 1, 1 track, ticks per quarter note)\n    write_header(\u0026mut data, 1, 1, ticks_per_quarter);\n\n    // Write track with all events\n    write_track(\u0026mut data, events, tempo_bpm, ticks_per_quarter);\n\n    Ok(data)\n}\n\n/// Write MIDI header chunk (MThd)\nfn write_header(data: \u0026mut Vec\u003cu8\u003e, format: u16, tracks: u16, tpqn: u16) {\n    // Chunk type: \"MThd\"\n    data.extend_from_slice(b\"MThd\");\n\n    // Chunk length (always 6 for header)\n    data.extend_from_slice(\u00266u32.to_be_bytes());\n\n    // Format (0 = single track, 1 = multiple tracks, 2 = multiple sequences)\n    data.extend_from_slice(\u0026format.to_be_bytes());\n\n    // Number of tracks\n    data.extend_from_slice(\u0026tracks.to_be_bytes());\n\n    // Ticks per quarter note\n    data.extend_from_slice(\u0026tpqn.to_be_bytes());\n}\n\n/// Write MIDI track chunk (MTrk)\nfn write_track(\n    data: \u0026mut Vec\u003cu8\u003e,\n    events: \u0026[MidiEvent],\n    tempo_bpm: f32,\n    _tpqn: u16,\n) {\n    let mut track_data = Vec::new();\n\n    // Write tempo meta event at the start\n    write_tempo_event(\u0026mut track_data, tempo_bpm);\n\n    // Write all MIDI events with delta times\n    let mut last_tick = 0u64;\n    for event in events {\n        let delta = event.tick.saturating_sub(last_tick);\n        write_variable_length(\u0026mut track_data, delta);\n        write_event(\u0026mut track_data, event);\n        last_tick = event.tick;\n    }\n\n    // End of track meta event\n    write_variable_length(\u0026mut track_data, 0);\n    track_data.extend_from_slice(\u0026[0xFF, 0x2F, 0x00]);\n\n    // Write track header\n    data.extend_from_slice(b\"MTrk\");\n    data.extend_from_slice(\u0026(track_data.len() as u32).to_be_bytes());\n    data.extend_from_slice(\u0026track_data);\n}\n\n/// Write tempo meta event\n///\n/// MIDI tempo is stored as microseconds per quarter note.\n/// Conversion: microseconds_per_quarter = 60,000,000 / BPM\nfn write_tempo_event(data: \u0026mut Vec\u003cu8\u003e, bpm: f32) {\n    let microseconds_per_quarter = (60_000_000.0 / bpm) as u32;\n\n    write_variable_length(data, 0); // Delta time = 0 (at start)\n    data.push(0xFF); // Meta event\n    data.push(0x51); // Tempo meta event type\n    data.push(0x03); // Length = 3 bytes\n\n    // Write 3-byte tempo value (big-endian, skip first byte of u32)\n    data.extend_from_slice(\u0026microseconds_per_quarter.to_be_bytes()[1..4]);\n}\n\n/// Write single MIDI event\nfn write_event(data: \u0026mut Vec\u003cu8\u003e, event: \u0026MidiEvent) {\n    match event.event_type {\n        MidiEventType::NoteOn =\u003e {\n            data.push(0x90 | (event.channel \u0026 0x0F));\n            data.push(event.note.unwrap_or(0) \u0026 0x7F);\n            data.push(event.velocity.unwrap_or(100) \u0026 0x7F);\n        }\n        MidiEventType::NoteOff =\u003e {\n            data.push(0x80 | (event.channel \u0026 0x0F));\n            data.push(event.note.unwrap_or(0) \u0026 0x7F);\n            data.push(0x00); // Note off velocity is always 0\n        }\n        MidiEventType::ControlChange =\u003e {\n            data.push(0xB0 | (event.channel \u0026 0x0F));\n            data.push(event.controller.unwrap_or(0) \u0026 0x7F);\n            data.push(event.value.unwrap_or(0) \u0026 0x7F);\n        }\n        MidiEventType::ProgramChange =\u003e {\n            data.push(0xC0 | (event.channel \u0026 0x0F));\n            data.push(event.program.unwrap_or(0) \u0026 0x7F);\n        }\n        MidiEventType::PitchBend =\u003e {\n            data.push(0xE0 | (event.channel \u0026 0x0F));\n            // Pitch bend is a 14-bit value (0-16383, center = 8192)\n            // For now, we'll write a neutral pitch bend\n            data.push(0x00); // LSB\n            data.push(0x40); // MSB (64 = center)\n        }\n        MidiEventType::Aftertouch =\u003e {\n            data.push(0xD0 | (event.channel \u0026 0x0F));\n            data.push(0x00); // Pressure value\n        }\n    }\n}\n\n/// Write variable-length quantity (MIDI standard encoding)\n///\n/// MIDI uses variable-length quantities to save space.\n/// - Values 0-127: single byte (0xxxxxxx)\n/// - Larger values: multiple bytes (1xxxxxxx 1xxxxxxx ... 0xxxxxxx)\n/// - Most significant bit = 1 means \"more bytes follow\"\n/// - Each byte contributes 7 bits to the value\n///\n/// Examples:\n/// - 0  [0x00]\n/// - 127  [0x7F]\n/// - 128  [0x81, 0x00]\n/// - 8192  [0xC0, 0x00]\nfn write_variable_length(data: \u0026mut Vec\u003cu8\u003e, mut value: u64) {\n    let mut bytes = Vec::new();\n\n    // Write least significant 7 bits (without continuation bit)\n    bytes.push((value \u0026 0x7F) as u8);\n    value \u003e\u003e= 7;\n\n    // Write remaining 7-bit groups (with continuation bit set)\n    while value \u003e 0 {\n        bytes.push(((value \u0026 0x7F) | 0x80) as u8);\n        value \u003e\u003e= 7;\n    }\n\n    // Reverse to get big-endian order\n    bytes.reverse();\n    data.extend_from_slice(\u0026bytes);\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_write_variable_length_small() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 0);\n        assert_eq!(data, vec![0x00]);\n\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 127);\n        assert_eq!(data, vec![0x7F]);\n    }\n\n    #[test]\n    fn test_write_variable_length_medium() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 128);\n        assert_eq!(data, vec![0x81, 0x00]);\n\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 255);\n        assert_eq!(data, vec![0x81, 0x7F]);\n    }\n\n    #[test]\n    fn test_write_variable_length_large() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 8192);\n        assert_eq!(data, vec![0xC0, 0x00]);\n    }\n\n    #[test]\n    fn test_write_simple_midi() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(100),\n                controller: None,\n                value: None,\n                program: None,\n            },\n            MidiEvent {\n                event_type: MidiEventType::NoteOff,\n                tick: 480,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(0),\n                controller: None,\n                value: None,\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n\n        let data = result.unwrap();\n        // Verify header\n        assert_eq!(\u0026data[0..4], b\"MThd\");\n        // Verify track chunk exists\n        assert!(data.windows(4).any(|w| w == b\"MTrk\"));\n    }\n\n    #[test]\n    fn test_write_empty_events() {\n        let events = vec![];\n        let result = write_midi_file(\u0026events, 480, 120.0);\n\n        assert!(result.is_ok());\n        let data = result.unwrap();\n\n        // Should still have valid MIDI structure\n        assert_eq!(\u0026data[0..4], b\"MThd\");\n        assert!(data.windows(4).any(|w| w == b\"MTrk\"));\n    }\n\n    #[test]\n    fn test_write_control_change() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::ControlChange,\n                tick: 0,\n                channel: 0,\n                note: None,\n                velocity: None,\n                controller: Some(7), // Volume\n                value: Some(100),\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_write_multiple_channels() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(100),\n                controller: None,\n                value: None,\n                program: None,\n            },\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 9, // Typically drums\n                note: Some(36), // Bass drum\n                velocity: Some(120),\n                controller: None,\n                value: None,\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","mod.rs"],"content":"//! Core business logic modules\n//!\n//! Trusty Modules: Pure functions with no I/O operations.\n//! All modules here contain deterministic, testable code.\n\npub mod midi;\npub mod sequencer;\npub mod compatibility;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","sequencer","mod.rs"],"content":"//! Sequencer Core - Trusty Modules\n//!\n//! Pure functions for timing calculations and sequencer logic.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod timing;\n\n#[allow(unused_imports)]\npub use timing::{\n    BarPosition, microseconds_per_tick, tick_to_bar_beat, bar_beat_to_tick,\n    ticks_to_seconds, seconds_to_ticks, ticks_to_microseconds,\n    microseconds_to_ticks, calculate_bar_position, ticks_per_bar,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","sequencer","timing.rs"],"content":"//! Sequencer timing calculations\n//!\n//! Trusty Module: Pure timing functions for MIDI sequencing.\n//! All functions are deterministic and thoroughly tested.\n\n/// Bar position structure\n///\n/// Represents a position in musical time as bar:beat:tick.\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub struct BarPosition {\n    pub bar: u32,\n    pub beat: u32,\n    pub tick: u64,\n}\n\n/// Calculate microseconds per tick at given BPM\n///\n/// Used for high-precision timing in MIDI playback.\n///\n/// # Arguments\n/// * `bpm` - Beats per minute\n/// * `ticks_per_quarter` - MIDI resolution (typically 480)\n///\n/// # Returns\n/// Microseconds per tick as f64\npub fn microseconds_per_tick(bpm: f32, ticks_per_quarter: u16) -\u003e f64 {\n    let microseconds_per_minute = 60_000_000.0;\n    let microseconds_per_beat = microseconds_per_minute / bpm as f64;\n    microseconds_per_beat / ticks_per_quarter as f64\n}\n\n/// Calculate bar and beat from tick position\n///\n/// Converts absolute tick position to musical bar:beat notation.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `ticks_per_quarter` - MIDI resolution\n/// * `beats_per_bar` - Time signature numerator (typically 4)\n///\n/// # Returns\n/// Tuple of (bar, beat) as (u32, u32)\npub fn tick_to_bar_beat(\n    tick: u64,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n) -\u003e (u32, u32) {\n    let ticks_per_beat = ticks_per_quarter as u64;\n    let ticks_per_bar = ticks_per_beat * beats_per_bar as u64;\n\n    let bar = (tick / ticks_per_bar) as u32;\n    let beat = ((tick % ticks_per_bar) / ticks_per_beat) as u32;\n\n    (bar, beat)\n}\n\n/// Calculate tick position from bar and beat\n///\n/// Converts musical bar:beat notation to absolute tick position.\n///\n/// # Arguments\n/// * `bar` - Bar number (0-indexed)\n/// * `beat` - Beat within bar (0-indexed)\n/// * `ticks_per_quarter` - MIDI resolution\n/// * `beats_per_bar` - Time signature numerator\n///\n/// # Returns\n/// Absolute tick position as u64\npub fn bar_beat_to_tick(\n    bar: u32,\n    beat: u32,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n) -\u003e u64 {\n    let ticks_per_beat = ticks_per_quarter as u64;\n    let ticks_per_bar = ticks_per_beat * beats_per_bar as u64;\n\n    (bar as u64 * ticks_per_bar) + (beat as u64 * ticks_per_beat)\n}\n\n/// Calculate seconds from ticks\n///\n/// Converts MIDI ticks to real time in seconds.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `bpm` - Current tempo\n/// * `ticks_per_quarter` - MIDI resolution\n///\n/// # Returns\n/// Time in seconds as f64\npub fn ticks_to_seconds(tick: u64, bpm: f32, ticks_per_quarter: u16) -\u003e f64 {\n    let us_per_tick = microseconds_per_tick(bpm, ticks_per_quarter);\n    (tick as f64 * us_per_tick) / 1_000_000.0\n}\n\n/// Calculate ticks from seconds\n///\n/// Converts real time in seconds to MIDI ticks.\n///\n/// # Arguments\n/// * `seconds` - Time in seconds\n/// * `bpm` - Current tempo\n/// * `ticks_per_quarter` - MIDI resolution\n///\n/// # Returns\n/// Absolute tick position as u64\npub fn seconds_to_ticks(seconds: f64, bpm: f32, ticks_per_quarter: u16) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, ticks_per_quarter);\n    ((seconds * 1_000_000.0) / us_per_tick) as u64\n}\n\n/// Convert ticks to microseconds\n///\n/// Converts MIDI ticks to microseconds for precise timing.\n///\n/// # Arguments\n/// * `ticks` - Number of ticks\n/// * `tpqn` - Ticks per quarter note\n/// * `bpm` - Beats per minute\n///\n/// # Returns\n/// Time in microseconds as u64\npub fn ticks_to_microseconds(ticks: u64, tpqn: u16, bpm: f32) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, tpqn);\n    (ticks as f64 * us_per_tick) as u64\n}\n\n/// Convert microseconds to ticks\n///\n/// Converts microseconds to MIDI ticks.\n///\n/// # Arguments\n/// * `micros` - Time in microseconds\n/// * `tpqn` - Ticks per quarter note\n/// * `bpm` - Beats per minute\n///\n/// # Returns\n/// Number of ticks as u64\npub fn microseconds_to_ticks(micros: u64, tpqn: u16, bpm: f32) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, tpqn);\n    (micros as f64 / us_per_tick) as u64\n}\n\n/// Calculate bar position from tick\n///\n/// Converts absolute tick to bar:beat:tick position.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `tpqn` - Ticks per quarter note\n/// * `time_sig_num` - Time signature numerator (e.g., 4 in 4/4)\n/// * `time_sig_denom` - Time signature denominator (e.g., 4 in 4/4)\n///\n/// # Returns\n/// BarPosition with bar, beat, and tick within beat\npub fn calculate_bar_position(\n    tick: u64,\n    tpqn: u16,\n    time_sig_num: u8,\n    time_sig_denom: u8,\n) -\u003e BarPosition {\n    let ticks_per_beat = (tpqn as u64 * 4) / time_sig_denom as u64;\n    let ticks_per_bar = ticks_per_beat * time_sig_num as u64;\n\n    let bar = (tick / ticks_per_bar) as u32;\n    let tick_in_bar = tick % ticks_per_bar;\n    let beat = (tick_in_bar / ticks_per_beat) as u32;\n    let tick_in_beat = tick_in_bar % ticks_per_beat;\n\n    BarPosition {\n        bar,\n        beat,\n        tick: tick_in_beat,\n    }\n}\n\n/// Calculate ticks per bar\n///\n/// Calculates the number of ticks in one bar based on time signature.\n///\n/// # Arguments\n/// * `tpqn` - Ticks per quarter note\n/// * `time_sig_num` - Time signature numerator (e.g., 4 in 4/4)\n/// * `time_sig_denom` - Time signature denominator (e.g., 4 in 4/4)\n///\n/// # Returns\n/// Number of ticks per bar as u64\n///\n/// # Examples\n/// - 4/4 time with 480 TPQN: 1920 ticks per bar (4 quarter notes)\n/// - 3/4 time with 480 TPQN: 1440 ticks per bar (3 quarter notes)\n/// - 6/8 time with 480 TPQN: 1440 ticks per bar (2 dotted quarter notes)\npub fn ticks_per_bar(tpqn: u16, time_sig_num: u8, time_sig_denom: u8) -\u003e u64 {\n    let ticks_per_beat = (tpqn as u64 * 4) / time_sig_denom as u64;\n    ticks_per_beat * time_sig_num as u64\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_per_tick() {\n        // At 120 BPM with 480 TPQN:\n        // 60,000,000 / 120 = 500,000 s per beat\n        // 500,000 / 480 = 1041.67 s per tick\n        let result = microseconds_per_tick(120.0, 480);\n        assert!((result - 1041.67).abs() \u003c 0.01);\n    }\n\n    #[test]\n    fn test_microseconds_per_tick_different_bpm() {\n        // At 90 BPM:\n        // 60,000,000 / 90 = 666,666.67 s per beat\n        // 666,666.67 / 480 = 1388.89 s per tick\n        let result = microseconds_per_tick(90.0, 480);\n        assert!((result - 1388.89).abs() \u003c 0.01);\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_start() {\n        // Bar 0, Beat 0 = tick 0\n        assert_eq!(tick_to_bar_beat(0, 480, 4), (0, 0));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_second_beat() {\n        // Bar 0, Beat 1 = tick 480\n        assert_eq!(tick_to_bar_beat(480, 480, 4), (0, 1));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_second_bar() {\n        // Bar 1, Beat 0 = tick 1920 (480 * 4)\n        assert_eq!(tick_to_bar_beat(1920, 480, 4), (1, 0));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_complex() {\n        // Bar 2, Beat 3 = tick 4560 (480 * 4 * 2 + 480 * 3)\n        assert_eq!(tick_to_bar_beat(5280, 480, 4), (2, 3));\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_start() {\n        assert_eq!(bar_beat_to_tick(0, 0, 480, 4), 0);\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_second_beat() {\n        assert_eq!(bar_beat_to_tick(0, 1, 480, 4), 480);\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_second_bar() {\n        assert_eq!(bar_beat_to_tick(1, 0, 480, 4), 1920);\n    }\n\n    #[test]\n    fn test_bar_beat_round_trip() {\n        // Test round-trip conversion\n        let original_tick = 5280u64;\n        let (bar, beat) = tick_to_bar_beat(original_tick, 480, 4);\n        let converted_tick = bar_beat_to_tick(bar, beat, 480, 4);\n        assert_eq!(original_tick, converted_tick);\n    }\n\n    #[test]\n    fn test_ticks_to_seconds() {\n        // At 120 BPM, 480 TPQN:\n        // 1920 ticks = 1 bar = 4 beats = 2 seconds\n        let seconds = ticks_to_seconds(1920, 120.0, 480);\n        assert!((seconds - 2.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_seconds_to_ticks() {\n        // At 120 BPM, 480 TPQN:\n        // 2 seconds = 4 beats = 1920 ticks\n        let ticks = seconds_to_ticks(2.0, 120.0, 480);\n        // Allow for floating point rounding (within 1 tick)\n        assert!((ticks as i64 - 1920).abs() \u003c= 1);\n    }\n\n    #[test]\n    fn test_time_conversion_round_trip() {\n        let original_ticks = 3840u64;\n        let seconds = ticks_to_seconds(original_ticks, 120.0, 480);\n        let converted_ticks = seconds_to_ticks(seconds, 120.0, 480);\n        assert_eq!(original_ticks, converted_ticks);\n    }\n\n    #[test]\n    fn test_different_time_signatures() {\n        // 3/4 time (3 beats per bar)\n        assert_eq!(tick_to_bar_beat(1440, 480, 3), (1, 0)); // Bar 1 in 3/4\n        assert_eq!(bar_beat_to_tick(1, 0, 480, 3), 1440);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","lib.rs"],"content":"//! MIDI Library DAW Interface\n//!\n//! Core library for DAW functionality including MIDI playback, sequencing, and search.\n\npub mod core;\npub mod models;\n\n// Re-export commonly used types\npub use models::{MidiFile, FileDetails, AppError, AppResult};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","main.rs"],"content":"// daw/src-tauri/src/main.rs\n// Task-O-Matic: Main entry point for DAW application\n// Purpose: Initialize app, register commands, manage state with MIDI hardware\n\n#![cfg_attr(\n    all(not(debug_assertions), target_os = \"windows\"),\n    windows_subsystem = \"windows\"\n)]\n\nuse tracing::{info, warn, error};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\nmod commands;\nmod models;\nmod core;\nmod midi;\nmod sequencer;\n\nuse commands::AppState;\nuse midi::MidiManager;\nuse sequencer::SequencerEngine;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    // Initialize tracing/logging\n    init_logging();\n\n    info!(\"Starting MIDI DAW application\");\n\n    // Initialize database connection pool\n    let db_pool = match initialize_database_pool().await {\n        Ok(pool) =\u003e {\n            info!(\" Database connection pool initialized\");\n            Some(pool)\n        }\n        Err(e) =\u003e {\n            warn!(\"  Database connection failed: {}\", e);\n            warn!(\"  DAW will run without database features (search, analysis, etc.)\");\n            None\n        }\n    };\n\n    // Initialize MIDI manager (no database required for DAW startup)\n    let midi_manager = Arc::new(MidiManager::new());\n    info!(\"MIDI manager initialized\");\n\n    // Initialize sequencer engine\n    let sequencer_engine = Arc::new(SequencerEngine::new(\n        midi_manager.clone(),\n        120.0, // Default 120 BPM\n        480,   // Standard MIDI resolution\n    ));\n    info!(\"Sequencer engine initialized\");\n\n    // Create application state\n    let state = AppState {\n        db_pool,\n    };\n\n    // Build and run Tauri application\n    tauri::Builder::default()\n        .manage(state)\n        .manage(midi_manager)\n        .manage(sequencer_engine)\n        .invoke_handler(tauri::generate_handler![\n            // Database commands\n            commands::initialize_database,\n            // MIDI commands\n            commands::midi::midi_list_devices,\n            commands::midi::midi_connect,\n            commands::midi::midi_disconnect,\n            commands::midi::midi_is_connected,\n            commands::midi::midi_get_current_device,\n            commands::midi::midi_send_test_note,\n            // Sequencer commands\n            commands::sequencer::start_sequencer,\n            commands::sequencer::stop_sequencer,\n            commands::sequencer::pause_sequencer,\n            commands::sequencer::resume_sequencer,\n            commands::sequencer::get_playback_position,\n            commands::sequencer::seek_position,\n            commands::sequencer::set_tempo,\n            commands::sequencer::get_tempo,\n            commands::sequencer::add_track,\n            commands::sequencer::remove_track,\n            commands::sequencer::update_track,\n            commands::sequencer::get_tracks,\n            commands::sequencer::load_sequencer_tracks,\n            commands::sequencer::is_sequencer_playing,\n            // Search commands\n            commands::search::search_files,\n            commands::search::get_file_details,\n            commands::search::get_search_suggestions,\n            // Analysis commands\n            commands::analysis::find_compatible_files,\n            commands::analysis::add_favorite,\n            commands::analysis::remove_favorite,\n            commands::analysis::is_favorite,\n            commands::analysis::get_favorites,\n            commands::analysis::get_usage_stats,\n            // Project commands\n            commands::project::load_multiple_tracks,\n            commands::project::clear_all_tracks,\n            commands::project::get_track_details,\n            // Export commands\n            commands::export::export_project_midi,\n        ])\n        .run(tauri::generate_context!())?;\n\n    Ok(())\n}\n\n/// Initialize logging/tracing system\nfn init_logging() {\n    let log_dir = std::env::var(\"LOG_DIR\").unwrap_or_else(|_| \"./logs\".to_string());\n    std::fs::create_dir_all(\u0026log_dir).ok();\n\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"daw.log\");\n    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);\n\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| \"info,midi_daw=debug\".into()),\n        )\n        .with(tracing_subscriber::fmt::layer().with_writer(std::io::stdout))\n        .with(tracing_subscriber::fmt::layer().with_writer(non_blocking))\n        .init();\n}\n\n/// Initialize PostgreSQL database connection pool\n///\n/// Reads DATABASE_URL from environment and creates a connection pool.\n/// Returns an error if DATABASE_URL is not set or connection fails.\nasync fn initialize_database_pool() -\u003e Result\u003csqlx::PgPool, String\u003e {\n    // Get DATABASE_URL from environment\n    let database_url = std::env::var(\"DATABASE_URL\")\n        .map_err(|_| {\n            \"DATABASE_URL not set. Please set it to: postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n        })?;\n\n    info!(\"Connecting to database: {}\", database_url.replace(\":145278963\", \":****\"));\n\n    // Get max connections from environment or use default\n    let max_connections: u32 = std::env::var(\"DB_MAX_CONNECTIONS\")\n        .ok()\n        .and_then(|s| s.parse().ok())\n        .unwrap_or(10);\n\n    // Create connection pool\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(max_connections)\n        .connect(\u0026database_url)\n        .await\n        .map_err(|e| format!(\"Failed to connect to database: {}\", e))?;\n\n    // Test connection with a simple query\n    sqlx::query(\"SELECT 1\")\n        .execute(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to execute test query: {}\", e))?;\n\n    info!(\"Database connection pool created with {} max connections\", max_connections);\n\n    Ok(pool)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","midi","manager.rs"],"content":"//! MIDI connection manager\n//!\n//! Grown-up Script: Handles MIDI device connections and message transmission.\n//! Delegates validation and encoding to Trusty Modules.\n\nuse midir::{MidiOutput, MidiOutputConnection};\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\nuse tracing::{info, warn, error};\n\nuse crate::core::midi::types::{MidiMessage, MidiEventType};\nuse crate::core::midi::validator;\nuse crate::models::MidiDevice;\n\n/// Thread-safe MIDI connection manager\n///\n/// Manages MIDI output connections with thread-safe access.\n/// Uses Arc\u003cMutex\u003c\u003e\u003e for safe concurrent access from multiple threads.\npub struct MidiManager {\n    connection: Arc\u003cMutex\u003cOption\u003cMidiOutputConnection\u003e\u003e\u003e,\n    current_device: Arc\u003cMutex\u003cOption\u003cString\u003e\u003e\u003e,\n}\n\nimpl MidiManager {\n    /// Create a new MIDI manager\n    pub fn new() -\u003e Self {\n        info!(\"Creating MIDI manager\");\n        Self {\n            connection: Arc::new(Mutex::new(None)),\n            current_device: Arc::new(Mutex::new(None)),\n        }\n    }\n\n    /// List available MIDI output devices\n    ///\n    /// Returns list of all MIDI output ports found on the system.\n    pub fn list_devices(\u0026self) -\u003e Result\u003cVec\u003cMidiDevice\u003e, String\u003e {\n        let midi_out = MidiOutput::new(\"MIDI Library DAW\")\n            .map_err(|e| {\n                error!(\"Failed to create MIDI output: {}\", e);\n                format!(\"Failed to create MIDI output: {}\", e)\n            })?;\n\n        let ports = midi_out.ports();\n        let mut devices = Vec::new();\n\n        for port in ports {\n            if let Ok(name) = midi_out.port_name(\u0026port) {\n                devices.push(MidiDevice {\n                    name: name.clone(),\n                    manufacturer: parse_manufacturer(\u0026name),\n                });\n            }\n        }\n\n        info!(\"Found {} MIDI devices\", devices.len());\n        Ok(devices)\n    }\n\n    /// Connect to a MIDI device\n    ///\n    /// Establishes connection to the specified MIDI output device.\n    pub async fn connect(\u0026self, device_name: \u0026str) -\u003e Result\u003c(), String\u003e {\n        info!(\"Attempting to connect to MIDI device: {}\", device_name);\n\n        // Create MIDI output\n        let midi_out = MidiOutput::new(\"MIDI Library DAW\")\n            .map_err(|e| {\n                error!(\"Failed to create MIDI output: {}\", e);\n                format!(\"Failed to create MIDI output: {}\", e)\n            })?;\n\n        // Find the port\n        let ports = midi_out.ports();\n        let port = ports\n            .iter()\n            .find(|p| {\n                midi_out\n                    .port_name(p)\n                    .ok()\n                    .as_ref()\n                    .map(|n| n == device_name)\n                    .unwrap_or(false)\n            })\n            .ok_or_else(|| {\n                error!(\"Device '{}' not found\", device_name);\n                format!(\"Device '{}' not found\", device_name)\n            })?;\n\n        // Connect\n        let connection = midi_out\n            .connect(port, \"daw-output\")\n            .map_err(|e| {\n                error!(\"Connection failed: {}\", e);\n                format!(\"Connection failed: {}\", e)\n            })?;\n\n        // Store connection\n        let mut conn_lock = self.connection.lock().await;\n        *conn_lock = Some(connection);\n\n        let mut device_lock = self.current_device.lock().await;\n        *device_lock = Some(device_name.to_string());\n\n        info!(\"Successfully connected to MIDI device: {}\", device_name);\n\n        Ok(())\n    }\n\n    /// Disconnect from MIDI device\n    ///\n    /// Closes the current MIDI connection if one exists.\n    pub async fn disconnect(\u0026self) {\n        let mut conn_lock = self.connection.lock().await;\n        *conn_lock = None;\n\n        let mut device_lock = self.current_device.lock().await;\n        let device_name = device_lock.take();\n\n        if let Some(name) = device_name {\n            info!(\"Disconnected from MIDI device: {}\", name);\n        } else {\n            info!(\"Disconnected (no device was connected)\");\n        }\n    }\n\n    /// Check if connected\n    ///\n    /// Returns true if a MIDI device is currently connected.\n    pub async fn is_connected(\u0026self) -\u003e bool {\n        let conn_lock = self.connection.lock().await;\n        conn_lock.is_some()\n    }\n\n    /// Get current device name\n    ///\n    /// Returns the name of the currently connected device, if any.\n    pub async fn current_device(\u0026self) -\u003e Option\u003cString\u003e {\n        let device_lock = self.current_device.lock().await;\n        device_lock.clone()\n    }\n\n    /// Send a MIDI message\n    ///\n    /// Validates and sends a MIDI message to the connected device.\n    /// Uses Trusty Module validation before sending.\n    pub async fn send_message(\u0026self, msg: \u0026MidiMessage) -\u003e Result\u003c(), String\u003e {\n        // Validate message (Trusty Module)\n        validator::validate_message(msg)?;\n\n        // Get connection\n        let mut conn_lock = self.connection.lock().await;\n\n        if let Some(connection) = conn_lock.as_mut() {\n            let bytes = msg.to_bytes();\n            connection.send(\u0026bytes).map_err(|e| {\n                error!(\"Failed to send MIDI message: {}\", e);\n                format!(\"Failed to send MIDI message: {}\", e)\n            })?;\n            Ok(())\n        } else {\n            warn!(\"Attempted to send MIDI message with no device connected\");\n            Err(\"No MIDI device connected\".to_string())\n        }\n    }\n\n    /// Send a note on message\n    ///\n    /// Convenience method for sending note on events.\n    pub async fn send_note_on(\n        \u0026self,\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel,\n            data1: note,\n            data2: velocity,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a note off message\n    ///\n    /// Convenience method for sending note off events.\n    pub async fn send_note_off(\u0026self, channel: u8, note: u8) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOff,\n            channel,\n            data1: note,\n            data2: 0,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a control change message\n    ///\n    /// Convenience method for sending control change events.\n    pub async fn send_control_change(\n        \u0026self,\n        channel: u8,\n        controller: u8,\n        value: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::ControlChange,\n            channel,\n            data1: controller,\n            data2: value,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a program change message\n    ///\n    /// Convenience method for sending program change events.\n    pub async fn send_program_change(\n        \u0026self,\n        channel: u8,\n        program: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::ProgramChange,\n            channel,\n            data1: program,\n            data2: 0,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n}\n\nimpl Default for MidiManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Parse manufacturer from device name\n///\n/// Attempts to extract manufacturer name from MIDI device name.\n/// This is a best-effort approach as device naming is not standardized.\nfn parse_manufacturer(name: \u0026str) -\u003e Option\u003cString\u003e {\n    // Common manufacturer patterns\n    if name.contains(\"Steinberg\") {\n        Some(\"Steinberg\".to_string())\n    } else if name.contains(\"Akai\") {\n        Some(\"Akai\".to_string())\n    } else if name.contains(\"Roland\") {\n        Some(\"Roland\".to_string())\n    } else if name.contains(\"Yamaha\") {\n        Some(\"Yamaha\".to_string())\n    } else if name.contains(\"Korg\") {\n        Some(\"Korg\".to_string())\n    } else if name.contains(\"Moog\") {\n        Some(\"Moog\".to_string())\n    } else if name.contains(\"Arturia\") {\n        Some(\"Arturia\".to_string())\n    } else if name.contains(\"Native Instruments\") || name.contains(\"NI\") {\n        Some(\"Native Instruments\".to_string())\n    } else {\n        None\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_list_devices() {\n        let manager = MidiManager::new();\n        let result = manager.list_devices();\n\n        // Should not error, even if no devices\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_connect_invalid_device() {\n        let manager = MidiManager::new();\n        let result = manager.connect(\"NonexistentDevice123\").await;\n\n        // Should error for nonexistent device\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_disconnect_when_not_connected() {\n        let manager = MidiManager::new();\n        manager.disconnect().await;\n\n        // Should not panic\n        assert!(!manager.is_connected().await);\n    }\n\n    #[tokio::test]\n    async fn test_is_connected_initially_false() {\n        let manager = MidiManager::new();\n        assert!(!manager.is_connected().await);\n    }\n\n    #[tokio::test]\n    async fn test_current_device_initially_none() {\n        let manager = MidiManager::new();\n        assert_eq!(manager.current_device().await, None);\n    }\n\n    #[test]\n    fn test_parse_manufacturer() {\n        assert_eq!(\n            parse_manufacturer(\"Steinberg UR22\"),\n            Some(\"Steinberg\".to_string())\n        );\n        assert_eq!(\n            parse_manufacturer(\"Akai MPC One\"),\n            Some(\"Akai\".to_string())\n        );\n        assert_eq!(parse_manufacturer(\"Unknown Device\"), None);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","midi","mod.rs"],"content":"//! MIDI hardware management\n//!\n//! Grown-up Scripts: Handle MIDI device I/O and state management.\n//! Delegates business logic to Trusty Modules in core/midi.\n\npub mod manager;\n\npub use manager::MidiManager;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","analysis.rs"],"content":"//! Analysis and compatibility models\n//!\n//! Trusty Module: Pure data structures for musical compatibility analysis.\n\nuse serde::Serialize;\nuse std::str::FromStr;\n\n/**\n * Compatible file match\n *\n * Represents a file that is musically compatible with a reference file.\n */\n#[derive(Debug, Serialize)]\npub struct CompatibleFile {\n    pub id: i32,\n    pub file_name: String,\n    pub compatibility_score: i32,         // 0-100\n    pub key_match: bool,\n    pub bpm_difference: Option\u003cf32\u003e,\n    pub time_signature_match: bool,\n    pub suggested_bpm_multiplier: Option\u003cf32\u003e,\n    pub category: Option\u003cString\u003e,\n}\n\n/**\n * Key signature for compatibility analysis\n *\n * Represents musical keys in semitone notation.\n */\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Key {\n    C,\n    CSharp,\n    D,\n    DSharp,\n    E,\n    F,\n    FSharp,\n    G,\n    GSharp,\n    A,\n    ASharp,\n    B,\n}\n\nimpl Key {\n    /// Parse key from string (e.g., \"C\", \"C#\", \"Cm\", \"C#m\")\n    ///\n    /// Handles both sharp and flat notations.\n    pub fn from_string(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let key_part = s.split('m').next()?;\n\n        match key_part {\n            \"C\" =\u003e Some(Key::C),\n            \"C#\" | \"Db\" =\u003e Some(Key::CSharp),\n            \"D\" =\u003e Some(Key::D),\n            \"D#\" | \"Eb\" =\u003e Some(Key::DSharp),\n            \"E\" =\u003e Some(Key::E),\n            \"F\" =\u003e Some(Key::F),\n            \"F#\" | \"Gb\" =\u003e Some(Key::FSharp),\n            \"G\" =\u003e Some(Key::G),\n            \"G#\" | \"Ab\" =\u003e Some(Key::GSharp),\n            \"A\" =\u003e Some(Key::A),\n            \"A#\" | \"Bb\" =\u003e Some(Key::ASharp),\n            \"B\" =\u003e Some(Key::B),\n            _ =\u003e None,\n        }\n    }\n\n    /// Get semitone value (0-11)\n    pub fn semitone(\u0026self) -\u003e i32 {\n        match self {\n            Key::C =\u003e 0,\n            Key::CSharp =\u003e 1,\n            Key::D =\u003e 2,\n            Key::DSharp =\u003e 3,\n            Key::E =\u003e 4,\n            Key::F =\u003e 5,\n            Key::FSharp =\u003e 6,\n            Key::G =\u003e 7,\n            Key::GSharp =\u003e 8,\n            Key::A =\u003e 9,\n            Key::ASharp =\u003e 10,\n            Key::B =\u003e 11,\n        }\n    }\n\n    /// Calculate distance between two keys (shortest path on circle of fifths)\n    pub fn distance(\u0026self, other: \u0026Key) -\u003e i32 {\n        let diff = (other.semitone() - self.semitone()).abs();\n        // Return shortest distance around the circle (max 6 semitones)\n        diff.min(12 - diff)\n    }\n}\n\nimpl FromStr for Key {\n    type Err = String;\n\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::from_string(s).ok_or_else(|| format!(\"Invalid key: {}\", s))\n    }\n}\n\n/**\n * Mode (major or minor)\n *\n * Musical mode for key signature analysis.\n */\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Mode {\n    Major,\n    Minor,\n}\n\nimpl Mode {\n    /// Parse mode from string\n    ///\n    /// Detects \"m\" suffix for minor, defaults to major.\n    pub fn from_string(s: \u0026str) -\u003e Self {\n        if s.ends_with('m') \u0026\u0026 !s.ends_with(\"Maj\") {\n            Mode::Minor\n        } else {\n            Mode::Major\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_parsing() {\n        assert_eq!(Key::from_string(\"C\"), Some(Key::C));\n        assert_eq!(Key::from_string(\"C#\"), Some(Key::CSharp));\n        assert_eq!(Key::from_string(\"Db\"), Some(Key::CSharp));\n        assert_eq!(Key::from_string(\"Cm\"), Some(Key::C));\n        assert_eq!(Key::from_string(\"C#m\"), Some(Key::CSharp));\n    }\n\n    #[test]\n    fn test_key_distance() {\n        let c = Key::C;\n        let g = Key::G;\n        let f = Key::F;\n\n        assert_eq!(c.distance(\u0026g), 5); // C to G is 5 semitones\n        assert_eq!(c.distance(\u0026f), 5); // C to F is 5 semitones (going backwards)\n        assert_eq!(c.distance(\u0026c), 0); // Same key\n    }\n\n    #[test]\n    fn test_mode_parsing() {\n        assert_eq!(Mode::from_string(\"C\"), Mode::Major);\n        assert_eq!(Mode::from_string(\"Cm\"), Mode::Minor);\n        assert_eq!(Mode::from_string(\"CMaj\"), Mode::Major);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","error.rs"],"content":"//! Error types for the DAW application\n//!\n//! Trusty Module: Centralized error handling with proper type definitions.\n\nuse thiserror::Error;\n\n/**\n * Application errors\n *\n * Unified error type for all DAW operations.\n * Implements proper error conversion and serialization.\n */\n#[derive(Debug, Error)]\npub enum AppError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n\n    #[error(\"MIDI error: {0}\")]\n    Midi(String),\n\n    #[error(\"File error: {0}\")]\n    File(#[from] std::io::Error),\n\n    #[error(\"Parse error: {0}\")]\n    Parse(String),\n\n    #[error(\"Not found: {0}\")]\n    NotFound(String),\n\n    #[error(\"Invalid input: {0}\")]\n    InvalidInput(String),\n\n    #[error(\"Sequencer error: {0}\")]\n    Sequencer(String),\n\n    #[error(\"Connection error: {0}\")]\n    Connection(String),\n}\n\nimpl serde::Serialize for AppError {\n    fn serialize\u003cS\u003e(\u0026self, serializer: S) -\u003e Result\u003cS::Ok, S::Error\u003e\n    where\n        S: serde::Serializer,\n    {\n        serializer.serialize_str(\u0026self.to_string())\n    }\n}\n\n/**\n * Result type for application\n *\n * Convenience type alias for operations that return AppError.\n */\npub type AppResult\u003cT\u003e = Result\u003cT, AppError\u003e;\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":1},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","midi.rs"],"content":"//! MIDI event and device models\n//!\n//! Trusty Module: Pure data structures for MIDI hardware and events.\n\nuse serde::{Deserialize, Serialize};\n\n/**\n * MIDI device information\n *\n * Represents a connected MIDI output device.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiDevice {\n    pub name: String,\n    pub manufacturer: Option\u003cString\u003e,\n}\n\n/**\n * MIDI event type\n *\n * Supported MIDI message types for playback and recording.\n */\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\npub enum MidiEventType {\n    NoteOn,\n    NoteOff,\n    ControlChange,\n    ProgramChange,\n    PitchBend,\n    Aftertouch,\n}\n\n/**\n * MIDI event\n *\n * Represents a single MIDI message with timing and data.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiEvent {\n    pub event_type: MidiEventType,\n    pub tick: u64,\n    pub channel: u8,\n\n    // Optional fields depending on event type\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub note: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub velocity: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub controller: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub value: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub program: Option\u003cu8\u003e,\n}\n\n/**\n * MIDI note (simplified for piano roll)\n *\n * Simplified representation of a note event with duration.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiNote {\n    pub pitch: u8,\n    pub velocity: u8,\n    pub start_tick: u64,\n    pub duration_ticks: u64,\n}\n\n/**\n * MIDI pattern\n *\n * Complete pattern with events and timing information.\n */\n#[derive(Debug, Serialize, Deserialize)]\npub struct MidiPattern {\n    pub events: Vec\u003cMidiEvent\u003e,\n    pub ticks_per_quarter_note: u16,\n    pub total_ticks: u64,\n}\n\n/**\n * MIDI connection status\n *\n * Represents the current state of MIDI hardware connection.\n */\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\npub enum ConnectionStatus {\n    Disconnected,\n    Connecting,\n    Connected,\n    Error,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","midi_file.rs"],"content":"//! MIDI file database models\n//!\n//! Trusty Module: Pure data structures for MIDI file records.\n//! Updated to match actual database schema with proper JOINs.\n\nuse serde::{Deserialize, Serialize};\nuse sqlx::FromRow;\n\n/// Main file record - matches the actual database schema\n/// Uses proper JOINs to musical_metadata and file_categories tables\n#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]\npub struct MidiFile {\n    pub id: i64,\n\n    // File metadata (from files table)\n    pub filename: String,\n    pub filepath: String,\n    pub file_size_bytes: i64,\n    #[sqlx(default)]\n    pub content_hash: Vec\u003cu8\u003e,\n\n    // Multi-track info\n    #[sqlx(default)]\n    pub is_multi_track: bool,\n    pub parent_file_id: Option\u003ci64\u003e,\n    pub track_number: Option\u003ci16\u003e,\n    pub total_tracks: Option\u003ci16\u003e,\n\n    // Context from folders\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    #[sqlx(default)]\n    pub folder_tags: Vec\u003cString\u003e,\n    pub parent_folder: Option\u003cString\u003e,\n\n    // Musical metadata (from musical_metadata table via JOIN)\n    pub bpm: Option\u003cf64\u003e,  // numeric(6,2) in DB\n    pub key_signature: Option\u003cString\u003e,\n\n    // Time signature (formatted as \"4/4\" from numerator/denominator)\n    pub time_signature: Option\u003cString\u003e,\n\n    // Duration and notes\n    pub duration_seconds: Option\u003cf64\u003e,  // numeric(10,3) in DB, can be NULL\n    pub total_notes: i32,  // note_count in musical_metadata, defaulted to 0 if NULL\n\n    // Track count from files table\n    pub num_tracks: i16,\n\n    // Categories (from file_categories table via subquery)\n    pub primary_category: Option\u003cString\u003e,\n\n    // Timestamps\n    pub created_at: chrono::DateTime\u003cchrono::Utc\u003e,\n    pub analyzed_at: Option\u003cchrono::DateTime\u003cchrono::Utc\u003e\u003e,\n}\n\n/// Lightweight file details for search results\n#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]\npub struct FileDetails {\n    pub id: i64,\n    #[serde(rename = \"file_name\")]\n    pub filename: String,\n    #[serde(rename = \"file_path\")]\n    pub filepath: String,\n    #[serde(rename = \"file_size\")]\n    pub file_size_bytes: i64,\n    pub bpm: Option\u003cf64\u003e,\n    #[serde(rename = \"key\")]\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n    pub total_notes: Option\u003ci32\u003e,\n    #[serde(rename = \"category\")]\n    pub primary_category: Option\u003cString\u003e,\n    pub parent_folder: Option\u003cString\u003e,\n    pub created_at: chrono::DateTime\u003cchrono::Utc\u003e,\n    #[sqlx(default)]\n    pub is_favorite: bool,\n    // Additional fields for compatibility with frontend\n    #[sqlx(default)]\n    #[serde(default)]\n    pub tags: Vec\u003cString\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    #[serde(rename = \"collection\")]\n    pub collection_name: Option\u003cString\u003e,\n    #[serde(default)]\n    pub track_count: i16,\n    #[serde(default)]\n    pub has_notes: bool,\n    pub has_drums: Option\u003cbool\u003e,\n    #[sqlx(default)]\n    #[serde(default, skip_serializing)]\n    pub content_hash: Vec\u003cu8\u003e,\n}\n\nimpl MidiFile {\n    /// Helper to format time signature from numerator and denominator\n    pub fn format_time_signature(numerator: Option\u003ci16\u003e, denominator: Option\u003ci16\u003e) -\u003e Option\u003cString\u003e {\n        match (numerator, denominator) {\n            (Some(num), Some(den)) =\u003e Some(format!(\"{}/{}\", num, den)),\n            _ =\u003e None,\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","mod.rs"],"content":"//! Data models for the DAW application\n//!\n//! These models match the TypeScript frontend types for proper serialization.\n//! Trusty Module: Type definitions only, no I/O operations.\n\npub mod midi_file;\npub mod search;\npub mod midi;\npub mod sequencer;\npub mod analysis;\npub mod error;\n\n// Re-export commonly used types\n#[allow(unused_imports)]\npub use midi_file::{MidiFile, FileDetails};\n#[allow(unused_imports)]\npub use search::{SearchFilters, SearchResponse, Suggestion, FilterOption};\n#[allow(unused_imports)]\npub use midi::{MidiDevice, MidiEventType, MidiEvent, MidiNote, MidiPattern, ConnectionStatus};\n#[allow(unused_imports)]\npub use sequencer::{Track, TrackProperties, PlaybackPosition};\n#[allow(unused_imports)]\npub use analysis::CompatibleFile;\n#[allow(unused_imports)]\npub use error::AppError;\n\n// Types used internally only\n#[allow(unused_imports)]\npub use sequencer::SequencerState;\n#[allow(unused_imports)]\npub use analysis::{Key, Mode};\n#[allow(unused_imports)]\npub use error::AppResult;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","search.rs"],"content":"//! Search and filter models\n//!\n//! Trusty Module: Pure data structures for search operations.\n\nuse serde::{Deserialize, Serialize};\nuse super::midi_file::FileDetails;\n\n/**\n * Search filters\n *\n * Filters applied to search queries. All fields are optional.\n */\n#[derive(Debug, Deserialize)]\npub struct SearchFilters {\n    // BPM range filtering\n    pub min_bpm: Option\u003cf32\u003e,\n    pub max_bpm: Option\u003cf32\u003e,\n\n    // Key and time signature\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n\n    // Category\n    pub category: Option\u003cString\u003e,\n\n    // Note count range\n    pub min_notes: Option\u003ci32\u003e,\n    pub max_notes: Option\u003ci32\u003e,\n\n    // Duration range (seconds)\n    pub min_duration: Option\u003cf64\u003e,\n    pub max_duration: Option\u003cf64\u003e,\n\n    // Instruments (array match)\n    pub instruments: Option\u003cVec\u003cString\u003e\u003e,\n\n    // Text search\n    pub search_text: Option\u003cString\u003e,\n\n    // Sorting and pagination\n    pub sort_by: Option\u003cString\u003e,\n    pub sort_desc: Option\u003cbool\u003e,\n    pub limit: Option\u003ci32\u003e,\n    pub offset: Option\u003ci32\u003e,\n}\n\n/**\n * Search response\n *\n * Contains matching files and total count for pagination.\n */\n#[derive(Debug, Serialize)]\npub struct SearchResponse {\n    pub files: Vec\u003cFileDetails\u003e,\n    pub total: i32,\n}\n\n/**\n * Autocomplete suggestion\n *\n * Used for search bar autocomplete functionality.\n */\n#[derive(Debug, Serialize, Deserialize)]\npub struct Suggestion {\n    pub value: String,\n}\n\n/**\n * Filter option\n *\n * Represents a single option in a filter dropdown with count.\n */\n#[derive(Debug, Serialize, sqlx::FromRow)]\npub struct FilterOption {\n    pub value: String,\n    pub label: String,\n    pub count: i64,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","sequencer.rs"],"content":"//! Sequencer models\n//!\n//! Trusty Module: Pure data structures for sequencer state and tracks.\n\nuse serde::{Deserialize, Serialize};\nuse super::midi::MidiEvent;\n\n/**\n * Sequencer track\n *\n * Represents a single track in the sequencer with playback properties.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Track {\n    pub id: i32,\n    pub name: String,\n    pub file_id: i32,\n    pub channel: u8,\n    pub muted: bool,\n    pub solo: bool,\n    pub volume: u8,      // 0-127\n    pub pan: u8,         // 0-127 (64 = center)\n    pub color: String,   // Hex color\n\n    // Internal data (not serialized to frontend)\n    #[serde(skip)]\n    pub events: Vec\u003cMidiEvent\u003e,\n}\n\n/**\n * Track properties for updates\n *\n * Partial update structure for modifying track properties.\n */\n#[derive(Debug, Deserialize)]\npub struct TrackProperties {\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub muted: Option\u003cbool\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub solo: Option\u003cbool\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub volume: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub pan: Option\u003cu8\u003e,\n}\n\n/**\n * Playback position\n *\n * Current position in the sequencer timeline.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PlaybackPosition {\n    pub current_tick: u64,\n    pub current_bar: u32,\n    pub current_beat: u32,\n}\n\n/**\n * Sequencer state\n *\n * Complete state of the sequencer engine.\n * This is internal state - not all fields are serialized to frontend.\n */\n#[derive(Debug)]\npub struct SequencerState {\n    pub is_playing: bool,\n    pub tempo: f32,\n    pub position: u64,\n    pub tracks: Vec\u003cTrack\u003e,\n    pub next_track_id: i32,\n}\n\nimpl SequencerState {\n    /// Create new sequencer state with defaults\n    pub fn new() -\u003e Self {\n        Self {\n            is_playing: false,\n            tempo: 120.0,\n            position: 0,\n            tracks: Vec::new(),\n            next_track_id: 1,\n        }\n    }\n}\n\nimpl Default for SequencerState {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","engine.rs"],"content":"//! Sequencer playback engine\n//!\n//! Grown-up Script: Coordinates playback, timing, and MIDI output.\n//! Integrates TrackManager, EventScheduler, and MidiManager.\n\nuse crate::core::sequencer::timing;\nuse crate::midi::MidiManager;\nuse crate::models::sequencer::PlaybackPosition;\nuse crate::sequencer::{EventScheduler, ScheduledEvent, TrackManager};\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::{Mutex, RwLock};\nuse tokio::time;\nuse tracing::{debug, error, info, warn};\n\n/// Playback state\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum PlaybackState {\n    Stopped,\n    Playing,\n    Paused,\n}\n\n/// Main sequencer engine\n///\n/// Manages playback state, timing, and coordinates all sequencer components.\npub struct SequencerEngine {\n    track_manager: Arc\u003cTrackManager\u003e,\n    scheduler: Arc\u003cEventScheduler\u003e,\n    midi_manager: Arc\u003cMidiManager\u003e,\n\n    // Playback state\n    state: Arc\u003cRwLock\u003cPlaybackState\u003e\u003e,\n    current_tick: Arc\u003cRwLock\u003cu64\u003e\u003e,\n    start_time: Arc\u003cMutex\u003cOption\u003cInstant\u003e\u003e\u003e,\n\n    // Transport settings\n    bpm: Arc\u003cRwLock\u003cf32\u003e\u003e,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n\n    // Playback control\n    loop_enabled: Arc\u003cRwLock\u003cbool\u003e\u003e,\n    loop_start: Arc\u003cRwLock\u003cu64\u003e\u003e,\n    loop_end: Arc\u003cRwLock\u003cu64\u003e\u003e,\n}\n\nimpl SequencerEngine {\n    /// Create a new sequencer engine\n    ///\n    /// # Arguments\n    /// * `midi_manager` - MIDI output manager\n    /// * `bpm` - Initial tempo (default: 120.0)\n    /// * `ticks_per_quarter` - MIDI resolution (default: 480)\n    pub fn new(midi_manager: Arc\u003cMidiManager\u003e, bpm: f32, ticks_per_quarter: u16) -\u003e Self {\n        Self {\n            track_manager: Arc::new(TrackManager::new()),\n            scheduler: Arc::new(EventScheduler::new()),\n            midi_manager,\n            state: Arc::new(RwLock::new(PlaybackState::Stopped)),\n            current_tick: Arc::new(RwLock::new(0)),\n            start_time: Arc::new(Mutex::new(None)),\n            bpm: Arc::new(RwLock::new(bpm)),\n            ticks_per_quarter,\n            beats_per_bar: 4,\n            loop_enabled: Arc::new(RwLock::new(false)),\n            loop_start: Arc::new(RwLock::new(0)),\n            loop_end: Arc::new(RwLock::new(0)),\n        }\n    }\n\n    /// Get track manager reference\n    pub fn track_manager(\u0026self) -\u003e Arc\u003cTrackManager\u003e {\n        self.track_manager.clone()\n    }\n\n    /// Get event scheduler reference\n    pub fn scheduler(\u0026self) -\u003e Arc\u003cEventScheduler\u003e {\n        self.scheduler.clone()\n    }\n\n    /// Start playback\n    pub async fn start(\u0026self) -\u003e Result\u003c(), String\u003e {\n        let mut state = self.state.write().await;\n\n        if *state == PlaybackState::Playing {\n            return Ok(()); // Already playing\n        }\n\n        // Check if MIDI is connected\n        if !self.midi_manager.is_connected().await {\n            return Err(\"MIDI device not connected\".to_string());\n        }\n\n        info!(\"Starting sequencer playback\");\n\n        *state = PlaybackState::Playing;\n        let mut start_time = self.start_time.lock().await;\n        *start_time = Some(Instant::now());\n\n        // Spawn playback task\n        self.spawn_playback_task().await;\n\n        Ok(())\n    }\n\n    /// Stop playback and reset position\n    pub async fn stop(\u0026self) {\n        let mut state = self.state.write().await;\n\n        if *state == PlaybackState::Stopped {\n            return;\n        }\n\n        info!(\"Stopping sequencer playback\");\n\n        *state = PlaybackState::Stopped;\n        let mut current_tick = self.current_tick.write().await;\n        *current_tick = 0;\n\n        // Send all notes off to prevent stuck notes\n        if let Err(e) = self.send_panic().await {\n            warn!(\"Failed to send panic message: {}\", e);\n        }\n    }\n\n    /// Pause playback (maintains position)\n    pub async fn pause(\u0026self) {\n        let mut state = self.state.write().await;\n\n        if *state != PlaybackState::Playing {\n            return;\n        }\n\n        info!(\"Pausing sequencer playback\");\n        *state = PlaybackState::Paused;\n\n        // Send all notes off to prevent stuck notes\n        if let Err(e) = self.send_panic().await {\n            warn!(\"Failed to send panic message: {}\", e);\n        }\n    }\n\n    /// Resume playback from paused state\n    pub async fn resume(\u0026self) -\u003e Result\u003c(), String\u003e {\n        let mut state = self.state.write().await;\n\n        if *state != PlaybackState::Paused {\n            return Ok(());\n        }\n\n        if !self.midi_manager.is_connected().await {\n            return Err(\"MIDI device not connected\".to_string());\n        }\n\n        info!(\"Resuming sequencer playback\");\n\n        *state = PlaybackState::Playing;\n        let mut start_time = self.start_time.lock().await;\n        *start_time = Some(Instant::now());\n\n        self.spawn_playback_task().await;\n\n        Ok(())\n    }\n\n    /// Get current playback state\n    pub async fn get_state(\u0026self) -\u003e PlaybackState {\n        *self.state.read().await\n    }\n\n    /// Set tempo (BPM)\n    pub async fn set_bpm(\u0026self, bpm: f32) -\u003e Result\u003c(), String\u003e {\n        if !(20.0..=300.0).contains(\u0026bpm) {\n            return Err(format!(\"Invalid BPM: {}. Must be 20-300\", bpm));\n        }\n\n        let mut current_bpm = self.bpm.write().await;\n        *current_bpm = bpm;\n        info!(\"Tempo set to {} BPM\", bpm);\n\n        Ok(())\n    }\n\n    /// Get current tempo\n    pub async fn get_bpm(\u0026self) -\u003e f32 {\n        *self.bpm.read().await\n    }\n\n    /// Get current playback position\n    pub async fn get_position(\u0026self) -\u003e PlaybackPosition {\n        let tick = *self.current_tick.read().await;\n        let (bar, beat) = timing::tick_to_bar_beat(tick, self.ticks_per_quarter, self.beats_per_bar);\n\n        PlaybackPosition {\n            current_tick: tick,\n            current_bar: bar,\n            current_beat: beat,\n        }\n    }\n\n    /// Seek to a specific tick position\n    pub async fn seek(\u0026self, tick: u64) {\n        let mut current_tick = self.current_tick.write().await;\n        *current_tick = tick;\n        debug!(\"Seeked to tick {}\", tick);\n    }\n\n    /// Load tracks into the scheduler\n    ///\n    /// Clears existing scheduled events and loads events from all active tracks.\n    pub async fn load_tracks(\u0026self) {\n        use crate::core::midi::types::{MidiEventType as CoreEventType, MidiMessage};\n        use crate::models::midi::MidiEventType;\n\n        self.scheduler.clear().await;\n\n        let tracks = self.track_manager.get_active_tracks().await;\n        let mut all_events = Vec::new();\n\n        for track in tracks {\n            for event in track.events {\n                // Convert MidiEvent to MidiMessage\n                let message = match event.event_type {\n                    MidiEventType::NoteOn =\u003e MidiMessage {\n                        event_type: CoreEventType::NoteOn,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.velocity.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::NoteOff =\u003e MidiMessage {\n                        event_type: CoreEventType::NoteOff,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.velocity.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::ControlChange =\u003e MidiMessage {\n                        event_type: CoreEventType::ControlChange,\n                        channel: track.channel,\n                        data1: event.controller.unwrap_or(0),\n                        data2: event.value.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::ProgramChange =\u003e MidiMessage {\n                        event_type: CoreEventType::ProgramChange,\n                        channel: track.channel,\n                        data1: event.program.unwrap_or(0),\n                        data2: 0,\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::PitchBend =\u003e MidiMessage {\n                        event_type: CoreEventType::PitchBend,\n                        channel: track.channel,\n                        data1: event.value.unwrap_or(0),\n                        data2: 0,\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::Aftertouch =\u003e MidiMessage {\n                        event_type: CoreEventType::Aftertouch,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.value.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                };\n\n                all_events.push(ScheduledEvent {\n                    message,\n                    tick: event.tick,\n                    track_id: track.id,\n                });\n            }\n        }\n\n        self.scheduler.schedule_many(all_events).await;\n        info!(\"Loaded {} events into scheduler\", self.scheduler.len().await);\n    }\n\n    /// Send MIDI panic (all notes off on all channels)\n    async fn send_panic(\u0026self) -\u003e Result\u003c(), String\u003e {\n        use crate::core::midi::types::{MidiEventType, MidiMessage};\n\n        for channel in 0..16 {\n            let panic_msg = MidiMessage {\n                event_type: MidiEventType::ControlChange,\n                channel,\n                data1: 123, // All Notes Off\n                data2: 0,\n                timestamp: 0,\n            };\n\n            self.midi_manager.send_message(\u0026panic_msg).await?;\n        }\n\n        Ok(())\n    }\n\n    /// Spawn the playback task\n    async fn spawn_playback_task(\u0026self) {\n        let state = self.state.clone();\n        let current_tick = self.current_tick.clone();\n        let start_time = self.start_time.clone();\n        let bpm = self.bpm.clone();\n        let ticks_per_quarter = self.ticks_per_quarter;\n        let scheduler = self.scheduler.clone();\n        let midi_manager = self.midi_manager.clone();\n\n        tokio::spawn(async move {\n            let mut interval = time::interval(Duration::from_millis(1)); // 1ms resolution\n\n            loop {\n                interval.tick().await;\n\n                // Check if still playing\n                {\n                    let state_guard = state.read().await;\n                    if *state_guard != PlaybackState::Playing {\n                        break;\n                    }\n                }\n\n                // Calculate current tick from elapsed time\n                let elapsed = {\n                    let start_guard = start_time.lock().await;\n                    match start_guard.as_ref() {\n                        Some(instant) =\u003e instant.elapsed(),\n                        None =\u003e {\n                            error!(\"Start time not set in sequencer playback loop\");\n                            break;\n                        }\n                    }\n                };\n\n                let bpm_val = *bpm.read().await;\n                let tick = timing::seconds_to_ticks(\n                    elapsed.as_secs_f64(),\n                    bpm_val,\n                    ticks_per_quarter,\n                );\n\n                // Update current tick\n                {\n                    let mut tick_guard = current_tick.write().await;\n                    *tick_guard = tick;\n                }\n\n                // Get ready events\n                let ready_events = scheduler.pop_ready(tick).await;\n\n                // Send MIDI messages\n                for event in ready_events {\n                    if let Err(e) = midi_manager.send_message(\u0026event.message).await {\n                        error!(\"Failed to send MIDI message: {}\", e);\n                    }\n                }\n            }\n\n            debug!(\"Playback task stopped\");\n        });\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_engine_creation() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert_eq!(engine.get_state().await, PlaybackState::Stopped);\n        assert_eq!(engine.get_bpm().await, 120.0);\n    }\n\n    #[tokio::test]\n    async fn test_set_bpm() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert!(engine.set_bpm(140.0).await.is_ok());\n        assert_eq!(engine.get_bpm().await, 140.0);\n    }\n\n    #[tokio::test]\n    async fn test_set_bpm_invalid() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert!(engine.set_bpm(500.0).await.is_err());\n        assert!(engine.set_bpm(10.0).await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_get_position() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 0);\n        assert_eq!(pos.current_bar, 0);\n        assert_eq!(pos.current_beat, 0);\n    }\n\n    #[tokio::test]\n    async fn test_seek() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        engine.seek(1920).await; // 1 bar\n\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 1920);\n        assert_eq!(pos.current_bar, 1);\n        assert_eq!(pos.current_beat, 0);\n    }\n\n    #[tokio::test]\n    #[ignore] // TODO: Fix in Phase 1 - position not resetting to 0 on stop\n    async fn test_stop_from_playing() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        engine.seek(1000).await;\n        engine.stop().await;\n\n        // Stop should reset position\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 0);\n        assert_eq!(engine.get_state().await, PlaybackState::Stopped);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","mod.rs"],"content":"//! Sequencer implementation\n//!\n//! Grown-up Scripts: Manage sequencer state, tracks, and playback.\n//! Delegates to Trusty Modules for timing calculations.\n\npub mod track;\npub mod scheduler;\npub mod engine;\n\npub use track::TrackManager;\npub use scheduler::{EventScheduler, ScheduledEvent};\n#[allow(unused_imports)]\npub use engine::{SequencerEngine, PlaybackState};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","scheduler.rs"],"content":"//! Event scheduling for sequencer\n//!\n//! Grown-up Script: Manages priority queue of MIDI events for precise playback timing.\n\nuse crate::core::midi::types::MidiMessage;\nuse std::cmp::Ordering;\nuse std::collections::BinaryHeap;\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\n\n/// A scheduled MIDI event with timing information\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct ScheduledEvent {\n    pub message: MidiMessage,\n    pub tick: u64,\n    pub track_id: i32,\n}\n\nimpl PartialEq for ScheduledEvent {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.tick == other.tick\n    }\n}\n\nimpl Eq for ScheduledEvent {}\n\nimpl PartialOrd for ScheduledEvent {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for ScheduledEvent {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        // Reverse ordering for min-heap (BinaryHeap is max-heap by default)\n        other.tick.cmp(\u0026self.tick)\n    }\n}\n\n/// Manages scheduling and retrieval of MIDI events\n///\n/// Uses a priority queue (min-heap) to efficiently retrieve events in chronological order.\n/// Thread-safe using Mutex for concurrent access.\npub struct EventScheduler {\n    events: Arc\u003cMutex\u003cBinaryHeap\u003cScheduledEvent\u003e\u003e\u003e,\n}\n\nimpl EventScheduler {\n    /// Create a new empty event scheduler\n    pub fn new() -\u003e Self {\n        Self {\n            events: Arc::new(Mutex::new(BinaryHeap::new())),\n        }\n    }\n\n    /// Schedule a MIDI event at a specific tick\n    ///\n    /// # Arguments\n    /// * `message` - The MIDI message to schedule\n    /// * `tick` - Absolute tick position when event should fire\n    /// * `track_id` - ID of the track this event belongs to\n    pub async fn schedule(\u0026self, message: MidiMessage, tick: u64, track_id: i32) {\n        let event = ScheduledEvent {\n            message,\n            tick,\n            track_id,\n        };\n\n        let mut events = self.events.lock().await;\n        events.push(event);\n    }\n\n    /// Schedule multiple events at once\n    ///\n    /// More efficient than calling schedule() repeatedly.\n    pub async fn schedule_many(\u0026self, events: Vec\u003cScheduledEvent\u003e) {\n        let mut heap = self.events.lock().await;\n        for event in events {\n            heap.push(event);\n        }\n    }\n\n    /// Get the next event at or before the current tick\n    ///\n    /// Returns None if no events are ready or queue is empty.\n    ///\n    /// # Arguments\n    /// * `current_tick` - Current playback position\n    pub async fn pop_next(\u0026self, current_tick: u64) -\u003e Option\u003cScheduledEvent\u003e {\n        let mut events = self.events.lock().await;\n\n        // Peek at next event\n        if let Some(next) = events.peek() {\n            if next.tick \u003c= current_tick {\n                return events.pop();\n            }\n        }\n\n        None\n    }\n\n    /// Get all events at or before the current tick\n    ///\n    /// Returns a vector of events in chronological order.\n    /// More efficient than calling pop_next() repeatedly.\n    ///\n    /// # Arguments\n    /// * `current_tick` - Current playback position\n    pub async fn pop_ready(\u0026self, current_tick: u64) -\u003e Vec\u003cScheduledEvent\u003e {\n        let mut events = self.events.lock().await;\n        let mut ready = Vec::new();\n\n        while let Some(next) = events.peek() {\n            if next.tick \u003c= current_tick {\n                // Safe to unwrap here since peek() returned Some, but we use if let for safety\n                if let Some(event) = events.pop() {\n                    ready.push(event);\n                }\n            } else {\n                break;\n            }\n        }\n\n        ready\n    }\n\n    /// Peek at the next event without removing it\n    pub async fn peek_next(\u0026self) -\u003e Option\u003cu64\u003e {\n        let events = self.events.lock().await;\n        events.peek().map(|e| e.tick)\n    }\n\n    /// Get the number of scheduled events\n    pub async fn len(\u0026self) -\u003e usize {\n        let events = self.events.lock().await;\n        events.len()\n    }\n\n    /// Check if scheduler is empty\n    pub async fn is_empty(\u0026self) -\u003e bool {\n        let events = self.events.lock().await;\n        events.is_empty()\n    }\n\n    /// Clear all scheduled events\n    pub async fn clear(\u0026self) {\n        let mut events = self.events.lock().await;\n        events.clear();\n    }\n\n    /// Remove all events for a specific track\n    pub async fn clear_track(\u0026self, track_id: i32) {\n        let mut events = self.events.lock().await;\n        let filtered: Vec\u003c_\u003e = events\n            .drain()\n            .filter(|e| e.track_id != track_id)\n            .collect();\n\n        events.clear();\n        for event in filtered {\n            events.push(event);\n        }\n    }\n}\n\nimpl Default for EventScheduler {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::core::midi::types::MidiEventType;\n\n    fn create_test_message(note: u8, velocity: u8) -\u003e MidiMessage {\n        MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: note,\n            data2: velocity,\n            timestamp: 0,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_schedule_and_pop() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        let event = scheduler.pop_next(100).await.unwrap();\n        assert_eq!(event.tick, 100);\n        assert_eq!(event.message.data1, 60);\n    }\n\n    #[tokio::test]\n    async fn test_pop_before_ready() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        // Try to pop at tick 50 (before event is ready)\n        let event = scheduler.pop_next(50).await;\n        assert!(event.is_none());\n\n        // Event should still be there at tick 100\n        let event = scheduler.pop_next(100).await.unwrap();\n        assert_eq!(event.tick, 100);\n    }\n\n    #[tokio::test]\n    async fn test_chronological_order() {\n        let scheduler = EventScheduler::new();\n\n        // Schedule events out of order\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        // Should come out in chronological order\n        let e1 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e1.tick, 100);\n        assert_eq!(e1.message.data1, 60);\n\n        let e2 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e2.tick, 200);\n        assert_eq!(e2.message.data1, 62);\n\n        let e3 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e3.tick, 300);\n        assert_eq!(e3.message.data1, 64);\n    }\n\n    #[tokio::test]\n    async fn test_pop_ready() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n\n        // Get all events up to tick 250\n        let ready = scheduler.pop_ready(250).await;\n        assert_eq!(ready.len(), 2);\n        assert_eq!(ready[0].tick, 100);\n        assert_eq!(ready[1].tick, 200);\n\n        // One event should remain\n        assert_eq!(scheduler.len().await, 1);\n    }\n\n    #[tokio::test]\n    async fn test_peek_next() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n\n        let next_tick = scheduler.peek_next().await.unwrap();\n        assert_eq!(next_tick, 100);\n\n        // Peek doesn't remove\n        assert_eq!(scheduler.len().await, 2);\n    }\n\n    #[tokio::test]\n    async fn test_clear_track() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 2)\n            .await;\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n\n        scheduler.clear_track(1).await;\n\n        // Only track 2 event should remain\n        assert_eq!(scheduler.len().await, 1);\n        let event = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(event.track_id, 2);\n    }\n\n    #[tokio::test]\n    async fn test_schedule_many() {\n        let scheduler = EventScheduler::new();\n\n        let events = vec![\n            ScheduledEvent {\n                message: create_test_message(60, 100),\n                tick: 100,\n                track_id: 1,\n            },\n            ScheduledEvent {\n                message: create_test_message(62, 100),\n                tick: 200,\n                track_id: 1,\n            },\n            ScheduledEvent {\n                message: create_test_message(64, 100),\n                tick: 300,\n                track_id: 1,\n            },\n        ];\n\n        scheduler.schedule_many(events).await;\n\n        assert_eq!(scheduler.len().await, 3);\n    }\n\n    #[tokio::test]\n    async fn test_clear() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n\n        scheduler.clear().await;\n\n        assert!(scheduler.is_empty().await);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","track.rs"],"content":"//! Track management for sequencer\n//!\n//! Grown-up Script: Manages collection of tracks with their properties and MIDI events.\n\nuse crate::models::sequencer::{Track, TrackProperties};\nuse crate::models::midi::MidiEvent;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Manages all tracks in the sequencer\n///\n/// Tracks contain MIDI events and playback properties (mute, solo, volume).\n/// Thread-safe using RwLock for concurrent read access.\npub struct TrackManager {\n    tracks: Arc\u003cRwLock\u003cHashMap\u003ci32, Track\u003e\u003e\u003e,\n    next_id: Arc\u003cRwLock\u003ci32\u003e\u003e,\n}\n\nimpl TrackManager {\n    /// Create a new empty track manager\n    pub fn new() -\u003e Self {\n        Self {\n            tracks: Arc::new(RwLock::new(HashMap::new())),\n            next_id: Arc::new(RwLock::new(1)),\n        }\n    }\n\n    /// Add a new track with specified properties\n    ///\n    /// # Arguments\n    /// * `file_id` - Database ID of the MIDI file for this track\n    /// * `channel` - MIDI channel (0-15)\n    /// * `events` - MIDI events for this track\n    ///\n    /// # Returns\n    /// The newly created Track with assigned ID\n    pub async fn add_track(\n        \u0026self,\n        file_id: i32,\n        channel: u8,\n        events: Vec\u003cMidiEvent\u003e,\n    ) -\u003e Result\u003cTrack, String\u003e {\n        if channel \u003e 15 {\n            return Err(format!(\"Invalid MIDI channel: {}. Must be 0-15\", channel));\n        }\n\n        let mut next_id = self.next_id.write().await;\n        let track_id = *next_id;\n        *next_id += 1;\n\n        let track = Track {\n            id: track_id,\n            name: format!(\"Track {}\", track_id),\n            file_id,\n            channel,\n            muted: false,\n            solo: false,\n            volume: 100,\n            pan: 64,\n            color: \"#888888\".to_string(),\n            events,\n        };\n\n        let mut tracks = self.tracks.write().await;\n        tracks.insert(track_id, track.clone());\n\n        Ok(track)\n    }\n\n    /// Remove a track by ID\n    ///\n    /// # Returns\n    /// Ok(()) if track was removed, Err if track not found\n    pub async fn remove_track(\u0026self, track_id: i32) -\u003e Result\u003c(), String\u003e {\n        let mut tracks = self.tracks.write().await;\n        tracks\n            .remove(\u0026track_id)\n            .ok_or_else(|| format!(\"Track {} not found\", track_id))?;\n        Ok(())\n    }\n\n    /// Update track properties (mute, solo, volume, pan)\n    pub async fn update_track(\n        \u0026self,\n        track_id: i32,\n        properties: TrackProperties,\n    ) -\u003e Result\u003c(), String\u003e {\n        let mut tracks = self.tracks.write().await;\n        let track = tracks\n            .get_mut(\u0026track_id)\n            .ok_or_else(|| format!(\"Track {} not found\", track_id))?;\n\n        if let Some(muted) = properties.muted {\n            track.muted = muted;\n        }\n        if let Some(solo) = properties.solo {\n            track.solo = solo;\n        }\n        if let Some(volume) = properties.volume {\n            if volume \u003e 127 {\n                return Err(\"Volume must be 0-127\".to_string());\n            }\n            track.volume = volume;\n        }\n        if let Some(pan) = properties.pan {\n            if pan \u003e 127 {\n                return Err(\"Pan must be 0-127\".to_string());\n            }\n            track.pan = pan;\n        }\n\n        Ok(())\n    }\n\n    /// Get all tracks\n    pub async fn get_tracks(\u0026self) -\u003e Vec\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        tracks.values().cloned().collect()\n    }\n\n    /// Get a specific track by ID\n    pub async fn get_track(\u0026self, track_id: i32) -\u003e Option\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        tracks.get(\u0026track_id).cloned()\n    }\n\n    /// Check if any track has solo enabled\n    pub async fn has_solo(\u0026self) -\u003e bool {\n        let tracks = self.tracks.read().await;\n        tracks.values().any(|t| t.solo)\n    }\n\n    /// Get tracks that should play (considering mute/solo)\n    ///\n    /// Logic:\n    /// - If any track is solo, only solo tracks play\n    /// - Otherwise, all non-muted tracks play\n    pub async fn get_active_tracks(\u0026self) -\u003e Vec\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        let has_solo = tracks.values().any(|t| t.solo);\n\n        tracks\n            .values()\n            .filter(|t| {\n                if has_solo {\n                    t.solo\n                } else {\n                    !t.muted\n                }\n            })\n            .cloned()\n            .collect()\n    }\n\n    /// Clear all tracks\n    pub async fn clear(\u0026self) {\n        let mut tracks = self.tracks.write().await;\n        tracks.clear();\n        let mut next_id = self.next_id.write().await;\n        *next_id = 1;\n    }\n}\n\nimpl Default for TrackManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn create_test_event(channel: u8) -\u003e MidiEvent {\n        use crate::models::midi::MidiEventType;\n\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 0,\n            channel,\n            note: Some(60),\n            velocity: Some(100),\n            controller: None,\n            value: None,\n            program: None,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_add_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n        assert_eq!(track.id, 1);\n        assert_eq!(track.file_id, 1);\n        assert_eq!(track.channel, 0);\n        assert!(!track.muted);\n        assert!(!track.solo);\n    }\n\n    #[tokio::test]\n    async fn test_add_track_invalid_channel() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let result = manager.add_track(1, 16, events).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"Invalid MIDI channel\"));\n    }\n\n    #[tokio::test]\n    async fn test_remove_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n        assert!(manager.remove_track(track.id).await.is_ok());\n        assert!(manager.get_track(track.id).await.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_update_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n\n        let props = TrackProperties {\n            muted: Some(true),\n            solo: Some(true),\n            volume: Some(80),\n            pan: Some(32),\n        };\n\n        manager.update_track(track.id, props).await.unwrap();\n\n        let updated = manager.get_track(track.id).await.unwrap();\n        assert!(updated.muted);\n        assert!(updated.solo);\n        assert_eq!(updated.volume, 80);\n        assert_eq!(updated.pan, 32);\n    }\n\n    #[tokio::test]\n    async fn test_update_track_invalid_volume() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n\n        let props = TrackProperties {\n            muted: None,\n            solo: None,\n            volume: Some(128),\n            pan: None,\n        };\n\n        let result = manager.update_track(track.id, props).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"Volume must be 0-127\"));\n    }\n\n    #[tokio::test]\n    async fn test_get_active_tracks_no_solo() {\n        let manager = TrackManager::new();\n\n        // Add 3 tracks: 1 muted, 2 unmuted\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        let track2 = manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n        manager.add_track(3, 2, vec![create_test_event(2)]).await.unwrap();\n\n        // Mute track 2\n        manager.update_track(track2.id, TrackProperties {\n            muted: Some(true),\n            solo: None,\n            volume: None,\n            pan: None,\n        }).await.unwrap();\n\n        let active = manager.get_active_tracks().await;\n        assert_eq!(active.len(), 2); // Only unmuted tracks\n    }\n\n    #[tokio::test]\n    async fn test_get_active_tracks_with_solo() {\n        let manager = TrackManager::new();\n\n        // Add 3 tracks\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        let track2 = manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n        manager.add_track(3, 2, vec![create_test_event(2)]).await.unwrap();\n\n        // Solo track 2\n        manager.update_track(track2.id, TrackProperties {\n            muted: None,\n            solo: Some(true),\n            volume: None,\n            pan: None,\n        }).await.unwrap();\n\n        let active = manager.get_active_tracks().await;\n        assert_eq!(active.len(), 1); // Only solo track\n        assert_eq!(active[0].id, track2.id);\n    }\n\n    #[tokio::test]\n    async fn test_clear() {\n        let manager = TrackManager::new();\n\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n\n        manager.clear().await;\n\n        let tracks = manager.get_tracks().await;\n        assert_eq!(tracks.len(), 0);\n\n        // Next track should start at ID 1 again\n        let track = manager.add_track(3, 0, vec![create_test_event(0)]).await.unwrap();\n        assert_eq!(track.id, 1);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","build.rs"],"content":"fn main() {\n    // Tell the linker to use webkit2gtk-4.1 instead of webkit2gtk-4.0\n    println!(\"cargo:rustc-link-lib=webkit2gtk-4.1\");\n    println!(\"cargo:rustc-link-lib=javascriptcoregtk-4.1\");\n\n    tauri_build::build()\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","analyze.rs"],"content":"//! MIDI Analysis CLI Tool\n//!\n//! Standalone binary to analyze all imported MIDI files\n//!\n//! Usage:\n//!   cargo run --bin analyze\n//!\n//! Environment Variables:\n//!   DATABASE_URL - PostgreSQL connection string\n//!                  Default: postgresql://midiuser:145278963@localhost:5433/midi_library\n\nuse std::env;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\nuse futures::stream::{self, StreamExt};\n\n// Import from the main library\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\n\n#[derive(Debug, Clone, sqlx::FromRow)]\nstruct FileRecord {\n    id: i64,\n    filepath: String,\n    filename: String,\n}\n\n#[derive(Debug, Clone)]\nstruct AnalyzedFile {\n    file_id: i64,\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n    complexity_score: Option\u003cf64\u003e,\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    println!(\" MIDI Analysis Tool\");\n    println!(\"====================\\n\");\n\n    // Get database URL from environment\n    let database_url = env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(20)\n        .connect(\u0026database_url)\n        .await?;\n    println!(\" Connected to database\\n\");\n\n    // Get total count of unanalyzed files\n    let total: i64 = sqlx::query_scalar(\n        \"SELECT COUNT(*) FROM files WHERE analyzed_at IS NULL\"\n    )\n    .fetch_one(\u0026pool)\n    .await?;\n\n    println!(\" Found {} unanalyzed files\\n\", total);\n\n    if total == 0 {\n        println!(\" All files are already analyzed!\");\n        return Ok(());\n    }\n\n    let start_time = std::time::Instant::now();\n\n    // Configuration\n    let concurrency_limit = 32;\n    let batch_size = 1000;\n\n    println!(\" Starting analysis:\");\n    println!(\"  Concurrency: {} workers\", concurrency_limit);\n    println!(\"  Batch size: {} files\\n\", batch_size);\n\n    // Thread-safe counters\n    let analyzed = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let total_usize = total as usize;\n\n    // Process files in batches\n    let mut offset = 0i64;\n\n    loop {\n        // Fetch batch of unanalyzed files\n        let files: Vec\u003cFileRecord\u003e = sqlx::query_as(\n            \"SELECT id, filepath, filename\n             FROM files\n             WHERE analyzed_at IS NULL\n             ORDER BY id\n             LIMIT $1 OFFSET $2\"\n        )\n        .bind(batch_size)\n        .bind(offset)\n        .fetch_all(\u0026pool)\n        .await?;\n\n        if files.is_empty() {\n            break;\n        }\n\n        let pool_clone = pool.clone();\n\n        // Process batch in parallel\n        stream::iter(files)\n            .map(|file_record| {\n                let sem = Arc::clone(\u0026semaphore);\n                let analyzed = Arc::clone(\u0026analyzed);\n                let skipped = Arc::clone(\u0026skipped);\n                let errors = Arc::clone(\u0026errors);\n                let current_index = Arc::clone(\u0026current_index);\n                let analyzed_files = Arc::clone(\u0026analyzed_files);\n                let pool = pool_clone.clone();\n\n                async move {\n                    let _permit = match sem.acquire().await {\n                        Ok(permit) =\u003e permit,\n                        Err(_) =\u003e {\n                            eprintln!(\"Warning: Semaphore closed during analysis\");\n                            return;\n                        }\n                    };\n\n                    let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                    // Print progress every 100 files\n                    if current % 100 == 0 || current == total_usize {\n                        let elapsed = start_time.elapsed().as_secs_f64();\n                        let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                        let remaining = total_usize - current;\n                        let eta_seconds = if rate \u003e 0.0 { remaining as f64 / rate } else { 0.0 };\n\n                        println!(\n                            \"Analyzing: {}/{} ({:.1}%) - {:.1} files/sec - ETA: {}\",\n                            current,\n                            total_usize,\n                            (current as f64 / total_usize as f64) * 100.0,\n                            rate,\n                            format_duration(eta_seconds)\n                        );\n                    }\n\n                    // Analyze the file\n                    match analyze_single_file(\u0026file_record).await {\n                        Ok(analyzed_data) =\u003e {\n                            analyzed_files.lock().await.push(analyzed_data);\n                            analyzed.fetch_add(1, Ordering::SeqCst);\n\n                            // Flush batch if threshold reached\n                            let mut files = analyzed_files.lock().await;\n                            if files.len() \u003e= 100 {\n                                let batch: Vec\u003cAnalyzedFile\u003e = files.drain(..).collect();\n                                drop(files);\n\n                                if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n                                    errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            skipped.fetch_add(1, Ordering::SeqCst);\n                            // Only log first 10 errors to avoid spam\n                            let mut err_list = errors.lock().await;\n                            if err_list.len() \u003c 10 {\n                                err_list.push(format!(\"{}: {}\", file_record.filepath, e));\n                            }\n                        }\n                    }\n                }\n            })\n            .buffer_unordered(concurrency_limit)\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .await;\n\n        offset += batch_size;\n    }\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        batch_insert_analyzed_files(\u0026batch, \u0026pool).await?;\n    }\n\n    // Print final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let analyzed_count = analyzed.load(Ordering::SeqCst);\n    let skipped_count = skipped.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { analyzed_count as f64 / duration } else { 0.0 };\n\n    println!(\"\\n Analysis complete!\");\n    println!(\"==================\");\n    println!(\"  Total files:    {}\", total_usize);\n    println!(\"  Analyzed:       {}\", analyzed_count);\n    println!(\"  Skipped:        {}\", skipped_count);\n    println!(\"  Duration:       {}\", format_duration(duration));\n    println!(\"  Average rate:   {:.1} files/sec\", rate);\n\n    let error_list = errors.lock().await;\n    if !error_list.is_empty() {\n        println!(\"\\n  Errors encountered:\");\n        for (i, error) in error_list.iter().enumerate().take(10) {\n            println!(\"  {}. {}\", i + 1, error);\n        }\n        if error_list.len() \u003e 10 {\n            println!(\"  ... and {} more errors\", error_list.len() - 10);\n        }\n    }\n\n    Ok(())\n}\n\n// Helper function to format duration in human-readable format\nfn format_duration(seconds: f64) -\u003e String {\n    if seconds \u003c 60.0 {\n        format!(\"{:.0}s\", seconds)\n    } else if seconds \u003c 3600.0 {\n        let minutes = (seconds / 60.0).floor();\n        let secs = seconds % 60.0;\n        format!(\"{}m {:.0}s\", minutes, secs)\n    } else {\n        let hours = (seconds / 3600.0).floor();\n        let minutes = ((seconds % 3600.0) / 60.0).floor();\n        format!(\"{}h {}m\", hours, minutes)\n    }\n}\n\n// Copy of analyze_single_file from commands/analyze.rs\nasync fn analyze_single_file(\n    file_record: \u0026FileRecord,\n) -\u003e Result\u003cAnalyzedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let file_bytes = tokio::fs::read(\u0026file_record.filepath).await?;\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n    let note_stats = analyze_notes(\u0026midi_file);\n    let instruments = extract_instrument_names(\u0026midi_file);\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    Ok(AnalyzedFile {\n        file_id: file_record.id,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n    })\n}\n\n// Copy of batch_insert_analyzed_files from commands/analyze.rs\nasync fn batch_insert_analyzed_files(\n    files: \u0026[AnalyzedFile],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    if files.is_empty() {\n        return Ok(());\n    }\n\n    let mut tx = pool.begin().await?;\n\n    for file in files {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id, tempo_bpm, bpm_confidence, has_tempo_variation,\n                key_signature, key_confidence, scale_type,\n                time_signature_num, time_signature_den,\n                duration_seconds, duration_ticks, note_count,\n                pitch_range_low, pitch_range_high, pitch_range_semitones,\n                avg_velocity, velocity_range_low, velocity_range_high,\n                polyphony_max, complexity_score, instruments,\n                has_pitch_bend, has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            ON CONFLICT (file_id) DO UPDATE SET\n                tempo_bpm = EXCLUDED.tempo_bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                has_tempo_variation = EXCLUDED.has_tempo_variation,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                scale_type = EXCLUDED.scale_type,\n                time_signature_num = EXCLUDED.time_signature_num,\n                time_signature_den = EXCLUDED.time_signature_den,\n                duration_seconds = EXCLUDED.duration_seconds,\n                duration_ticks = EXCLUDED.duration_ticks,\n                note_count = EXCLUDED.note_count,\n                pitch_range_low = EXCLUDED.pitch_range_low,\n                pitch_range_high = EXCLUDED.pitch_range_high,\n                pitch_range_semitones = EXCLUDED.pitch_range_semitones,\n                avg_velocity = EXCLUDED.avg_velocity,\n                velocity_range_low = EXCLUDED.velocity_range_low,\n                velocity_range_high = EXCLUDED.velocity_range_high,\n                polyphony_max = EXCLUDED.polyphony_max,\n                complexity_score = EXCLUDED.complexity_score,\n                instruments = EXCLUDED.instruments,\n                has_pitch_bend = EXCLUDED.has_pitch_bend,\n                has_cc_messages = EXCLUDED.has_cc_messages\n            \"#\n        )\n        .bind(file.file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        sqlx::query(\"UPDATE files SET analyzed_at = NOW() WHERE id = $1\")\n            .bind(file.file_id)\n            .execute(\u0026mut *tx)\n            .await?;\n    }\n\n    tx.commit().await?;\n    Ok(())\n}\n\n// Helper analysis functions (copied from commands/analyze.rs)\n\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4))\n}\n\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i32\n}\n\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        Some(minutes * 60.0)\n    } else {\n        None\n    }\n}\n\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026name) {\n                            instruments.push(name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n    instruments\n}\n\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0);\n    }\n\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0);\n    }\n\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0);\n    }\n\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0);\n\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0);\n    }\n\n    Some(score.min(100.0))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","batch_import.rs"],"content":"#!/usr/bin/env cargo\n//! Batch import using existing repository layer\n//!\n//! This imports MIDI files using the FileRepository and MetadataRepository\n//! which are already aligned with the database schema.\n\nuse anyhow::Result;\nuse clap::Parser;\nuse sqlx::types::BigDecimal;\nuse std::path::{Path, PathBuf};\nuse std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse std::time::Instant;\n\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\nuse midi_pipeline::core::hash::calculate_file_hash;\nuse midi_pipeline::db::models::{NewFile, NewMusicalMetadata};\nuse midi_pipeline::db::repositories::file_repository::FileRepository;\nuse midi_pipeline::db::repositories::metadata_repository::MetadataRepository;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\n\n#[derive(Parser)]\n#[command(name = \"batch-import\")]\n#[command(about = \"Batch import MIDI files using repository layer\")]\nstruct Args {\n    /// Directory containing MIDI files\n    #[arg(short, long)]\n    directory: PathBuf,\n\n    /// Number of parallel workers\n    #[arg(short = 'w', long, default_value = \"32\")]\n    workers: usize,\n\n    /// Database URL\n    #[arg(long, env = \"DATABASE_URL\")]\n    database_url: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Default)]\nstruct ImportStats {\n    files_found: AtomicU64,\n    files_imported: AtomicU64,\n    files_duplicates: AtomicU64,\n    files_errors: AtomicU64,\n    start_time: Option\u003cInstant\u003e,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    dotenv::dotenv().ok();\n\n    let args = Args::parse();\n\n    println!(\"\\n BATCH MIDI IMPORT (Repository Layer)\");\n    println!(\"\\n\");\n\n    // Connect to database\n    let database_url = args.database_url.unwrap_or_else(|| {\n        std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                eprintln!(\" Error: DATABASE_URL environment variable must be set\");\n                std::process::exit(1);\n            })\n    });\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::PgPool::connect(\u0026database_url).await?;\n    println!(\" Database connected\\n\");\n\n    // Find all MIDI files\n    println!(\" Scanning for MIDI files in: {}\", args.directory.display());\n    let midi_files = find_midi_files(\u0026args.directory)?;\n    let total_files = midi_files.len();\n\n    println!(\" Found {} MIDI files\\n\", total_files);\n\n    if total_files == 0 {\n        println!(\"  No MIDI files found\");\n        return Ok(());\n    }\n\n    // Initialize stats\n    let stats = Arc::new(ImportStats {\n        files_found: AtomicU64::new(total_files as u64),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    // Process files in parallel\n    println!(\" Processing {} files with {} workers...\\n\", total_files, args.workers);\n\n    use futures::stream::{self, StreamExt};\n\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(args.workers));\n    let processed = Arc::new(AtomicUsize::new(0));\n\n    stream::iter(midi_files)\n        .map(|file_path| {\n            let sem = Arc::clone(\u0026semaphore);\n            let pool = pool.clone();\n            let stats = Arc::clone(\u0026stats);\n            let processed = Arc::clone(\u0026processed);\n\n            async move {\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        eprintln!(\"Warning: Semaphore closed during import\");\n                        return;\n                    }\n                };\n\n                let current = processed.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Show progress every 100 files\n                if current % 100 == 0 || current == total_files {\n                    let elapsed = stats.start_time\n                        .map(|t| t.elapsed().as_secs_f64())\n                        .unwrap_or(0.0);\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                    println!(\n                        \"    Processing: {}/{} ({:.1}%) - {:.1} files/sec\",\n                        current,\n                        total_files,\n                        (current as f64 / total_files as f64) * 100.0,\n                        rate\n                    );\n                }\n\n                // Process the file\n                match process_file(\u0026pool, \u0026file_path).await {\n                    Ok(imported) =\u003e {\n                        if imported {\n                            stats.files_imported.fetch_add(1, Ordering::SeqCst);\n                        } else {\n                            stats.files_duplicates.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                    Err(e) =\u003e {\n                        eprintln!(\"        Error processing {}: {}\", file_path.display(), e);\n                        stats.files_errors.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(args.workers)\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // Print final summary\n    print_summary(\u0026stats);\n\n    Ok(())\n}\n\n/// Process a single MIDI file\nasync fn process_file(pool: \u0026sqlx::PgPool, file_path: \u0026Path) -\u003e Result\u003cbool\u003e {\n    // 1. Read file\n    let file_bytes = tokio::fs::read(file_path).await?;\n    let file_size = file_bytes.len() as i64;\n\n    // 2. Calculate content hash\n    let content_hash = calculate_file_hash(file_path)?;\n\n    // 3. Check for duplicate\n    if FileRepository::check_duplicate(pool, \u0026content_hash).await? {\n        return Ok(false); // Duplicate, skip\n    }\n\n    // 4. Parse MIDI file\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    // 5. Extract file metadata\n    let filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\")\n        .to_string();\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    let format = Some(midi_file.header.format as i16);\n    let num_tracks = midi_file.tracks.len() as i16;\n    let ticks_per_quarter = Some(midi_file.header.ticks_per_quarter_note as i32);\n\n    // 6. Run BPM detection\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(BigDecimal::from(bpm_result.bpm as i64))\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence as f32);\n\n    // 7. Run key detection\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence as f32);\n\n    // 8. Extract time signature\n    let (time_sig_num, time_sig_den) = extract_time_signature(\u0026midi_file);\n\n    // 9. Calculate duration\n    let total_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = if let Some(ref bpm_val) = bpm {\n        let bpm_f64 = bpm_result.bpm;\n        let ticks = total_ticks as f64;\n        let tpq = midi_file.header.ticks_per_quarter_note as f64;\n        if tpq \u003e 0.0 \u0026\u0026 bpm_f64 \u003e 0.0 {\n            let quarters = ticks / tpq;\n            let minutes = quarters / bpm_f64;\n            let seconds = minutes * 60.0;\n            Some(BigDecimal::from(seconds as i64))\n        } else {\n            None\n        }\n    } else {\n        None\n    };\n\n    let duration_ticks = Some(total_ticks);\n\n    // 10. Analyze notes\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 11. Insert file using FileRepository\n    let new_file = NewFile {\n        filename: filename.clone(),\n        filepath: filepath.clone(),\n        original_filename: filename,\n        content_hash: content_hash.to_vec(),\n        file_size_bytes: file_size,\n        format,\n        num_tracks,\n        ticks_per_quarter_note: ticks_per_quarter,\n        duration_seconds,\n        duration_ticks,\n        manufacturer: None,\n        collection_name: None,\n        folder_tags: None,\n        import_batch_id: None,\n    };\n\n    let file_id = FileRepository::insert(pool, new_file).await?;\n\n    // 12. Insert metadata using MetadataRepository\n    let new_metadata = NewMusicalMetadata {\n        file_id,\n        bpm,\n        bpm_confidence,\n        key_signature,\n        key_confidence,\n        time_signature_numerator: time_sig_num,\n        time_signature_denominator: time_sig_den,\n        total_notes: note_stats.note_count,\n        unique_pitches: note_stats.unique_pitches,\n        pitch_range_min: note_stats.pitch_min,\n        pitch_range_max: note_stats.pitch_max,\n        avg_velocity: note_stats.avg_velocity,\n        note_density: None, // Can be calculated later\n        polyphony_max: note_stats.polyphony_max,\n        polyphony_avg: None,\n        is_percussive: None,\n    };\n\n    MetadataRepository::insert(pool, new_metadata).await?;\n\n    Ok(true) // Successfully imported\n}\n\n/// Find all MIDI files in a directory\nfn find_midi_files(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e\u003e {\n    let mut files = Vec::new();\n\n    for entry in walkdir::WalkDir::new(dir) {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_file() {\n            if let Some(ext) = path.extension() {\n                if ext.eq_ignore_ascii_case(\"mid\") || ext.eq_ignore_ascii_case(\"midi\") {\n                    files.push(path.to_path_buf());\n                }\n            }\n        }\n    }\n\n    Ok(files)\n}\n\n/// Extract time signature from MIDI file\nfn extract_time_signature(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    use midi_library_shared::core::midi::types::Event;\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4)) // Default\n}\n\n/// Calculate total ticks in MIDI file\nfn calculate_total_ticks(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e i64 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i64\n}\n\n/// Note statistics\n#[derive(Debug)]\nstruct NoteStats {\n    note_count: i32,\n    unique_pitches: Option\u003ci32\u003e,\n    pitch_min: Option\u003ci16\u003e,\n    pitch_max: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cBigDecimal\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\n/// Analyze notes in MIDI file\nfn analyze_notes(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e NoteStats {\n    use midi_library_shared::core::midi::types::Event;\n    use std::collections::{HashMap, HashSet};\n\n    let mut note_count = 0i32;\n    let mut pitches = HashSet::new();\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: HashMap\u003cu32, usize\u003e = HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    pitches.insert(*note);\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(BigDecimal::from((velocity_sum / note_count as u32) as i64))\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick\n        .values()\n        .max()\n        .copied()\n        .map(|v| v as i16);\n\n    let (pitch_min, pitch_max) = if note_count \u003e 0 {\n        (Some(min_pitch as i16), Some(max_pitch as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        unique_pitches: Some(pitches.len() as i32),\n        pitch_min,\n        pitch_max,\n        avg_velocity,\n        polyphony_max,\n    }\n}\n\n/// Print final summary\nfn print_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed())\n        .unwrap_or_else(|| std::time::Duration::from_secs(0));\n    let duration_secs = elapsed.as_secs_f64();\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if duration_secs \u003e 0.0 {\n        imported as f64 / duration_secs\n    } else {\n        0.0\n    };\n\n    println!(\"\\n========================================\");\n    println!(\"BATCH IMPORT COMPLETE\");\n    println!(\"========================================\");\n    println!(\"Files found: {}\", stats.files_found.load(Ordering::SeqCst));\n    println!(\"Successfully imported: {}\", imported);\n    println!(\"Duplicates skipped: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"Time: {:.0}h {:.0}m {:.0}s\",\n        duration_secs / 3600.0,\n        (duration_secs % 3600.0) / 60.0,\n        duration_secs % 60.0\n    );\n    println!(\"Avg speed: {:.0} files/sec\", rate);\n    println!(\"========================================\");\n    println!(\"All files include: BPM, Key, Notes, Stats\");\n    println!(\"========================================\\n\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","import.rs"],"content":"//! Import binary - standalone executable for batch importing MIDI files\n\nuse anyhow::{Context, Result};\nuse clap::Parser;\nuse sqlx::PgPool;\nuse std::path::PathBuf;\n\n// Note: This binary needs to be restructured to not depend on main crate\n// For now, this is a placeholder that shows the intended structure\n\n#[derive(Parser, Debug)]\n#[command(name = \"import\")]\n#[command(about = \"Import MIDI files into the library\", long_about = None)]\nstruct Args {\n    /// Directory containing MIDI files to import\n    #[arg(short, long)]\n    directory: PathBuf,\n\n    /// Database connection string\n    #[arg(short = 'D', long, env = \"DATABASE_URL\")]\n    database_url: String,\n\n    /// Number of parallel workers\n    #[arg(short, long, default_value = \"4\")]\n    workers: usize,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    let args = Args::parse();\n\n    println!(\" MIDI Import Tool\");\n    println!(\"Directory: {:?}\", args.directory);\n    println!(\"Workers: {}\", args.workers);\n\n    // Connect to database\n    let pool = PgPool::connect(\u0026args.database_url)\n        .await\n        .context(\"Failed to connect to database\")?;\n\n    println!(\" Database connected\");\n\n    // TODO: Implement actual import logic\n    // This will be implemented once the module structure is finalized\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","import_unified.rs"],"content":"//! Unified MIDI Import Pipeline\n//!\n//! This binary orchestrates ALL existing modules to provide a complete, single-pass\n//! import pipeline that processes compressed archives directly into the database with\n//! FULL analysis (BPM, key, tags, complexity, etc.).\n//!\n//! # Architecture: Orchestration Layer\n//! This is a thin orchestration layer that combines:\n//! - Archive extraction (io::decompressor)\n//! - MIDI parsing (core::midi::parser)\n//! - Musical analysis (core::analysis)\n//! - Intelligent tagging (core::analysis::auto_tagger)\n//! - Hash-based deduplication (core::hash)\n//! - Batch database inserts (database::batch_insert)\n//!\n//! # Workflow:\n//! ```text\n//! For each archive in input directory:\n//!   1. Extract archive  temp directory\n//!   2. Find all .mid/.midi files\n//!   3. For EACH MIDI file (in parallel with 32 workers):\n//!      a. Read file bytes\n//!      b. Parse MIDI\n//!      c. Detect BPM and key\n//!      d. Extract tags from path and content\n//!      e. Analyze notes (complexity, pitch range, polyphony, etc.)\n//!      f. Calculate BLAKE3 hash for deduplication\n//!      g. INSERT INTO files + musical_metadata (ONE transaction)\n//!   4. Clean up temp files\n//!   5. Move to next archive\n//! ```\n//!\n//! # Performance:\n//! - Target: 350-400 files/sec with full analysis\n//! - 1.5M files completed in ~1-1.5 hours\n//! - Single-pass processing (no re-analysis needed)\n//!\n//! # Usage:\n//! ```bash\n//! # Process directory of archives\n//! cargo run --release --bin import_unified -- ~/floorp_downloads/_1.002.000-Midi-Collection_/\n//!\n//! # Process single archive\n//! cargo run --release --bin import_unified -- ~/path/to/archive.zip\n//! ```\n\nuse std::path::{Path, PathBuf};\nuse std::sync::atomic::{AtomicUsize, AtomicU64, Ordering};\nuse std::sync::Arc;\nuse std::time::Instant;\n\nuse tokio::sync::Mutex;\nuse futures::stream::{self, StreamExt};\nuse clap::Parser;\n// Unused: use indicatif::{ProgressBar, ProgressStyle, MultiProgress};\n\n// Import existing modules - we just orchestrate them\nuse midi_pipeline::io::decompressor::extractor::{extract_archive, ExtractionConfig};\nuse midi_pipeline::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\nuse midi_pipeline::core::analysis::auto_tagger::AutoTagger;\nuse midi_pipeline::database::Database;\n\n//=============================================================================\n// CLI ARGUMENTS\n//=============================================================================\n\n#[derive(Parser, Debug)]\n#[command(name = \"import-unified\")]\n#[command(about = \"Unified MIDI import pipeline with full analysis in single pass\")]\nstruct Args {\n    /// Path to archive directory or single archive file\n    #[arg(help = \"Directory containing .zip/.rar/.7z archives, or single archive file\")]\n    path: PathBuf,\n\n    /// Number of parallel MIDI processing workers (default: 32)\n    #[arg(short = 'w', long, default_value = \"32\")]\n    workers: usize,\n\n    /// Batch size for database inserts (default: 100)\n    #[arg(short = 'b', long, default_value = \"100\")]\n    batch_size: usize,\n\n    /// Database URL (default: from DATABASE_URL env var)\n    #[arg(long)]\n    database_url: Option\u003cString\u003e,\n}\n\n//=============================================================================\n// DATA STRUCTURES\n//=============================================================================\n\n/// Fully analyzed MIDI file ready for database insertion\n#[derive(Debug, Clone)]\nstruct AnalyzedMidiFile {\n    // File metadata\n    filename: String,\n    original_filename: String,\n    filepath: String,\n    parent_folder: Option\u003cString\u003e,\n    content_hash: Vec\u003cu8\u003e,\n    file_size_bytes: i64,\n    num_tracks: i16,\n    format: Option\u003ci16\u003e,\n    is_multi_track: bool,\n\n    // Musical metadata - tempo\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n\n    // Musical metadata - key\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n\n    // Musical metadata - time\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n\n    // Musical metadata - notes\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n\n    // Musical metadata - complexity\n    complexity_score: Option\u003cf64\u003e,\n\n    // Musical metadata - features\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n\n    // Tags\n    tags: Vec\u003cString\u003e,\n    category: Option\u003cString\u003e,\n}\n\n/// Statistics for the import operation\n#[derive(Debug, Default)]\nstruct ImportStats {\n    archives_processed: AtomicUsize,\n    archives_total: AtomicUsize,\n    files_found: AtomicU64,\n    files_imported: AtomicU64,\n    files_duplicates: AtomicU64,\n    files_errors: AtomicU64,\n    start_time: Option\u003cInstant\u003e,\n}\n\n//=============================================================================\n// MAIN ENTRY POINT\n//=============================================================================\n\n#[tokio::main]\nasync fn main() -\u003e anyhow::Result\u003c()\u003e {\n    // Load environment variables\n    dotenv::dotenv().ok();\n\n    // Parse CLI arguments\n    let args = Args::parse();\n\n    // Setup logging\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .init();\n\n    println!(\"\\n UNIFIED MIDI IMPORT PIPELINE\");\n    println!(\"\\n\");\n\n    // Connect to database\n    let database_url = args.database_url.unwrap_or_else(|| {\n        std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                eprintln!(\" Error: DATABASE_URL must be set in environment or via --database-url\");\n                std::process::exit(1);\n            })\n    });\n\n    println!(\" Connecting to database...\");\n    let db = Database::new(\u0026database_url).await?;\n    println!(\" Database connected\\n\");\n\n    // Check if path is directory or single archive\n    if args.path.is_dir() {\n        process_archive_directory(\u0026args.path, \u0026db, args.workers, args.batch_size).await?;\n    } else if args.path.is_file() {\n        process_single_archive(\u0026args.path, \u0026db, args.workers, args.batch_size).await?;\n    } else {\n        anyhow::bail!(\"Path does not exist: {}\", args.path.display());\n    }\n\n    println!(\"\\n Import pipeline completed successfully!\");\n\n    Ok(())\n}\n\n//=============================================================================\n// ARCHIVE DIRECTORY PROCESSING\n//=============================================================================\n\n/// Process all archives in a directory\nasync fn process_archive_directory(\n    dir_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n) -\u003e anyhow::Result\u003c()\u003e {\n    println!(\" Scanning for archives in: {}\", dir_path.display());\n\n    // Find all archive files (.zip, .rar, .7z)\n    let archives: Vec\u003cPathBuf\u003e = std::fs::read_dir(dir_path)?\n        .filter_map(|entry| entry.ok())\n        .map(|entry| entry.path())\n        .filter(|path| {\n            path.extension()\n                .and_then(|ext| ext.to_str())\n                .map(|ext| {\n                    ext.eq_ignore_ascii_case(\"zip\")\n                        || ext.eq_ignore_ascii_case(\"rar\")\n                        || ext.eq_ignore_ascii_case(\"7z\")\n                })\n                .unwrap_or(false)\n        })\n        .collect();\n\n    let total_archives = archives.len();\n    println!(\" Found {} archives to process\\n\", total_archives);\n\n    if total_archives == 0 {\n        println!(\"  No archives found in directory\");\n        return Ok(());\n    }\n\n    // Initialize statistics\n    let stats = Arc::new(ImportStats {\n        archives_total: AtomicUsize::new(total_archives),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    // Process archives sequentially (avoid I/O bottleneck)\n    for (index, archive_path) in archives.iter().enumerate() {\n        let archive_name = archive_path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"unknown\");\n\n        println!(\"\\n\");\n        println!(\" Archive [{}/{}]: {}\", index + 1, total_archives, archive_name);\n        println!(\"\");\n\n        match process_archive_with_stats(archive_path, db, workers, batch_size, stats.clone()).await {\n            Ok(_) =\u003e {\n                stats.archives_processed.fetch_add(1, Ordering::SeqCst);\n                print_progress_summary(\u0026stats);\n            }\n            Err(e) =\u003e {\n                eprintln!(\" Failed to process archive {}: {}\", archive_name, e);\n                stats.archives_processed.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n    }\n\n    // Print final summary\n    print_final_summary(\u0026stats);\n\n    Ok(())\n}\n\n/// Process a single archive file\nasync fn process_single_archive(\n    archive_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n) -\u003e anyhow::Result\u003c()\u003e {\n    let archive_name = archive_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\");\n\n    println!(\" Processing archive: {}\\n\", archive_name);\n\n    let stats = Arc::new(ImportStats {\n        archives_total: AtomicUsize::new(1),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    process_archive_with_stats(archive_path, db, workers, batch_size, stats.clone()).await?;\n\n    print_final_summary(\u0026stats);\n\n    Ok(())\n}\n\n//=============================================================================\n// ARCHIVE PROCESSING WITH FULL ANALYSIS\n//=============================================================================\n\n/// Process a single archive with full analysis and database insertion\nasync fn process_archive_with_stats(\n    archive_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n    stats: Arc\u003cImportStats\u003e,\n) -\u003e anyhow::Result\u003c()\u003e {\n    let start_time = Instant::now();\n\n    // Step 1: Extract archive to temp directory\n    println!(\"   Extracting archive...\");\n    let temp_dir = std::env::temp_dir().join(format!(\"midi_unified_{}\", uuid::Uuid::new_v4()));\n    std::fs::create_dir_all(\u0026temp_dir)?;\n\n    let config = ExtractionConfig::default();\n    let extraction_result = extract_archive(archive_path, \u0026temp_dir, \u0026config).map_err(|e| anyhow::anyhow!(\"{}\", e))?;\n\n    let midi_files = extraction_result.midi_files;\n    let midi_count = midi_files.len();\n    stats.files_found.fetch_add(midi_count as u64, Ordering::SeqCst);\n\n    println!(\"   Found {} MIDI files\", midi_count);\n\n    if midi_count == 0 {\n        std::fs::remove_dir_all(\u0026temp_dir)?;\n        return Ok(());\n    }\n\n    // Extract category from archive name\n    let category = archive_path\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .map(|s| s.to_string());\n\n    // Step 2: Process MIDI files in parallel with full analysis\n    println!(\"   Processing {} MIDI files with {} workers...\", midi_count, workers);\n\n    // Thread-safe counters\n    let processed = Arc::new(AtomicUsize::new(0));\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(workers));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n    let pool = db.pool().await;\n\n    // Process files in parallel with buffer_unordered\n    stream::iter(midi_files)\n        .map(|file_path| {\n            let sem = Arc::clone(\u0026semaphore);\n            let category = category.clone();\n            let processed = Arc::clone(\u0026processed);\n            let analyzed_files = Arc::clone(\u0026analyzed_files);\n            let stats = Arc::clone(\u0026stats);\n            let pool = pool.clone();\n\n            async move {\n                // Acquire semaphore permit\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        eprintln!(\"Warning: Semaphore closed during import\");\n                        return;\n                    }\n                };\n\n                let current = processed.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Show progress every 100 files\n                if current % 100 == 0 || current == midi_count {\n                    let elapsed = start_time.elapsed().as_secs_f64();\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                    println!(\"    Processing: {}/{} ({:.1}%) - {:.1} files/sec\",\n                        current, midi_count,\n                        (current as f64 / midi_count as f64) * 100.0,\n                        rate\n                    );\n                }\n\n                // Analyze the file with full analysis\n                match analyze_midi_file(\u0026file_path, category).await {\n                    Ok(analyzed) =\u003e {\n                        // Add to batch for insertion\n                        analyzed_files.lock().await.push(analyzed);\n\n                        // Flush batch if it reaches threshold\n                        let mut files = analyzed_files.lock().await;\n                        if files.len() \u003e= batch_size {\n                            let batch: Vec\u003cAnalyzedMidiFile\u003e = files.drain(..).collect();\n                            drop(files); // Release lock\n\n                            match insert_batch(\u0026pool, \u0026batch).await {\n                                Ok(inserted) =\u003e {\n                                    stats.files_imported.fetch_add(inserted as u64, Ordering::SeqCst);\n                                    let duplicates = batch.len() - inserted;\n                                    stats.files_duplicates.fetch_add(duplicates as u64, Ordering::SeqCst);\n                                }\n                                Err(e) =\u003e {\n                                    eprintln!(\"       Batch insert failed: {}\", e);\n                                    stats.files_errors.fetch_add(batch.len() as u64, Ordering::SeqCst);\n                                }\n                            }\n                        }\n                    }\n                    Err(e) =\u003e {\n                        eprintln!(\"        Failed to analyze {}: {}\", file_path.display(), e);\n                        stats.files_errors.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(workers) // THE MAGIC: Process N files concurrently!\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedMidiFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        match insert_batch(\u0026pool, \u0026batch).await {\n            Ok(inserted) =\u003e {\n                stats.files_imported.fetch_add(inserted as u64, Ordering::SeqCst);\n                let duplicates = batch.len() - inserted;\n                stats.files_duplicates.fetch_add(duplicates as u64, Ordering::SeqCst);\n            }\n            Err(e) =\u003e {\n                eprintln!(\"       Final batch insert failed: {}\", e);\n                stats.files_errors.fetch_add(batch.len() as u64, Ordering::SeqCst);\n            }\n        }\n    }\n\n    // Cleanup temp directory\n    std::fs::remove_dir_all(\u0026temp_dir)?;\n\n    let elapsed = start_time.elapsed().as_secs_f64();\n    let rate = if elapsed \u003e 0.0 { midi_count as f64 / elapsed } else { 0.0 };\n    println!(\"   Completed in {:.1}s ({:.1} files/sec)\\n\", elapsed, rate);\n\n    Ok(())\n}\n\n//=============================================================================\n// MIDI FILE ANALYSIS (Full Analysis in Single Pass)\n//=============================================================================\n\n/// Analyze a single MIDI file with FULL analysis (BPM, key, tags, complexity, etc.)\nasync fn analyze_midi_file(\n    file_path: \u0026Path,\n    category: Option\u003cString\u003e,\n) -\u003e anyhow::Result\u003cAnalyzedMidiFile\u003e {\n    // 1. Read file bytes\n    let file_bytes = tokio::fs::read(file_path).await?;\n    let file_size_bytes = file_bytes.len() as i64;\n\n    // 2. Calculate BLAKE3 hash for deduplication\n    let hash_bytes = calculate_file_hash(file_path)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec();\n\n    // 3. Parse MIDI file\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n    let num_tracks = midi_file.tracks.len() as i16;\n    let format = Some(midi_file.header.format as i16);\n    let is_multi_track = midi_file.tracks.len() \u003e 1;\n\n    // 4. BPM Detection\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    // 5. Key Detection\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    // 6. Time Signature\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n\n    // 7. Duration Calculation\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n\n    // 8. Note Analysis\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 9. Extract Instruments\n    let instruments = extract_instrument_names(\u0026midi_file);\n\n    // 10. Detect MIDI Features\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n\n    // 11. Calculate Complexity Score\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    // 12. Extract Tags\n    let filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\")\n        .to_string();\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    let auto_tagger = AutoTagger::new()?;\n    let tags_obj = auto_tagger.extract_tags(\n        \u0026filepath,\n        \u0026filename,\n        \u0026instruments,\n        tempo_bpm,\n        key_signature.as_deref(),\n    );\n\n    // Convert tags to strings for database\n    let tags: Vec\u003cString\u003e = tags_obj.iter().map(|t| {\n        match \u0026t.category {\n            Some(cat) =\u003e format!(\"{}:{}\", cat, t.name),\n            None =\u003e t.name.clone(),\n        }\n    }).collect();\n\n    // 13. Extract parent folder\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    Ok(AnalyzedMidiFile {\n        filename: filename.clone(),\n        original_filename: filename,\n        filepath,\n        parent_folder,\n        content_hash,\n        file_size_bytes,\n        num_tracks,\n        format,\n        is_multi_track,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n        tags,\n        category,\n    })\n}\n\n//=============================================================================\n// DATABASE BATCH INSERTION\n//=============================================================================\n\n/// Insert batch of analyzed files into database\n/// Returns number of files successfully inserted (excludes duplicates)\nasync fn insert_batch(pool: \u0026sqlx::PgPool, files: \u0026[AnalyzedMidiFile]) -\u003e anyhow::Result\u003cusize\u003e {\n    let mut inserted_count = 0;\n\n    for file in files {\n        let mut tx = pool.begin().await?;\n\n        // Insert file with ON CONFLICT to handle duplicates\n        let file_id_opt = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            INSERT INTO files (\n                filename, original_filename, filepath, parent_folder,\n                content_hash, file_size_bytes, num_tracks,\n                format, is_multi_track, created_at\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, NOW())\n            ON CONFLICT (content_hash) DO NOTHING\n            RETURNING id\n            \"#\n        )\n        .bind(\u0026file.filename)\n        .bind(\u0026file.original_filename)\n        .bind(\u0026file.filepath)\n        .bind(\u0026file.parent_folder)\n        .bind(\u0026file.content_hash)\n        .bind(file.file_size_bytes)\n        .bind(file.num_tracks)\n        .bind(file.format)\n        .bind(file.is_multi_track)\n        .fetch_optional(\u0026mut *tx)\n        .await?;\n\n        // If duplicate, skip\n        let file_id = match file_id_opt {\n            Some(id) =\u003e id,\n            None =\u003e {\n                tx.rollback().await?;\n                continue; // Skip duplicate\n            }\n        };\n\n        // Insert musical metadata\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id, tempo_bpm, bpm_confidence, has_tempo_variation,\n                key_signature, key_confidence, scale_type,\n                time_signature_num, time_signature_den,\n                duration_seconds, duration_ticks,\n                note_count, pitch_range_low, pitch_range_high, pitch_range_semitones,\n                avg_velocity, velocity_range_low, velocity_range_high,\n                polyphony_max, complexity_score,\n                instruments, has_pitch_bend, has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            \"#\n        )\n        .bind(file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Update analyzed_at timestamp\n        sqlx::query(\"UPDATE files SET analyzed_at = NOW() WHERE id = $1\")\n            .bind(file_id)\n            .execute(\u0026mut *tx)\n            .await?;\n\n        tx.commit().await?;\n        inserted_count += 1;\n    }\n\n    Ok(inserted_count)\n}\n\n//=============================================================================\n// HELPER FUNCTIONS - MIDI ANALYSIS\n//=============================================================================\n\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4))\n}\n\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i32\n}\n\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        let seconds = minutes * 60.0;\n        Some(seconds)\n    } else {\n        None\n    }\n}\n\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026instrument_name) {\n                            instruments.push(instrument_name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    // Factor 1: Note density\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0);\n    }\n\n    // Factor 2: Pitch range\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0);\n    }\n\n    // Factor 3: Polyphony\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0);\n    }\n\n    // Factor 4: Track count\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0);\n\n    // Factor 5: Velocity variation\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0);\n    }\n\n    Some(score.min(100.0))\n}\n\n//=============================================================================\n// PROGRESS REPORTING\n//=============================================================================\n\nfn print_progress_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed().as_secs_f64())\n        .unwrap_or(0.0);\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if elapsed \u003e 0.0 { imported as f64 / elapsed } else { 0.0 };\n\n    println!(\"   Progress:\");\n    println!(\"    Archives: {}/{}\",\n        stats.archives_processed.load(Ordering::SeqCst),\n        stats.archives_total.load(Ordering::SeqCst)\n    );\n    println!(\"    Imported: {}\", imported);\n    println!(\"    Duplicates: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"    Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"    Rate: {:.1} files/sec\", rate);\n}\n\nfn print_final_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed())\n        .unwrap_or_else(|| std::time::Duration::from_secs(0));\n    let duration_secs = elapsed.as_secs_f64();\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if duration_secs \u003e 0.0 { imported as f64 / duration_secs } else { 0.0 };\n\n    println!(\"\\n========================================\");\n    println!(\"UNIFIED IMPORT COMPLETE\");\n    println!(\"========================================\");\n    println!(\"Archives processed: {}/{}\",\n        stats.archives_processed.load(Ordering::SeqCst),\n        stats.archives_total.load(Ordering::SeqCst)\n    );\n    println!(\"MIDI files found: {}\", stats.files_found.load(Ordering::SeqCst));\n    println!(\"Successfully imported: {}\", imported);\n    println!(\"  With full analysis: {}\", imported);\n    println!(\"Duplicates skipped: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"Time: {:.0}h {:.0}m {:.0}s\",\n        duration_secs / 3600.0,\n        (duration_secs % 3600.0) / 60.0,\n        duration_secs % 60.0\n    );\n    println!(\"Avg speed: {:.0} files/sec\", rate);\n    println!(\"========================================\");\n    println!(\"All files include: BPM, Key, Tags, Complexity\");\n    println!(\"Ready to use in DAW!\");\n    println!(\"========================================\\n\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","split.rs"],"content":"//! Split binary - standalone executable for splitting multi-track MIDI files\n\nuse anyhow::{Context, Result};\nuse clap::Parser;\nuse sqlx::PgPool;\nuse std::path::PathBuf;\n\n#[derive(Parser, Debug)]\n#[command(name = \"split\")]\n#[command(about = \"Split multi-track MIDI files\", long_about = None)]\nstruct Args {\n    /// MIDI file to split\n    #[arg(short, long)]\n    file: PathBuf,\n\n    /// Output directory for split files\n    #[arg(short, long)]\n    output: PathBuf,\n\n    /// Database connection string\n    #[arg(short = 'D', long, env = \"DATABASE_URL\")]\n    database_url: String,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    let args = Args::parse();\n\n    println!(\" MIDI Split Tool\");\n    println!(\"File: {:?}\", args.file);\n    println!(\"Output: {:?}\", args.output);\n\n    // Connect to database\n    let pool = PgPool::connect(\u0026args.database_url)\n        .await\n        .context(\"Failed to connect to database\")?;\n\n    println!(\" Database connected\");\n\n    // TODO: Implement actual split logic\n    // This will be implemented once the module structure is finalized\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","analyze.rs"],"content":"//! Musical Analysis Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION\n//!\n//! Architecture: Grown-up Script\n//! Purpose: Analyze all imported MIDI files using existing analysis modules\n//!\n//! This module processes 1.1M+ imported files by:\n//! - Reading unanalyzed files from database in batches\n//! - Parallel processing with buffer_unordered (32 workers)\n//! - Running BPM detection, key detection, and auto-tagging\n//! - Batch database inserts for musical_metadata\n//! - Real-time progress updates\n//!\n//! Performance Target: 400-500 files/sec (complete 1.1M files in ~40-60 minutes)\n\nuse crate::AppState;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\n// Unused: use crate::core::analysis::auto_tagger::{AutoTagger, Tag};\n\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\nuse tauri::{Emitter, State, Window};\nuse futures::stream::{self, StreamExt};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Progress event for real-time UI updates\n#[derive(Debug, Clone, Serialize)]\npub struct AnalysisProgress {\n    pub current: usize,\n    pub total: usize,\n    pub current_file: String,\n    pub rate: f64, // files per second\n    pub eta_seconds: f64,\n}\n\n/// Summary of analysis operation results\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AnalysisSummary {\n    pub total_files: usize,\n    pub analyzed: usize,\n    pub skipped: usize,\n    pub errors: Vec\u003cString\u003e,\n    pub duration_secs: f64,\n    pub rate: f64, // files per second\n}\n\n/// File record from database\n#[derive(Debug, Clone, sqlx::FromRow)]\nstruct FileRecord {\n    id: i64,\n    filepath: String,\n    filename: String,\n}\n\n/// Analyzed file data ready for database insertion\n#[derive(Debug, Clone)]\nstruct AnalyzedFile {\n    file_id: i64,\n\n    // Tempo\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n\n    // Key\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n\n    // Time signature\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n\n    // Duration\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n\n    // Note analysis\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n\n    // Velocity\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n\n    // Polyphony\n    polyphony_max: Option\u003ci16\u003e,\n\n    // Complexity\n    complexity_score: Option\u003cf64\u003e,\n\n    // Additional properties\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n}\n\n//=============================================================================\n// TAURI COMMANDS\n//=============================================================================\n\n/// Analyze all unanalyzed MIDI files (HIGH-PERFORMANCE PARALLEL VERSION)\n///\n/// This command:\n/// 1. Reads unanalyzed files from database in batches\n/// 2. Processes them in parallel with 32 workers\n/// 3. Runs BPM detection, key detection, note analysis\n/// 4. Batch inserts results into musical_metadata\n/// 5. Updates files.analyzed_at timestamp\n/// 6. Shows real-time progress\n#[tauri::command]\npub async fn start_analysis(\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cAnalysisSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let pool: sqlx::PgPool = state.database.pool().await;\n\n    // Get total count of unanalyzed files\n    let total: i64 = sqlx::query_scalar(\n        \"SELECT COUNT(*) FROM files WHERE analyzed_at IS NULL\"\n    )\n    .fetch_one(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to count unanalyzed files: {}\", e))?;\n\n    println!(\" Found {} unanalyzed files\", total);\n\n    if total == 0 {\n        return Ok(AnalysisSummary {\n            total_files: 0,\n            analyzed: 0,\n            skipped: 0,\n            errors: vec![],\n            duration_secs: 0.0,\n            rate: 0.0,\n        });\n    }\n\n    // Parallel processing configuration\n    let concurrency_limit = 32; // Process 32 files concurrently\n    let batch_size = 1000; // Fetch files in batches of 1000\n\n    println!(\" Starting analysis:\");\n    println!(\"  Concurrency: {} workers\", concurrency_limit);\n    println!(\"  Batch size: {} files\", batch_size);\n\n    // Thread-safe counters\n    let analyzed = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let total_usize = total as usize;\n\n    // Process files in batches\n    let mut offset = 0i64;\n\n    loop {\n        // Fetch batch of unanalyzed files\n        let files: Vec\u003cFileRecord\u003e = sqlx::query_as(\n            \"SELECT id, filepath, filename\n             FROM files\n             WHERE analyzed_at IS NULL\n             ORDER BY id\n             LIMIT $1 OFFSET $2\"\n        )\n        .bind(batch_size)\n        .bind(offset)\n        .fetch_all(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to fetch files: {}\", e))?;\n\n        if files.is_empty() {\n            break;\n        }\n\n        let batch_len = files.len();\n        println!(\" Processing batch: {} files (offset: {})\", batch_len, offset);\n\n        // Process batch in parallel\n        stream::iter(files)\n            .map(|file_record| {\n                // Clone Arc pointers for each concurrent task\n                let sem = Arc::clone(\u0026semaphore);\n                let analyzed = Arc::clone(\u0026analyzed);\n                let skipped = Arc::clone(\u0026skipped);\n                let errors = Arc::clone(\u0026errors);\n                let current_index = Arc::clone(\u0026current_index);\n                let analyzed_files = Arc::clone(\u0026analyzed_files);\n                let window = window.clone();\n\n                    let pool = pool.clone();\n                async move {\n                    // Acquire semaphore permit (blocks if at limit)\n                    let _permit = match sem.acquire().await {\n                        Ok(permit) =\u003e permit,\n                        Err(_) =\u003e {\n                            eprintln!(\"Warning: Semaphore closed during analysis\");\n                            return;\n                        }\n                    };\n\n                    let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                    // Emit progress every 10 files\n                    if current % 10 == 0 || current == total_usize {\n                        let elapsed = start_time.elapsed().as_secs_f64();\n                        let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                        let remaining = total_usize - current;\n                        let eta_seconds = if rate \u003e 0.0 { remaining as f64 / rate } else { 0.0 };\n\n                        let _ = window.emit(\"analysis-progress\", AnalysisProgress {\n                            current,\n                            total: total_usize,\n                            current_file: file_record.filename.clone(),\n                            rate,\n                            eta_seconds,\n                        });\n\n                        // Print progress every 100 files\n                        if current % 100 == 0 {\n                            println!(\n                                \"Analyzing: {}/{} ({:.1}%) - {:.1} files/sec - ETA: {:.0}s\",\n                                current,\n                                total_usize,\n                                (current as f64 / total_usize as f64) * 100.0,\n                                rate,\n                                eta_seconds\n                            );\n                        }\n                    }\n\n                    // Analyze the file\n                    match analyze_single_file(\u0026file_record).await {\n                        Ok(analyzed_data) =\u003e {\n                            // Add to batch for insertion\n                            analyzed_files.lock().await.push(analyzed_data);\n                            analyzed.fetch_add(1, Ordering::SeqCst);\n\n                            // Flush batch if it reaches threshold (100 files)\n                            let mut files = analyzed_files.lock().await;\n                            if files.len() \u003e= 100 {\n                                let batch: Vec\u003cAnalyzedFile\u003e = files.drain(..).collect();\n                                drop(files); // Release lock\n\n                                if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n                                    errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            let error_msg = format!(\"{}: {}\", file_record.filepath, e);\n                            errors.lock().await.push(error_msg);\n                            skipped.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                }\n            })\n            .buffer_unordered(concurrency_limit) //  THE MAGIC: Process N files concurrently!\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .await;\n\n        offset += batch_size;\n    }\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n            errors.lock().await.push(format!(\"Final batch insert failed: {}\", e));\n        }\n    }\n\n    // Calculate final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let analyzed_count = analyzed.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { analyzed_count as f64 / duration } else { 0.0 };\n\n    println!(\"\\n Analysis complete!\");\n    println!(\"  Total files: {}\", total_usize);\n    println!(\"  Analyzed: {}\", analyzed_count);\n    println!(\"  Skipped: {}\", skipped.load(Ordering::SeqCst));\n    println!(\"  Duration: {:.1}s\", duration);\n    println!(\"  Rate: {:.1} files/sec\", rate);\n\n    // Extract errors before creating summary\n    let error_list = errors.lock().await.clone();\n\n    Ok(AnalysisSummary {\n        total_files: total_usize,\n        analyzed: analyzed_count,\n        skipped: skipped.load(Ordering::SeqCst),\n        errors: error_list,\n        duration_secs: duration,\n        rate,\n    })\n}\n\n//=============================================================================\n// CORE ANALYSIS LOGIC\n//=============================================================================\n\n/// Analyze a single MIDI file using all analysis modules\nasync fn analyze_single_file(\n    file_record: \u0026FileRecord,\n) -\u003e Result\u003cAnalyzedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // 1. Read MIDI file from filesystem\n    let file_bytes = tokio::fs::read(\u0026file_record.filepath).await?;\n\n    // 2. Parse MIDI file (Trusty Module)\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    // 3. BPM Detection (Trusty Module)\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    // 4. Key Detection (Trusty Module)\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    // 5. Extract time signature from MIDI events\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n\n    // 6. Calculate duration\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n\n    // 7. Note analysis\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 8. Extract instruments\n    let instruments = extract_instrument_names(\u0026midi_file);\n\n    // 9. Detect MIDI features\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n\n    // 10. Calculate complexity score (simple heuristic)\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    Ok(AnalyzedFile {\n        file_id: file_record.id,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n    })\n}\n\n/// Batch insert analyzed files into musical_metadata and update files.analyzed_at\nasync fn batch_insert_analyzed_files(\n    files: \u0026[AnalyzedFile],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    if files.is_empty() {\n        return Ok(());\n    }\n\n    let mut tx = pool.begin().await?;\n\n    for file in files {\n        // Insert or update musical_metadata\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                tempo_bpm,\n                bpm_confidence,\n                has_tempo_variation,\n                key_signature,\n                key_confidence,\n                scale_type,\n                time_signature_num,\n                time_signature_den,\n                duration_seconds,\n                duration_ticks,\n                note_count,\n                pitch_range_low,\n                pitch_range_high,\n                pitch_range_semitones,\n                avg_velocity,\n                velocity_range_low,\n                velocity_range_high,\n                polyphony_max,\n                complexity_score,\n                instruments,\n                has_pitch_bend,\n                has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            ON CONFLICT (file_id) DO UPDATE SET\n                tempo_bpm = EXCLUDED.tempo_bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                has_tempo_variation = EXCLUDED.has_tempo_variation,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                scale_type = EXCLUDED.scale_type,\n                time_signature_num = EXCLUDED.time_signature_num,\n                time_signature_den = EXCLUDED.time_signature_den,\n                duration_seconds = EXCLUDED.duration_seconds,\n                duration_ticks = EXCLUDED.duration_ticks,\n                note_count = EXCLUDED.note_count,\n                pitch_range_low = EXCLUDED.pitch_range_low,\n                pitch_range_high = EXCLUDED.pitch_range_high,\n                pitch_range_semitones = EXCLUDED.pitch_range_semitones,\n                avg_velocity = EXCLUDED.avg_velocity,\n                velocity_range_low = EXCLUDED.velocity_range_low,\n                velocity_range_high = EXCLUDED.velocity_range_high,\n                polyphony_max = EXCLUDED.polyphony_max,\n                complexity_score = EXCLUDED.complexity_score,\n                instruments = EXCLUDED.instruments,\n                has_pitch_bend = EXCLUDED.has_pitch_bend,\n                has_cc_messages = EXCLUDED.has_cc_messages\n            \"#\n        )\n        .bind(file.file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Update files.analyzed_at timestamp\n        sqlx::query(\n            \"UPDATE files SET analyzed_at = NOW() WHERE id = $1\"\n        )\n        .bind(file.file_id)\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    tx.commit().await?;\n\n    Ok(())\n}\n\n//=============================================================================\n// HELPER FUNCTIONS - MIDI ANALYSIS\n//=============================================================================\n\n/// Note statistics\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\n/// Analyze notes in MIDI file\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\n/// Extract time signature from MIDI file\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                // MIDI stores denominator as power of 2 (2 = quarter note, 3 = eighth note, etc.)\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n\n    // Default to 4/4 if not found\n    (Some(4), Some(4))\n}\n\n/// Calculate total number of ticks in MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks as i32\n}\n\n/// Calculate duration in seconds\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        let seconds = minutes * 60.0;\n        Some(seconds)\n    } else {\n        None\n    }\n}\n\n/// Extract instrument names from MIDI file\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026instrument_name) {\n                            instruments.push(instrument_name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\n/// Map MIDI General MIDI program number to instrument name\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\n/// Detect if MIDI file contains pitch bend events\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\n/// Detect if MIDI file contains control change messages\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\n/// Calculate complexity score based on various factors\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    // Factor 1: Note density (notes per second)\n    // Assume average 120 BPM for rough estimate\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0); // Max 30 points\n    }\n\n    // Factor 2: Pitch range (wider range = more complex)\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0); // Max 20 points\n    }\n\n    // Factor 3: Polyphony (more simultaneous notes = more complex)\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0); // Max 25 points\n    }\n\n    // Factor 4: Track count\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0); // Max 15 points\n\n    // Factor 5: Velocity variation\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0); // Max 10 points\n    }\n\n    // Normalize to 0-100 scale\n    Some(score.min(100.0))\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_program_to_instrument_name() {\n        assert_eq!(program_to_instrument_name(0), Some(\"Piano\".to_string()));\n        assert_eq!(program_to_instrument_name(32), Some(\"Bass\".to_string()));\n        assert_eq!(program_to_instrument_name(80), Some(\"Lead\".to_string()));\n    }\n\n    #[test]\n    fn test_complexity_score_empty() {\n        let note_stats = NoteStats {\n            note_count: 0,\n            pitch_range_low: None,\n            pitch_range_high: None,\n            pitch_range_semitones: None,\n            avg_velocity: None,\n            velocity_range_low: None,\n            velocity_range_high: None,\n            polyphony_max: None,\n        };\n\n        let midi_file = MidiFile {\n            header: midi_library_shared::core::midi::types::Header {\n                format: 0,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![],\n        };\n\n        let score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n        assert_eq!(score, Some(0.0));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","archive_import.rs"],"content":"//! Archive Collection Import Command\n//!\n//! Processes entire collections of nested archives, extracting and importing\n//! all MIDI files with automatic tagging.\n//!\n//! # Archetype: Grown-up Script (Tauri Command Wrapper)\n//! - Thin wrapper around core functionality\n//! - Coordinates decompressor + file import modules\n//! - Provides progress feedback to UI\n\nuse crate::AppState;\nuse crate::io::decompressor::extractor::{extract_archive, ExtractionConfig};\nuse crate::commands::file_import::import_directory;\nuse serde::{Deserialize, Serialize};\nuse std::path::Path;\nuse tauri::{Emitter, State, Window};\n\n/// Summary of archive collection import\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ArchiveImportSummary {\n    pub total_archives: usize,\n    pub total_files_imported: usize,\n    pub total_files_skipped: usize,\n    pub total_errors: usize,\n    pub duration_secs: f64,\n    pub archives_processed: Vec\u003cArchiveStatus\u003e,\n}\n\n/// Status of individual archive processing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ArchiveStatus {\n    pub archive_name: String,\n    pub midi_files_found: usize,\n    pub files_imported: usize,\n    pub success: bool,\n    pub error_message: Option\u003cString\u003e,\n}\n\n/// Import entire collection of archives (recursively extracts and imports all MIDI files)\n///\n/// # Arguments\n/// * `collection_path` - Directory containing zip archives\n/// * `state` - Application state\n/// * `window` - Tauri window for progress events\n///\n/// # Frontend Usage\n/// ```typescript\n/// await invoke('import_archive_collection', {\n///   collectionPath: '/home/user/midi-collection/'\n/// });\n/// ```\n#[tauri::command]\npub async fn import_archive_collection(\n    collection_path: String,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cArchiveImportSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let collection_dir = Path::new(\u0026collection_path);\n\n    if !collection_dir.exists() {\n        return Err(format!(\"Collection directory not found: {}\", collection_path));\n    }\n\n    if !collection_dir.is_dir() {\n        return Err(format!(\"Path is not a directory: {}\", collection_path));\n    }\n\n    println!(\"\\n Starting archive collection import from: {}\", collection_path);\n    println!(\" Scanning for zip archives...\\n\");\n\n    // Scan for zip files\n    let archives: Vec\u003c_\u003e = std::fs::read_dir(collection_dir)\n        .map_err(|e| format!(\"Failed to read directory: {}\", e))?\n        .filter_map(|entry| entry.ok())\n        .filter(|entry| {\n            entry.path().extension()\n                .and_then(|ext| ext.to_str())\n                .map(|ext| ext.eq_ignore_ascii_case(\"zip\"))\n                .unwrap_or(false)\n        })\n        .collect();\n\n    let total_archives = archives.len();\n    println!(\" Found {} archives to process\\n\", total_archives);\n\n    let mut archive_statuses = Vec::new();\n    let mut total_files_imported = 0;\n    let mut total_files_skipped = 0;\n    let mut total_errors = 0;\n\n    // Process each archive\n    for (index, entry) in archives.iter().enumerate() {\n        let archive_path = entry.path();\n        let archive_name = archive_path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"unknown\")\n            .to_string();\n\n        println!(\"\");\n        println!(\" [{}/{}] Processing: {}\", index + 1, total_archives, archive_name);\n        println!(\"\");\n\n        // Emit progress event\n        let _ = window.emit(\"archive-progress\", serde_json::json!({\n            \"current\": index + 1,\n            \"total\": total_archives,\n            \"archive_name\": archive_name\n        }));\n\n        // Process this archive\n        let status = process_single_archive(\n            \u0026archive_path,\n            \u0026archive_name,\n            state.clone(),\n            window.clone(),\n        ).await;\n\n        match \u0026status {\n            Ok(s) =\u003e {\n                total_files_imported += s.files_imported;\n                total_files_skipped += s.midi_files_found.saturating_sub(s.files_imported);\n                println!(\" Success: {} MIDIs found, {} imported\\n\", s.midi_files_found, s.files_imported);\n            }\n            Err(e) =\u003e {\n                total_errors += 1;\n                println!(\" Error: {}\\n\", e);\n            }\n        }\n\n        archive_statuses.push(status.unwrap_or_else(|e| ArchiveStatus {\n            archive_name: archive_name.clone(),\n            midi_files_found: 0,\n            files_imported: 0,\n            success: false,\n            error_message: Some(e),\n        }));\n    }\n\n    let duration = start_time.elapsed();\n    let duration_secs = duration.as_secs_f64();\n\n    println!(\"\\n\");\n    println!(\"      ARCHIVE COLLECTION IMPORT COMPLETE      \");\n    println!(\"\");\n    println!(\" Archives Processed: {:\u003e28} \", total_archives);\n    println!(\" Files Imported:     {:\u003e28} \", total_files_imported);\n    println!(\" Files Skipped:      {:\u003e28} \", total_files_skipped);\n    println!(\" Errors:             {:\u003e28} \", total_errors);\n    println!(\" Duration:           {:\u003e25.1}s \", duration_secs);\n    println!(\" Rate:               {:\u003e23.0} f/s \", total_files_imported as f64 / duration_secs);\n    println!(\"\\n\");\n\n    Ok(ArchiveImportSummary {\n        total_archives,\n        total_files_imported,\n        total_files_skipped,\n        total_errors,\n        duration_secs,\n        archives_processed: archive_statuses,\n    })\n}\n\n/// Process a single archive file\nasync fn process_single_archive(\n    archive_path: \u0026Path,\n    archive_name: \u0026str,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cArchiveStatus, String\u003e {\n    // Create temporary extraction directory\n    let temp_dir = std::env::temp_dir().join(format!(\"midi_extract_{}\", uuid::Uuid::new_v4()));\n    std::fs::create_dir_all(\u0026temp_dir)\n        .map_err(|e| format!(\"Failed to create temp directory: {}\", e))?;\n\n    // Extract with recursive decompression\n    println!(\"    Extracting (recursive, max depth 10)...\");\n    let config = ExtractionConfig::default(); // Uses max_depth: 10\n    let extract_result = extract_archive(archive_path, \u0026temp_dir, \u0026config)\n        .map_err(|e| format!(\"Extraction failed: {}\", e))?;\n\n    let midi_count = extract_result.midi_files.len();\n    println!(\"    Found {} MIDI files\", midi_count);\n\n    if midi_count == 0 {\n        // Cleanup and return\n        let _ = std::fs::remove_dir_all(\u0026temp_dir);\n        return Ok(ArchiveStatus {\n            archive_name: archive_name.to_string(),\n            midi_files_found: 0,\n            files_imported: 0,\n            success: true,\n            error_message: None,\n        });\n    }\n\n    // Import extracted files using existing import_directory command\n    println!(\"    Importing to database with auto-tagging...\");\n    let import_result = import_directory(\n        temp_dir.to_string_lossy().to_string(),\n        true, // recursive\n        Some(archive_name.trim_end_matches(\".zip\").to_string()), // category from archive name\n        state.clone(),\n        window.clone(),\n    ).await;\n\n    // Cleanup temp directory\n    let _ = std::fs::remove_dir_all(\u0026temp_dir);\n\n    match import_result {\n        Ok(summary) =\u003e {\n            Ok(ArchiveStatus {\n                archive_name: archive_name.to_string(),\n                midi_files_found: midi_count,\n                files_imported: summary.imported,\n                success: true,\n                error_message: None,\n            })\n        }\n        Err(e) =\u003e {\n            Err(format!(\"Import failed: {}\", e))\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","file_import.rs"],"content":"//! File Import Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION\n//!\n//! Architecture: Grown-up Script\n//! Purpose: Tauri commands for importing MIDI files with parallel processing\n//!\n//! This module integrates ALL optimizations:\n//! - BLAKE3 hashing (7x faster than SHA-256)\n//! - Parallel processing with buffer_unordered (40x speedup)\n//! - Batch database inserts (10x faster writes)\n//! - Dynamic concurrency tuning (optimal for any system)\n//!\n//! Performance Targets:\n//! - 1,000 files: \u003c 2 seconds\n//! - 10,000 files: ~25 seconds\n//! - 3,000,000 files: 1.5-2 hours (400-500 files/sec)\n\nuse crate::AppState;\nuse crate::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\nuse crate::core::analysis::auto_tagger::{AutoTagger, Tag};\nuse crate::core::performance::concurrency::{detect_system_resources, calculate_optimal_concurrency};\nuse crate::database::batch_insert::BatchInserter;\n\nuse serde::{Deserialize, Serialize};\nuse std::path::{Path, PathBuf};\nuse std::sync::Arc;\nuse tauri::{Emitter, State, Window};\nuse futures::stream::{self, StreamExt};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Progress event for real-time UI updates\n#[derive(Debug, Clone, Serialize)]\npub struct ImportProgress {\n    pub current: usize,\n    pub total: usize,\n    pub current_file: String,\n    pub rate: f64, // files per second\n}\n\n/// Summary of import operation results\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ImportSummary {\n    pub total_files: usize,\n    pub imported: usize,\n    pub skipped: usize,\n    pub errors: Vec\u003cString\u003e,\n    pub duration_secs: f64,\n    pub rate: f64, // files per second\n}\n\n/// File metadata returned from database\n#[derive(Debug, Clone, Serialize, sqlx::FromRow)]\npub struct FileMetadata {\n    pub id: i64,\n    pub filename: String,\n    pub original_filename: String,\n    pub filepath: String,\n    #[sqlx(rename = \"content_hash_hex\")]\n    pub content_hash: String, // Hex-encoded for JSON response\n    pub file_size_bytes: i64,\n    pub bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n}\n\n/// Intermediate structure for batch processing\n#[derive(Debug, Clone)]\nstruct ProcessedFile {\n    filename: String,\n    original_filename: String,\n    filepath: String,\n    parent_folder: Option\u003cString\u003e, // Parent directory name (e.g., \"bass\", \"drums\")\n    content_hash: Vec\u003cu8\u003e,\n    file_size_bytes: i64,\n    category: Option\u003cString\u003e, // Handled separately via file_categories table\n    bpm: Option\u003cf64\u003e,         // numeric(6,2) in DB\n    key_signature: Option\u003cString\u003e,\n    tags: Vec\u003cTag\u003e,           // Auto-extracted tags from filename, path, and MIDI content\n}\n\n//=============================================================================\n// TAURI COMMANDS (Thin Wrappers - Grown-up Script Pattern)\n//=============================================================================\n\n/// Import a single MIDI file\n///\n/// This is a thin wrapper that:\n/// 1. Validates the file path\n/// 2. Calls process_single_file (the actual logic)\n/// 3. Inserts to database and returns the result\n#[tauri::command]\npub async fn import_single_file(\n    file_path: String,\n    category: Option\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cFileMetadata, String\u003e {\n    let path = Path::new(\u0026file_path);\n\n    if !path.exists() {\n        return Err(format!(\"File not found: {}\", file_path));\n    }\n\n    if !is_midi_file(path) {\n        return Err(\"Not a MIDI file\".to_string());\n    }\n\n    // Process the file (calls Trusty Modules)\n    let processed = process_single_file(path, category.clone())\n        .await\n        .map_err(|e| format!(\"Failed to process file: {}\", e))?;\n\n    // Insert to database\n    let pool = state.database.pool().await;\n    let file_id = insert_single_file(\u0026processed, \u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to insert file: {}\", e))?;\n\n    // Retrieve the complete record\n    let file = sqlx::query_as::\u003c_, FileMetadata\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.original_filename,\n            f.filepath,\n            encode(f.content_hash, 'hex') as content_hash_hex,\n            f.file_size_bytes,\n            m.bpm,\n            m.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata m ON f.id = m.file_id\n        WHERE f.id = $1\n        \"#\n    )\n    .bind(file_id)\n    .fetch_one(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to retrieve file: {}\", e))?;\n\n    // Emit progress event\n    let _ = window.emit(\"import-progress\", ImportProgress {\n        current: 1,\n        total: 1,\n        current_file: file.filename.clone(),\n        rate: 1.0,\n    });\n\n    Ok(file)\n}\n\n/// Import all MIDI files from a directory (HIGH-PERFORMANCE PARALLEL VERSION)\n///\n/// This implementation integrates ALL optimizations:\n/// - Dynamic concurrency based on system resources\n/// - BLAKE3 hashing (7x faster)\n/// - Batch database inserts (10x faster)\n/// - Parallel processing with buffer_unordered\n/// - Progress updates throttled (every 10 files)\n/// - Semaphore to limit concurrency\n#[tauri::command]\npub async fn import_directory(\n    directory_path: String,\n    recursive: bool,\n    category: Option\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cImportSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let path = Path::new(\u0026directory_path);\n\n    if !path.exists() {\n        return Err(format!(\"Directory not found: {}\", directory_path));\n    }\n\n    // Collect all MIDI files\n    let files = if recursive {\n        find_midi_files_recursive(path)\n    } else {\n        find_midi_files_shallow(path)\n    }\n    .map_err(|e| format!(\"Error scanning directory: {}\", e))?;\n\n    let total = files.len();\n\n    if total == 0 {\n        return Ok(ImportSummary {\n            total_files: 0,\n            imported: 0,\n            skipped: 0,\n            errors: vec![],\n            duration_secs: 0.0,\n            rate: 0.0,\n        });\n    }\n\n    // OPTIMIZATION 1: Dynamic concurrency based on system resources\n    let resources = detect_system_resources();\n    let concurrency_limit = calculate_optimal_concurrency(\u0026resources);\n\n    println!(\" System resources detected:\");\n    println!(\"  CPU cores: {}\", resources.cpu_cores);\n    println!(\"  Available memory: {:.2} GB\", resources.available_memory_gb);\n    println!(\"  Optimal concurrency: {}\", concurrency_limit);\n\n    // Thread-safe counters for parallel processing\n    let imported = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // OPTIMIZATION 2: Batch inserter for database writes\n    let pool = state.database.pool().await;\n    let batch_inserter = Arc::new(BatchInserter::new(pool.clone(), 1000));\n    let processed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let category_clone = category.clone();\n    let total_clone = total;\n\n    //  PARALLEL PROCESSING WITH ALL OPTIMIZATIONS\n    stream::iter(files)\n        .map(|file_path| {\n            // Clone Arc pointers for each concurrent task\n            let sem = Arc::clone(\u0026semaphore);\n            let category = category_clone.clone();\n            let imported = Arc::clone(\u0026imported);\n            let skipped = Arc::clone(\u0026skipped);\n            let errors = Arc::clone(\u0026errors);\n            let current_index = Arc::clone(\u0026current_index);\n            let processed_files = Arc::clone(\u0026processed_files);\n            let batch_inserter = Arc::clone(\u0026batch_inserter);\n            let window = window.clone();\n\n            async move {\n                // Acquire semaphore permit (blocks if at limit)\n                // This should never fail unless semaphore is closed, which we never do\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        // Semaphore closed - skip this file (should never happen)\n                        eprintln!(\"Warning: Semaphore closed during file import\");\n                        return;\n                    }\n                };\n\n                let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Emit progress every 10 files (reduce UI spam)\n                if current % 10 == 0 || current == total_clone {\n                    let elapsed = start_time.elapsed().as_secs_f64();\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n\n                    let _ = window.emit(\"import-progress\", ImportProgress {\n                        current,\n                        total: total_clone,\n                        current_file: file_path.file_name()\n                            .and_then(|n| n.to_str())\n                            .unwrap_or(\"unknown\")\n                            .to_string(),\n                        rate,\n                    });\n                }\n\n                // OPTIMIZATION 3: Process file with BLAKE3 hashing\n                match process_single_file(\u0026file_path, category).await {\n                    Ok(processed) =\u003e {\n                        // Add to batch for insertion\n                        processed_files.lock().await.push(processed);\n                        imported.fetch_add(1, Ordering::SeqCst);\n\n                        // Flush batch if it reaches threshold\n                        let mut files = processed_files.lock().await;\n                        if files.len() \u003e= 100 {\n                            let batch: Vec\u003cProcessedFile\u003e = files.drain(..).collect();\n                            drop(files); // Release lock\n\n                            // Convert ProcessedFile to FileRecord for batch insert\n                            let file_records: Vec\u003ccrate::database::batch_insert::FileRecord\u003e = batch.iter().map(|f| {\n                                crate::database::batch_insert::FileRecord::new(\n                                    f.filename.clone(),\n                                    f.original_filename.clone(),\n                                    f.filepath.clone(),\n                                    f.parent_folder.clone(),\n                                    hex::encode(\u0026f.content_hash), // Convert bytea to hex string\n                                    f.file_size_bytes,\n                                    f.category.clone(),\n                                )\n                            }).collect();\n\n                            if let Err(e) = batch_inserter.insert_files_batch(file_records).await {\n                                errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                            }\n                        }\n                    }\n                    Err(e) =\u003e {\n                        let error_msg = format!(\"{}: {}\", file_path.display(), e);\n                        errors.lock().await.push(error_msg);\n                        skipped.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(concurrency_limit)  //  THE MAGIC: Process N files concurrently!\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // OPTIMIZATION 4: Flush remaining batch\n    let remaining_files = processed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cProcessedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files); // Release lock before async operation\n\n        // Convert ProcessedFile to FileRecord for batch insert\n        let file_records: Vec\u003ccrate::database::batch_insert::FileRecord\u003e = batch.iter().map(|f| {\n            crate::database::batch_insert::FileRecord::new(\n                f.filename.clone(),\n                f.original_filename.clone(),\n                f.filepath.clone(),\n                f.parent_folder.clone(),\n                hex::encode(\u0026f.content_hash), // Convert bytea to hex string\n                f.file_size_bytes,\n                f.category.clone(),\n            )\n        }).collect();\n\n        if let Err(e) = batch_inserter.insert_files_batch(file_records).await {\n            errors.lock().await.push(format!(\"Final batch insert failed: {}\", e));\n        }\n    }\n\n    // Calculate final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let imported_count = imported.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { imported_count as f64 / duration } else { 0.0 };\n\n    // Extract errors before creating summary\n    let error_list = errors.lock().await.clone();\n\n    Ok(ImportSummary {\n        total_files: total,\n        imported: imported_count,\n        skipped: skipped.load(Ordering::SeqCst),\n        errors: error_list,\n        duration_secs: duration,\n        rate,\n    })\n}\n\n//=============================================================================\n// CORE LOGIC (Grown-up Script - orchestrates Trusty Modules)\n//=============================================================================\n\n/// Process a single MIDI file and prepare for database insertion\n///\n/// This function orchestrates multiple Trusty Modules:\n/// - hash::blake3 (BLAKE3 hashing - 7x faster than SHA-256)\n/// - midi::parser (MIDI parsing)\n/// - analysis::bpm_detector (tempo detection)\n/// - analysis::key_detector (key signature detection)\n/// - analysis::auto_tagger (intelligent tag extraction)\n/// - naming::generator (filename generation)\nasync fn process_single_file(\n    file_path: \u0026Path,\n    category: Option\u003cString\u003e,\n) -\u003e Result\u003cProcessedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // 1. Generate BLAKE3 hash for deduplication (7x faster than SHA-256)\n    let hash_bytes = calculate_file_hash(file_path)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec(); // Convert [u8; 32] to Vec\u003cu8\u003e for bytea\n\n    // 2. Read file bytes\n    let file_bytes = tokio::fs::read(file_path).await?;\n\n    // 3. Parse MIDI file (Trusty Module)\n    let midi_data = parse_midi_file(\u0026file_bytes)?;\n\n    // 4. Extract parent folder name\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    // 5. Extract metadata (Trusty Modules)\n    let bpm_result = detect_bpm(\u0026midi_data);\n    let bpm = if bpm_result.confidence \u003e 0.5 {\n        Some(bpm_result.bpm) // Keep as f64 for numeric(6,2)\n    } else {\n        None\n    };\n\n    let key_result = detect_key(\u0026midi_data);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n\n    // 6. Get file info\n    let filename = file_path.file_name()\n        .and_then(|n| n.to_str())\n        .ok_or(\"Invalid filename\")?\n        .to_string();\n\n    let original_filename = filename.clone(); // Store original filename\n\n    let filepath = file_path.to_str()\n        .ok_or(\"Invalid file path\")?\n        .to_string();\n\n    let file_size_bytes = tokio::fs::metadata(file_path).await?.len() as i64;\n\n    // 7. Extract MIDI instruments for tag extraction\n    let midi_instruments = extract_instrument_names(\u0026midi_data);\n\n    // 8. Auto-tag extraction (NEW: intelligently extract tags from filename, path, and MIDI content)\n    let auto_tagger = AutoTagger::new()\n        .map_err(|e| format!(\"Failed to initialize auto-tagger: {}\", e))?;\n    let tags = auto_tagger.extract_tags(\n        \u0026filepath,\n        \u0026filename,\n        \u0026midi_instruments,\n        bpm,\n        key_signature.as_deref(),\n    );\n\n    Ok(ProcessedFile {\n        filename,\n        original_filename,\n        filepath,\n        parent_folder,\n        content_hash,\n        file_size_bytes,\n        category,\n        bpm,\n        key_signature,\n        tags,\n    })\n}\n\n/// Extract instrument names from MIDI file for tag extraction\nfn extract_instrument_names(midi: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e Vec\u003cString\u003e {\n    use midi_library_shared::core::midi::types::{Event, TextType};\n\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                // Extract track/instrument names from MIDI text events\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        instruments.push(text.clone());\n                    }\n                }\n                // Map MIDI program changes to GM instrument names\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        instruments.push(instrument_name);\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\n/// Map MIDI General MIDI program number to instrument name\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    // General MIDI Level 1 Sound Set\n    match program {\n        // Piano (0-7)\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        // Chromatic Percussion (8-15)\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        // Organ (16-23)\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        // Guitar (24-31)\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        // Bass (32-39)\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        // Strings (40-47)\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        // Ensemble (48-55)\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        // Brass (56-63)\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        // Reed (64-71)\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        // Pipe (72-79)\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        // Synth Lead (80-87)\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        // Synth Pad (88-95)\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        // Synth Effects (96-103)\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        // Ethnic (104-111)\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        // Percussive (112-119)\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        // Sound Effects (120-127)\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\n/// Insert a single file to database (used by single file import)\nasync fn insert_single_file(\n    file: \u0026ProcessedFile,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // Insert in transaction\n    let mut tx = pool.begin().await?;\n\n    // Insert file with ON CONFLICT to handle duplicates\n    let file_id_opt = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, 1, NOW())\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#\n    )\n    .bind(\u0026file.filename)\n    .bind(\u0026file.original_filename)\n    .bind(\u0026file.filepath)\n    .bind(\u0026file.content_hash)\n    .bind(file.file_size_bytes)\n    .fetch_optional(\u0026mut *tx)\n    .await?;\n\n    // If file already exists (conflict), return error\n    let file_id: i64 = match file_id_opt {\n        Some(id) =\u003e id,\n        None =\u003e {\n            tx.rollback().await?;\n            return Err(\"File already exists (duplicate hash)\".into());\n        }\n    };\n\n    // Insert musical metadata if available\n    if file.bpm.is_some() || file.key_signature.is_some() {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                key_signature,\n                time_signature_numerator,\n                time_signature_denominator\n            ) VALUES ($1, $2, $3::musical_key, 4, 4)\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                key_signature = EXCLUDED.key_signature\n            \"#\n        )\n        .bind(file_id)\n        .bind(file.bpm)\n        .bind(file.key_signature.as_deref())\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Handle category if provided\n    if let Some(ref category_name) = file.category {\n        // Get or create category\n        let category_id = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            INSERT INTO categories (name, created_at)\n            VALUES ($1, NOW())\n            ON CONFLICT (name) DO UPDATE SET name = EXCLUDED.name\n            RETURNING id\n            \"#\n        )\n        .bind(category_name)\n        .fetch_one(\u0026mut *tx)\n        .await?;\n\n        // Link file to category\n        sqlx::query(\n            r#\"\n            INSERT INTO file_categories (file_id, category_id)\n            VALUES ($1, $2)\n            ON CONFLICT DO NOTHING\n            \"#\n        )\n        .bind(file_id)\n        .bind(category_id)\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Insert auto-generated tags\n    if !file.tags.is_empty() {\n        // Prepare tag data (name, category)\n        let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = file\n            .tags\n            .iter()\n            .map(|tag| (tag.name.clone(), tag.category.clone()))\n            .collect();\n\n        // Create/get tags and insert file_tags associations\n        for (name, category) in tag_data {\n            // Get or create tag\n            let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n                r#\"\n                INSERT INTO tags (name, category, usage_count, created_at)\n                VALUES ($1, $2, 0, NOW())\n                ON CONFLICT (name) DO UPDATE\n                SET name = EXCLUDED.name\n                RETURNING id\n                \"#,\n            )\n            .bind(\u0026name)\n            .bind(category.as_deref())\n            .fetch_one(\u0026mut *tx)\n            .await?;\n\n            // Associate tag with file\n            sqlx::query(\n                r#\"\n                INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n                VALUES ($1, $2, NOW(), 'system')\n                ON CONFLICT (file_id, tag_id) DO NOTHING\n                \"#,\n            )\n            .bind(file_id)\n            .bind(tag_id)\n            .execute(\u0026mut *tx)\n            .await?;\n        }\n    }\n\n    tx.commit().await?;\n\n    Ok(file_id)\n}\n\n//=============================================================================\n// HELPER FUNCTIONS\n//=============================================================================\n\n/// Recursively collect all MIDI files in a directory\nfn find_midi_files_recursive(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e, std::io::Error\u003e {\n    let mut files = Vec::new();\n\n    for entry in std::fs::read_dir(dir)? {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_dir() {\n            match find_midi_files_recursive(\u0026path) {\n                Ok(subfiles) =\u003e files.extend(subfiles),\n                Err(e) =\u003e {\n                    eprintln!(\"Warning: Failed to read directory {}: {}\", path.display(), e);\n                    // Continue with other directories\n                }\n            }\n        } else if is_midi_file(\u0026path) {\n            files.push(path);\n        }\n    }\n\n    Ok(files)\n}\n\n/// Finds MIDI files in directory (non-recursive)\nfn find_midi_files_shallow(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e, std::io::Error\u003e {\n    let mut files = Vec::new();\n\n    for entry in std::fs::read_dir(dir)? {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_file() \u0026\u0026 is_midi_file(\u0026path) {\n            files.push(path);\n        }\n    }\n\n    Ok(files)\n}\n\n/// Check if a file is a MIDI file based on extension\nfn is_midi_file(path: \u0026Path) -\u003e bool {\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.eq_ignore_ascii_case(\"mid\") || ext.eq_ignore_ascii_case(\"midi\"))\n        .unwrap_or(false)\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_is_midi_file() {\n        assert!(is_midi_file(Path::new(\"test.mid\")));\n        assert!(is_midi_file(Path::new(\"test.MID\")));\n        assert!(is_midi_file(Path::new(\"test.midi\")));\n        assert!(is_midi_file(Path::new(\"test.MIDI\")));\n        assert!(!is_midi_file(Path::new(\"test.txt\")));\n        assert!(!is_midi_file(Path::new(\"test\")));\n    }\n\n    #[test]\n    fn test_find_midi_files_shallow() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let test_dir = temp_dir.path();\n\n        std::fs::write(test_dir.join(\"file1.mid\"), b\"\").unwrap();\n        std::fs::write(test_dir.join(\"file2.midi\"), b\"\").unwrap();\n        std::fs::write(test_dir.join(\"file3.txt\"), b\"\").unwrap();\n\n        let files = find_midi_files_shallow(test_dir).unwrap();\n        assert_eq!(files.len(), 2);\n    }\n\n    #[test]\n    fn test_find_midi_files_recursive() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let test_dir = temp_dir.path();\n        let sub_dir = test_dir.join(\"subdir\");\n        std::fs::create_dir(\u0026sub_dir).unwrap();\n\n        std::fs::write(test_dir.join(\"file1.mid\"), b\"\").unwrap();\n        std::fs::write(sub_dir.join(\"file2.mid\"), b\"\").unwrap();\n\n        let files = find_midi_files_recursive(test_dir).unwrap();\n        assert_eq!(files.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_auto_tagging_import() {\n        println!(\"\\n Starting auto-tagging integration test...\");\n\n        // 1. Connect to test database\n        let database_url = \"postgresql://midiuser:145278963@localhost:5433/midi_library\";\n        let pool = match sqlx::PgPool::connect(database_url).await {\n            Ok(pool) =\u003e {\n                println!(\" Connected to database\");\n                pool\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to connect to database: {:?}\", e);\n            }\n        };\n\n        // 2. Verify test file exists\n        let test_file_path = std::path::Path::new(\"/tmp/midi_test_import/Vengeance_Deep_House_Kick_128_C.mid\");\n        if !test_file_path.exists() {\n            panic!(\" Test file not found: {:?}\", test_file_path);\n        }\n        println!(\" Test file found: {:?}\", test_file_path);\n\n        // 3. Process the file (extracts tags)\n        println!(\" Processing file...\");\n        let processed = match process_single_file(test_file_path, Some(\"test\".to_string())).await {\n            Ok(p) =\u003e {\n                println!(\" File processed successfully\");\n                println!(\"   Filename: {}\", p.filename);\n                println!(\"   Tags extracted: {}\", p.tags.len());\n                for tag in \u0026p.tags {\n                    match \u0026tag.category {\n                        Some(cat) =\u003e println!(\"     - {}:{}\", cat, tag.name),\n                        None =\u003e println!(\"     - {}\", tag.name),\n                    }\n                }\n                p\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to process file: {:?}\", e);\n            }\n        };\n\n        // 4. Insert into database (including tags)\n        println!(\" Inserting into database...\");\n        let file_id = match insert_single_file(\u0026processed, \u0026pool).await {\n            Ok(id) =\u003e {\n                println!(\" File inserted with ID: {}\", id);\n                id\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to insert file: {:?}\", e);\n            }\n        };\n\n        // 5. Verify tags were stored in database\n        println!(\" Verifying tags in database...\");\n        let tags: Vec\u003c(String, Option\u003cString\u003e)\u003e = sqlx::query_as(\n            r#\"\n            SELECT t.name, t.category\n            FROM tags t\n            JOIN file_tags ft ON t.id = ft.tag_id\n            WHERE ft.file_id = $1\n            ORDER BY t.category, t.name\n            \"#\n        )\n        .bind(file_id)\n        .fetch_all(\u0026pool)\n        .await\n        .expect(\"Failed to fetch tags from database\");\n\n        println!(\" Tags found in database: {}\", tags.len());\n        for (name, category) in \u0026tags {\n            match category {\n                Some(cat) =\u003e println!(\"     - {}:{}\", cat, name),\n                None =\u003e println!(\"     - {}\", name),\n            }\n        }\n\n        // 6. Verify expected tags exist\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|(name, cat)| {\n            match cat {\n                Some(c) =\u003e format!(\"{}:{}\", c, name),\n                None =\u003e name.clone(),\n            }\n        }).collect();\n\n        println!(\"\\n Checking for expected tags...\");\n\n        // Check for \"vengeance\" tag (should be brand:vengeance or just vengeance)\n        let has_vengeance = tag_names.iter().any(|t| t.to_lowercase().contains(\"vengeance\"));\n        assert!(has_vengeance, \" Missing 'vengeance' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found vengeance tag\");\n\n        // Check for \"house\" tag (should be genre:house or just house)\n        let has_house = tag_names.iter().any(|t| t.to_lowercase().contains(\"house\"));\n        assert!(has_house, \" Missing 'house' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found house tag\");\n\n        // Check for \"kick\" tag (should be instrument:kick or category:kick)\n        let has_kick = tag_names.iter().any(|t| t.to_lowercase().contains(\"kick\"));\n        assert!(has_kick, \" Missing 'kick' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found kick tag\");\n\n        // Check for BPM tag\n        let has_bpm = tag_names.iter().any(|t| t.contains(\"bpm:\") || t.contains(\"128\"));\n        assert!(has_bpm, \" Missing BPM tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found BPM tag\");\n\n        // Check for key tag\n        let has_key = tag_names.iter().any(|t| t.to_lowercase().contains(\"key:\") || t.to_lowercase().contains(\":c\"));\n        assert!(has_key, \" Missing key tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found key tag\");\n\n        println!(\"\\n   ALL AUTO-TAGGING TESTS PASSED!   \\n\");\n\n        // Cleanup: Remove test file from database\n        sqlx::query(\"DELETE FROM files WHERE id = $1\")\n            .bind(file_id)\n            .execute(\u0026pool)\n            .await\n            .expect(\"Failed to cleanup test file\");\n        println!(\" Cleaned up test data\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","files.rs"],"content":"// src-tauri/src/commands/files.rs\n//\n// ARCHETYPE: MANAGER (Grown-up Script)\n// PURPOSE: Tauri commands for file operations with database I/O\n//\n//  CAN: Perform database I/O (queries)\n//  CAN: Have side effects (database reads/writes)\n//  CAN: Be async\n//  SHOULD: Handle errors using AppError\n//  MUST NOT: Contain complex business logic\n//  MUST NOT: Have UI concerns\n//  SHOULD: Delegate complex logic to separate modules\n\nuse chrono::{DateTime, Utc};\nuse serde::Serialize;\nuse sqlx::FromRow;\nuse tauri::State;\n\nuse crate::AppState;\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// MIDI file record with musical metadata\n///\n/// Combined data from files and musical_metadata tables.\n/// Used for displaying file information in the UI.\n///\n/// # Archetype: Trusty Module (data structure)\n///\n/// This is a pure data container with no behavior.\n#[derive(Debug, FromRow, Serialize)]\npub struct MidiFile {\n    /// Unique file ID\n    pub id: i64,\n\n    /// Display filename (e.g., \"my-song.mid\")\n    pub filename: String,\n\n    /// Full path to file (e.g., \"/library/bass/my-song.mid\")\n    pub filepath: String,\n\n    /// Original filename before processing\n    #[serde(rename = \"originalFilename\")]\n    pub original_filename: String,\n\n    /// Primary category (e.g., \"BASS\", \"LEAD\")\n    pub category: String,\n\n    /// Parent folder name (e.g., \"bass\", \"drums\", \"leads\")\n    #[serde(rename = \"parentFolder\")]\n    pub parent_folder: Option\u003cString\u003e,\n\n    /// File size in bytes\n    #[serde(rename = \"fileSize\")]\n    pub file_size: i64,\n\n    /// Detected BPM (nullable)\n    pub bpm: Option\u003cf64\u003e,\n\n    /// Detected key signature (nullable, e.g., \"C\", \"Am\")\n    #[serde(rename = \"key\")]\n    pub key_signature: Option\u003cString\u003e,\n\n    /// Duration in seconds (nullable)\n    #[serde(rename = \"duration\")]\n    pub duration_seconds: Option\u003cf64\u003e,\n\n    /// Timestamp when file was added to database\n    #[serde(rename = \"createdAt\")]\n    pub created_at: DateTime\u003cUtc\u003e,\n\n    /// Timestamp when file was last updated\n    #[serde(rename = \"updatedAt\")]\n    pub updated_at: DateTime\u003cUtc\u003e,\n}\n\n// =============================================================================\n// TAURI COMMANDS - MANAGER ARCHETYPE\n// =============================================================================\n\n/// Test database connection\n///\n/// Verifies that the database is reachable and responds to queries.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (network call to database)\n/// -  Handles errors properly (converts to String)\n/// -  No complex business logic\n///\n/// # Returns\n///\n/// * `Result\u003cbool, String\u003e` - True if connected, error message if failed\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const connected = await invoke\u003cboolean\u003e('test_db_connection');\n/// if (connected) {\n///   console.log('Database is ready');\n/// }\n/// ```\n#[tauri::command]\npub async fn test_db_connection(state: State\u003c'_, AppState\u003e) -\u003e Result\u003cbool, String\u003e {\n    state\n        .database\n        .test_connection()\n        .await\n        .map_err(|e| format!(\"Database connection failed: {}\", e))\n}\n\n/// Get total count of files in database\n///\n/// Returns the number of MIDI files currently stored.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n/// -  No complex business logic\n///\n/// # Returns\n///\n/// * `Result\u003ci64, String\u003e` - Total file count or error message\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_file_count');\n/// console.log(`Library contains ${count} files`);\n/// ```\n#[tauri::command]\npub async fn get_file_count(state: State\u003c'_, AppState\u003e) -\u003e Result\u003ci64, String\u003e {\n    let pool = state.database.pool().await;\n    let count: i64 = sqlx::query_scalar(\"SELECT COUNT(*) FROM files\")\n        .fetch_one(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to get file count: {}\", e))?;\n\n    Ok(count)\n}\n\n/// Get file details by ID\n///\n/// Retrieves complete information for a single MIDI file.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly (including NotFound)\n/// -  No complex business logic\n///\n/// # Arguments\n///\n/// * `file_id` - Unique file ID to retrieve\n///\n/// # Returns\n///\n/// * `Result\u003cMidiFile, String\u003e` - File details or error message\n///\n/// # Errors\n///\n/// Returns error if file doesn't exist or query fails.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const file = await invoke\u003cMidiFile\u003e('get_file_details', { fileId: 123 });\n/// console.log(`File: ${file.filename}, BPM: ${file.bpm}`);\n/// ```\n#[tauri::command]\npub async fn get_file_details(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cMidiFile, String\u003e {\n    let pool = state.database.pool().await;\n    let file = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id = $1\n        \"#,\n    )\n    .bind(file_id)\n    .fetch_optional(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to fetch file details: {}\", e))?\n    .ok_or_else(|| format!(\"File with ID {} not found\", file_id))?;\n\n    Ok(file)\n}\n\n/// Get file by ID (alias for get_file_details for frontend compatibility)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const file = await invoke\u003cMidiFile\u003e('get_file', { fileId: 123 });\n/// ```\n#[tauri::command]\npub async fn get_file(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cMidiFile, String\u003e {\n    get_file_details(file_id, state).await\n}\n\n/// List files with pagination\n///\n/// Returns a paginated list of files ordered by creation date (newest first).\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n///\n/// # Arguments\n///\n/// * `limit` - Maximum number of files to return (default: 50)\n/// * `offset` - Number of files to skip (default: 0)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('list_files', { limit: 50, offset: 0 });\n/// ```\n#[tauri::command]\npub async fn list_files(\n    limit: Option\u003ci64\u003e,\n    offset: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(50);\n    let offset = offset.unwrap_or(0);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY f.created_at DESC\n        LIMIT $1 OFFSET $2\n        \"#,\n    )\n    .bind(limit)\n    .bind(offset)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to list files: {}\", e))?;\n\n    // Debug logging\n    tracing::info!(\n        \"list_files: Returning {} files, first file parent_folder: {:?}\",\n        files.len(),\n        files.first().map(|f| \u0026f.parent_folder)\n    );\n\n    Ok(files)\n}\n\n/// Get files by category\n///\n/// Returns all files in a specific category.\n///\n/// # Arguments\n///\n/// * `category` - Category name (e.g., \"bass\", \"drums\", \"melody\")\n/// * `limit` - Maximum number of files to return (default: 50)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('get_files_by_category', {\n///   category: 'bass',\n///   limit: 50\n/// });\n/// ```\n#[tauri::command]\npub async fn get_files_by_category(\n    category: String,\n    limit: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(50);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE fc.primary_category::text = $1\n        ORDER BY f.created_at DESC\n        LIMIT $2\n        \"#,\n    )\n    .bind(category)\n    .bind(limit)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get files by category: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Get recently added files\n///\n/// Returns the most recently imported files.\n///\n/// # Arguments\n///\n/// * `limit` - Maximum number of files to return (default: 10)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('get_recent_files', { limit: 10 });\n/// ```\n#[tauri::command]\npub async fn get_recent_files(\n    limit: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(10);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY f.created_at DESC\n        LIMIT $1\n        \"#,\n    )\n    .bind(limit)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get recent files: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Delete a file\n///\n/// Removes a file from the database (cascading deletes related records).\n///\n/// # Arguments\n///\n/// * `file_id` - ID of the file to delete\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// await invoke('delete_file', { fileId: 123 });\n/// ```\n#[tauri::command]\npub async fn delete_file(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    sqlx::query(\"DELETE FROM files WHERE id = $1\")\n        .bind(file_id)\n        .execute(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to delete file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Update file tags\n///\n// update_file_tags moved to commands/tags.rs to use TagRepository\n\n// =============================================================================\n// TESTS - MANAGER ARCHETYPE TESTING\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    /// Test that MidiFile struct has all required fields\n    #[test]\n    fn test_midi_file_struct() {\n        let now = Utc::now();\n        let file = MidiFile {\n            id: 1,\n            filename: \"test.mid\".to_string(),\n            filepath: \"/path/to/test.mid\".to_string(),\n            original_filename: \"original_test.mid\".to_string(),\n            category: \"DRUMS\".to_string(),\n            parent_folder: Some(\"drums\".to_string()),\n            file_size: 1024,\n            bpm: Some(120.0),\n            key_signature: Some(\"Cm\".to_string()),\n            duration_seconds: Some(180.0),\n            created_at: now,\n            updated_at: now,\n        };\n\n        assert_eq!(file.id, 1);\n        assert_eq!(file.filename, \"test.mid\");\n        assert_eq!(file.bpm, Some(120.0));\n        assert_eq!(file.key_signature, Some(\"Cm\".to_string()));\n    }\n\n    // NOTE: Advanced search functionality is in commands/search.rs\n\n    // Integration tests require database connection and Tauri runtime\n    // These tests should be run as part of E2E testing, not unit tests\n    // For manual testing:\n    // 1. Start database: docker-compose up -d\n    // 2. Run the Tauri app and test commands from the frontend\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","mod.rs"],"content":"//! Tauri command handlers\n//!\n//! All commands are Grown-up Scripts:\n//! - Perform I/O (file system, database, network)\n//! - Delegate business logic to Trusty Modules\n//! - Handle errors and convert to frontend-friendly format\n//! - Provide progress updates for long-running operations\n\npub mod analyze;\npub mod archive_import;\npub mod files;\npub mod file_import;\npub mod progress;\npub mod search;\npub mod split_file;\npub mod stats;\npub mod system;\npub mod tags;\n\n// Re-export commonly used split types\npub use split_file::{split_and_import, SplitResult};\n\n// Re-export analysis command\npub use analyze::start_analysis;\n\n// Future command modules:\n// pub mod playback;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","progress.rs"],"content":"// ARCHETYPE: MANAGER (Grown-up Script)\n// Purpose: Track import progress and emit real-time updates to frontend\n// Side effects: Emits Tauri events, manages mutable state\n\nuse serde::{Deserialize, Serialize};\nuse std::sync::{Arc, Mutex};\nuse tauri::{AppHandle, Emitter, State};\n\n/// Progress state for file import operations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProgressState {\n    pub current_file: String,\n    pub current_index: usize,\n    pub total_files: usize,\n    pub percentage: f64,\n    pub phase: String,\n    pub files_per_second: f64,\n    pub errors_count: usize,\n    pub duplicates_found: usize,\n    pub estimated_time_remaining: f64,\n}\n\nimpl Default for ProgressState {\n    fn default() -\u003e Self {\n        Self {\n            current_file: String::new(),\n            current_index: 0,\n            total_files: 0,\n            percentage: 0.0,\n            phase: \"idle\".to_string(),\n            files_per_second: 0.0,\n            errors_count: 0,\n            duplicates_found: 0,\n            estimated_time_remaining: 0.0,\n        }\n    }\n}\n\n/// Thread-safe progress tracker\n#[derive(Clone)]\npub struct ProgressTracker {\n    state: Arc\u003cMutex\u003cProgressState\u003e\u003e,\n    start_time: Arc\u003cMutex\u003cOption\u003cstd::time::Instant\u003e\u003e\u003e,\n}\n\nimpl ProgressTracker {\n    pub fn new() -\u003e Self {\n        Self {\n            state: Arc::new(Mutex::new(ProgressState::default())),\n            start_time: Arc::new(Mutex::new(None)),\n        }\n    }\n\n    /// Get current progress state\n    pub fn get_state(\u0026self) -\u003e ProgressState {\n        self.state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner())\n            .clone()\n    }\n\n    /// Update state and return the new state\n    fn update_state\u003cF\u003e(\u0026self, updater: F) -\u003e ProgressState\n    where\n        F: FnOnce(\u0026mut ProgressState),\n    {\n        let mut state = self\n            .state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n        updater(\u0026mut state);\n        state.clone()\n    }\n\n    /// Calculate metrics based on current progress\n    fn calculate_metrics(\u0026self, current_index: usize, total_files: usize) -\u003e (f64, f64) {\n        let start_time = self\n            .start_time\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n\n        if let Some(start) = *start_time {\n            let elapsed = start.elapsed().as_secs_f64();\n\n            if elapsed \u003e 0.0 \u0026\u0026 current_index \u003e 0 {\n                let files_per_second = current_index as f64 / elapsed;\n                let remaining_files = total_files.saturating_sub(current_index);\n                let estimated_time_remaining = if files_per_second \u003e 0.0 {\n                    remaining_files as f64 / files_per_second\n                } else {\n                    0.0\n                };\n\n                return (files_per_second, estimated_time_remaining);\n            }\n        }\n\n        (0.0, 0.0)\n    }\n}\n\nimpl Default for ProgressTracker {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Start progress tracking for a new import operation\n#[tauri::command]\npub async fn start_progress_tracking(\n    total: usize,\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    // Reset start time\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = Some(std::time::Instant::now());\n\n    // Initialize state\n    let state = tracker.update_state(|s| {\n        s.current_file = String::new();\n        s.current_index = 0;\n        s.total_files = total;\n        s.percentage = 0.0;\n        s.phase = \"scanning\".to_string();\n        s.files_per_second = 0.0;\n        s.errors_count = 0;\n        s.duplicates_found = 0;\n        s.estimated_time_remaining = 0.0;\n    });\n\n    // Emit initial state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Update progress with current file and phase\n#[tauri::command]\npub async fn update_progress(\n    current: usize,\n    file: String,\n    phase: String,\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let total = {\n        let state = tracker\n            .state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n        state.total_files\n    };\n\n    // Calculate metrics\n    let (files_per_second, estimated_time_remaining) =\n        tracker.calculate_metrics(current, total);\n\n    // Update state\n    let state = tracker.update_state(|s| {\n        s.current_file = file;\n        s.current_index = current;\n        s.phase = phase;\n        s.percentage = if total \u003e 0 {\n            (current as f64 / total as f64) * 100.0\n        } else {\n            0.0\n        };\n        s.files_per_second = files_per_second;\n        s.estimated_time_remaining = estimated_time_remaining;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Mark an error during processing\n#[tauri::command]\npub async fn increment_error_count(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.errors_count += 1;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Mark a duplicate file found\n#[tauri::command]\npub async fn increment_duplicate_count(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.duplicates_found += 1;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Complete progress tracking\n#[tauri::command]\npub async fn complete_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.percentage = 100.0;\n        s.phase = \"complete\".to_string();\n        s.estimated_time_remaining = 0.0;\n    });\n\n    // Emit final state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    // Reset start time\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = None;\n\n    Ok(())\n}\n\n/// Get current progress state (for polling if needed)\n#[tauri::command]\npub async fn get_current_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n) -\u003e Result\u003cProgressState, String\u003e {\n    Ok(tracker.get_state())\n}\n\n/// Reset progress to idle state\n#[tauri::command]\npub async fn reset_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = None;\n\n    let state = tracker.update_state(|s| {\n        *s = ProgressState::default();\n    });\n\n    // Emit reset state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_progress_state_default() {\n        let state = ProgressState::default();\n        assert_eq!(state.current_index, 0);\n        assert_eq!(state.total_files, 0);\n        assert_eq!(state.percentage, 0.0);\n        assert_eq!(state.phase, \"idle\");\n    }\n\n    #[test]\n    fn test_progress_tracker_new() {\n        let tracker = ProgressTracker::new();\n        let state = tracker.get_state();\n        assert_eq!(state.current_index, 0);\n        assert_eq!(state.total_files, 0);\n    }\n\n    #[test]\n    fn test_progress_tracker_update() {\n        let tracker = ProgressTracker::new();\n\n        // Simulate starting tracking\n        *tracker.start_time.lock().unwrap() = Some(std::time::Instant::now());\n\n        let state = tracker.update_state(|s| {\n            s.total_files = 100;\n            s.current_index = 50;\n            s.phase = \"analyzing\".to_string();\n            s.percentage = 50.0;\n        });\n\n        assert_eq!(state.total_files, 100);\n        assert_eq!(state.current_index, 50);\n        assert_eq!(state.phase, \"analyzing\");\n        assert_eq!(state.percentage, 50.0);\n    }\n\n    #[test]\n    fn test_calculate_metrics() {\n        let tracker = ProgressTracker::new();\n\n        // Before start time is set\n        let (fps, eta) = tracker.calculate_metrics(10, 100);\n        assert_eq!(fps, 0.0);\n        assert_eq!(eta, 0.0);\n\n        // After start time is set\n        *tracker.start_time.lock().unwrap() = Some(std::time::Instant::now());\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let (fps, eta) = tracker.calculate_metrics(10, 100);\n        assert!(fps \u003e 0.0); // Should be processing files\n        assert!(eta \u003e 0.0); // Should have estimated time\n    }\n}\n","traces":[{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":5},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","search.rs"],"content":"//! Search command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: Advanced search functionality with filters and pagination\n//! ARCHETYPE: Grown-up Script (I/O operations, reusable logic)\n//!\n//!  CAN: Perform database I/O\n//!  CAN: Have side effects (complex queries)\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic (delegate to Trusty Modules)\n\nuse crate::AppState;\nuse tauri::State;\nuse serde::{Deserialize, Serialize};\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// Search filters from frontend\n#[derive(Debug, Clone, Deserialize)]\npub struct SearchFilters {\n    pub category: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n}\n\n/// Search result item (simplified for list view)\n///\n/// Note: NUMERIC columns are cast to float8 in SQL queries for simplicity\n#[derive(Debug, Clone, Serialize, sqlx::FromRow)]\npub struct SearchResultItem {\n    pub id: i64,\n    pub filename: String,\n    pub filepath: String,\n    pub bpm: Option\u003cf64\u003e,  // Cast from NUMERIC in SQL\n    pub key_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,  // Cast from NUMERIC in SQL\n    pub category: Option\u003cString\u003e,\n}\n\n/// Paginated search results\n#[derive(Debug, Serialize)]\npub struct SearchResults {\n    pub items: Vec\u003cSearchResultItem\u003e,\n    pub total_count: i64,\n    pub page: i32,\n    pub page_size: i32,\n    pub total_pages: i32,\n}\n\n// =============================================================================\n// HELPER FUNCTIONS\n// =============================================================================\n\n/// Count search results for pagination\nasync fn count_search_results(\n    query: \u0026str,\n    filters: \u0026SearchFilters,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, sqlx::Error\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE\n            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')\n            AND ($2::text IS NULL OR fc.primary_category::text = $2)\n            AND ($3::float8 IS NULL OR mm.bpm \u003e= $3)\n            AND ($4::float8 IS NULL OR mm.bpm \u003c= $4)\n            AND ($5::text IS NULL OR mm.key_signature::text = $5)\n        \"#\n    )\n    .bind(query)\n    .bind(\u0026filters.category)\n    .bind(filters.min_bpm)\n    .bind(filters.max_bpm)\n    .bind(\u0026filters.key_signature)\n    .fetch_one(pool)\n    .await?;\n\n    Ok(count.0)\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Search files with filters and pagination\n///\n/// # Manager Archetype\n/// -  Performs I/O (complex database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n///\n/// # Arguments\n///\n/// * `query` - Text search query (searches filename and filepath)\n/// * `filters` - Search filters (category, BPM range, key)\n/// * `page` - Page number (1-indexed)\n/// * `page_size` - Items per page (1-100)\n///\n/// # Returns\n///\n/// Paginated search results with total count\n#[tauri::command]\npub async fn search_files(\n    query: String,\n    filters: SearchFilters,\n    page: i32,\n    page_size: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cSearchResults, String\u003e {\n    let pool = state.database.pool().await;\n\n    // Validate pagination\n    if page \u003c 1 {\n        return Err(\"Page must be \u003e= 1\".to_string());\n    }\n    if page_size \u003c 1 || page_size \u003e 100 {\n        return Err(\"Page size must be between 1 and 100\".to_string());\n    }\n\n    // Calculate offset\n    let offset = (page - 1) * page_size;\n\n    // Query with correct column names from schema\n    let items = sqlx::query_as::\u003c_, SearchResultItem\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            mm.bpm::float8 as bpm,\n            mm.key_signature::text as key_signature,\n            f.duration_seconds::float8 as duration_seconds,\n            fc.primary_category::text as category\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE\n            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')\n            AND ($2::text IS NULL OR fc.primary_category::text = $2)\n            AND ($3::float8 IS NULL OR mm.bpm \u003e= $3)\n            AND ($4::float8 IS NULL OR mm.bpm \u003c= $4)\n            AND ($5::text IS NULL OR mm.key_signature::text = $5)\n        ORDER BY f.created_at DESC\n        LIMIT $6 OFFSET $7\n        \"#\n    )\n    .bind(\u0026query)\n    .bind(\u0026filters.category)\n    .bind(filters.min_bpm)\n    .bind(filters.max_bpm)\n    .bind(\u0026filters.key_signature)\n    .bind(page_size as i64)\n    .bind(offset as i64)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Search error: {}\", e))?;\n\n    let total_count = count_search_results(\u0026query, \u0026filters, \u0026pool)\n        .await\n        .map_err(|e| format!(\"Count error: {}\", e))?;\n\n    Ok(SearchResults {\n        items,\n        total_count,\n        page,\n        page_size,\n        total_pages: ((total_count as f64) / (page_size as f64)).ceil() as i32,\n    })\n}\n\n/// Get all unique tags from database\n///\n/// Returns a list of all unique tag names used in the database.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const tags = await invoke\u003cstring[]\u003e('get_all_tags');\n/// ```\n#[tauri::command]\npub async fn get_all_tags(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let tags: Vec\u003c(String,)\u003e = sqlx::query_as(\n        r#\"\n        SELECT DISTINCT tag_name\n        FROM file_tags\n        ORDER BY tag_name ASC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(|(tag,)| tag).collect())\n}\n\n/// Get files by tag\n///\n/// Returns all files that have a specific tag.\n///\n/// # Arguments\n///\n/// * `tag` - Tag name to filter by\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cFileMetadata[]\u003e('get_files_by_tag', { tag: 'ambient' });\n/// ```\n#[tauri::command]\npub async fn get_files_by_tag(\n    tag: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cSearchResultItem\u003e, String\u003e {\n    let files = sqlx::query_as::\u003c_, SearchResultItem\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            mm.bpm::float8 as bpm,\n            mm.key_signature::text as key_signature,\n            f.duration_seconds::float8 as duration_seconds,\n            fc.primary_category::text as category\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        INNER JOIN file_tags ft ON f.id = ft.file_id\n        WHERE ft.tag_name = $1\n        ORDER BY f.created_at DESC\n        \"#\n    )\n    .bind(tag)\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get files by tag: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Get BPM range from database\n///\n/// Returns the minimum and maximum BPM values in the database.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const range = await invoke\u003c{min: number, max: number}\u003e('get_bpm_range');\n/// ```\n#[tauri::command]\npub async fn get_bpm_range(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cBpmRange, String\u003e {\n    let pool = state.database.pool().await;\n    let result: Option\u003c(Option\u003cf64\u003e, Option\u003cf64\u003e)\u003e = sqlx::query_as(\n        r#\"\n        SELECT MIN(bpm)::float8, MAX(bpm)::float8\n        FROM musical_metadata\n        WHERE bpm IS NOT NULL\n        \"#\n    )\n    .fetch_optional(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get BPM range: {}\", e))?;\n\n    match result {\n        Some((Some(min), Some(max))) =\u003e Ok(BpmRange { min, max }),\n        _ =\u003e Ok(BpmRange { min: 0.0, max: 300.0 }), // Default range if no data\n    }\n}\n\n/// Get all unique key signatures from database\n///\n/// Returns a list of all unique key signatures.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const keys = await invoke\u003cstring[]\u003e('get_all_keys');\n/// ```\n#[tauri::command]\npub async fn get_all_keys(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let keys: Vec\u003c(String,)\u003e = sqlx::query_as(\n        r#\"\n        SELECT DISTINCT key_signature::text\n        FROM musical_metadata\n        WHERE key_signature IS NOT NULL\n        ORDER BY key_signature ASC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get keys: {}\", e))?;\n\n    Ok(keys.into_iter().map(|(key,)| key).collect())\n}\n\n/// BPM range response\n#[derive(Debug, Serialize)]\npub struct BpmRange {\n    pub min: f64,\n    pub max: f64,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","split_file.rs"],"content":"//! Track Splitting Commands - GROWN-UP SCRIPT\n//!\n//! Architecture: Grown-up Script\n//! Purpose: I/O wrapper around track_splitter Trusty Module\n//!\n//! This module provides Tauri commands for splitting multi-track MIDI files\n//! into individual single-track files. It handles:\n//! - Database queries (fetch file info)\n//! - File I/O (read original, write splits)\n//! - Database transactions (insert splits, create relationships)\n//! - Error handling and user-friendly messages\n//!\n//! The actual splitting logic is delegated to the track_splitter Trusty Module,\n//! which operates on byte arrays with no I/O.\n\nuse crate::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\nuse crate::core::splitting::track_splitter::{split_tracks, SplitTrack, SplitError};\nuse serde::{Deserialize, Serialize};\nuse std::path::{Path, PathBuf};\nuse thiserror::Error;\n\n//=============================================================================\n// ERROR TYPES\n//=============================================================================\n\n/// Errors that can occur during split and import operations\n#[derive(Error, Debug)]\npub enum SplitCommandError {\n    #[error(\"File not found in database: {0}\")]\n    FileNotFound(i64),\n\n    #[error(\"File not found on disk: {0}\")]\n    FileNotFoundOnDisk(String),\n\n    #[error(\"Failed to read file: {0}\")]\n    IoError(#[from] std::io::Error),\n\n    #[error(\"Failed to split tracks: {0}\")]\n    SplitError(#[from] SplitError),\n\n    #[error(\"Database error: {0}\")]\n    DatabaseError(String),\n\n    #[error(\"Failed to create output directory: {0}\")]\n    DirectoryCreationError(String),\n\n    #[error(\"Transaction failed: {0}\")]\n    TransactionError(String),\n}\n\n// Convert to user-friendly string for Tauri commands\nimpl From\u003cSplitCommandError\u003e for String {\n    fn from(err: SplitCommandError) -\u003e String {\n        err.to_string()\n    }\n}\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Result of a successful split operation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SplitResult {\n    /// IDs of the newly created split files in the database\n    pub split_file_ids: Vec\u003ci64\u003e,\n\n    /// Number of tracks that were split\n    pub tracks_split: usize,\n\n    /// Directory where split files were written\n    pub output_dir: PathBuf,\n}\n\n//=============================================================================\n// PUBLIC API (Grown-up Script Pattern)\n//=============================================================================\n\n/// Split a multi-track MIDI file and import each track as a separate file.\n///\n/// This is the main entry point for track splitting operations. It:\n/// 1. Queries the database for the original file's info\n/// 2. Reads the original MIDI file from disk\n/// 3. Calls the track_splitter Trusty Module to split tracks\n/// 4. Creates output directory\n/// 5. For each split track:\n///    - Generates filename based on track metadata\n///    - Writes MIDI bytes to disk\n///    - Imports to database with full metadata\n///    - Creates relationship in track_splits table\n/// 6. Returns list of created file IDs\n///\n/// # Arguments\n///\n/// * `file_id` - Database ID of the parent file to split\n/// * `output_dir` - Directory where split files will be written\n/// * `pool` - Database connection pool\n///\n/// # Returns\n///\n/// `SplitResult` containing IDs of created files and statistics\n///\n/// # Errors\n///\n/// Returns error if:\n/// - File not found in database\n/// - File not found on disk\n/// - Failed to read/parse MIDI file\n/// - Failed to split tracks (e.g., only tempo track)\n/// - Failed to create output directory\n/// - Database transaction fails\n///\n/// # Examples\n///\n/// ```no_run\n/// use pipeline::commands::split_file::split_and_import;\n/// use std::path::PathBuf;\n///\n/// # async fn example(pool: sqlx::PgPool) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n/// let result = split_and_import(\n///     42,\n///     PathBuf::from(\"/output/splits\"),\n///     \u0026pool\n/// ).await?;\n///\n/// println!(\"Split {} tracks into {} files\",\n///     result.tracks_split,\n///     result.split_file_ids.len()\n/// );\n/// # Ok(())\n/// # }\n/// ```\npub async fn split_and_import(\n    file_id: i64,\n    output_dir: PathBuf,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003cSplitResult, SplitCommandError\u003e {\n    // 1. Query database for parent file info\n    let parent_file = sqlx::query!(\n        r#\"\n        SELECT id, filename, original_filename, filepath\n        FROM files\n        WHERE id = $1\n        \"#,\n        file_id\n    )\n    .fetch_optional(pool)\n    .await\n    .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?\n    .ok_or(SplitCommandError::FileNotFound(file_id))?;\n\n    // 2. Read original file from disk\n    let file_path = Path::new(\u0026parent_file.filepath);\n    if !file_path.exists() {\n        return Err(SplitCommandError::FileNotFoundOnDisk(\n            parent_file.filepath.clone(),\n        ));\n    }\n\n    let original_bytes = tokio::fs::read(file_path).await?;\n\n    // 3. Call Trusty Module to split tracks (pure logic, no I/O)\n    let split_tracks = split_tracks(\u0026original_bytes)?;\n\n    if split_tracks.is_empty() {\n        return Err(SplitCommandError::SplitError(SplitError::NoTracksToSplit));\n    }\n\n    // 4. Create output directory if it doesn't exist\n    if !output_dir.exists() {\n        tokio::fs::create_dir_all(\u0026output_dir)\n            .await\n            .map_err(|e| SplitCommandError::DirectoryCreationError(e.to_string()))?;\n    }\n\n    // 5. Process each split track\n    let mut split_file_ids = Vec::new();\n    let base_filename = Path::new(\u0026parent_file.original_filename)\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"track\");\n\n    for split_track in \u0026split_tracks {\n        // Generate filename: {base}_track_{num:02}_{instrument}.mid\n        let filename = generate_split_filename(base_filename, split_track);\n\n        // Full path for split file\n        let split_path = output_dir.join(\u0026filename);\n\n        // Write MIDI bytes to disk\n        tokio::fs::write(\u0026split_path, \u0026split_track.midi_bytes).await?;\n\n        // Import split file to database with full metadata\n        let split_file_id = import_split_track(\n            \u0026split_path,\n            \u0026filename,\n            \u0026split_track.midi_bytes,\n            pool,\n        )\n        .await\n        .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?;\n\n        // Create relationship in track_splits table\n        insert_track_split_relationship(\n            file_id,\n            split_file_id,\n            split_track,\n            pool,\n        )\n        .await\n        .map_err(|e| SplitCommandError::TransactionError(e.to_string()))?;\n\n        split_file_ids.push(split_file_id);\n    }\n\n    Ok(SplitResult {\n        split_file_ids,\n        tracks_split: split_tracks.len(),\n        output_dir,\n    })\n}\n\n//=============================================================================\n// HELPER FUNCTIONS (Grown-up Script - I/O Operations)\n//=============================================================================\n\n/// Import a split track file to the database with full metadata.\n///\n/// Performs a complete import operation including:\n/// - Hash calculation for deduplication\n/// - MIDI parsing for metadata extraction\n/// - BPM and key detection\n/// - Transaction-safe insertion to files and musical_metadata tables\n///\n/// # Arguments\n///\n/// * `filepath` - Path to the split MIDI file on disk\n/// * `filename` - Filename to store in database\n/// * `file_data` - MIDI file bytes (already in memory)\n/// * `pool` - Database connection pool\n///\n/// # Returns\n///\n/// Database ID of the newly inserted file\n///\n/// # Errors\n///\n/// Returns error if database insertion fails or file already exists (duplicate hash)\nasync fn import_split_track(\n    filepath: \u0026Path,\n    filename: \u0026str,\n    file_data: \u0026[u8],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // Calculate hash for deduplication (BLAKE3)\n    let hash_bytes = calculate_file_hash(filepath)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec();\n\n    // Parse MIDI for metadata\n    let midi_data = parse_midi_file(file_data)?;\n\n    // Detect BPM\n    let bpm_result = detect_bpm(\u0026midi_data);\n    let bpm = if bpm_result.confidence \u003e 0.5 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n\n    // Detect key signature\n    let key_result = detect_key(\u0026midi_data);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n\n    // Get file size\n    let file_size_bytes = file_data.len() as i64;\n    let filepath_str = filepath.to_str().ok_or(\"Invalid file path\")?;\n\n    // Begin transaction\n    let mut tx = pool.begin().await?;\n\n    // Insert file record\n    let file_id = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, 1, NOW())\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#,\n    )\n    .bind(filename)\n    .bind(filename) // Original filename is same as filename for splits\n    .bind(filepath_str)\n    .bind(\u0026content_hash)\n    .bind(file_size_bytes)\n    .fetch_optional(\u0026mut *tx)\n    .await?\n    .ok_or(\"File already exists (duplicate hash)\")?;\n\n    // Insert musical metadata if available\n    if bpm.is_some() || key_signature.is_some() {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                key_signature,\n                time_signature_numerator,\n                time_signature_denominator\n            ) VALUES ($1, $2, $3::musical_key, 4, 4)\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                key_signature = EXCLUDED.key_signature\n            \"#,\n        )\n        .bind(file_id)\n        .bind(bpm)\n        .bind(key_signature.as_deref())\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Commit transaction\n    tx.commit().await?;\n\n    Ok(file_id)\n}\n\n/// Insert relationship between parent file and split track into track_splits table.\n///\n/// Creates a record linking the parent multi-track file to the split single-track file\n/// with metadata about the track (number, name, instrument, note count).\n///\n/// # Arguments\n///\n/// * `parent_file_id` - Database ID of the parent file\n/// * `split_file_id` - Database ID of the split file\n/// * `split_track` - Metadata about the split track\n/// * `pool` - Database connection pool\n///\n/// # Errors\n///\n/// Returns error if insertion fails or relationship already exists\nasync fn insert_track_split_relationship(\n    parent_file_id: i64,\n    split_file_id: i64,\n    split_track: \u0026SplitTrack,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    sqlx::query!(\n        r#\"\n        INSERT INTO track_splits (\n            parent_file_id,\n            split_file_id,\n            track_number,\n            track_name,\n            instrument,\n            note_count,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, NOW())\n        \"#,\n        parent_file_id,\n        split_file_id,\n        split_track.track_number as i32,\n        split_track.track_name.as_deref(),\n        split_track.instrument.as_deref(),\n        split_track.note_count as i32,\n    )\n    .execute(pool)\n    .await?;\n\n    Ok(())\n}\n\n//=============================================================================\n// UTILITY FUNCTIONS (Pure - Could be Trusty Module)\n//=============================================================================\n\n/// Generate a filename for a split track based on metadata.\n///\n/// Format: `{base}_track_{num:02}_{instrument}.mid`\n///\n/// If instrument is not available, uses track name. If neither available,\n/// uses just track number.\n///\n/// Sanitizes all components to ensure valid filenames.\n///\n/// # Arguments\n///\n/// * `base_filename` - Base filename from the parent file (without extension)\n/// * `split_track` - Metadata about the split track\n///\n/// # Returns\n///\n/// Sanitized filename with .mid extension\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::commands::split_file::generate_split_filename;\n/// use pipeline::core::splitting::track_splitter::SplitTrack;\n///\n/// let track = SplitTrack {\n///     track_number: 1,\n///     track_name: Some(\"Piano\".to_string()),\n///     channel: Some(0),\n///     instrument: Some(\"Acoustic Grand Piano\".to_string()),\n///     note_count: 100,\n///     midi_bytes: vec![],\n/// };\n///\n/// let filename = generate_split_filename(\"my_song\", \u0026track);\n/// assert_eq!(filename, \"my_song_track_01_Acoustic_Grand_Piano.mid\");\n/// ```\npub fn generate_split_filename(base_filename: \u0026str, split_track: \u0026SplitTrack) -\u003e String {\n    let base = sanitize_filename(base_filename);\n    let track_num = format!(\"{:02}\", split_track.track_number);\n\n    // Build suffix: prefer instrument, fall back to track name, then just number\n    let suffix = if let Some(ref instrument) = split_track.instrument {\n        sanitize_filename(instrument)\n    } else if let Some(ref track_name) = split_track.track_name {\n        sanitize_filename(track_name)\n    } else {\n        String::new()\n    };\n\n    if suffix.is_empty() {\n        format!(\"{}_track_{}.mid\", base, track_num)\n    } else {\n        format!(\"{}_track_{}_{}.mid\", base, track_num, suffix)\n    }\n}\n\n/// Sanitize a string to be used as a filename component.\n///\n/// Removes or replaces problematic characters:\n/// - Replaces spaces with underscores\n/// - Removes: / \\ : * ? \" \u003c \u003e | (filesystem-unsafe characters)\n/// - Removes: control characters, non-ASCII if problematic\n/// - Collapses multiple underscores to single underscore\n/// - Trims underscores from start and end\n///\n/// # Arguments\n///\n/// * `name` - String to sanitize\n///\n/// # Returns\n///\n/// Sanitized string safe for use in filenames\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::commands::split_file::sanitize_filename;\n///\n/// assert_eq!(sanitize_filename(\"Piano Track\"), \"Piano_Track\");\n/// assert_eq!(sanitize_filename(\"Track: 1 (Lead)\"), \"Track_1_Lead\");\n/// assert_eq!(sanitize_filename(\"Bass/Guitar\"), \"BassGuitar\");\n/// assert_eq!(sanitize_filename(\"  Piano  \"), \"Piano\");\n/// ```\npub fn sanitize_filename(name: \u0026str) -\u003e String {\n    name.chars()\n        .map(|c| match c {\n            // Replace spaces with underscores\n            ' ' =\u003e '_',\n            // Remove problematic characters\n            '/' | '\\\\' | ':' | '*' | '?' | '\"' | '\u003c' | '\u003e' | '|' =\u003e '_',\n            // Keep alphanumeric, underscore, hyphen, period, parentheses\n            c if c.is_alphanumeric() || c == '_' || c == '-' || c == '.' || c == '(' || c == ')' =\u003e c,\n            // Replace everything else with underscore\n            _ =\u003e '_',\n        })\n        .collect::\u003cString\u003e()\n        // Collapse multiple underscores\n        .split('_')\n        .filter(|s| !s.is_empty())\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .join(\"_\")\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sanitize_filename_spaces() {\n        assert_eq!(sanitize_filename(\"Piano Track\"), \"Piano_Track\");\n        assert_eq!(sanitize_filename(\"My Song Name\"), \"My_Song_Name\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_special_chars() {\n        assert_eq!(sanitize_filename(\"Track: 1\"), \"Track_1\");\n        assert_eq!(sanitize_filename(\"Bass/Guitar\"), \"Bass_Guitar\");\n        assert_eq!(sanitize_filename(\"Lead (Synth)\"), \"Lead_(Synth)\");\n        assert_eq!(sanitize_filename(\"File*Name?\"), \"File_Name\");\n        assert_eq!(sanitize_filename(\"Path\\\\To\\\\File\"), \"Path_To_File\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_multiple_underscores() {\n        assert_eq!(sanitize_filename(\"Track___1\"), \"Track_1\");\n        assert_eq!(sanitize_filename(\"__Piano__\"), \"Piano\");\n        assert_eq!(sanitize_filename(\"A___B___C\"), \"A_B_C\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_edge_cases() {\n        assert_eq!(sanitize_filename(\"\"), \"\");\n        assert_eq!(sanitize_filename(\"   \"), \"\");\n        assert_eq!(sanitize_filename(\"___\"), \"\");\n        assert_eq!(sanitize_filename(\"ValidName123\"), \"ValidName123\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_unicode() {\n        // Keep alphanumeric Unicode (includes accented characters)\n        assert_eq!(sanitize_filename(\"Caf\"), \"Caf\");\n        assert_eq!(sanitize_filename(\"Track1\"), \"Track_1\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_with_instrument() {\n        let track = SplitTrack {\n            track_number: 1,\n            track_name: Some(\"Piano Part\".to_string()),\n            channel: Some(0),\n            instrument: Some(\"Acoustic Grand Piano\".to_string()),\n            note_count: 100,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"my_song\", \u0026track);\n        assert_eq!(filename, \"my_song_track_01_Acoustic_Grand_Piano.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_with_track_name_only() {\n        let track = SplitTrack {\n            track_number: 2,\n            track_name: Some(\"Bass Line\".to_string()),\n            channel: Some(1),\n            instrument: None,\n            note_count: 50,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"song\", \u0026track);\n        assert_eq!(filename, \"song_track_02_Bass_Line.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_no_metadata() {\n        let track = SplitTrack {\n            track_number: 0,\n            track_name: None,\n            channel: None,\n            instrument: None,\n            note_count: 10,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"minimal\", \u0026track);\n        assert_eq!(filename, \"minimal_track_00.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_sanitizes_base() {\n        let track = SplitTrack {\n            track_number: 5,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Guitar\".to_string()),\n            note_count: 75,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"My/Bad\\\\Filename:1\", \u0026track);\n        assert_eq!(filename, \"My_Bad_Filename_1_track_05_Guitar.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_sanitizes_instrument() {\n        let track = SplitTrack {\n            track_number: 3,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Electric Piano (DX7)\".to_string()),\n            note_count: 80,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"track\", \u0026track);\n        assert_eq!(filename, \"track_track_03_Electric_Piano_(DX7).mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_high_track_numbers() {\n        let track = SplitTrack {\n            track_number: 99,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Drums\".to_string()),\n            note_count: 200,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"orchestra\", \u0026track);\n        assert_eq!(filename, \"orchestra_track_99_Drums.mid\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","stats.rs"],"content":"//! Statistics command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: Database statistics and metrics\n//! ARCHETYPE: Grown-up Script (I/O operations)\n//!\n//!  CAN: Perform database I/O\n//!  CAN: Have side effects (complex queries)\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic (delegate to Trusty Modules)\n\nuse crate::AppState;\nuse tauri::State;\nuse std::collections::HashMap;\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get file count breakdown by category\n///\n/// Returns a map of category names to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_category_stats');\n/// // { \"bass\": 150, \"drums\": 200, \"melody\": 100 }\n/// ```\n#[tauri::command]\npub async fn get_category_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT fc.primary_category::text as category, COUNT(*) as count\n        FROM files f\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        GROUP BY fc.primary_category\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get category stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (category, count) in results {\n        let category_name = category.unwrap_or_else(|| \"Uncategorized\".to_string());\n        stats.insert(category_name, count);\n    }\n\n    Ok(stats)\n}\n\n/// Get file count breakdown by manufacturer\n///\n/// Returns a map of manufacturer names to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_manufacturer_stats');\n/// ```\n#[tauri::command]\npub async fn get_manufacturer_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT mm.manufacturer::text as manufacturer, COUNT(*) as count\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        WHERE mm.manufacturer IS NOT NULL\n        GROUP BY mm.manufacturer\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get manufacturer stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (manufacturer, count) in results {\n        if let Some(mfr) = manufacturer {\n            stats.insert(mfr, count);\n        }\n    }\n\n    Ok(stats)\n}\n\n/// Get file count breakdown by key signature\n///\n/// Returns a map of key signatures to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_key_signature_stats');\n/// ```\n#[tauri::command]\npub async fn get_key_signature_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT mm.key_signature::text as key_sig, COUNT(*) as count\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        WHERE mm.key_signature IS NOT NULL\n        GROUP BY mm.key_signature\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get key signature stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (key_sig, count) in results {\n        if let Some(key) = key_sig {\n            stats.insert(key, count);\n        }\n    }\n\n    Ok(stats)\n}\n\n/// Get count of recently added files (last 7 days)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_recently_added_count');\n/// ```\n#[tauri::command]\npub async fn get_recently_added_count(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM files\n        WHERE created_at \u003e= NOW() - INTERVAL '7 days'\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get recently added count: {}\", e))?;\n\n    Ok(count.0)\n}\n\n/// Get count of duplicate files\n///\n/// Files are considered duplicates if they have the same content hash.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_duplicate_count');\n/// ```\n#[tauri::command]\npub async fn get_duplicate_count(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM (\n            SELECT content_hash\n            FROM files\n            GROUP BY content_hash\n            HAVING COUNT(*) \u003e 1\n        ) as duplicates\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get duplicate count: {}\", e))?;\n\n    Ok(count.0)\n}\n\n/// Get database size as formatted string\n///\n/// Returns the total size of the database in a human-readable format.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const size = await invoke\u003cstring\u003e('get_database_size');\n/// // \"125.4 MB\"\n/// ```\n#[tauri::command]\npub async fn get_database_size(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    let size: (Option\u003cString\u003e,) = sqlx::query_as(\n        r#\"\n        SELECT pg_size_pretty(pg_database_size(current_database()))\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get database size: {}\", e))?;\n\n    Ok(size.0.unwrap_or_else(|| \"Unknown\".to_string()))\n}\n\n/// Check database health status\n///\n/// Returns health status based on connection and basic query tests.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const health = await invoke\u003c'good' | 'warning' | 'error'\u003e('check_database_health');\n/// ```\n#[tauri::command]\npub async fn check_database_health(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    // Try a simple query\n    match state.database.test_connection().await {\n        Ok(_) =\u003e {\n            // Check if we can count files\n            match sqlx::query_scalar::\u003c_, i64\u003e(\"SELECT COUNT(*) FROM files\")\n                .fetch_one(\u0026state.database.pool().await)\n                .await\n            {\n                Ok(_) =\u003e Ok(\"good\".to_string()),\n                Err(_) =\u003e Ok(\"warning\".to_string()),\n            }\n        }\n        Err(_) =\u003e Ok(\"error\".to_string()),\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","system.rs"],"content":"//! System command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: System-level operations and information\n//! ARCHETYPE: Grown-up Script (I/O operations)\n//!\n//!  CAN: Perform system I/O\n//!  CAN: Have side effects\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic\n\nuse serde::Serialize;\nuse tauri::State;\nuse crate::AppState;\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// System information response\n#[derive(Debug, Serialize)]\npub struct SystemInfo {\n    pub version: String,\n    pub platform: String,\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get system information\n///\n/// Returns the application version and platform information.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const info = await invoke\u003c{version: string, platform: string}\u003e('get_system_info');\n/// // { version: \"0.1.0\", platform: \"linux\" }\n/// ```\n#[tauri::command]\npub async fn get_system_info() -\u003e Result\u003cSystemInfo, String\u003e {\n    Ok(SystemInfo {\n        version: env!(\"CARGO_PKG_VERSION\").to_string(),\n        platform: std::env::consts::OS.to_string(),\n    })\n}\n\n/// Initialize database connection on first use\n///\n/// This allows Tauri to start up without blocking, then connects\n/// to database on first command. If already connected, returns ok.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// await invoke('initialize_database');\n/// // Now all database commands will work\n/// ```\n#[tauri::command]\npub async fn initialize_database(state: State\u003c'_, AppState\u003e) -\u003e Result\u003c(), String\u003e {\n    // Database is eagerly initialized in main.rs, so this is a no-op\n    // This command exists for completeness if we switch to lazy initialization\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","tags.rs"],"content":"//! Tag Commands - Tauri commands for tag operations\n//!\n//! This module provides frontend-facing commands for:\n//! - Retrieving tags for files\n//! - Getting popular tags (for tag cloud)\n//! - Searching tags (for autocomplete)\n//! - Updating file tags\n\nuse crate::AppState;\nuse crate::db::repositories::tag_repository::{DbTag, TagRepository, TagWithCount};\nuse serde::{Deserialize, Serialize};\nuse tauri::State;\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n\n/// Tag for JSON serialization (frontend-friendly)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TagResponse {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\nimpl From\u003cDbTag\u003e for TagResponse {\n    fn from(db_tag: DbTag) -\u003e Self {\n        Self {\n            id: db_tag.id,\n            name: db_tag.name,\n            category: db_tag.category,\n            usage_count: db_tag.usage_count,\n        }\n    }\n}\n\nimpl From\u003cTagWithCount\u003e for TagResponse {\n    fn from(tag: TagWithCount) -\u003e Self {\n        Self {\n            id: tag.id,\n            name: tag.name,\n            category: tag.category,\n            usage_count: tag.usage_count,\n        }\n    }\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get all tags for a specific file\n#[tauri::command]\npub async fn get_file_tags(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let tags = repo\n        .get_file_tags(file_id)\n        .await\n        .map_err(|e| format!(\"Failed to get file tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Get popular tags with usage counts (for tag cloud)\n///\n/// # Arguments\n/// * `limit` - Maximum number of tags to return (default: 50)\n#[tauri::command]\npub async fn get_popular_tags(\n    limit: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let limit = limit.unwrap_or(50);\n\n    let tags = repo\n        .get_popular_tags(limit)\n        .await\n        .map_err(|e| format!(\"Failed to get popular tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Search tags by name prefix (for autocomplete)\n///\n/// # Arguments\n/// * `query` - Search query (prefix match)\n/// * `limit` - Maximum number of results (default: 10)\n#[tauri::command]\npub async fn search_tags(\n    query: String,\n    limit: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let limit = limit.unwrap_or(10);\n\n    let tags = repo\n        .search_tags(\u0026query, limit)\n        .await\n        .map_err(|e| format!(\"Failed to search tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Get all unique tag categories\n#[tauri::command]\npub async fn get_tag_categories(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let categories = repo\n        .get_tag_categories()\n        .await\n        .map_err(|e| format!(\"Failed to get tag categories: {}\", e))?;\n\n    Ok(categories)\n}\n\n/// Get tags by category\n#[tauri::command]\npub async fn get_tags_by_category(\n    category: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let tags = repo\n        .get_tags_by_category(\u0026category)\n        .await\n        .map_err(|e| format!(\"Failed to get tags by category: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Update tags for a file (replace all existing tags)\n///\n/// # Arguments\n/// * `file_id` - File ID\n/// * `tag_names` - Array of tag names to set\n#[tauri::command]\npub async fn update_file_tags(\n    file_id: i64,\n    tag_names: Vec\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    // Get or create tags and get their IDs\n    let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = tag_names\n        .into_iter()\n        .map(|name| (name, None)) // No category for user-added tags\n        .collect();\n\n    let tag_ids = repo\n        .get_or_create_tags_batch(\u0026tag_data)\n        .await\n        .map_err(|e| format!(\"Failed to create tags: {}\", e))?;\n\n    // Update file tags\n    repo.update_file_tags(file_id, \u0026tag_ids)\n        .await\n        .map_err(|e| format!(\"Failed to update file tags: {}\", e))?;\n\n    Ok(())\n}\n\n/// Add tags to a file (without removing existing tags)\n#[tauri::command]\npub async fn add_tags_to_file(\n    file_id: i64,\n    tag_names: Vec\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    // Get or create tags and get their IDs\n    let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = tag_names\n        .into_iter()\n        .map(|name| (name, None))\n        .collect();\n\n    let tag_ids = repo\n        .get_or_create_tags_batch(\u0026tag_data)\n        .await\n        .map_err(|e| format!(\"Failed to create tags: {}\", e))?;\n\n    // Add tags to file\n    repo.add_tags_to_file(file_id, \u0026tag_ids)\n        .await\n        .map_err(|e| format!(\"Failed to add tags to file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Remove a specific tag from a file\n#[tauri::command]\npub async fn remove_tag_from_file(\n    file_id: i64,\n    tag_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    repo.remove_tag_from_file(file_id, tag_id)\n        .await\n        .map_err(|e| format!(\"Failed to remove tag from file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Get files by tags (for filtering)\n///\n/// # Arguments\n/// * `tag_names` - Array of tag names to filter by\n/// * `match_all` - If true, file must have ALL tags (AND logic). If false, file must have at least one tag (OR logic)\n#[tauri::command]\npub async fn get_files_by_tags(\n    tag_names: Vec\u003cString\u003e,\n    match_all: bool,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003ci64\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let file_ids = repo\n        .get_files_by_tags(\u0026tag_names, match_all)\n        .await\n        .map_err(|e| format!(\"Failed to get files by tags: {}\", e))?;\n\n    Ok(file_ids)\n}\n\n/// Get usage statistics for a tag\n#[tauri::command]\npub async fn get_tag_stats(\n    tag_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let count = repo\n        .get_tag_file_count(tag_id)\n        .await\n        .map_err(|e| format!(\"Failed to get tag stats: {}\", e))?;\n\n    Ok(count)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","auto_tagger.rs"],"content":"//! Auto-Tagging System for MIDI Files\n//!\n//! This module provides intelligent tag extraction from:\n//! - File names (splitting on _, -, space, camelCase)\n//! - Folder paths (manufacturer, genre, category)\n//! - MIDI content (instrument names, track names)\n//!\n//! Tags are categorized as:\n//! - genre:house, genre:techno, etc.\n//! - instrument:kick, instrument:bass, etc.\n//! - brand:vengeance, brand:splice, etc.\n//! - Style tags: deep, dark, melodic, etc.\n\nuse regex::Regex;\nuse std::collections::HashSet;\n\n/// Main auto-tagging engine\npub struct AutoTagger {\n    genre_keywords: HashSet\u003cString\u003e,\n    instrument_keywords: HashSet\u003cString\u003e,\n    manufacturer_keywords: HashSet\u003cString\u003e,\n    style_keywords: HashSet\u003cString\u003e,\n    common_words: HashSet\u003cString\u003e,\n    split_pattern: Regex,\n}\n\n/// Tag with optional category prefix\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct Tag {\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n}\n\nimpl Tag {\n    pub fn new(name: impl Into\u003cString\u003e, category: Option\u003cimpl Into\u003cString\u003e\u003e) -\u003e Self {\n        Self {\n            name: name.into(),\n            category: category.map(|c| c.into()),\n        }\n    }\n\n    /// Get the full tag string (e.g., \"genre:house\" or just \"deep\")\n    pub fn full_name(\u0026self) -\u003e String {\n        match \u0026self.category {\n            Some(cat) =\u003e format!(\"{}:{}\", cat, self.name),\n            None =\u003e self.name.clone(),\n        }\n    }\n}\n\nimpl AutoTagger {\n    /// Create a new auto-tagger with default keyword dictionaries\n    ///\n    /// # Errors\n    /// Returns error if internal regex pattern compilation fails (should never happen with valid pattern)\n    pub fn new() -\u003e Result\u003cSelf, regex::Error\u003e {\n        Ok(Self {\n            genre_keywords: Self::load_genre_keywords(),\n            instrument_keywords: Self::load_instrument_keywords(),\n            manufacturer_keywords: Self::load_manufacturer_keywords(),\n            style_keywords: Self::load_style_keywords(),\n            common_words: Self::load_common_words(),\n            // Split on underscores, hyphens, spaces, and dots\n            // Note: camelCase splitting requires lookahead/lookbehind which isn't supported in Rust regex\n            split_pattern: Regex::new(r\"[_\\-\\s.]+\")?,\n        })\n    }\n\n    /// Extract tags from file path, name, and MIDI content\n    ///\n    /// # Arguments\n    /// * `file_path` - Full file path (e.g., \"/Vengeance/DeepHouse/Kicks/VEC_Kick_128.mid\")\n    /// * `file_name` - File name only (e.g., \"VEC_Kick_128.mid\")\n    /// * `midi_instruments` - Instrument names from MIDI file (e.g., [\"Acoustic Bass Drum\"])\n    /// * `bpm` - Detected BPM (optional, added as tag if present)\n    /// * `key_signature` - Detected key (optional, added as tag if present)\n    ///\n    /// # Returns\n    /// Vector of unique tags with categories\n    pub fn extract_tags(\n        \u0026self,\n        file_path: \u0026str,\n        file_name: \u0026str,\n        midi_instruments: \u0026[String],\n        bpm: Option\u003cf64\u003e,\n        key_signature: Option\u003c\u0026str\u003e,\n    ) -\u003e Vec\u003cTag\u003e {\n        let mut tags = HashSet::new();\n\n        // 1. Extract from file name\n        tags.extend(self.extract_from_filename(file_name));\n\n        // 2. Extract from folder path\n        tags.extend(self.extract_from_path(file_path));\n\n        // 3. Extract from MIDI instruments\n        tags.extend(self.extract_from_instruments(midi_instruments));\n\n        // 4. Add BPM tag if available\n        if let Some(bpm_val) = bpm {\n            let bpm_rounded = bpm_val.round() as i32;\n            tags.insert(Tag::new(bpm_rounded.to_string(), Some(\"bpm\")));\n        }\n\n        // 5. Add key signature tag if available\n        if let Some(key) = key_signature {\n            let key_normalized = key.to_lowercase();\n            if key_normalized != \"unknown\" {\n                tags.insert(Tag::new(key_normalized, Some(\"key\")));\n            }\n        }\n\n        tags.into_iter().collect()\n    }\n\n    /// Extract tags from filename by splitting on common separators\n    fn extract_from_filename(\u0026self, filename: \u0026str) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        // Remove extension\n        let name = filename\n            .trim_end_matches(\".mid\")\n            .trim_end_matches(\".MID\")\n            .trim_end_matches(\".midi\")\n            .trim_end_matches(\".MIDI\");\n\n        // Split on separators: _, -, space, and camelCase\n        let words: Vec\u003c\u0026str\u003e = self.split_pattern.split(name).collect();\n\n        for word in words {\n            let word_lower = word.to_lowercase();\n\n            // Skip common/meaningless words\n            if word.len() \u003c 2 || self.common_words.contains(\u0026word_lower) {\n                continue;\n            }\n\n            // Check against known dictionaries with fuzzy matching\n            if let Some(matched_genre) = self.fuzzy_match(\u0026word_lower, \u0026self.genre_keywords) {\n                tags.push(Tag::new(matched_genre, Some(\"genre\")));\n            } else if let Some(matched_instrument) =\n                self.fuzzy_match(\u0026word_lower, \u0026self.instrument_keywords)\n            {\n                tags.push(Tag::new(matched_instrument, Some(\"instrument\")));\n            } else if let Some(matched_brand) =\n                self.fuzzy_match(\u0026word_lower, \u0026self.manufacturer_keywords)\n            {\n                tags.push(Tag::new(matched_brand, Some(\"brand\")));\n            } else if let Some(matched_style) = self.fuzzy_match(\u0026word_lower, \u0026self.style_keywords)\n            {\n                tags.push(Tag::new(matched_style, None::\u003cString\u003e)); // Style tags have no category prefix\n            } else if word.len() \u003e 3 \u0026\u0026 word.chars().all(|c| c.is_alphanumeric()) {\n                // Add as generic tag if it's meaningful (\u003e3 chars, alphanumeric)\n                tags.push(Tag::new(word_lower, None::\u003cString\u003e));\n            }\n        }\n\n        tags\n    }\n\n    /// Extract tags from folder path\n    fn extract_from_path(\u0026self, path: \u0026str) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        // Split path into components\n        let parts: Vec\u003c\u0026str\u003e = path.split('/').filter(|s| !s.is_empty()).collect();\n\n        for part in parts {\n            let part_lower = part.to_lowercase();\n\n            // Check against dictionaries\n            if let Some(matched_genre) = self.fuzzy_match(\u0026part_lower, \u0026self.genre_keywords) {\n                tags.push(Tag::new(matched_genre, Some(\"genre\")));\n            } else if let Some(matched_instrument) =\n                self.fuzzy_match(\u0026part_lower, \u0026self.instrument_keywords)\n            {\n                tags.push(Tag::new(matched_instrument, Some(\"category\")));\n            } else if let Some(matched_brand) =\n                self.fuzzy_match(\u0026part_lower, \u0026self.manufacturer_keywords)\n            {\n                tags.push(Tag::new(matched_brand, Some(\"brand\")));\n            }\n        }\n\n        tags\n    }\n\n    /// Extract tags from MIDI instrument names\n    fn extract_from_instruments(\u0026self, instruments: \u0026[String]) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        for instrument in instruments {\n            let inst_lower = instrument.to_lowercase();\n\n            // Map MIDI GM instrument names to our keywords\n            if let Some(matched) = self.fuzzy_match(\u0026inst_lower, \u0026self.instrument_keywords) {\n                tags.push(Tag::new(matched, Some(\"instrument\")));\n            }\n        }\n\n        tags\n    }\n\n    /// Fuzzy match a word against a dictionary using Levenshtein distance\n    /// Returns the matched keyword if distance \u003c= 2\n    fn fuzzy_match(\u0026self, input: \u0026str, dictionary: \u0026HashSet\u003cString\u003e) -\u003e Option\u003cString\u003e {\n        // First try exact match\n        if dictionary.contains(input) {\n            return Some(input.to_string());\n        }\n\n        // Try fuzzy matching with threshold of 2 edits\n        let threshold = 2;\n\n        dictionary\n            .iter()\n            .filter(|keyword| {\n                // Only fuzzy match if input is reasonably long\n                if input.len() \u003c 4 {\n                    return false;\n                }\n                strsim::levenshtein(input, keyword) \u003c= threshold\n            })\n            .min_by_key(|keyword| strsim::levenshtein(input, keyword))\n            .cloned()\n    }\n\n    // ==========================================================================\n    // KEYWORD DICTIONARIES\n    // ==========================================================================\n\n    fn load_genre_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"house\",\n            \"deephouse\",\n            \"deep_house\",\n            \"techhouse\",\n            \"tech_house\",\n            \"techno\",\n            \"trance\",\n            \"dubstep\",\n            \"dnb\",\n            \"drum_and_bass\",\n            \"drumnbass\",\n            \"edm\",\n            \"electro\",\n            \"progressive\",\n            \"minimal\",\n            \"acid\",\n            \"ambient\",\n            \"breakbeat\",\n            \"garage\",\n            \"trap\",\n            \"hip_hop\",\n            \"hiphop\",\n            \"lofi\",\n            \"chillout\",\n            \"downtempo\",\n            \"industrial\",\n            \"hardstyle\",\n            \"hardcore\",\n            \"jungle\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_instrument_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            // Drums\n            \"kick\",\n            \"bass_drum\",\n            \"bassdrum\",\n            \"snare\",\n            \"hihat\",\n            \"hat\",\n            \"clap\",\n            \"tom\",\n            \"cymbal\",\n            \"percussion\",\n            \"perc\",\n            \"drum\",\n            \"drums\",\n            // Bass\n            \"bass\",\n            \"sub\",\n            \"subbass\",\n            \"reese\",\n            // Synths\n            \"pluck\",\n            \"lead\",\n            \"synth\",\n            \"pad\",\n            \"chord\",\n            \"stab\",\n            \"arp\",\n            \"arpeggiated\",\n            \"melody\",\n            \"melodic\",\n            // Keys\n            \"piano\",\n            \"keys\",\n            \"organ\",\n            \"rhodes\",\n            \"wurlitzer\",\n            // Orchestral\n            \"strings\",\n            \"string\",\n            \"brass\",\n            \"woodwind\",\n            \"orchestra\",\n            // Vocals\n            \"vocal\",\n            \"vox\",\n            \"voice\",\n            // FX\n            \"fx\",\n            \"effect\",\n            \"riser\",\n            \"impact\",\n            \"sweep\",\n            \"transition\",\n            // Loops\n            \"loop\",\n            \"pattern\",\n            \"sequence\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_manufacturer_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"vengeance\",\n            \"splice\",\n            \"loopmasters\",\n            \"sample_magic\",\n            \"samplemagic\",\n            \"black_octopus\",\n            \"blackoctopus\",\n            \"cymatics\",\n            \"production_master\",\n            \"productionmaster\",\n            \"roland\",\n            \"korg\",\n            \"moog\",\n            \"arturia\",\n            \"native_instruments\",\n            \"native\",\n            \"serum\",\n            \"massive\",\n            \"sylenth\",\n            \"spire\",\n            \"abletonlive\",\n            \"ableton\",\n            \"flstudio\",\n            \"logic\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_style_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"dark\",\n            \"melodic\",\n            \"aggressive\",\n            \"soft\",\n            \"hard\",\n            \"heavy\",\n            \"rolling\",\n            \"bouncy\",\n            \"groovy\",\n            \"punchy\",\n            \"warm\",\n            \"cold\",\n            \"analog\",\n            \"digital\",\n            \"vintage\",\n            \"modern\",\n            \"classic\",\n            \"dirty\",\n            \"clean\",\n            \"distorted\",\n            \"atmospheric\",\n            \"uplifting\",\n            \"euphoric\",\n            \"deep\",\n            \"driving\",\n            \"energetic\",\n            \"chill\",\n            \"relaxed\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_common_words() -\u003e HashSet\u003cString\u003e {\n        [\n            \"the\", \"and\", \"for\", \"with\", \"track\", \"midi\", \"file\", \"new\", \"ver\", \"vol\", \"v\", \"pt\",\n            \"part\", \"demo\", \"edit\", \"mix\", \"original\", \"version\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n}\n\n// Note: Default trait removed since AutoTagger::new() now returns Result.\n// Users should call AutoTagger::new()? instead of using Default.\n\n// =============================================================================\n// TESTS\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_extract_from_filename() {\n        let tagger = AutoTagger::new().unwrap();\n\n        // Test 1: Vengeance style naming\n        let tags = tagger.extract_from_filename(\"VEC_Deep_House_Kick_128_C.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"genre:house\".to_string()));\n        assert!(tag_names.contains(\u0026\"deep\".to_string()));\n        assert!(tag_names.contains(\u0026\"instrument:kick\".to_string()));\n\n        // Test 2: CamelCase naming\n        let tags = tagger.extract_from_filename(\"TechnoLeadSynth.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"genre:techno\".to_string()));\n        assert!(tag_names.contains(\u0026\"instrument:lead\".to_string()));\n    }\n\n    #[test]\n    fn test_extract_from_path() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_from_path(\"/Vengeance/DeepHouse/Drums/Kicks/file.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"brand:vengeance\".to_string()));\n        assert!(tag_names.contains(\u0026\"category:drums\".to_string()));\n    }\n\n    #[test]\n    fn test_fuzzy_matching() {\n        let tagger = AutoTagger::new().unwrap();\n\n        // \"vengance\" should match \"vengeance\" (1 char difference)\n        let result = tagger.fuzzy_match(\"vengance\", \u0026tagger.manufacturer_keywords);\n        assert_eq!(result, Some(\"vengeance\".to_string()));\n\n        // \"teckno\" should match \"techno\" (1 char swap)\n        let result = tagger.fuzzy_match(\"teckno\", \u0026tagger.genre_keywords);\n        assert_eq!(result, Some(\"techno\".to_string()));\n    }\n\n    #[test]\n    fn test_full_tag_extraction() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_tags(\n            \"/Samples/Vengeance/DeepHouse/Drums/VEC_Deep_Kick_128_C.mid\",\n            \"VEC_Deep_Kick_128_C.mid\",\n            \u0026[\"Acoustic Bass Drum\".to_string()],\n            Some(128.0),\n            Some(\"C\"),\n        );\n\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        // Should have brand\n        assert!(tag_names.iter().any(|t| t.starts_with(\"brand:\")));\n        // Should have genre\n        assert!(tag_names.iter().any(|t| t.starts_with(\"genre:\")));\n        // Should have instrument\n        assert!(tag_names.iter().any(|t| t.starts_with(\"instrument:\")));\n        // Should have BPM\n        assert!(tag_names.contains(\u0026\"bpm:128\".to_string()));\n        // Should have key\n        assert!(tag_names.contains(\u0026\"key:c\".to_string()));\n    }\n\n    #[test]\n    fn test_common_words_filtered() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_from_filename(\"The_New_Kick_For_Mix.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.name.clone()).collect();\n\n        // Common words should be filtered out\n        assert!(!tag_names.contains(\u0026\"the\".to_string()));\n        assert!(!tag_names.contains(\u0026\"new\".to_string()));\n        assert!(!tag_names.contains(\u0026\"for\".to_string()));\n        assert!(!tag_names.contains(\u0026\"mix\".to_string()));\n\n        // But \"kick\" should remain\n        assert!(tag_names.contains(\u0026\"kick\".to_string()));\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":3},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","bpm_detector.rs"],"content":"//! BPM Detection Module\n//!\n//! This module provides BPM (Beats Per Minute) detection for MIDI files.\n//! It analyzes tempo change events and provides confidence scores.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse midi_library_shared::core::midi::types::{Event, MidiFile};\n\n/// Default BPM when no tempo events are found\nconst DEFAULT_BPM: f64 = 120.0;\n\n/// Minimum valid BPM\nconst MIN_BPM: f64 = 20.0;\n\n/// Maximum valid BPM\nconst MAX_BPM: f64 = 300.0;\n\n/// Result of BPM detection\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmDetectionResult {\n    /// Detected BPM (beats per minute)\n    pub bpm: f64,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Detection method used\n    pub method: BpmDetectionMethod,\n\n    /// Additional metadata\n    pub metadata: BpmMetadata,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum BpmDetectionMethod {\n    /// Single tempo event found\n    SingleTempo,\n\n    /// Multiple tempo events, used weighted average\n    WeightedAverage,\n\n    /// No tempo events, used default\n    DefaultTempo,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmMetadata {\n    /// All tempo changes in the file\n    pub tempo_changes: Vec\u003cTempoChange\u003e,\n\n    /// Whether tempo is constant throughout\n    pub is_constant: bool,\n\n    /// Tempo range (min, max) if multiple tempos\n    pub tempo_range: Option\u003c(f64, f64)\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct TempoChange {\n    pub tick: u32,\n    pub bpm: f64,\n}\n\n/// Detects BPM from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `BpmDetectionResult` - Detection result with confidence and metadata\n///\n/// # Examples\n/// ```no_run\n/// use pipeline::core::analysis::bpm_detector::detect_bpm;\n/// use pipeline::core::midi::types::MidiFile;\n///\n/// # fn example() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n/// # let midi_file = MidiFile {\n/// #     header: pipeline::core::midi::types::Header {\n/// #         format: 1,\n/// #         num_tracks: 1,\n/// #         ticks_per_quarter_note: 480,\n/// #     },\n/// #     tracks: vec![],\n/// # };\n/// let result = detect_bpm(\u0026midi_file);\n/// println!(\"Detected BPM: {:.2}\", result.bpm);\n/// # Ok(())\n/// # }\n/// ```\npub fn detect_bpm(midi_file: \u0026MidiFile) -\u003e BpmDetectionResult {\n    // Extract all tempo events from all tracks\n    let tempo_events = extract_tempo_events(midi_file);\n\n    if tempo_events.is_empty() {\n        return BpmDetectionResult {\n            bpm: DEFAULT_BPM,\n            confidence: 0.3, // Low confidence for default tempo\n            method: BpmDetectionMethod::DefaultTempo,\n            metadata: BpmMetadata {\n                tempo_changes: vec![],\n                is_constant: true,\n                tempo_range: None,\n            },\n        };\n    }\n\n    // Convert tempo changes to BPM values\n    let tempo_changes: Vec\u003cTempoChange\u003e = tempo_events\n        .into_iter()\n        .map(|(tick, microseconds_per_quarter)| TempoChange {\n            tick,\n            bpm: microseconds_to_bpm(microseconds_per_quarter),\n        })\n        .collect();\n\n    // Calculate statistics\n    let is_constant = tempo_changes.len() == 1;\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let total_ticks = calculate_total_ticks(midi_file);\n    let avg_bpm = calculate_weighted_average(\u0026tempo_changes, total_ticks);\n\n    let tempo_range = if tempo_changes.len() \u003e 1 {\n        let min = bpms.iter().cloned().fold(f64::INFINITY, f64::min);\n        let max = bpms.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n        Some((min, max))\n    } else {\n        None\n    };\n\n    // Determine confidence based on consistency\n    let confidence = calculate_confidence(\u0026tempo_changes);\n\n    let method = if tempo_changes.len() == 1 {\n        BpmDetectionMethod::SingleTempo\n    } else {\n        BpmDetectionMethod::WeightedAverage\n    };\n\n    BpmDetectionResult {\n        bpm: avg_bpm,\n        confidence,\n        method,\n        metadata: BpmMetadata {\n            tempo_changes,\n            is_constant,\n            tempo_range,\n        },\n    }\n}\n\n/// Extracts tempo events from all tracks in the MIDI file\nfn extract_tempo_events(midi_file: \u0026MidiFile) -\u003e Vec\u003c(u32, u32)\u003e {\n    let mut tempo_events = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            if let Event::TempoChange {\n                microseconds_per_quarter,\n            } = timed_event.event\n            {\n                tempo_events.push((current_tick, microseconds_per_quarter));\n            }\n        }\n    }\n\n    // Sort by tick position\n    tempo_events.sort_by_key(|(tick, _)| *tick);\n    tempo_events\n}\n\n/// Calculates the total number of ticks in the MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e u32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks\n}\n\n/// Converts microseconds per quarter note to BPM\nfn microseconds_to_bpm(microseconds_per_quarter: u32) -\u003e f64 {\n    let bpm = 60_000_000.0 / microseconds_per_quarter as f64;\n\n    // Clamp to valid range\n    bpm.clamp(MIN_BPM, MAX_BPM)\n}\n\n/// Calculates weighted average BPM based on duration each tempo is active\nfn calculate_weighted_average(tempo_changes: \u0026[TempoChange], total_ticks: u32) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return DEFAULT_BPM;\n    }\n\n    if tempo_changes.len() == 1 {\n        return tempo_changes[0].bpm;\n    }\n\n    let mut weighted_sum = 0.0;\n    let mut total_weight = 0.0;\n\n    for (i, tempo_change) in tempo_changes.iter().enumerate() {\n        let duration = if i + 1 \u003c tempo_changes.len() {\n            tempo_changes[i + 1].tick - tempo_change.tick\n        } else {\n            total_ticks.saturating_sub(tempo_change.tick)\n        };\n\n        let weight = duration as f64;\n        weighted_sum += tempo_change.bpm * weight;\n        total_weight += weight;\n    }\n\n    if total_weight \u003e 0.0 {\n        weighted_sum / total_weight\n    } else {\n        tempo_changes[0].bpm\n    }\n}\n\n/// Calculates confidence score based on tempo consistency\nfn calculate_confidence(tempo_changes: \u0026[TempoChange]) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return 0.3; // Low confidence for default\n    }\n\n    if tempo_changes.len() == 1 {\n        return 1.0; // High confidence for single tempo\n    }\n\n    // Calculate variance in BPM values\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let mean = bpms.iter().sum::\u003cf64\u003e() / bpms.len() as f64;\n    let variance = bpms.iter().map(|bpm| (bpm - mean).powi(2)).sum::\u003cf64\u003e() / bpms.len() as f64;\n    let std_dev = variance.sqrt();\n\n    // Lower variance = higher confidence\n    // Scale confidence based on coefficient of variation\n    let cv = std_dev / mean;\n    (1.0 - cv).clamp(0.5, 1.0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_to_bpm() {\n        // 120 BPM = 500,000 microseconds per quarter note\n        assert_eq!(microseconds_to_bpm(500_000), 120.0);\n\n        // 60 BPM = 1,000,000 microseconds\n        assert_eq!(microseconds_to_bpm(1_000_000), 60.0);\n\n        // 140 BPM  428,571 microseconds\n        let bpm = microseconds_to_bpm(428_571);\n        assert!((bpm - 140.0).abs() \u003c 0.1);\n    }\n\n    #[test]\n    fn test_bpm_clamping() {\n        // Test minimum clamping\n        let too_slow = microseconds_to_bpm(5_000_000); // Would be 12 BPM\n        assert_eq!(too_slow, MIN_BPM);\n\n        // Test maximum clamping\n        let too_fast = microseconds_to_bpm(100_000); // Would be 600 BPM\n        assert_eq!(too_fast, MAX_BPM);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","key_detector.rs"],"content":"//! Key Detection Module\n//!\n//! Implements the Krumhansl-Schmuckler key-finding algorithm to detect\n//! the musical key of MIDI files.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse crate::core::analysis::key_profiles::*;\nuse midi_library_shared::core::midi::types::{Event, MidiFile};\n\n/// Musical scale types\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ScaleType {\n    Major,\n    Minor,\n}\n\nimpl std::fmt::Display for ScaleType {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            ScaleType::Major =\u003e write!(f, \"major\"),\n            ScaleType::Minor =\u003e write!(f, \"minor\"),\n        }\n    }\n}\n\n/// Result of key detection\n#[derive(Debug, Clone, PartialEq)]\npub struct KeyDetectionResult {\n    /// Detected key (e.g., \"C\", \"Am\", \"F#\")\n    pub key: String,\n\n    /// Whether the key is major or minor\n    pub scale_type: ScaleType,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Top 3 alternative keys with their correlation scores\n    pub alternatives: Vec\u003cKeyAlternative\u003e,\n\n    /// Pitch class distribution from the MIDI file\n    pub pitch_class_distribution: [f64; 12],\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct KeyAlternative {\n    pub key: String,\n    pub scale_type: ScaleType,\n    pub correlation: f64,\n}\n\n/// Detects the musical key from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `KeyDetectionResult` - Detection result with confidence and alternatives\n///\n/// # Algorithm\n/// Uses Krumhansl-Schmuckler key-finding algorithm:\n/// 1. Extract all notes and build pitch class histogram\n/// 2. Normalize histogram to probability distribution\n/// 3. Correlate with all 24 key profiles (12 major + 12 minor)\n/// 4. Return key with highest correlation\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::midi::types::MidiFile;\n/// use pipeline::core::analysis::key_detector::detect_key;\n///\n/// // Assuming you have a parsed MIDI file\n/// // let midi_file = parse_midi_file(\u0026data)?;\n/// // let result = detect_key(\u0026midi_file);\n/// // println!(\"Detected key: {} ({})\", result.key, result.scale_type);\n/// ```\npub fn detect_key(midi_file: \u0026MidiFile) -\u003e KeyDetectionResult {\n    // Build pitch class histogram\n    let pitch_class_counts = build_pitch_class_histogram(midi_file);\n\n    // Normalize to probability distribution\n    let pitch_class_distribution = normalize_histogram(\u0026pitch_class_counts);\n\n    // Calculate correlations with all 24 key profiles\n    let mut correlations = Vec::new();\n\n    for pitch_class in 0..12 {\n        // Major key\n        let major_correlation = calculate_correlation(\n            \u0026pitch_class_distribution,\n            \u0026rotate_profile(\u0026MAJOR_PROFILE, pitch_class),\n        );\n        correlations.push((pitch_class, ScaleType::Major, major_correlation));\n\n        // Minor key\n        let minor_correlation = calculate_correlation(\n            \u0026pitch_class_distribution,\n            \u0026rotate_profile(\u0026MINOR_PROFILE, pitch_class),\n        );\n        correlations.push((pitch_class, ScaleType::Minor, minor_correlation));\n    }\n\n    // Sort by correlation (descending)\n    // Note: partial_cmp can return None for NaN values, treat them as equal\n    correlations.sort_by(|a, b| b.2.partial_cmp(\u0026a.2).unwrap_or(std::cmp::Ordering::Equal));\n\n    // Get top result\n    let (best_pitch_class, best_scale_type, _best_correlation) = correlations[0];\n\n    let key_name = format_key_name(best_pitch_class, best_scale_type);\n\n    // Calculate confidence from correlation\n    let confidence = calculate_confidence(\u0026correlations);\n\n    // Get top 3 alternatives\n    let alternatives: Vec\u003cKeyAlternative\u003e = correlations[1..4]\n        .iter()\n        .map(|(pc, st, corr)| KeyAlternative {\n            key: format_key_name(*pc, *st),\n            scale_type: *st,\n            correlation: *corr,\n        })\n        .collect();\n\n    KeyDetectionResult {\n        key: key_name,\n        scale_type: best_scale_type,\n        confidence,\n        alternatives,\n        pitch_class_distribution,\n    }\n}\n\n/// Builds a histogram of pitch class occurrences\nfn build_pitch_class_histogram(midi_file: \u0026MidiFile) -\u003e [u32; 12] {\n    let mut histogram = [0u32; 12];\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::NoteOn { note, velocity, .. } = timed_event.event {\n                if velocity \u003e 0 {\n                    let pitch_class = (note % 12) as usize;\n                    histogram[pitch_class] += 1;\n                }\n            }\n        }\n    }\n\n    histogram\n}\n\n/// Normalizes histogram to probability distribution\nfn normalize_histogram(histogram: \u0026[u32; 12]) -\u003e [f64; 12] {\n    let total: u32 = histogram.iter().sum();\n\n    if total == 0 {\n        return [0.0; 12];\n    }\n\n    let mut normalized = [0.0; 12];\n    for i in 0..12 {\n        normalized[i] = histogram[i] as f64 / total as f64;\n    }\n\n    normalized\n}\n\n/// Rotates a key profile to a different tonic\n///\n/// Takes a profile defined for C (pitch class 0) and rotates it to be\n/// defined for a different pitch class. The rotation shifts the profile\n/// so that the tonic weight appears at the target pitch class.\nfn rotate_profile(profile: \u0026[f64; 12], rotation: usize) -\u003e [f64; 12] {\n    let mut rotated = [0.0; 12];\n\n    for i in 0..12 {\n        rotated[i] = profile[(i + 12 - rotation) % 12];\n    }\n\n    rotated\n}\n\n/// Calculates Pearson correlation coefficient between two distributions\nfn calculate_correlation(distribution: \u0026[f64; 12], profile: \u0026[f64; 12]) -\u003e f64 {\n    // Calculate means\n    let mean_dist = distribution.iter().sum::\u003cf64\u003e() / 12.0;\n    let mean_prof = profile.iter().sum::\u003cf64\u003e() / 12.0;\n\n    // Calculate covariance and standard deviations\n    let mut covariance = 0.0;\n    let mut var_dist = 0.0;\n    let mut var_prof = 0.0;\n\n    for i in 0..12 {\n        let diff_dist = distribution[i] - mean_dist;\n        let diff_prof = profile[i] - mean_prof;\n\n        covariance += diff_dist * diff_prof;\n        var_dist += diff_dist * diff_dist;\n        var_prof += diff_prof * diff_prof;\n    }\n\n    // Calculate correlation\n    let std_dist = var_dist.sqrt();\n    let std_prof = var_prof.sqrt();\n\n    if std_dist == 0.0 || std_prof == 0.0 {\n        return 0.0;\n    }\n\n    covariance / (std_dist * std_prof)\n}\n\n/// Calculates confidence based on separation between best and second-best keys\nfn calculate_confidence(correlations: \u0026[(usize, ScaleType, f64)]) -\u003e f64 {\n    if correlations.len() \u003c 2 {\n        return 0.5;\n    }\n\n    let best = correlations[0].2;\n    let second_best = correlations[1].2;\n\n    // Larger gap = higher confidence\n    let gap = best - second_best;\n\n    // Map gap to confidence score\n    // Gap of 0.0 = 0.5 confidence\n    // Gap of 0.2+ = 1.0 confidence\n    let confidence = 0.5 + (gap * 2.5).min(0.5);\n\n    confidence.clamp(0.5, 1.0)\n}\n\n/// Formats key name based on pitch class and scale type\nfn format_key_name(pitch_class: usize, scale_type: ScaleType) -\u003e String {\n    let base_name = pitch_class_to_key_name(pitch_class);\n\n    match scale_type {\n        ScaleType::Major =\u003e base_name.to_string(),\n        ScaleType::Minor =\u003e format!(\"{}m\", base_name),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_normalize_histogram() {\n        let histogram = [10, 0, 5, 0, 3, 0, 0, 7, 0, 2, 0, 3];\n        let normalized = normalize_histogram(\u0026histogram);\n\n        let total: f64 = normalized.iter().sum();\n        assert!((total - 1.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_normalize_empty_histogram() {\n        let histogram = [0; 12];\n        let normalized = normalize_histogram(\u0026histogram);\n\n        assert_eq!(normalized, [0.0; 12]);\n    }\n\n    #[test]\n    fn test_rotate_profile() {\n        // Test that rotating a profile moves the tonic weight to the correct position\n        let profile = [\n            1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0,\n        ];\n\n        // Rotate to pitch class 3 (D#)\n        let rotated = rotate_profile(\u0026profile, 3);\n\n        // The tonic weight (1.0) should now be at position 3\n        assert_eq!(rotated[3], 1.0);\n        // Position 0 should have the weight that was 3 positions back\n        assert_eq!(rotated[0], 10.0);\n        // Position 4 should have the weight that was at position 1 (the scale degree above tonic)\n        assert_eq!(rotated[4], 2.0);\n    }\n\n    #[test]\n    fn test_correlation_identical() {\n        let dist1 = [\n            0.1, 0.2, 0.1, 0.05, 0.15, 0.1, 0.05, 0.15, 0.03, 0.02, 0.03, 0.02,\n        ];\n        let correlation = calculate_correlation(\u0026dist1, \u0026dist1);\n\n        assert!((correlation - 1.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_correlation_zero() {\n        let dist1 = [0.0; 12];\n        let dist2 = [\n            0.1, 0.2, 0.1, 0.05, 0.15, 0.1, 0.05, 0.15, 0.03, 0.02, 0.03, 0.02,\n        ];\n        let correlation = calculate_correlation(\u0026dist1, \u0026dist2);\n\n        assert_eq!(correlation, 0.0);\n    }\n\n    #[test]\n    fn test_format_key_name() {\n        assert_eq!(format_key_name(0, ScaleType::Major), \"C\");\n        assert_eq!(format_key_name(0, ScaleType::Minor), \"Cm\");\n        assert_eq!(format_key_name(9, ScaleType::Minor), \"Am\");\n        assert_eq!(format_key_name(7, ScaleType::Major), \"G\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","key_profiles.rs"],"content":"//! Krumhansl-Schmuckler Key Profiles\n//!\n//! These profiles represent the expected distribution of pitch classes\n//! in major and minor keys, derived from music theory research.\n\n/// Major key profile (Krumhansl \u0026 Kessler, 1982)\n/// Indexed by pitch class: C, C#, D, D#, E, F, F#, G, G#, A, A#, B\npub const MAJOR_PROFILE: [f64; 12] = [\n    6.35, // C  - Tonic (strongest)\n    2.23, // C# - Minor 2nd\n    3.48, // D  - Major 2nd\n    2.33, // D# - Minor 3rd\n    4.38, // E  - Major 3rd\n    4.09, // F  - Perfect 4th\n    2.52, // F# - Tritone\n    5.19, // G  - Perfect 5th\n    2.39, // G# - Minor 6th\n    3.66, // A  - Major 6th\n    2.29, // A# - Minor 7th\n    2.88, // B  - Major 7th\n];\n\n/// Minor key profile (Krumhansl \u0026 Kessler, 1982)\npub const MINOR_PROFILE: [f64; 12] = [\n    6.33, // C  - Tonic (strongest)\n    2.68, // C# - Minor 2nd\n    3.52, // D  - Major 2nd\n    5.38, // D# - Minor 3rd (characteristic of minor)\n    2.60, // E  - Major 3rd\n    3.53, // F  - Perfect 4th\n    2.54, // F# - Tritone\n    4.75, // G  - Perfect 5th\n    3.98, // G# - Minor 6th (characteristic of minor)\n    2.69, // A  - Major 6th\n    3.34, // A# - Minor 7th\n    3.17, // B  - Major 7th\n];\n\n/// All possible key names in circle of fifths order\npub const KEY_NAMES: [\u0026str; 12] = [\n    \"C\", \"G\", \"D\", \"A\", \"E\", \"B\", \"F#\", \"C#\", \"G#\", \"D#\", \"A#\", \"F\",\n];\n\n/// Maps pitch class to key name\npub fn pitch_class_to_key_name(pitch_class: usize) -\u003e \u0026'static str {\n    match pitch_class {\n        0 =\u003e \"C\",\n        1 =\u003e \"C#\",\n        2 =\u003e \"D\",\n        3 =\u003e \"D#\",\n        4 =\u003e \"E\",\n        5 =\u003e \"F\",\n        6 =\u003e \"F#\",\n        7 =\u003e \"G\",\n        8 =\u003e \"G#\",\n        9 =\u003e \"A\",\n        10 =\u003e \"A#\",\n        11 =\u003e \"B\",\n        _ =\u003e \"UNKNOWN\",\n    }\n}\n\n/// Returns the minor key name for a given pitch class\npub fn pitch_class_to_minor_key_name(pitch_class: usize) -\u003e String {\n    format!(\"{}m\", pitch_class_to_key_name(pitch_class))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","mod.rs"],"content":"//! Analysis modules for MIDI file processing\n\npub mod auto_tagger;\npub mod bpm_detector;\npub mod key_detector;\npub mod key_profiles;\n\n// Re-export main types\npub use auto_tagger::{AutoTagger, Tag};\npub use bpm_detector::{detect_bpm, BpmDetectionMethod, BpmDetectionResult, BpmMetadata};\npub use key_detector::{detect_key, KeyDetectionResult, ScaleType};\n\n// Tests will be added during Phase 1 of test coverage initiative\n// #[cfg(test)]\n// mod tests;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","hash","blake3.rs"],"content":"//! BLAKE3 hashing module for file content deduplication and integrity verification.\n//!\n//! This is a **Trusty Module** with pure hashing logic.\n//!\n//! # Architecture Pattern\n//!\n//! Core functions are pure (no I/O):\n//! - `calculate_content_hash()` - Pure hash calculation\n//! - `hash_to_hex()` - Pure conversion\n//!\n//! Convenience wrapper (does I/O):\n//! - `calculate_file_hash()` - Reads file and calculates hash\n//!\n//! # Performance\n//!\n//! BLAKE3 provides significant performance improvements over SHA-256:\n//! - **Single-threaded**: ~3,000 MB/s (vs SHA-256 ~400 MB/s)\n//! - **Multi-threaded**: ~10,000 MB/s with parallel tree hashing\n//! - **7x faster** than SHA-256 for typical file sizes\n//!\n//! # Examples\n//!\n//! ```rust\n//! use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n//!\n//! let data = b\"Hello, MIDI Library System!\";\n//! let hash = calculate_content_hash(data);\n//! let hex_string = hash_to_hex(\u0026hash);\n//! println!(\"Hash: {}\", hex_string);\n//! ```\n\nuse std::fs::File;\nuse std::io::{self, Read};\nuse std::path::Path;\nuse thiserror::Error;\n\n/// Hash calculation errors\n#[derive(Error, Debug)]\npub enum HashError {\n    /// File could not be opened or read\n    #[error(\"Failed to read file: {0}\")]\n    IoError(#[from] io::Error),\n\n    /// File path is invalid\n    #[error(\"Invalid file path: {0}\")]\n    InvalidPath(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, HashError\u003e;\n\n/// Calculate BLAKE3 hash of byte content.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `data` - Byte slice to hash\n///\n/// # Returns\n///\n/// 32-byte BLAKE3 hash\n///\n/// # Performance\n///\n/// - Single-threaded: ~3,000 MB/s\n/// - For data larger than 128 KB, BLAKE3 automatically uses parallel tree hashing\n/// - Significantly faster than SHA-256 (~400 MB/s)\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::calculate_content_hash;\n///\n/// let data = b\"MIDI file content\";\n/// let hash = calculate_content_hash(data);\n/// assert_eq!(hash.len(), 32);\n/// ```\npub fn calculate_content_hash(data: \u0026[u8]) -\u003e [u8; 32] {\n    // BLAKE3 uses parallel tree hashing automatically for large inputs\n    // This provides multi-threaded performance without explicit parallelism\n    blake3::hash(data).into()\n}\n\n/// Calculate BLAKE3 hash of a file.\n///\n/// This is a **convenience wrapper** that performs file I/O.\n/// For pure hashing logic, use `calculate_content_hash()`.\n///\n/// # Arguments\n///\n/// * `path` - Path to file to hash\n///\n/// # Returns\n///\n/// 32-byte BLAKE3 hash or error if file cannot be read\n///\n/// # Errors\n///\n/// - `HashError::IoError` - File cannot be opened or read\n/// - `HashError::InvalidPath` - Path is invalid or does not exist\n///\n/// # Performance\n///\n/// For large files (\u003e10 MB), consider using memory-mapped files for better performance.\n/// This implementation reads the file into memory, which is optimal for files \u003c100 MB.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use std::path::Path;\n/// use pipeline::core::hash::blake3::calculate_file_hash;\n///\n/// let path = Path::new(\"test.mid\");\n/// let hash = calculate_file_hash(path)?;\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn calculate_file_hash(path: \u0026Path) -\u003e Result\u003c[u8; 32]\u003e {\n    // Validate path\n    if !path.exists() {\n        return Err(HashError::InvalidPath(\n            format!(\"File does not exist: {}\", path.display())\n        ));\n    }\n\n    if !path.is_file() {\n        return Err(HashError::InvalidPath(\n            format!(\"Path is not a file: {}\", path.display())\n        ));\n    }\n\n    // Open file\n    let mut file = File::open(path)?;\n\n    // For small to medium files (\u003c100 MB), read entire file into memory\n    // This is fastest approach for most MIDI files which are typically \u003c10 MB\n    let mut buffer = Vec::new();\n    file.read_to_end(\u0026mut buffer)?;\n\n    // Use pure hash function\n    Ok(calculate_content_hash(\u0026buffer))\n}\n\n/// Convert 32-byte hash to hexadecimal string.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `hash` - 32-byte hash to convert\n///\n/// # Returns\n///\n/// 64-character lowercase hexadecimal string\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n///\n/// let data = b\"test\";\n/// let hash = calculate_content_hash(data);\n/// let hex = hash_to_hex(\u0026hash);\n///\n/// assert_eq!(hex.len(), 64); // 32 bytes = 64 hex characters\n/// assert!(hex.chars().all(|c| c.is_ascii_hexdigit()));\n/// ```\npub fn hash_to_hex(hash: \u0026[u8; 32]) -\u003e String {\n    // Use blake3's built-in hex encoding for efficiency\n    blake3::Hash::from(*hash).to_hex().to_string()\n}\n\n/// Convert hexadecimal string back to 32-byte hash.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `hex` - 64-character hexadecimal string\n///\n/// # Returns\n///\n/// 32-byte hash or error if hex string is invalid\n///\n/// # Errors\n///\n/// Returns error if:\n/// - String is not exactly 64 characters\n/// - String contains non-hexadecimal characters\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::{hash_to_hex, hex_to_hash};\n///\n/// let original = [0u8; 32];\n/// let hex = hash_to_hex(\u0026original);\n/// let decoded = hex_to_hash(\u0026hex)?;\n/// assert_eq!(original, decoded);\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn hex_to_hash(hex: \u0026str) -\u003e Result\u003c[u8; 32]\u003e {\n    if hex.len() != 64 {\n        return Err(HashError::InvalidPath(\n            format!(\"Hex string must be exactly 64 characters, got {}\", hex.len())\n        ));\n    }\n\n    let mut hash = [0u8; 32];\n    for i in 0..32 {\n        let byte_str = \u0026hex[i * 2..i * 2 + 2];\n        hash[i] = u8::from_str_radix(byte_str, 16)\n            .map_err(|_| HashError::InvalidPath(\n                format!(\"Invalid hex character in string: {}\", byte_str)\n            ))?;\n    }\n\n    Ok(hash)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n\n    #[test]\n    fn test_calculate_content_hash_empty() {\n        let data = b\"\";\n        let hash = calculate_content_hash(data);\n\n        // BLAKE3 hash of empty string (known value)\n        let expected = hex_to_hash(\"af1349b9f5f9a1a6a0404dea36dcc9499bcb25c9adc112b7cc9a93cae41f3262\").unwrap();\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_hello_world() {\n        let data = b\"Hello, World!\";\n        let hash = calculate_content_hash(data);\n\n        // BLAKE3 hash of \"Hello, World!\" (verified with blake3 crate)\n        let expected = hex_to_hash(\"288a86a79f20a3d6dccdca7713beaed178798296bdfa7913fa2a62d9727bf8f8\").unwrap();\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_consistency() {\n        let data = b\"Consistent hashing test\";\n\n        let hash1 = calculate_content_hash(data);\n        let hash2 = calculate_content_hash(data);\n        let hash3 = calculate_content_hash(data);\n\n        // Same input must always produce same hash\n        assert_eq!(hash1, hash2);\n        assert_eq!(hash2, hash3);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_different_inputs() {\n        let data1 = b\"First input\";\n        let data2 = b\"Second input\";\n\n        let hash1 = calculate_content_hash(data1);\n        let hash2 = calculate_content_hash(data2);\n\n        // Different inputs must produce different hashes\n        assert_ne!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_large_data() {\n        // Test with 1 MB of data (triggers parallel tree hashing)\n        let data = vec![0xAB; 1_000_000];\n        let hash = calculate_content_hash(\u0026data);\n\n        // Just verify we get a valid hash\n        assert_eq!(hash.len(), 32);\n\n        // Verify consistency\n        let hash2 = calculate_content_hash(\u0026data);\n        assert_eq!(hash, hash2);\n    }\n\n    #[test]\n    fn test_hash_to_hex() {\n        let hash = [0u8; 32]; // All zeros\n        let hex = hash_to_hex(\u0026hash);\n\n        assert_eq!(hex.len(), 64);\n        assert_eq!(hex, \"0\".repeat(64));\n    }\n\n    #[test]\n    fn test_hash_to_hex_mixed_values() {\n        let hash = [\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n        ];\n        let hex = hash_to_hex(\u0026hash);\n\n        assert_eq!(hex.len(), 64);\n        assert_eq!(\n            hex,\n            \"0123456789abcdeffedcba9876543210\\\n             0123456789abcdeffedcba9876543210\"\n        );\n    }\n\n    #[test]\n    fn test_hex_to_hash_valid() {\n        let hex = \"0123456789abcdef\\\n                   fedcba9876543210\\\n                   0123456789abcdef\\\n                   fedcba9876543210\";\n        let hash = hex_to_hash(hex).unwrap();\n\n        let expected = [\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n        ];\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_hex_to_hash_roundtrip() {\n        let original = [0xAB; 32];\n        let hex = hash_to_hex(\u0026original);\n        let decoded = hex_to_hash(\u0026hex).unwrap();\n\n        assert_eq!(original, decoded);\n    }\n\n    #[test]\n    fn test_hex_to_hash_invalid_length() {\n        let hex = \"too_short\";\n        let result = hex_to_hash(hex);\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"64 characters\"));\n    }\n\n    #[test]\n    fn test_hex_to_hash_invalid_characters() {\n        let hex = \"0123456789abcdefg123456789abcdef0123456789abcdef0123456789abcdef\"; // 'g' is invalid\n        let result = hex_to_hash(hex);\n\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_calculate_file_hash_nonexistent() {\n        let path = Path::new(\"/nonexistent/file.mid\");\n        let result = calculate_file_hash(path);\n\n        assert!(result.is_err());\n        let error = result.unwrap_err();\n        assert!(matches!(error, HashError::InvalidPath(_)));\n    }\n\n    #[test]\n    fn test_calculate_file_hash_directory() {\n        // Try to hash a directory (should fail)\n        let path = Path::new(\"/tmp\");\n        let result = calculate_file_hash(path);\n\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_calculate_file_hash_real_file() {\n        // Create temporary test file\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"blake3_test.txt\");\n\n        // Write test data\n        let test_data = b\"Test MIDI file content for hashing\";\n        fs::write(\u0026test_file, test_data).unwrap();\n\n        // Calculate hash from file\n        let file_hash = calculate_file_hash(\u0026test_file).unwrap();\n\n        // Calculate hash from data directly\n        let content_hash = calculate_content_hash(test_data);\n\n        // Should match\n        assert_eq!(file_hash, content_hash);\n\n        // Cleanup\n        fs::remove_file(\u0026test_file).unwrap();\n    }\n\n    #[test]\n    fn test_calculate_file_hash_consistency() {\n        // Create temporary test file\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"blake3_consistency_test.txt\");\n\n        // Write test data\n        let test_data = b\"Consistency test for file hashing\";\n        fs::write(\u0026test_file, test_data).unwrap();\n\n        // Calculate hash multiple times\n        let hash1 = calculate_file_hash(\u0026test_file).unwrap();\n        let hash2 = calculate_file_hash(\u0026test_file).unwrap();\n        let hash3 = calculate_file_hash(\u0026test_file).unwrap();\n\n        // All hashes must match\n        assert_eq!(hash1, hash2);\n        assert_eq!(hash2, hash3);\n\n        // Cleanup\n        fs::remove_file(\u0026test_file).unwrap();\n    }\n\n    #[test]\n    fn test_integration_full_workflow() {\n        // Test the complete workflow: data -\u003e hash -\u003e hex -\u003e hash -\u003e verify\n        let original_data = b\"Complete integration test for BLAKE3 hashing\";\n\n        // Step 1: Calculate hash\n        let hash = calculate_content_hash(original_data);\n        assert_eq!(hash.len(), 32);\n\n        // Step 2: Convert to hex\n        let hex = hash_to_hex(\u0026hash);\n        assert_eq!(hex.len(), 64);\n\n        // Step 3: Convert back to hash\n        let decoded_hash = hex_to_hash(\u0026hex).unwrap();\n        assert_eq!(hash, decoded_hash);\n\n        // Step 4: Verify hash matches content\n        let verification_hash = calculate_content_hash(original_data);\n        assert_eq!(hash, verification_hash);\n    }\n\n    #[test]\n    fn test_hash_collision_resistance() {\n        // Test that very similar inputs produce different hashes\n        let data1 = b\"test1\";\n        let data2 = b\"test2\";\n\n        let hash1 = calculate_content_hash(data1);\n        let hash2 = calculate_content_hash(data2);\n\n        // Even single bit difference should produce completely different hash\n        assert_ne!(hash1, hash2);\n\n        // Count number of different bytes (should be high due to avalanche effect)\n        let differences = hash1.iter()\n            .zip(hash2.iter())\n            .filter(|(a, b)| a != b)\n            .count();\n\n        // Expect at least 50% of bytes to be different (avalanche effect)\n        assert!(differences \u003e 16, \"Only {} bytes different\", differences);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","hash","mod.rs"],"content":"//! Hash calculation module for file content deduplication.\n//!\n//! This module provides BLAKE3 hashing functionality for calculating\n//! file content hashes to detect and prevent duplicate files in the\n//! MIDI library system.\n//!\n//! # Architecture Pattern: Trusty Module\n//!\n//! This module follows the **Trusty Module** pattern:\n//! - Pure, stateless hash calculation functions\n//! - Comprehensive test coverage\n//! - No side effects (except convenience file I/O wrapper)\n//! - Single responsibility: hash calculation\n//!\n//! # Performance\n//!\n//! BLAKE3 provides 7x performance improvement over SHA-256:\n//! - Single-threaded: ~3,000 MB/s (vs SHA-256 ~400 MB/s)\n//! - Multi-threaded: ~10,000 MB/s (automatic tree hashing)\n//!\n//! # Usage\n//!\n//! ```rust\n//! use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n//!\n//! let data = b\"MIDI file content\";\n//! let hash = calculate_content_hash(data);\n//! let hex_string = hash_to_hex(\u0026hash);\n//! ```\n\npub mod blake3;\n\n// Re-export commonly used items\npub use self::blake3::{\n    calculate_content_hash,\n    calculate_file_hash,\n    hash_to_hex,\n    hex_to_hash,\n    HashError,\n    Result,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","mod.rs"],"content":"pub mod analysis;\npub mod hash;\n// pub mod midi; // Moved to shared library (midi-library-shared)\npub mod naming;\npub mod normalization;\npub mod performance;\npub mod splitting;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","generator.rs"],"content":"//! Filename Generator\n//!\n//! Generates intelligent filenames from MIDI file metadata.\n\nuse crate::core::analysis::{BpmDetectionResult, KeyDetectionResult};\nuse crate::core::naming::{sanitizer, templates};\n\n/// Configuration for filename generation\n#[derive(Debug, Clone)]\npub struct NamingConfig {\n    pub template: templates::NamingTemplate,\n    pub include_description: bool,\n    pub max_description_length: usize,\n}\n\nimpl Default for NamingConfig {\n    fn default() -\u003e Self {\n        Self {\n            template: templates::NamingTemplate::Standard,\n            include_description: true,\n            max_description_length: 50,\n        }\n    }\n}\n\n/// Input metadata for filename generation\n#[derive(Debug, Clone)]\npub struct FileMetadata {\n    pub category: String,\n    pub bpm: f64,\n    pub key: String,\n    pub description: Option\u003cString\u003e,\n    pub file_id: String,\n}\n\n/// Generates a new filename from metadata\n///\n/// # Arguments\n/// * `metadata` - File metadata\n/// * `config` - Naming configuration\n///\n/// # Returns\n/// * Generated filename with .mid extension\n///\n/// # Examples\n/// ```\n/// use pipeline::core::naming::generator::*;\n///\n/// let metadata = FileMetadata {\n///     category: \"BASS\".to_string(),\n///     bpm: 140.0,\n///     key: \"Cm\".to_string(),\n///     description: Some(\"Deep Rolling\".to_string()),\n///     file_id: \"001\".to_string(),\n/// };\n///\n/// let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n/// // Result: \"BASS_Cm_140BPM_Deep_Rolling_001.mid\"\n/// ```\npub fn generate_filename(metadata: \u0026FileMetadata, config: \u0026NamingConfig) -\u003e String {\n    // Sanitize category\n    let category = sanitizer::sanitize_filename(\u0026metadata.category.to_uppercase());\n\n    // Sanitize key\n    let key = sanitizer::sanitize_filename(\u0026metadata.key);\n\n    // Process description\n    let description = if config.include_description {\n        process_description(\u0026metadata.description, config.max_description_length)\n    } else {\n        String::new()\n    };\n\n    // Apply template\n    let filename_base = templates::apply_template(\n        \u0026config.template,\n        \u0026category,\n        \u0026key,\n        metadata.bpm,\n        \u0026description,\n        \u0026metadata.file_id,\n    );\n\n    // Final sanitization\n    let sanitized = sanitizer::sanitize_filename(\u0026filename_base);\n\n    // Ensure .mid extension\n    sanitizer::ensure_mid_extension(\u0026sanitized)\n}\n\n/// Processes description text\nfn process_description(description: \u0026Option\u003cString\u003e, max_length: usize) -\u003e String {\n    match description {\n        None =\u003e String::new(),\n        Some(desc) =\u003e {\n            // First sanitize to convert spaces to underscores\n            let sanitized = sanitizer::sanitize_filename(desc);\n\n            // Then clean filler words\n            let cleaned = sanitizer::clean_description(\u0026sanitized);\n\n            // Truncate if needed\n            if cleaned.len() \u003e max_length {\n                cleaned[..max_length].to_string()\n            } else {\n                cleaned\n            }\n        }\n    }\n}\n\n/// Generates filename from analysis results (convenience function)\n///\n/// # Arguments\n/// * `category` - File category (BASS, KICK, etc.)\n/// * `bpm_result` - BPM detection result\n/// * `key_result` - Key detection result\n/// * `original_filename` - Original filename to extract description from\n/// * `file_id` - Unique file identifier\n/// * `config` - Naming configuration\n///\n/// # Returns\n/// * Generated filename with .mid extension\npub fn generate_from_analysis(\n    category: \u0026str,\n    bpm_result: \u0026BpmDetectionResult,\n    key_result: \u0026KeyDetectionResult,\n    original_filename: \u0026str,\n    file_id: \u0026str,\n    config: \u0026NamingConfig,\n) -\u003e String {\n    // Extract description from original filename if useful\n    let description = extract_useful_description(original_filename);\n\n    let metadata = FileMetadata {\n        category: category.to_string(),\n        bpm: bpm_result.bpm,\n        key: key_result.key.clone(),\n        description,\n        file_id: file_id.to_string(),\n    };\n\n    generate_filename(\u0026metadata, config)\n}\n\n/// Extracts useful parts from original filename\nfn extract_useful_description(original_filename: \u0026str) -\u003e Option\u003cString\u003e {\n    // Remove extension\n    let without_ext = original_filename\n        .trim_end_matches(\".mid\")\n        .trim_end_matches(\".MID\");\n\n    // Remove common prefixes\n    let prefixes = [\"MIDI_\", \"Track_\", \"File_\", \"Song_\"];\n    let mut cleaned = without_ext.to_string();\n\n    for prefix in \u0026prefixes {\n        if cleaned.starts_with(prefix) {\n            cleaned = cleaned[prefix.len()..].to_string();\n        }\n    }\n\n    // If cleaned version is meaningful, use it\n    if !cleaned.is_empty() \u0026\u0026 cleaned.len() \u003e 3 {\n        Some(cleaned)\n    } else {\n        None\n    }\n}\n\n/// Handles naming conflicts by appending counter\n///\n/// # Arguments\n/// * `base_filename` - The desired filename\n/// * `existing_files` - List of existing filenames to check against\n///\n/// # Returns\n/// * Unique filename that doesn't conflict with existing files\npub fn resolve_naming_conflict(base_filename: \u0026str, existing_files: \u0026[String]) -\u003e String {\n    let without_ext = base_filename.trim_end_matches(\".mid\");\n\n    if !existing_files.contains(\u0026base_filename.to_string()) {\n        return base_filename.to_string();\n    }\n\n    // Try incrementing counter\n    for i in 1..1000 {\n        let candidate = format!(\"{}_v{}.mid\", without_ext, i);\n        if !existing_files.contains(\u0026candidate) {\n            return candidate;\n        }\n    }\n\n    // Fallback with timestamp\n    // Note: SystemTime before Unix epoch is impossible on modern systems,\n    // but we handle it gracefully per architecture requirements\n    let timestamp = std::time::SystemTime::now()\n        .duration_since(std::time::UNIX_EPOCH)\n        .unwrap_or_else(|_| std::time::Duration::from_secs(0))\n        .as_secs();\n\n    format!(\"{}_{}.mid\", without_ext, timestamp)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_generate_filename_standard() {\n        let metadata = FileMetadata {\n            category: \"BASS\".to_string(),\n            bpm: 140.5,\n            key: \"Cm\".to_string(),\n            description: Some(\"Deep Rolling\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        assert!(filename.starts_with(\"BASS_Cm_140BPM\"));\n        assert!(filename.ends_with(\".mid\"));\n    }\n\n    #[test]\n    fn test_generate_filename_no_description() {\n        let metadata = FileMetadata {\n            category: \"KICK\".to_string(),\n            bpm: 128.0,\n            key: \"C\".to_string(),\n            description: None,\n            file_id: \"042\".to_string(),\n        };\n\n        let config = NamingConfig {\n            include_description: false,\n            ..Default::default()\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026config);\n\n        // Sanitizer removes double underscores, so result is clean\n        assert_eq!(filename, \"KICK_C_128BPM_042.mid\");\n    }\n\n    #[test]\n    fn test_extract_useful_description() {\n        assert_eq!(\n            extract_useful_description(\"MIDI_Cool_Bass.mid\"),\n            Some(\"Cool_Bass\".to_string())\n        );\n\n        assert_eq!(\n            extract_useful_description(\"Track_1.mid\"),\n            None // Too short\n        );\n    }\n\n    #[test]\n    fn test_extract_no_prefix() {\n        assert_eq!(\n            extract_useful_description(\"Amazing_Lead.mid\"),\n            Some(\"Amazing_Lead\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_resolve_naming_conflict() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![base.to_string()];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_ne!(resolved, base);\n        assert!(resolved.ends_with(\".mid\"));\n        assert!(resolved.contains(\"_v1\"));\n    }\n\n    #[test]\n    fn test_resolve_no_conflict() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_eq!(resolved, base);\n    }\n\n    #[test]\n    fn test_category_uppercase() {\n        let metadata = FileMetadata {\n            category: \"bass\".to_string(), // lowercase\n            bpm: 140.0,\n            key: \"Cm\".to_string(),\n            description: None,\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        assert!(filename.starts_with(\"BASS\")); // Should be uppercase\n    }\n\n    #[test]\n    fn test_process_description_truncation() {\n        let long_desc = Some(\"A\".repeat(100));\n\n        let result = process_description(\u0026long_desc, 20);\n\n        assert!(result.len() \u003c= 20);\n    }\n\n    #[test]\n    fn test_process_description_none() {\n        let result = process_description(\u0026None, 50);\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_compact_template() {\n        let metadata = FileMetadata {\n            category: \"KICK\".to_string(),\n            bpm: 128.0,\n            key: \"C\".to_string(),\n            description: Some(\"Heavy\".to_string()),\n            file_id: \"042\".to_string(),\n        };\n\n        let config = NamingConfig {\n            template: templates::NamingTemplate::Compact,\n            include_description: true,\n            max_description_length: 50,\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026config);\n\n        // Compact template doesn't include description in the template\n        assert_eq!(filename, \"KICK_C_128BPM_042.mid\");\n    }\n\n    #[test]\n    fn test_invalid_characters_in_metadata() {\n        let metadata = FileMetadata {\n            category: \"BA\u003cSS\u003e\".to_string(),\n            bpm: 140.0,\n            key: \"C:m\".to_string(),\n            description: Some(\"Deep/Rolling*\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        // Should sanitize all invalid characters\n        assert!(!filename.contains('\u003c'));\n        assert!(!filename.contains('\u003e'));\n        assert!(!filename.contains(':'));\n        assert!(!filename.contains('/'));\n        assert!(!filename.contains('*'));\n    }\n\n    #[test]\n    fn test_description_with_filler_words() {\n        let metadata = FileMetadata {\n            category: \"BASS\".to_string(),\n            bpm: 140.0,\n            key: \"Cm\".to_string(),\n            description: Some(\"the new bass and track file\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        println!(\"Generated filename: {}\", filename);\n\n        // Filler words should be removed (the, new, and, track, file)\n        // Result should have \"bass\" but not the filler words\n        assert!(filename.contains(\"bass\"));\n    }\n\n    #[test]\n    fn test_multiple_conflicts() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![\n            base.to_string(),\n            \"BASS_Cm_140BPM_Deep_001_v1.mid\".to_string(),\n            \"BASS_Cm_140BPM_Deep_001_v2.mid\".to_string(),\n        ];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_eq!(resolved, \"BASS_Cm_140BPM_Deep_001_v3.mid\");\n    }\n\n    #[test]\n    fn test_extract_empty_filename() {\n        assert_eq!(extract_useful_description(\"\"), None);\n        assert_eq!(extract_useful_description(\".mid\"), None);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","mod.rs"],"content":"//! Intelligent filename generation\n\npub mod generator;\npub mod sanitizer;\npub mod templates;\n\n// Re-export main types\npub use generator::{\n    generate_filename, generate_from_analysis, resolve_naming_conflict, FileMetadata, NamingConfig,\n};\npub use templates::NamingTemplate;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","sanitizer.rs"],"content":"//! Filename Sanitization\n//!\n//! Ensures filenames are valid across all operating systems.\n\n/// Sanitizes a string for use in filenames\n///\n/// # Rules\n/// - Removes/replaces invalid characters\n/// - Limits length to 255 characters\n/// - Removes leading/trailing spaces\n/// - Converts to ASCII where possible\n///\n/// # Arguments\n/// * `input` - String to sanitize\n///\n/// # Returns\n/// * Sanitized string safe for filenames\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::naming::sanitizer::sanitize_filename;\n///\n/// let sanitized = sanitize_filename(\"my file\u003cname\u003e\");\n/// assert_eq!(sanitized, \"my_file_name_\");\n/// ```\npub fn sanitize_filename(input: \u0026str) -\u003e String {\n    let mut sanitized = input.to_string();\n\n    // Remove/replace invalid characters\n    sanitized = sanitized\n        .chars()\n        .map(|c| match c {\n            // Windows reserved characters\n            '\u003c' | '\u003e' | ':' | '\"' | '/' | '\\\\' | '|' | '?' | '*' =\u003e '_',\n            // Control characters\n            c if c.is_control() =\u003e '_',\n            // Keep valid characters\n            c =\u003e c,\n        })\n        .collect();\n\n    // Remove leading/trailing whitespace\n    sanitized = sanitized.trim().to_string();\n\n    // Replace multiple spaces with single space\n    while sanitized.contains(\"  \") {\n        sanitized = sanitized.replace(\"  \", \" \");\n    }\n\n    // Replace spaces with underscores for consistency\n    sanitized = sanitized.replace(' ', \"_\");\n\n    // Remove multiple underscores\n    while sanitized.contains(\"__\") {\n        sanitized = sanitized.replace(\"__\", \"_\");\n    }\n\n    // Limit length (leave room for extension)\n    if sanitized.len() \u003e 250 {\n        sanitized.truncate(250);\n    }\n\n    // Remove leading/trailing underscores\n    sanitized = sanitized.trim_matches('_').to_string();\n\n    // If empty after sanitization, use default\n    if sanitized.is_empty() {\n        sanitized = \"untitled\".to_string();\n    }\n\n    sanitized\n}\n\n/// Removes common filler words from descriptions\n///\n/// # Arguments\n/// * `description` - Description text to clean\n///\n/// # Returns\n/// * Description with filler words removed\npub fn clean_description(description: \u0026str) -\u003e String {\n    let filler_words = [\n        \"untitled\", \"new\", \"midi\", \"file\", \"song\", \"track\", \"the\", \"a\", \"an\", \"and\", \"or\", \"but\",\n    ];\n\n    let words: Vec\u003c\u0026str\u003e = description\n        .split('_')\n        .filter(|word| {\n            let lower = word.to_lowercase();\n            !filler_words.contains(\u0026lower.as_str()) \u0026\u0026 !lower.is_empty()\n        })\n        .collect();\n\n    words.join(\"_\")\n}\n\n/// Ensures filename has .mid extension\n///\n/// # Arguments\n/// * `filename` - Filename to check\n///\n/// # Returns\n/// * Filename with .mid extension\npub fn ensure_mid_extension(filename: \u0026str) -\u003e String {\n    if filename.to_lowercase().ends_with(\".mid\") {\n        filename.to_string()\n    } else {\n        format!(\"{}.mid\", filename)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_remove_invalid_characters() {\n        let input = \"test\u003cfile\u003ename:with|invalid*chars\";\n        let output = sanitize_filename(input);\n\n        assert!(!output.contains('\u003c'));\n        assert!(!output.contains('\u003e'));\n        assert!(!output.contains(':'));\n        assert!(!output.contains('|'));\n        assert!(!output.contains('*'));\n    }\n\n    #[test]\n    fn test_replace_spaces() {\n        let input = \"test file name\";\n        let output = sanitize_filename(input);\n\n        assert_eq!(output, \"test_file_name\");\n    }\n\n    #[test]\n    fn test_remove_multiple_underscores() {\n        let input = \"test___file___name\";\n        let output = sanitize_filename(input);\n\n        assert_eq!(output, \"test_file_name\");\n    }\n\n    #[test]\n    fn test_length_limit() {\n        let input = \"a\".repeat(300);\n        let output = sanitize_filename(\u0026input);\n\n        assert!(output.len() \u003c= 250);\n    }\n\n    #[test]\n    fn test_empty_input() {\n        let output = sanitize_filename(\"\");\n        assert_eq!(output, \"untitled\");\n    }\n\n    #[test]\n    fn test_clean_description() {\n        let input = \"the_new_bass_and_lead_file\";\n        let output = clean_description(input);\n\n        // Should remove filler words\n        assert_eq!(output, \"bass_lead\");\n    }\n\n    #[test]\n    fn test_ensure_extension() {\n        assert_eq!(ensure_mid_extension(\"test\"), \"test.mid\");\n        assert_eq!(ensure_mid_extension(\"test.mid\"), \"test.mid\");\n        assert_eq!(ensure_mid_extension(\"test.MID\"), \"test.MID\");\n    }\n\n    #[test]\n    fn test_trim_leading_trailing_underscores() {\n        let input = \"___test___\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"test\");\n    }\n\n    #[test]\n    fn test_control_characters() {\n        let input = \"test\\n\\r\\tfile\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"test_file\");\n    }\n\n    #[test]\n    fn test_only_invalid_characters() {\n        let input = \"\u003c\u003e?*|\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"untitled\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","templates.rs"],"content":"//! Naming Templates\n//!\n//! Provides different template formats for filename generation.\n\n/// Naming template format\n#[derive(Debug, Clone, PartialEq, Default)]\npub enum NamingTemplate {\n    /// {CATEGORY}_{KEY}_{BPM}BPM_{DESCRIPTION}_{ID}\n    #[default]\n    Standard,\n\n    /// {CATEGORY}_{KEY}_{BPM}BPM_{ID}\n    Compact,\n\n    /// {BPM}BPM_{KEY}_{CATEGORY}_{DESCRIPTION}\n    BpmFirst,\n\n    /// Custom template with placeholders\n    Custom(String),\n}\n\n/// Applies template to metadata\n///\n/// # Arguments\n/// * `template` - The naming template to use\n/// * `category` - File category (e.g., BASS, KICK, CHORD)\n/// * `key` - Musical key (e.g., C, Am, F#)\n/// * `bpm` - Beats per minute\n/// * `description` - Optional description text\n/// * `id` - File identifier\n///\n/// # Returns\n/// * Formatted filename string (without extension)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::naming::templates::{NamingTemplate, apply_template};\n///\n/// let result = apply_template(\n///     \u0026NamingTemplate::Standard,\n///     \"BASS\",\n///     \"Cm\",\n///     140.0,\n///     \"Deep_Rolling\",\n///     \"001\"\n/// );\n/// assert_eq!(result, \"BASS_Cm_140BPM_Deep_Rolling_001\");\n/// ```\npub fn apply_template(\n    template: \u0026NamingTemplate,\n    category: \u0026str,\n    key: \u0026str,\n    bpm: f64,\n    description: \u0026str,\n    id: \u0026str,\n) -\u003e String {\n    match template {\n        NamingTemplate::Standard =\u003e {\n            format!(\"{}_{}_{:.0}BPM_{}_{}\", category, key, bpm, description, id)\n        }\n\n        NamingTemplate::Compact =\u003e {\n            format!(\"{}_{}_{:.0}BPM_{}\", category, key, bpm, id)\n        }\n\n        NamingTemplate::BpmFirst =\u003e {\n            format!(\"{:.0}BPM_{}_{}_{}\", bpm, key, category, description)\n        }\n\n        NamingTemplate::Custom(template_str) =\u003e template_str\n            .replace(\"{CATEGORY}\", category)\n            .replace(\"{KEY}\", key)\n            .replace(\"{BPM}\", \u0026format!(\"{:.0}\", bpm))\n            .replace(\"{DESCRIPTION}\", description)\n            .replace(\"{ID}\", id),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_standard_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::Standard,\n            \"BASS\",\n            \"Cm\",\n            140.0,\n            \"Deep_Rolling\",\n            \"001\",\n        );\n\n        assert_eq!(result, \"BASS_Cm_140BPM_Deep_Rolling_001\");\n    }\n\n    #[test]\n    fn test_compact_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::Compact,\n            \"KICK\",\n            \"C\",\n            128.0,\n            \"\", // Description ignored in compact\n            \"042\",\n        );\n\n        assert_eq!(result, \"KICK_C_128BPM_042\");\n    }\n\n    #[test]\n    fn test_bpm_first_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::BpmFirst,\n            \"LEAD\",\n            \"Am\",\n            150.0,\n            \"Energetic\",\n            \"123\",\n        );\n\n        assert_eq!(result, \"150BPM_Am_LEAD_Energetic\");\n    }\n\n    #[test]\n    fn test_custom_template() {\n        let custom = NamingTemplate::Custom(\"{BPM}bpm_{KEY}_{CATEGORY}\".to_string());\n\n        let result = apply_template(\n            \u0026custom, \"LEAD\", \"Am\", 150.0, \"\", // Not used in this template\n            \"\", // Not used in this template\n        );\n\n        assert_eq!(result, \"150bpm_Am_LEAD\");\n    }\n\n    #[test]\n    fn test_custom_template_with_all_placeholders() {\n        let custom =\n            NamingTemplate::Custom(\"{ID}_{CATEGORY}_{KEY}_{BPM}_{DESCRIPTION}\".to_string());\n\n        let result = apply_template(\u0026custom, \"BASS\", \"Dm\", 120.0, \"Groovy\", \"999\");\n\n        assert_eq!(result, \"999_BASS_Dm_120_Groovy\");\n    }\n\n    #[test]\n    fn test_default_template() {\n        let default = NamingTemplate::default();\n        assert_eq!(default, NamingTemplate::Standard);\n    }\n\n    #[test]\n    fn test_bpm_rounding() {\n        let result = apply_template(\u0026NamingTemplate::Standard, \"KICK\", \"C\", 127.8, \"desc\", \"001\");\n\n        assert!(result.contains(\"128BPM\"));\n    }\n\n    #[test]\n    fn test_empty_description() {\n        let result = apply_template(\u0026NamingTemplate::Standard, \"BASS\", \"C\", 120.0, \"\", \"001\");\n\n        assert_eq!(result, \"BASS_C_120BPM__001\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","normalization","filename.rs"],"content":"//! Filename normalization utilities for MIDI files.\n//!\n//! This module provides pure functions for normalizing MIDI filenames,\n//! specifically converting `.midi` extensions to `.mid` and replacing\n//! spaces with underscores.\n//!\n//! # Archetype: Trusty Module\n//!\n//! This is a pure logic module with NO side effects:\n//! -  NO file I/O\n//! -  NO database access\n//! -  NO printing/logging\n//! -  Pure functions only\n//! -  Comprehensive tests\n//!\n//! # Examples\n//!\n//! ```\n//! use pipeline::core::normalization::filename::normalize_midi_filename;\n//!\n//! // Extension normalization\n//! let normalized = normalize_midi_filename(\"song.midi\");\n//! assert_eq!(normalized, \"song.mid\");\n//!\n//! // Space replacement\n//! let normalized = normalize_midi_filename(\"my song.mid\");\n//! assert_eq!(normalized, \"my_song.mid\");\n//!\n//! // Both transformations\n//! let normalized = normalize_midi_filename(\"Cool Track.midi\");\n//! assert_eq!(normalized, \"Cool_Track.mid\");\n//! ```\n\n/// Normalize a MIDI filename by converting `.midi` extension to `.mid`\n/// and replacing all spaces with underscores.\n///\n/// This function performs two normalizations:\n/// 1. Converts `.midi` extension to `.mid` (case-insensitive)\n/// 2. Replaces all spaces ` ` with underscores `_`\n///\n/// # Arguments\n///\n/// * `filename` - The filename to normalize (without path, just the filename)\n///\n/// # Returns\n///\n/// A new `String` with the normalized filename.\n///\n/// # Examples\n///\n/// ```\n/// # use pipeline::core::normalization::filename::normalize_midi_filename;\n/// // Convert .midi to .mid\n/// assert_eq!(normalize_midi_filename(\"song.midi\"), \"song.mid\");\n///\n/// // Replace spaces with underscores\n/// assert_eq!(normalize_midi_filename(\"my song.mid\"), \"my_song.mid\");\n///\n/// // Both transformations\n/// assert_eq!(normalize_midi_filename(\"Cool Track.midi\"), \"Cool_Track.mid\");\n///\n/// // Case insensitive extension\n/// assert_eq!(normalize_midi_filename(\"song.MIDI\"), \"song.mid\");\n///\n/// // Multiple spaces become multiple underscores\n/// assert_eq!(normalize_midi_filename(\"jazz  blues.midi\"), \"jazz__blues.mid\");\n///\n/// // Already normalized - unchanged\n/// assert_eq!(normalize_midi_filename(\"song.mid\"), \"song.mid\");\n///\n/// // Preserve other special characters\n/// assert_eq!(normalize_midi_filename(\"my-song_123.midi\"), \"my-song_123.mid\");\n/// ```\npub fn normalize_midi_filename(filename: \u0026str) -\u003e String {\n    // Step 1: Normalize extension (.midi -\u003e .mid)\n    let extension_normalized = if let Some(name_without_ext) = strip_midi_extension(filename) {\n        format!(\"{}.mid\", name_without_ext)\n    } else {\n        filename.to_string()\n    };\n\n    // Step 2: Replace all spaces with underscores\n    extension_normalized.replace(' ', \"_\")\n}\n\n/// Check if a filename needs normalization.\n///\n/// Returns `true` if the filename:\n/// - Has a `.midi` extension (case-insensitive) that should be converted to `.mid`, OR\n/// - Contains spaces that should be replaced with underscores\n///\n/// # Arguments\n///\n/// * `filename` - The filename to check\n///\n/// # Returns\n///\n/// `true` if the filename needs normalization, `false` otherwise.\n///\n/// # Examples\n///\n/// ```\n/// # use pipeline::core::normalization::filename::needs_normalization;\n/// // Has .midi extension\n/// assert!(needs_normalization(\"song.midi\"));\n/// assert!(needs_normalization(\"song.MIDI\"));\n///\n/// // Has spaces\n/// assert!(needs_normalization(\"my song.mid\"));\n/// assert!(needs_normalization(\"Cool Track.mp3\"));\n///\n/// // Has both\n/// assert!(needs_normalization(\"my song.midi\"));\n///\n/// // Already normalized\n/// assert!(!needs_normalization(\"song.mid\"));\n/// assert!(!needs_normalization(\"my_song.mid\"));\n/// ```\npub fn needs_normalization(filename: \u0026str) -\u003e bool {\n    // Check if has .midi extension OR contains spaces\n    strip_midi_extension(filename).is_some() || filename.contains(' ')\n}\n\n/// Strip `.midi` extension from filename if present (case-insensitive).\n///\n/// This is an internal helper function that checks if a filename ends with\n/// `.midi` (in any case combination) and returns the filename without the\n/// extension if found.\n///\n/// # Arguments\n///\n/// * `filename` - The filename to process\n///\n/// # Returns\n///\n/// `Some(\u0026str)` containing the filename without `.midi` extension if found,\n/// `None` otherwise.\nfn strip_midi_extension(filename: \u0026str) -\u003e Option\u003c\u0026str\u003e {\n    // Check for .midi extension (case-insensitive)\n    // We need to check the last 5 characters (.midi)\n    if filename.len() \u003e 5 {\n        let extension_start = filename.len() - 5;\n        let potential_ext = \u0026filename[extension_start..];\n\n        if potential_ext.eq_ignore_ascii_case(\".midi\") {\n            return Some(\u0026filename[..extension_start]);\n        }\n    } else if filename.len() == 5 {\n        // Special case: filename is exactly \".midi\"\n        if filename.eq_ignore_ascii_case(\".midi\") {\n            return Some(\"\");\n        }\n    }\n\n    None\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    // Basic functionality tests\n    #[test]\n    fn test_normalize_midi_to_mid() {\n        assert_eq!(normalize_midi_filename(\"song.midi\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_already_mid_unchanged() {\n        assert_eq!(normalize_midi_filename(\"song.mid\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_uppercase_midi() {\n        assert_eq!(normalize_midi_filename(\"song.MIDI\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_mixed_case_midi() {\n        assert_eq!(normalize_midi_filename(\"song.MiDi\"), \"song.mid\");\n        assert_eq!(normalize_midi_filename(\"song.mIdI\"), \"song.mid\");\n        assert_eq!(normalize_midi_filename(\"song.Midi\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_uppercase_mid_unchanged() {\n        // .MID is already the correct length, just different case\n        // We should preserve it as-is since it's not .midi\n        assert_eq!(normalize_midi_filename(\"song.MID\"), \"song.MID\");\n    }\n\n    // Space replacement tests\n    #[test]\n    fn test_space_replacement() {\n        assert_eq!(\n            normalize_midi_filename(\"my song.mid\"),\n            \"my_song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_multiple_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my  song.midi\"),\n            \"my__song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_space_and_midi_extension() {\n        assert_eq!(\n            normalize_midi_filename(\"Cool Track.midi\"),\n            \"Cool_Track.mid\"\n        );\n    }\n\n    #[test]\n    fn test_no_spaces_no_change() {\n        assert_eq!(\n            normalize_midi_filename(\"song.mid\"),\n            \"song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_spaces_in_complex_filename() {\n        assert_eq!(\n            normalize_midi_filename(\"120bpm Cmaj Scale.midi\"),\n            \"120bpm_Cmaj_Scale.mid\"\n        );\n    }\n\n    #[test]\n    fn test_needs_normalization_with_spaces() {\n        assert!(needs_normalization(\"my song.mid\"));\n        assert!(needs_normalization(\"song.midi\"));\n        assert!(needs_normalization(\"my song.midi\"));\n        assert!(!needs_normalization(\"song.mid\"));\n        assert!(!needs_normalization(\"my_song.mid\"));\n    }\n\n    // Special characters and spaces\n    #[test]\n    fn test_filename_with_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my song name.midi\"),\n            \"my_song_name.mid\"\n        );\n    }\n\n    #[test]\n    fn test_filename_with_special_chars() {\n        assert_eq!(\n            normalize_midi_filename(\"song-123_test@example.midi\"),\n            \"song-123_test@example.mid\"\n        );\n    }\n\n    #[test]\n    fn test_filename_with_unicode() {\n        assert_eq!(\n            normalize_midi_filename(\".midi\"),\n            \".mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"caf-song.midi\"),\n            \"caf-song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_spaces_with_unicode() {\n        assert_eq!(\n            normalize_midi_filename(\"caf song.midi\"),\n            \"caf_song.mid\"\n        );\n    }\n\n    // Multiple dots\n    #[test]\n    fn test_multiple_dots_in_filename() {\n        assert_eq!(\n            normalize_midi_filename(\"my.song.title.midi\"),\n            \"my.song.title.mid\"\n        );\n    }\n\n    #[test]\n    fn test_dots_preserved() {\n        assert_eq!(\n            normalize_midi_filename(\"song.v2.final.midi\"),\n            \"song.v2.final.mid\"\n        );\n    }\n\n    #[test]\n    fn test_dots_and_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my.song v2.midi\"),\n            \"my.song_v2.mid\"\n        );\n    }\n\n    // Edge cases\n    #[test]\n    fn test_no_extension() {\n        assert_eq!(normalize_midi_filename(\"song\"), \"song\");\n    }\n\n    #[test]\n    fn test_no_extension_with_spaces() {\n        assert_eq!(normalize_midi_filename(\"my song\"), \"my_song\");\n    }\n\n    #[test]\n    fn test_wrong_extension() {\n        assert_eq!(normalize_midi_filename(\"song.mp3\"), \"song.mp3\");\n        assert_eq!(normalize_midi_filename(\"song.wav\"), \"song.wav\");\n        assert_eq!(normalize_midi_filename(\"song.txt\"), \"song.txt\");\n    }\n\n    #[test]\n    fn test_wrong_extension_with_spaces() {\n        assert_eq!(normalize_midi_filename(\"my song.mp3\"), \"my_song.mp3\");\n    }\n\n    #[test]\n    fn test_midi_not_at_end() {\n        // .midi in the middle of filename shouldn't be changed\n        assert_eq!(\n            normalize_midi_filename(\"song.midi.backup\"),\n            \"song.midi.backup\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"midi.txt\"),\n            \"midi.txt\"\n        );\n    }\n\n    #[test]\n    fn test_just_extension() {\n        // Edge case: filename is just \".midi\"\n        assert_eq!(normalize_midi_filename(\".midi\"), \".mid\");\n    }\n\n    #[test]\n    fn test_empty_string() {\n        assert_eq!(normalize_midi_filename(\"\"), \"\");\n    }\n\n    #[test]\n    fn test_very_short_filename() {\n        assert_eq!(normalize_midi_filename(\"a.midi\"), \"a.mid\");\n        assert_eq!(normalize_midi_filename(\"ab.midi\"), \"ab.mid\");\n    }\n\n    #[test]\n    fn test_very_short_filename_with_space() {\n        assert_eq!(normalize_midi_filename(\"a b.midi\"), \"a_b.mid\");\n    }\n\n    #[test]\n    fn test_only_spaces() {\n        assert_eq!(normalize_midi_filename(\"   .midi\"), \"___.mid\");\n        assert_eq!(normalize_midi_filename(\" \"), \"_\");\n    }\n\n    #[test]\n    fn test_leading_trailing_spaces() {\n        assert_eq!(normalize_midi_filename(\" song.midi\"), \"_song.mid\");\n        assert_eq!(normalize_midi_filename(\"song .midi\"), \"song_.mid\");\n        assert_eq!(normalize_midi_filename(\" song .midi\"), \"_song_.mid\");\n    }\n\n    // needs_normalization tests\n    #[test]\n    fn test_needs_normalization_true() {\n        // Has .midi extension\n        assert!(needs_normalization(\"song.midi\"));\n        assert!(needs_normalization(\"song.MIDI\"));\n        assert!(needs_normalization(\"song.MiDi\"));\n        assert!(needs_normalization(\"my.song.midi\"));\n\n        // Has spaces\n        assert!(needs_normalization(\"my song.mid\"));\n        assert!(needs_normalization(\"Cool Track.mp3\"));\n\n        // Has both\n        assert!(needs_normalization(\"my song.midi\"));\n        assert!(needs_normalization(\"Cool Track.MIDI\"));\n    }\n\n    #[test]\n    fn test_needs_normalization_false() {\n        assert!(!needs_normalization(\"song.mid\"));\n        assert!(!needs_normalization(\"song.MID\"));\n        assert!(!needs_normalization(\"song.mp3\"));\n        assert!(!needs_normalization(\"song\"));\n        assert!(!needs_normalization(\"\"));\n        assert!(!needs_normalization(\"song.midi.backup\"));\n        assert!(!needs_normalization(\"my_song.mid\"));\n        assert!(!needs_normalization(\"my-song.mid\"));\n    }\n\n    // strip_midi_extension tests\n    #[test]\n    fn test_strip_midi_extension() {\n        assert_eq!(strip_midi_extension(\"song.midi\"), Some(\"song\"));\n        assert_eq!(strip_midi_extension(\"song.MIDI\"), Some(\"song\"));\n        assert_eq!(strip_midi_extension(\"my.song.midi\"), Some(\"my.song\"));\n        assert_eq!(strip_midi_extension(\".midi\"), Some(\"\"));\n        assert_eq!(strip_midi_extension(\"my song.midi\"), Some(\"my song\"));\n    }\n\n    #[test]\n    fn test_strip_midi_extension_none() {\n        assert_eq!(strip_midi_extension(\"song.mid\"), None);\n        assert_eq!(strip_midi_extension(\"song\"), None);\n        assert_eq!(strip_midi_extension(\"\"), None);\n        assert_eq!(strip_midi_extension(\"song.mp3\"), None);\n        assert_eq!(strip_midi_extension(\"my song.mid\"), None);\n    }\n\n    // Property-based style tests\n    #[test]\n    fn test_normalization_idempotent() {\n        // Normalizing twice should give same result\n        let filename = \"my song.midi\";\n        let normalized_once = normalize_midi_filename(filename);\n        let normalized_twice = normalize_midi_filename(\u0026normalized_once);\n        assert_eq!(normalized_once, normalized_twice);\n        assert_eq!(normalized_once, \"my_song.mid\");\n    }\n\n    #[test]\n    fn test_normalized_files_dont_need_normalization() {\n        // After normalization, needs_normalization should return false\n        let filename = \"my song.midi\";\n        let normalized = normalize_midi_filename(filename);\n        assert!(!needs_normalization(\u0026normalized));\n        assert_eq!(normalized, \"my_song.mid\");\n    }\n\n    #[test]\n    fn test_long_filename() {\n        let long_name = \"a\".repeat(200) + \".midi\";\n        let normalized = normalize_midi_filename(\u0026long_name);\n        assert_eq!(normalized, \"a\".repeat(200) + \".mid\");\n    }\n\n    #[test]\n    fn test_long_filename_with_spaces() {\n        let long_name = \"a b \".repeat(50) + \"c.midi\";\n        let normalized = normalize_midi_filename(\u0026long_name);\n        assert!(normalized.contains('_'));\n        assert!(!normalized.contains(' '));\n        assert!(normalized.ends_with(\".mid\"));\n    }\n\n    #[test]\n    fn test_real_world_examples() {\n        // Common real-world filename patterns\n        assert_eq!(\n            normalize_midi_filename(\"Drum Loop 120 BPM.midi\"),\n            \"Drum_Loop_120_BPM.mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Bass Line - C Minor.MIDI\"),\n            \"Bass_Line_-_C_Minor.mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Synth Pad (Ambient).midi\"),\n            \"Synth_Pad_(Ambient).mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Track 01 Intro.midi\"),\n            \"Track_01_Intro.mid\"\n        );\n    }\n\n    #[test]\n    fn test_consecutive_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"song     name.midi\"),\n            \"song_____name.mid\"\n        );\n    }\n\n    #[test]\n    fn test_space_preservation_in_count() {\n        // Each space becomes exactly one underscore\n        let input = \"a b c d.midi\";\n        let output = normalize_midi_filename(input);\n        assert_eq!(output, \"a_b_c_d.mid\");\n        assert_eq!(output.matches('_').count(), 3);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","normalization","mod.rs"],"content":"//! Filename and path normalization utilities.\n//!\n//! This module provides utilities for normalizing MIDI filenames and paths,\n//! ensuring consistency across the system.\n\npub mod filename;\n\n// Re-export commonly used functions for convenience\npub use filename::{normalize_midi_filename, needs_normalization};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","performance","concurrency.rs"],"content":"//! Dynamic Concurrency Tuning Module\n//!\n//! This module provides automatic detection and calculation of optimal concurrency\n//! settings based on system resources (CPU cores, RAM, disk type).\n//!\n//! # Architecture\n//!\n//! This is a **Trusty Module** - pure logic with comprehensive tests.\n//! - NO I/O operations (system detection is read-only introspection)\n//! - All functions are pure calculations\n//! - Highly testable with different configurations\n//!\n//! # Usage\n//!\n//! ```rust\n//! use pipeline::core::performance::concurrency::{\n//!     detect_system_resources,\n//!     calculate_optimal_concurrency\n//! };\n//!\n//! // Auto-detect system resources\n//! let resources = detect_system_resources();\n//!\n//! // Calculate optimal concurrency\n//! let concurrency = calculate_optimal_concurrency(\u0026resources);\n//! println!(\"Using {} concurrent workers\", concurrency);\n//! ```\n//!\n//! # Performance Tuning Strategy\n//!\n//! The optimal concurrency is calculated using a multi-factor formula:\n//!\n//! 1. **CPU-based baseline**: `cpu_cores  2`\n//!    - Accounts for I/O-bound operations (file reading, database writes)\n//!    - Each core can handle ~2 concurrent I/O operations efficiently\n//!\n//! 2. **Memory constraints**: Reduce concurrency if RAM \u003c 8GB\n//!    - 4GB RAM: Divide by 4 (risk of swapping)\n//!    - 6GB RAM: Divide by 2 (limited headroom)\n//!    - 8GB+ RAM: No reduction\n//!\n//! 3. **Storage type**: Cap based on disk performance\n//!    - HDD: Cap at 50 (seek times limit parallelism)\n//!    - SSD: Cap at 100 (near-linear scaling)\n//!\n//! 4. **Absolute bounds**: Clamp to [10, 100]\n//!    - Minimum 10: Ensure reasonable throughput on any system\n//!    - Maximum 100: Prevent database connection exhaustion\n\nuse sysinfo::System;\nuse std::thread;\n\n/// System resource information used to calculate optimal concurrency.\n///\n/// This struct captures the relevant system capabilities that affect\n/// file processing performance.\n#[derive(Debug, Clone, PartialEq)]\npub struct SystemResources {\n    /// Number of logical CPU cores (includes hyperthreading)\n    pub cpu_cores: usize,\n\n    /// Available system memory in gigabytes\n    pub available_memory_gb: f64,\n\n    /// Whether the primary storage is an SSD (true) or HDD (false)\n    pub is_ssd: bool,\n}\n\nimpl SystemResources {\n    /// Create a new SystemResources with explicit values.\n    ///\n    /// Useful for testing different configurations.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use pipeline::core::performance::concurrency::SystemResources;\n    ///\n    /// let resources = SystemResources::new(8, 16.0, true);\n    /// assert_eq!(resources.cpu_cores, 8);\n    /// assert_eq!(resources.available_memory_gb, 16.0);\n    /// assert!(resources.is_ssd);\n    /// ```\n    pub fn new(cpu_cores: usize, available_memory_gb: f64, is_ssd: bool) -\u003e Self {\n        Self {\n            cpu_cores,\n            available_memory_gb,\n            is_ssd,\n        }\n    }\n}\n\n/// Automatically detect system resources.\n///\n/// This function queries the operating system to determine:\n/// - CPU core count (logical cores including hyperthreading)\n/// - Available system memory\n/// - Primary disk type (SSD vs HDD)\n///\n/// # Returns\n///\n/// A `SystemResources` struct with detected values.\n///\n/// # Fallback Behavior\n///\n/// If detection fails:\n/// - CPU cores: Falls back to 4\n/// - Memory: Falls back to 8.0 GB\n/// - SSD: Assumes true (conservative for performance)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::detect_system_resources;\n///\n/// let resources = detect_system_resources();\n/// println!(\"Detected {} CPU cores\", resources.cpu_cores);\n/// println!(\"Available memory: {:.2} GB\", resources.available_memory_gb);\n/// println!(\"SSD: {}\", resources.is_ssd);\n/// ```\npub fn detect_system_resources() -\u003e SystemResources {\n    // Detect CPU cores\n    let cpu_cores = thread::available_parallelism()\n        .map(|n| n.get())\n        .unwrap_or(4); // Fallback to 4 cores if detection fails\n\n    // Initialize system info\n    let sys = System::new_all();\n\n    // Detect available memory (convert bytes to GB)\n    // sysinfo 0.30 returns memory in bytes\n    let total_memory_bytes = sys.total_memory();\n    let available_memory_gb = (total_memory_bytes as f64) / (1024.0 * 1024.0 * 1024.0);\n\n    // Detect if primary disk is SSD\n    // Strategy: In sysinfo 0.30, we don't have direct SSD detection\n    // Default to true (SSD) as a conservative assumption for modern systems\n    // In production, this could be enhanced with platform-specific detection\n    let is_ssd = true; // Conservative default: assume SSD for better performance\n\n    SystemResources {\n        cpu_cores,\n        available_memory_gb,\n        is_ssd,\n    }\n}\n\n/// Calculate the optimal concurrency limit based on system resources.\n///\n/// This function implements a multi-factor formula to determine the ideal\n/// number of concurrent file processing workers.\n///\n/// # Algorithm\n///\n/// 1. Start with CPU-based baseline: `cpu_cores  2`\n/// 2. Apply memory constraints:\n///    - If RAM \u003c 4GB: divide by 4\n///    - If RAM \u003c 6GB: divide by 2\n///    - If RAM \u003e= 8GB: no reduction\n/// 3. Apply storage type cap:\n///    - HDD: cap at 50\n///    - SSD: cap at 100\n/// 4. Clamp to absolute bounds [10, 100]\n///\n/// # Arguments\n///\n/// * `resources` - System resource information\n///\n/// # Returns\n///\n/// Optimal concurrency limit (10-100)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::{SystemResources, calculate_optimal_concurrency};\n///\n/// // High-end system: 16 cores, 32GB RAM, SSD\n/// let resources = SystemResources::new(16, 32.0, true);\n/// let concurrency = calculate_optimal_concurrency(\u0026resources);\n/// assert_eq!(concurrency, 32); // 16  2, no constraints\n///\n/// // Low-end system: 4 cores, 4GB RAM, HDD\n/// let resources = SystemResources::new(4, 4.0, false);\n/// let concurrency = calculate_optimal_concurrency(\u0026resources);\n/// assert_eq!(concurrency, 10); // Limited by memory and minimum bound\n/// ```\npub fn calculate_optimal_concurrency(resources: \u0026SystemResources) -\u003e usize {\n    // Step 1: CPU-based baseline (2 cores for I/O-bound operations)\n    let mut concurrency = resources.cpu_cores * 2;\n\n    // Step 2: Apply memory constraints\n    if resources.available_memory_gb \u003c 4.0 {\n        // Very limited memory: reduce significantly to avoid swapping\n        concurrency /= 4;\n    } else if resources.available_memory_gb \u003c 6.0 {\n        // Limited memory: reduce moderately\n        concurrency /= 2;\n    }\n    // 8GB+ RAM: no memory-based reduction\n\n    // Step 3: Apply storage type cap\n    let storage_cap = if resources.is_ssd {\n        100 // SSDs scale well with parallelism\n    } else {\n        50 // HDDs are limited by seek times\n    };\n\n    concurrency = concurrency.min(storage_cap);\n\n    // Step 4: Apply absolute bounds\n    // - Minimum 10: ensure reasonable throughput\n    // - Maximum 100: prevent resource exhaustion\n    concurrency.clamp(10, 100)\n}\n\n/// Calculate the optimal database connection pool size.\n///\n/// The pool size should support concurrent operations plus some overhead\n/// for connection management and potential contention.\n///\n/// # Formula\n///\n/// `pool_size = (concurrency  1.5).clamp(20, 200)`\n///\n/// - 1.5 multiplier: Provides headroom for connection recycling\n/// - Minimum 20: Ensures adequate connections even on small systems\n/// - Maximum 200: Prevents PostgreSQL connection exhaustion\n///\n/// # Arguments\n///\n/// * `concurrency` - Target concurrency limit\n///\n/// # Returns\n///\n/// Optimal database connection pool size (20-200)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_database_pool_size;\n///\n/// let pool_size = calculate_database_pool_size(50);\n/// assert_eq!(pool_size, 75); // 50  1.5\n///\n/// let pool_size = calculate_database_pool_size(10);\n/// assert_eq!(pool_size, 20); // Clamped to minimum\n///\n/// let pool_size = calculate_database_pool_size(150);\n/// assert_eq!(pool_size, 200); // Clamped to maximum\n/// ```\npub fn calculate_database_pool_size(concurrency: usize) -\u003e usize {\n    // 1.5 concurrency to provide connection headroom\n    let pool_size = (concurrency as f64 * 1.5) as usize;\n\n    // Clamp to PostgreSQL-friendly bounds\n    pool_size.clamp(20, 200)\n}\n\n/// Calculate the optimal batch size for database operations.\n///\n/// Larger batches reduce transaction overhead but increase memory usage\n/// and potential lock contention. The optimal size balances these factors.\n///\n/// # Formula\n///\n/// `batch_size = (concurrency  100).clamp(500, 10000)`\n///\n/// - 100 multiplier: Each worker can handle ~100 records per batch\n/// - Minimum 500: Ensures meaningful batch performance improvement\n/// - Maximum 10,000: Prevents excessive memory usage and lock duration\n///\n/// # Arguments\n///\n/// * `concurrency` - Target concurrency limit\n///\n/// # Returns\n///\n/// Optimal batch size for database inserts (500-10,000)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_batch_size;\n///\n/// let batch_size = calculate_batch_size(50);\n/// assert_eq!(batch_size, 5000); // 50  100\n///\n/// let batch_size = calculate_batch_size(10);\n/// assert_eq!(batch_size, 1000); // 10  100\n///\n/// let batch_size = calculate_batch_size(150);\n/// assert_eq!(batch_size, 10000); // Clamped to maximum\n/// ```\npub fn calculate_batch_size(concurrency: usize) -\u003e usize {\n    // Each concurrent worker can process ~100 records efficiently\n    let batch_size = concurrency * 100;\n\n    // Clamp to reasonable bounds\n    batch_size.clamp(500, 10_000)\n}\n\n/// Calculate all performance settings in one call.\n///\n/// This is a convenience function that calculates optimal concurrency,\n/// database pool size, and batch size based on detected system resources.\n///\n/// # Returns\n///\n/// Tuple of (concurrency, pool_size, batch_size)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_all_settings;\n///\n/// let (concurrency, pool_size, batch_size) = calculate_all_settings();\n/// println!(\"Concurrency: {}\", concurrency);\n/// println!(\"DB Pool: {}\", pool_size);\n/// println!(\"Batch Size: {}\", batch_size);\n/// ```\npub fn calculate_all_settings() -\u003e (usize, usize, usize) {\n    let resources = detect_system_resources();\n    let concurrency = calculate_optimal_concurrency(\u0026resources);\n    let pool_size = calculate_database_pool_size(concurrency);\n    let batch_size = calculate_batch_size(concurrency);\n\n    (concurrency, pool_size, batch_size)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_system_resources_new() {\n        let resources = SystemResources::new(8, 16.0, true);\n        assert_eq!(resources.cpu_cores, 8);\n        assert_eq!(resources.available_memory_gb, 16.0);\n        assert!(resources.is_ssd);\n    }\n\n    #[test]\n    fn test_detect_system_resources() {\n        let resources = detect_system_resources();\n\n        // Should detect at least 1 core\n        assert!(resources.cpu_cores \u003e= 1);\n\n        // Should detect some memory\n        assert!(resources.available_memory_gb \u003e 0.0);\n\n        // is_ssd is boolean\n        assert!(resources.is_ssd || !resources.is_ssd);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_high_end_system() {\n        // 16 cores, 32GB RAM, SSD\n        let resources = SystemResources::new(16, 32.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be 16  2 = 32 (no constraints)\n        assert_eq!(concurrency, 32);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_mid_range_system() {\n        // 8 cores, 16GB RAM, SSD\n        let resources = SystemResources::new(8, 16.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be 8  2 = 16 (no constraints)\n        assert_eq!(concurrency, 16);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_low_end_system() {\n        // 4 cores, 4GB RAM, HDD\n        let resources = SystemResources::new(4, 4.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be limited by memory: 4  2 = 8, then / 4 = 2, clamped to 10\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_memory_constrained() {\n        // 8 cores, 5GB RAM, SSD\n        let resources = SystemResources::new(8, 5.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be: 8  2 = 16, then / 2 = 8, clamped to 10 (minimum)\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_hdd_cap() {\n        // 32 cores, 64GB RAM, HDD\n        let resources = SystemResources::new(32, 64.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be capped at 50 for HDD\n        assert_eq!(concurrency, 50);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_ssd_cap() {\n        // 64 cores, 128GB RAM, SSD\n        let resources = SystemResources::new(64, 128.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be capped at 100 (absolute maximum)\n        assert_eq!(concurrency, 100);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_minimum_bound() {\n        // 2 cores, 2GB RAM, HDD\n        let resources = SystemResources::new(2, 2.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be clamped to minimum of 10\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_various_cpu_counts() {\n        let test_cases = vec![\n            (4, 16.0, true, 10),   // 4 cores: 42=8, clamped to 10\n            (6, 16.0, true, 12),   // 6 cores: 62=12\n            (8, 16.0, true, 16),   // 8 cores: 82=16\n            (12, 16.0, true, 24),  // 12 cores: 122=24\n            (16, 16.0, true, 32),  // 16 cores: 162=32\n            (24, 16.0, true, 48),  // 24 cores: 242=48\n            (32, 16.0, true, 64),  // 32 cores: 322=64\n        ];\n\n        for (cores, ram, ssd, expected) in test_cases {\n            let resources = SystemResources::new(cores, ram, ssd);\n            let concurrency = calculate_optimal_concurrency(\u0026resources);\n            assert_eq!(\n                concurrency, expected,\n                \"Failed for {} cores: expected {}, got {}\",\n                cores, expected, concurrency\n            );\n        }\n    }\n\n    #[test]\n    fn test_database_pool_size() {\n        // Test various concurrency levels\n        assert_eq!(calculate_database_pool_size(10), 20);   // Clamped to minimum\n        assert_eq!(calculate_database_pool_size(20), 30);   // 20  1.5 = 30\n        assert_eq!(calculate_database_pool_size(50), 75);   // 50  1.5 = 75\n        assert_eq!(calculate_database_pool_size(100), 150); // 100  1.5 = 150\n        assert_eq!(calculate_database_pool_size(150), 200); // Clamped to maximum\n    }\n\n    #[test]\n    fn test_database_pool_size_minimum_bound() {\n        // Very low concurrency should still get minimum pool\n        assert_eq!(calculate_database_pool_size(1), 20);\n        assert_eq!(calculate_database_pool_size(5), 20);\n        assert_eq!(calculate_database_pool_size(10), 20);\n    }\n\n    #[test]\n    fn test_database_pool_size_maximum_bound() {\n        // Very high concurrency should be capped\n        assert_eq!(calculate_database_pool_size(200), 200);\n        assert_eq!(calculate_database_pool_size(500), 200);\n    }\n\n    #[test]\n    fn test_batch_size() {\n        // Test various concurrency levels\n        assert_eq!(calculate_batch_size(10), 1000);   // 10  100 = 1000\n        assert_eq!(calculate_batch_size(20), 2000);   // 20  100 = 2000\n        assert_eq!(calculate_batch_size(50), 5000);   // 50  100 = 5000\n        assert_eq!(calculate_batch_size(100), 10000); // 100  100 = 10000 (clamped)\n        assert_eq!(calculate_batch_size(150), 10000); // Clamped to maximum\n    }\n\n    #[test]\n    fn test_batch_size_minimum_bound() {\n        // Very low concurrency should get minimum batch\n        assert_eq!(calculate_batch_size(1), 500);\n        assert_eq!(calculate_batch_size(3), 500);\n        assert_eq!(calculate_batch_size(5), 500);\n    }\n\n    #[test]\n    fn test_batch_size_maximum_bound() {\n        // Very high concurrency should be capped\n        assert_eq!(calculate_batch_size(150), 10000);\n        assert_eq!(calculate_batch_size(500), 10000);\n    }\n\n    #[test]\n    fn test_calculate_all_settings() {\n        let (concurrency, pool_size, batch_size) = calculate_all_settings();\n\n        // Verify all values are in expected ranges\n        assert!(concurrency \u003e= 10 \u0026\u0026 concurrency \u003c= 100);\n        assert!(pool_size \u003e= 20 \u0026\u0026 pool_size \u003c= 200);\n        assert!(batch_size \u003e= 500 \u0026\u0026 batch_size \u003c= 10000);\n\n        // Verify relationships\n        assert!(pool_size \u003e= concurrency, \"Pool should be \u003e= concurrency\");\n        assert!(batch_size \u003e= concurrency * 50, \"Batch should be \u003e= concurrency  50\");\n    }\n\n    #[test]\n    fn test_realistic_scenarios() {\n        // Scenario 1: Development laptop (MacBook Pro)\n        let dev_laptop = SystemResources::new(8, 16.0, true);\n        let conc = calculate_optimal_concurrency(\u0026dev_laptop);\n        assert_eq!(conc, 16);\n        assert_eq!(calculate_database_pool_size(conc), 24);\n        assert_eq!(calculate_batch_size(conc), 1600);\n\n        // Scenario 2: Entry-level desktop\n        let entry_desktop = SystemResources::new(4, 8.0, false);\n        let conc = calculate_optimal_concurrency(\u0026entry_desktop);\n        assert_eq!(conc, 10); // 42=8, clamped to 10\n        assert_eq!(calculate_database_pool_size(conc), 20);\n        assert_eq!(calculate_batch_size(conc), 1000);\n\n        // Scenario 3: High-end workstation\n        let workstation = SystemResources::new(32, 64.0, true);\n        let conc = calculate_optimal_concurrency(\u0026workstation);\n        assert_eq!(conc, 64);\n        assert_eq!(calculate_database_pool_size(conc), 96);\n        assert_eq!(calculate_batch_size(conc), 6400);\n\n        // Scenario 4: Cloud server (16 vCPUs, SSD)\n        let cloud_server = SystemResources::new(16, 32.0, true);\n        let conc = calculate_optimal_concurrency(\u0026cloud_server);\n        assert_eq!(conc, 32);\n        assert_eq!(calculate_database_pool_size(conc), 48);\n        assert_eq!(calculate_batch_size(conc), 3200);\n    }\n\n    #[test]\n    fn test_memory_threshold_boundaries() {\n        // Test exact boundary conditions\n\n        // Just below 4GB\n        let resources = SystemResources::new(8, 3.9, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 824=4, clamped to 10\n\n        // Just at 4GB\n        let resources = SystemResources::new(8, 4.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 824=4, clamped to 10\n\n        // Just above 4GB\n        let resources = SystemResources::new(8, 4.1, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 822=8, clamped to 10\n\n        // Just below 6GB\n        let resources = SystemResources::new(8, 5.9, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 822=8, clamped to 10\n\n        // Just at 6GB (boundary - no reduction)\n        let resources = SystemResources::new(8, 6.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n\n        // Just above 6GB (no reduction)\n        let resources = SystemResources::new(8, 6.1, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n\n        // At 8GB (no reduction)\n        let resources = SystemResources::new(8, 8.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","performance","mod.rs"],"content":"//! Performance optimization modules\n//!\n//! This module contains pure logic for optimizing file processing performance\n//! based on system resources and workload characteristics.\n//!\n//! # Architecture\n//!\n//! All modules in this package are **Trusty Modules** - pure logic with no I/O.\n//!\n//! # Modules\n//!\n//! - `concurrency`: Dynamic concurrency tuning based on system resources\n\npub mod concurrency;\n\n// Re-export commonly used items\npub use concurrency::{\n    SystemResources,\n    detect_system_resources,\n    calculate_optimal_concurrency,\n    calculate_database_pool_size,\n    calculate_batch_size,\n    calculate_all_settings,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","splitting","mod.rs"],"content":"//! Splitting Module\n//!\n//! Pure logic for splitting multi-track MIDI files into individual tracks.\n//!\n//! # Archetype: TRUSTY MODULE\n//!\n//! This module contains pure functions for:\n//! - Parsing multi-track MIDI files\n//! - Splitting into separate Format 0 (single-track) files\n//! - Extracting track metadata\n//!\n//! All functions operate on byte arrays with no I/O operations.\n\npub mod track_splitter;\n\n// Re-export main types and functions\npub use track_splitter::{\n    count_notes, create_single_track_midi, extract_instrument, extract_primary_channel,\n    extract_track_name, get_instrument_name, is_tempo_track, split_tracks, SplitError, SplitTrack,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","splitting","track_splitter.rs"],"content":"//! Track Splitter - TRUSTY MODULE\n//!\n//! Pure logic for splitting multi-track MIDI files into individual single-track files.\n//!\n//! This module operates on byte arrays (no I/O) and provides functions to:\n//! - Parse multi-track MIDI files (Format 1)\n//! - Split into separate Format 0 (single-track) MIDI files\n//! - Extract metadata (track name, channel, instrument, note count)\n//! - Handle tempo tracks and edge cases\n//!\n//! # Archetype: TRUSTY MODULE\n//! -  Pure functions, no side effects\n//! -  No I/O operations\n//! -  Operates on byte slices\n//! -  Comprehensive error handling\n//! -  Well-tested\n\nuse midly::{Format, Header, MetaMessage, Smf, Track, TrackEvent, TrackEventKind};\nuse thiserror::Error;\n\n/// Error types for track splitting operations\n#[derive(Error, Debug, Clone, PartialEq)]\npub enum SplitError {\n    /// Failed to parse MIDI data\n    #[error(\"Failed to parse MIDI data: {0}\")]\n    ParseError(String),\n\n    /// Failed to write MIDI data\n    #[error(\"Failed to write MIDI data: {0}\")]\n    WriteError(String),\n\n    /// No tracks to split (empty or single tempo track)\n    #[error(\"No tracks to split - file contains only tempo track or is empty\")]\n    NoTracksToSplit,\n}\n\n/// Information about a split track\n#[derive(Debug, Clone, PartialEq)]\npub struct SplitTrack {\n    /// Original track number (0-indexed)\n    pub track_number: usize,\n\n    /// Track name from meta events (if present)\n    pub track_name: Option\u003cString\u003e,\n\n    /// Primary MIDI channel used by this track (0-15)\n    pub channel: Option\u003cu8\u003e,\n\n    /// General MIDI instrument name\n    pub instrument: Option\u003cString\u003e,\n\n    /// Number of note-on events in this track\n    pub note_count: usize,\n\n    /// Complete Format 0 MIDI file as bytes\n    pub midi_bytes: Vec\u003cu8\u003e,\n}\n\n/// Split multi-track MIDI file into individual single-track files.\n///\n/// Parses a MIDI file and creates separate Format 0 (single-track) MIDI files\n/// for each music track. Skips tempo-only tracks (Track 0 in Format 1 files).\n/// Preserves tempo, time signature, and key signature from the original file.\n///\n/// # Arguments\n///\n/// * `original_midi_bytes` - Complete MIDI file as byte slice\n///\n/// # Returns\n///\n/// Vector of `SplitTrack` structs, one for each music track found.\n/// Returns error if parsing fails or no music tracks exist.\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::splitting::track_splitter::split_tracks;\n///\n/// // Parse multi-track MIDI\n/// let midi_bytes = include_bytes!(\"test_data/multitrack.mid\");\n/// let tracks = split_tracks(midi_bytes)?;\n///\n/// for track in tracks {\n///     println!(\"Track {}: {} notes\", track.track_number, track.note_count);\n///     if let Some(name) = track.track_name {\n///         println!(\"  Name: {}\", name);\n///     }\n/// }\n/// # Ok::\u003c(), pipeline::core::splitting::track_splitter::SplitError\u003e(())\n/// ```\npub fn split_tracks(original_midi_bytes: \u0026[u8]) -\u003e Result\u003cVec\u003cSplitTrack\u003e, SplitError\u003e {\n    // Parse the original MIDI file\n    let smf = Smf::parse(original_midi_bytes)\n        .map_err(|e| SplitError::ParseError(format!(\"midly parse error: {}\", e)))?;\n\n    // Check format - if already Format 0, return as-is\n    if smf.header.format == Format::SingleTrack {\n        let track = \u0026smf.tracks[0];\n        let note_count = count_notes(track);\n\n        // Only return if it has notes\n        if note_count == 0 {\n            return Err(SplitError::NoTracksToSplit);\n        }\n\n        return Ok(vec![SplitTrack {\n            track_number: 0,\n            track_name: extract_track_name(track),\n            channel: extract_primary_channel(track),\n            instrument: extract_instrument(track),\n            note_count,\n            midi_bytes: original_midi_bytes.to_vec(),\n        }]);\n    }\n\n    // Process Format 1 (parallel tracks) or Format 2 (sequential)\n    let mut split_tracks = Vec::new();\n\n    for (idx, track) in smf.tracks.iter().enumerate() {\n        // Skip tempo-only tracks (usually Track 0)\n        if is_tempo_track(track) {\n            continue;\n        }\n\n        let note_count = count_notes(track);\n\n        // Skip tracks with no notes\n        if note_count == 0 {\n            continue;\n        }\n\n        // Create Format 0 MIDI file for this track\n        let midi_bytes = create_single_track_midi(\u0026smf, track, idx)?;\n\n        split_tracks.push(SplitTrack {\n            track_number: idx,\n            track_name: extract_track_name(track),\n            channel: extract_primary_channel(track),\n            instrument: extract_instrument(track),\n            note_count,\n            midi_bytes,\n        });\n    }\n\n    if split_tracks.is_empty() {\n        return Err(SplitError::NoTracksToSplit);\n    }\n\n    Ok(split_tracks)\n}\n\n/// Check if a track is a tempo-only track.\n///\n/// Tempo tracks contain only meta events (tempo, time signature, key signature)\n/// and no note events. Common in Format 1 MIDI files as Track 0.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// `true` if track contains only meta events, `false` otherwise\npub fn is_tempo_track(track: \u0026Track) -\u003e bool {\n    let mut has_meta_events = false;\n    let mut has_note_events = false;\n\n    for event in track.iter() {\n        match event.kind {\n            TrackEventKind::Meta(_) =\u003e has_meta_events = true,\n            TrackEventKind::Midi { message, .. } =\u003e {\n                // Check for note-on or note-off\n                use midly::MidiMessage;\n                match message {\n                    MidiMessage::NoteOn { .. } | MidiMessage::NoteOff { .. } =\u003e {\n                        has_note_events = true;\n                        break;\n                    }\n                    _ =\u003e {}\n                }\n            }\n            _ =\u003e {}\n        }\n    }\n\n    has_meta_events \u0026\u0026 !has_note_events\n}\n\n/// Create a Format 0 (single-track) MIDI file from a single track.\n///\n/// Merges tempo/time signature/key signature events from Track 0 (if Format 1)\n/// with the music events from the specified track. Creates a valid Format 0 MIDI file.\n///\n/// # Arguments\n///\n/// * `original` - Original parsed MIDI file\n/// * `track` - Track to extract\n/// * `track_idx` - Index of the track (for reference)\n///\n/// # Returns\n///\n/// Complete Format 0 MIDI file as bytes\npub fn create_single_track_midi(\n    original: \u0026Smf,\n    track: \u0026Track,\n    track_idx: usize,\n) -\u003e Result\u003cVec\u003cu8\u003e, SplitError\u003e {\n    // Create new Format 0 header with same timing\n    let new_header = Header {\n        format: Format::SingleTrack,\n        timing: original.header.timing,\n    };\n\n    // Build new track by merging tempo events from Track 0 (if exists) with this track\n    let mut new_track_events = Vec::new();\n\n    // If Format 1 and this isn't Track 0, copy tempo/meta events from Track 0\n    if original.header.format == Format::Parallel \u0026\u0026 track_idx \u003e 0 \u0026\u0026 !original.tracks.is_empty() {\n        let track_0 = \u0026original.tracks[0];\n        for event in track_0.iter() {\n            match event.kind {\n                TrackEventKind::Meta(MetaMessage::Tempo(_))\n                | TrackEventKind::Meta(MetaMessage::TimeSignature(..))\n                | TrackEventKind::Meta(MetaMessage::KeySignature(..)) =\u003e {\n                    new_track_events.push(event.clone());\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    // Add all events from the target track\n    new_track_events.extend(track.iter().cloned());\n\n    // Ensure track ends with End of Track\n    let has_end_of_track = new_track_events.iter().any(|e| {\n        matches!(e.kind, TrackEventKind::Meta(MetaMessage::EndOfTrack))\n    });\n\n    if !has_end_of_track {\n        new_track_events.push(TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::EndOfTrack),\n        });\n    }\n\n    // Create new SMF with single track\n    let new_smf = Smf {\n        header: new_header,\n        tracks: vec![new_track_events],\n    };\n\n    // Write to bytes\n    let mut bytes = Vec::new();\n    new_smf\n        .write_std(\u0026mut bytes)\n        .map_err(|e| SplitError::WriteError(format!(\"midly write error: {}\", e)))?;\n\n    Ok(bytes)\n}\n\n/// Extract track name from meta events.\n///\n/// Searches for TrackName or InstrumentName meta events.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Track name if found, `None` otherwise\npub fn extract_track_name(track: \u0026Track) -\u003e Option\u003cString\u003e {\n    for event in track.iter() {\n        if let TrackEventKind::Meta(meta) = \u0026event.kind {\n            match meta {\n                MetaMessage::TrackName(name) | MetaMessage::InstrumentName(name) =\u003e {\n                    // Convert bytes to string\n                    if let Ok(name_str) = String::from_utf8(name.to_vec()) {\n                        let trimmed = name_str.trim();\n                        if !trimmed.is_empty() {\n                            return Some(trimmed.to_string());\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n    None\n}\n\n/// Extract the primary MIDI channel used by this track.\n///\n/// Analyzes all MIDI messages and returns the most frequently used channel.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Most frequently used channel (0-15), or `None` if no MIDI messages found\npub fn extract_primary_channel(track: \u0026Track) -\u003e Option\u003cu8\u003e {\n    let mut channel_counts = [0u32; 16];\n\n    for event in track.iter() {\n        if let TrackEventKind::Midi { channel, .. } = event.kind {\n            channel_counts[channel.as_int() as usize] += 1;\n        }\n    }\n\n    // Find channel with highest count\n    let max_channel = channel_counts\n        .iter()\n        .enumerate()\n        .max_by_key(|(_, \u0026count)| count)?;\n\n    if max_channel.1 \u003e \u00260 {\n        Some(max_channel.0 as u8)\n    } else {\n        None\n    }\n}\n\n/// Extract instrument name from Program Change events.\n///\n/// Searches for the first Program Change event and maps to General MIDI instrument name.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// General MIDI instrument name, or `None` if no Program Change found\npub fn extract_instrument(track: \u0026Track) -\u003e Option\u003cString\u003e {\n    for event in track.iter() {\n        if let TrackEventKind::Midi { message, .. } = \u0026event.kind {\n            use midly::MidiMessage;\n            if let MidiMessage::ProgramChange { program } = message {\n                return Some(get_instrument_name(program.as_int()));\n            }\n        }\n    }\n    None\n}\n\n/// Count note-on events in a track.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Number of note-on events with velocity \u003e 0\npub fn count_notes(track: \u0026Track) -\u003e usize {\n    let mut count = 0;\n\n    for event in track.iter() {\n        if let TrackEventKind::Midi { message, .. } = \u0026event.kind {\n            use midly::MidiMessage;\n            if let MidiMessage::NoteOn { vel, .. } = message {\n                if vel.as_int() \u003e 0 {\n                    count += 1;\n                }\n            }\n        }\n    }\n\n    count\n}\n\n/// Get General MIDI instrument name from program number.\n///\n/// Maps GM program numbers (0-127) to standard instrument names.\n///\n/// # Arguments\n///\n/// * `program` - GM program number (0-127)\n///\n/// # Returns\n///\n/// General MIDI instrument name\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::splitting::track_splitter::get_instrument_name;\n///\n/// assert_eq!(get_instrument_name(0), \"Acoustic Grand Piano\");\n/// assert_eq!(get_instrument_name(25), \"Acoustic Guitar (nylon)\");\n/// assert_eq!(get_instrument_name(127), \"Gunshot\");\n/// ```\npub fn get_instrument_name(program: u8) -\u003e String {\n    match program {\n        // Piano (0-7)\n        0 =\u003e \"Acoustic Grand Piano\",\n        1 =\u003e \"Bright Acoustic Piano\",\n        2 =\u003e \"Electric Grand Piano\",\n        3 =\u003e \"Honky-tonk Piano\",\n        4 =\u003e \"Electric Piano 1\",\n        5 =\u003e \"Electric Piano 2\",\n        6 =\u003e \"Harpsichord\",\n        7 =\u003e \"Clavinet\",\n\n        // Chromatic Percussion (8-15)\n        8 =\u003e \"Celesta\",\n        9 =\u003e \"Glockenspiel\",\n        10 =\u003e \"Music Box\",\n        11 =\u003e \"Vibraphone\",\n        12 =\u003e \"Marimba\",\n        13 =\u003e \"Xylophone\",\n        14 =\u003e \"Tubular Bells\",\n        15 =\u003e \"Dulcimer\",\n\n        // Organ (16-23)\n        16 =\u003e \"Drawbar Organ\",\n        17 =\u003e \"Percussive Organ\",\n        18 =\u003e \"Rock Organ\",\n        19 =\u003e \"Church Organ\",\n        20 =\u003e \"Reed Organ\",\n        21 =\u003e \"Accordion\",\n        22 =\u003e \"Harmonica\",\n        23 =\u003e \"Tango Accordion\",\n\n        // Guitar (24-31)\n        24 =\u003e \"Acoustic Guitar (nylon)\",\n        25 =\u003e \"Acoustic Guitar (steel)\",\n        26 =\u003e \"Electric Guitar (jazz)\",\n        27 =\u003e \"Electric Guitar (clean)\",\n        28 =\u003e \"Electric Guitar (muted)\",\n        29 =\u003e \"Overdriven Guitar\",\n        30 =\u003e \"Distortion Guitar\",\n        31 =\u003e \"Guitar Harmonics\",\n\n        // Bass (32-39)\n        32 =\u003e \"Acoustic Bass\",\n        33 =\u003e \"Electric Bass (finger)\",\n        34 =\u003e \"Electric Bass (pick)\",\n        35 =\u003e \"Fretless Bass\",\n        36 =\u003e \"Slap Bass 1\",\n        37 =\u003e \"Slap Bass 2\",\n        38 =\u003e \"Synth Bass 1\",\n        39 =\u003e \"Synth Bass 2\",\n\n        // Strings (40-47)\n        40 =\u003e \"Violin\",\n        41 =\u003e \"Viola\",\n        42 =\u003e \"Cello\",\n        43 =\u003e \"Contrabass\",\n        44 =\u003e \"Tremolo Strings\",\n        45 =\u003e \"Pizzicato Strings\",\n        46 =\u003e \"Orchestral Harp\",\n        47 =\u003e \"Timpani\",\n\n        // Ensemble (48-55)\n        48 =\u003e \"String Ensemble 1\",\n        49 =\u003e \"String Ensemble 2\",\n        50 =\u003e \"Synth Strings 1\",\n        51 =\u003e \"Synth Strings 2\",\n        52 =\u003e \"Choir Aahs\",\n        53 =\u003e \"Voice Oohs\",\n        54 =\u003e \"Synth Voice\",\n        55 =\u003e \"Orchestra Hit\",\n\n        // Brass (56-63)\n        56 =\u003e \"Trumpet\",\n        57 =\u003e \"Trombone\",\n        58 =\u003e \"Tuba\",\n        59 =\u003e \"Muted Trumpet\",\n        60 =\u003e \"French Horn\",\n        61 =\u003e \"Brass Section\",\n        62 =\u003e \"Synth Brass 1\",\n        63 =\u003e \"Synth Brass 2\",\n\n        // Reed (64-71)\n        64 =\u003e \"Soprano Sax\",\n        65 =\u003e \"Alto Sax\",\n        66 =\u003e \"Tenor Sax\",\n        67 =\u003e \"Baritone Sax\",\n        68 =\u003e \"Oboe\",\n        69 =\u003e \"English Horn\",\n        70 =\u003e \"Bassoon\",\n        71 =\u003e \"Clarinet\",\n\n        // Pipe (72-79)\n        72 =\u003e \"Piccolo\",\n        73 =\u003e \"Flute\",\n        74 =\u003e \"Recorder\",\n        75 =\u003e \"Pan Flute\",\n        76 =\u003e \"Blown Bottle\",\n        77 =\u003e \"Shakuhachi\",\n        78 =\u003e \"Whistle\",\n        79 =\u003e \"Ocarina\",\n\n        // Synth Lead (80-87)\n        80 =\u003e \"Lead 1 (square)\",\n        81 =\u003e \"Lead 2 (sawtooth)\",\n        82 =\u003e \"Lead 3 (calliope)\",\n        83 =\u003e \"Lead 4 (chiff)\",\n        84 =\u003e \"Lead 5 (charang)\",\n        85 =\u003e \"Lead 6 (voice)\",\n        86 =\u003e \"Lead 7 (fifths)\",\n        87 =\u003e \"Lead 8 (bass + lead)\",\n\n        // Synth Pad (88-95)\n        88 =\u003e \"Pad 1 (new age)\",\n        89 =\u003e \"Pad 2 (warm)\",\n        90 =\u003e \"Pad 3 (polysynth)\",\n        91 =\u003e \"Pad 4 (choir)\",\n        92 =\u003e \"Pad 5 (bowed)\",\n        93 =\u003e \"Pad 6 (metallic)\",\n        94 =\u003e \"Pad 7 (halo)\",\n        95 =\u003e \"Pad 8 (sweep)\",\n\n        // Synth Effects (96-103)\n        96 =\u003e \"FX 1 (rain)\",\n        97 =\u003e \"FX 2 (soundtrack)\",\n        98 =\u003e \"FX 3 (crystal)\",\n        99 =\u003e \"FX 4 (atmosphere)\",\n        100 =\u003e \"FX 5 (brightness)\",\n        101 =\u003e \"FX 6 (goblins)\",\n        102 =\u003e \"FX 7 (echoes)\",\n        103 =\u003e \"FX 8 (sci-fi)\",\n\n        // Ethnic (104-111)\n        104 =\u003e \"Sitar\",\n        105 =\u003e \"Banjo\",\n        106 =\u003e \"Shamisen\",\n        107 =\u003e \"Koto\",\n        108 =\u003e \"Kalimba\",\n        109 =\u003e \"Bag pipe\",\n        110 =\u003e \"Fiddle\",\n        111 =\u003e \"Shanai\",\n\n        // Percussive (112-119)\n        112 =\u003e \"Tinkle Bell\",\n        113 =\u003e \"Agogo\",\n        114 =\u003e \"Steel Drums\",\n        115 =\u003e \"Woodblock\",\n        116 =\u003e \"Taiko Drum\",\n        117 =\u003e \"Melodic Tom\",\n        118 =\u003e \"Synth Drum\",\n        119 =\u003e \"Reverse Cymbal\",\n\n        // Sound Effects (120-127)\n        120 =\u003e \"Guitar Fret Noise\",\n        121 =\u003e \"Breath Noise\",\n        122 =\u003e \"Seashore\",\n        123 =\u003e \"Bird Tweet\",\n        124 =\u003e \"Telephone Ring\",\n        125 =\u003e \"Helicopter\",\n        126 =\u003e \"Applause\",\n        127 =\u003e \"Gunshot\",\n\n        // Fallback (should never happen with u8)\n        _ =\u003e \"Unknown Instrument\",\n    }\n    .to_string()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use midly::{MetaMessage, MidiMessage, TrackEvent, TrackEventKind};\n\n    // Helper: Create test track with events\n    fn create_test_track(events: Vec\u003cTrackEvent\u003e) -\u003e Track {\n        events\n    }\n\n    #[test]\n    fn test_get_instrument_name_piano() {\n        assert_eq!(get_instrument_name(0), \"Acoustic Grand Piano\");\n        assert_eq!(get_instrument_name(1), \"Bright Acoustic Piano\");\n        assert_eq!(get_instrument_name(7), \"Clavinet\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_guitar() {\n        assert_eq!(get_instrument_name(24), \"Acoustic Guitar (nylon)\");\n        assert_eq!(get_instrument_name(25), \"Acoustic Guitar (steel)\");\n        assert_eq!(get_instrument_name(30), \"Distortion Guitar\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_strings() {\n        assert_eq!(get_instrument_name(40), \"Violin\");\n        assert_eq!(get_instrument_name(42), \"Cello\");\n        assert_eq!(get_instrument_name(46), \"Orchestral Harp\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_brass() {\n        assert_eq!(get_instrument_name(56), \"Trumpet\");\n        assert_eq!(get_instrument_name(57), \"Trombone\");\n        assert_eq!(get_instrument_name(60), \"French Horn\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_effects() {\n        assert_eq!(get_instrument_name(120), \"Guitar Fret Noise\");\n        assert_eq!(get_instrument_name(122), \"Seashore\");\n        assert_eq!(get_instrument_name(127), \"Gunshot\");\n    }\n\n    #[test]\n    fn test_count_notes_empty_track() {\n        let track = create_test_track(vec![]);\n        assert_eq!(count_notes(\u0026track), 0);\n    }\n\n    #[test]\n    fn test_count_notes_with_notes() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 80.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOff {\n                        key: 60.into(),\n                        vel: 0.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(count_notes(\u0026track), 2);\n    }\n\n    #[test]\n    fn test_count_notes_ignores_zero_velocity() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 0.into(), // Zero velocity = note off\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(count_notes(\u0026track), 1);\n    }\n\n    #[test]\n    fn test_is_tempo_track_true() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::TimeSignature(4, 2, 24, 8)),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::EndOfTrack),\n            },\n        ]);\n\n        assert!(is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_is_tempo_track_false_with_notes() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert!(!is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_is_tempo_track_false_empty() {\n        let track = create_test_track(vec![]);\n        assert!(!is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_extract_track_name_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::TrackName(b\"Piano Track\")),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), Some(\"Piano Track\".to_string()));\n    }\n\n    #[test]\n    fn test_extract_track_name_instrument_name() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::InstrumentName(b\"Grand Piano\")),\n        }]);\n\n        assert_eq!(\n            extract_track_name(\u0026track),\n            Some(\"Grand Piano\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_extract_track_name_not_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_track_name_empty_string() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::TrackName(b\"   \")),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_primary_channel_single_channel() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 5.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 5.into(),\n                    message: MidiMessage::NoteOff {\n                        key: 60.into(),\n                        vel: 0.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(extract_primary_channel(\u0026track), Some(5));\n    }\n\n    #[test]\n    fn test_extract_primary_channel_multiple_channels() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 1.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 1.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 67.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n        ]);\n\n        // Channel 1 has more events\n        assert_eq!(extract_primary_channel(\u0026track), Some(1));\n    }\n\n    #[test]\n    fn test_extract_primary_channel_no_midi() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n        }]);\n\n        assert_eq!(extract_primary_channel(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_instrument_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Midi {\n                channel: 0.into(),\n                message: MidiMessage::ProgramChange { program: 0.into() },\n            },\n        }]);\n\n        assert_eq!(\n            extract_instrument(\u0026track),\n            Some(\"Acoustic Grand Piano\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_extract_instrument_not_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Midi {\n                channel: 0.into(),\n                message: MidiMessage::NoteOn {\n                    key: 60.into(),\n                    vel: 64.into(),\n                },\n            },\n        }]);\n\n        assert_eq!(extract_instrument(\u0026track), None);\n    }\n\n    #[test]\n    fn test_split_error_display() {\n        let err = SplitError::ParseError(\"test error\".to_string());\n        assert_eq!(err.to_string(), \"Failed to parse MIDI data: test error\");\n\n        let err = SplitError::NoTracksToSplit;\n        assert_eq!(\n            err.to_string(),\n            \"No tracks to split - file contains only tempo track or is empty\"\n        );\n    }\n\n    #[test]\n    fn test_split_track_struct() {\n        let track = SplitTrack {\n            track_number: 1,\n            track_name: Some(\"Piano\".to_string()),\n            channel: Some(0),\n            instrument: Some(\"Acoustic Grand Piano\".to_string()),\n            note_count: 42,\n            midi_bytes: vec![0x4d, 0x54, 0x68, 0x64],\n        };\n\n        assert_eq!(track.track_number, 1);\n        assert_eq!(track.track_name, Some(\"Piano\".to_string()));\n        assert_eq!(track.channel, Some(0));\n        assert_eq!(track.note_count, 42);\n        assert_eq!(track.midi_bytes.len(), 4);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","database","batch_insert.rs"],"content":"//! Batch Database Insert Operations\n//!\n//! Architecture: Grown-up Script (service layer with database access)\n//! Purpose: High-performance batch insertion of MIDI file records and metadata\n//!\n//! This module provides batched database operations for importing large numbers\n//! of MIDI files. It uses chunked transactions to achieve 10-50x speedup over\n//! individual INSERT statements.\n//!\n//! # Performance\n//!\n//! - Individual INSERT: ~200 rows/sec\n//! - Batched INSERT: ~10,000-50,000 rows/sec\n//!\n//! # Examples\n//!\n//! ```rust\n//! use batch_insert::BatchInserter;\n//!\n//! let inserter = BatchInserter::new(pool, 1000);\n//! let file_ids = inserter.insert_files_batch(file_records).await?;\n//! inserter.insert_metadata_batch(metadata_records).await?;\n//! ```\n\nuse crate::core::performance::concurrency::calculate_all_settings;\nuse sqlx::{PgPool, Postgres, Transaction};\nuse thiserror::Error;\nuse serde::{Deserialize, Serialize};\n\n//=============================================================================\n// ERROR TYPES\n//=============================================================================\n\n#[derive(Error, Debug)]\npub enum BatchInsertError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n\n    #[error(\"Transaction failed: {0}\")]\n    Transaction(String),\n\n    #[error(\"Empty batch provided\")]\n    EmptyBatch,\n\n    #[error(\"Batch size mismatch: expected {expected}, got {actual}\")]\n    BatchSizeMismatch { expected: usize, actual: usize },\n\n    #[error(\"Invalid data: {0}\")]\n    InvalidData(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, BatchInsertError\u003e;\n\n//=============================================================================\n// DATA STRUCTURES\n//=============================================================================\n\n/// File record for batch insertion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FileRecord {\n    pub filename: String,\n    pub new_filename: String,\n    pub filepath: String,\n    pub parent_folder: Option\u003cString\u003e,\n    pub hash: String,\n    pub file_size: i64,\n    pub category: Option\u003cString\u003e,\n}\n\nimpl FileRecord {\n    pub fn new(\n        filename: String,\n        new_filename: String,\n        filepath: String,\n        parent_folder: Option\u003cString\u003e,\n        hash: String,\n        file_size: i64,\n        category: Option\u003cString\u003e,\n    ) -\u003e Self {\n        Self {\n            filename,\n            new_filename,\n            filepath,\n            parent_folder,\n            hash,\n            file_size,\n            category,\n        }\n    }\n\n    /// Validate record data\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        if self.filename.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"filename cannot be empty\".to_string()));\n        }\n        if self.filepath.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"filepath cannot be empty\".to_string()));\n        }\n        if self.hash.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"hash cannot be empty\".to_string()));\n        }\n        if self.file_size \u003c= 0 {\n            return Err(BatchInsertError::InvalidData(\"file_size must be positive\".to_string()));\n        }\n        Ok(())\n    }\n}\n\n/// Musical metadata for batch insertion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MusicalMetadata {\n    pub file_id: i64,\n    pub bpm: Option\u003ci32\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n    pub num_tracks: Option\u003ci32\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n}\n\nimpl MusicalMetadata {\n    pub fn new(file_id: i64) -\u003e Self {\n        Self {\n            file_id,\n            bpm: None,\n            key_signature: None,\n            time_signature: Some(\"4/4\".to_string()),\n            num_tracks: None,\n            duration_seconds: None,\n        }\n    }\n\n    pub fn with_bpm(mut self, bpm: i32) -\u003e Self {\n        self.bpm = Some(bpm);\n        self\n    }\n\n    pub fn with_key(mut self, key: String) -\u003e Self {\n        self.key_signature = Some(key);\n        self\n    }\n\n    pub fn with_time_signature(mut self, time_sig: String) -\u003e Self {\n        self.time_signature = Some(time_sig);\n        self\n    }\n\n    pub fn with_tracks(mut self, tracks: i32) -\u003e Self {\n        self.num_tracks = Some(tracks);\n        self\n    }\n\n    pub fn with_duration(mut self, duration: f64) -\u003e Self {\n        self.duration_seconds = Some(duration);\n        self\n    }\n\n    /// Validate metadata\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        if self.file_id \u003c= 0 {\n            return Err(BatchInsertError::InvalidData(\"file_id must be positive\".to_string()));\n        }\n        if let Some(bpm) = self.bpm {\n            if bpm \u003c 20 || bpm \u003e 300 {\n                return Err(BatchInsertError::InvalidData(\n                    format!(\"BPM {} out of range (20-300)\", bpm)\n                ));\n            }\n        }\n        if let Some(duration) = self.duration_seconds {\n            if duration \u003c 0.0 {\n                return Err(BatchInsertError::InvalidData(\"duration cannot be negative\".to_string()));\n            }\n        }\n        Ok(())\n    }\n}\n\n//=============================================================================\n// BATCH INSERTER\n//=============================================================================\n\n/// High-performance batch inserter for MIDI file records\n///\n/// This struct provides methods for inserting large numbers of records\n/// efficiently using chunked transactions. It automatically handles\n/// batching, transaction management, and error recovery.\n///\n/// # Performance Characteristics\n///\n/// - Batch size affects memory usage vs speed tradeoff\n/// - Larger batches = fewer transactions = faster (but more memory)\n/// - Default batch size of 1000 is optimal for most cases\n/// - Can achieve 10,000-50,000 inserts/second\n///\n/// # Transaction Safety\n///\n/// All operations use transactions with automatic rollback on error.\n/// If any record in a batch fails, the entire batch is rolled back.\npub struct BatchInserter {\n    pool: PgPool,\n    batch_size: usize,\n}\n\nimpl BatchInserter {\n    /// Create a new batch inserter with specified batch size\n    ///\n    /// # Arguments\n    ///\n    /// * `pool` - PostgreSQL connection pool\n    /// * `batch_size` - Number of records per transaction (recommended: 500-2000)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let inserter = BatchInserter::new(pool, 1000);\n    /// ```\n    pub fn new(pool: PgPool, batch_size: usize) -\u003e Self {\n        Self { pool, batch_size }\n    }\n\n    /// Create with default batch size (1000)\n    ///\n    /// # Deprecated\n    ///\n    /// Consider using `with_optimal_batch_size()` instead for dynamic tuning.\n    pub fn with_defaults(pool: PgPool) -\u003e Self {\n        Self::new(pool, 1000)\n    }\n\n    /// Create with dynamically calculated optimal batch size\n    ///\n    /// Automatically determines the best batch size based on system resources\n    /// (CPU cores, RAM, storage type). This is the recommended constructor.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let inserter = BatchInserter::with_optimal_batch_size(pool);\n    /// ```\n    pub fn with_optimal_batch_size(pool: PgPool) -\u003e Self {\n        let (_, _, batch_size) = calculate_all_settings();\n        println!(\" BatchInserter: Using optimal batch size of {} records\", batch_size);\n        Self::new(pool, batch_size)\n    }\n\n    /// Insert multiple file records in batches\n    ///\n    /// This method chunks the input into batches and inserts each batch\n    /// within a single transaction. Returns the database IDs of all\n    /// inserted records in the same order as input.\n    ///\n    /// # Arguments\n    ///\n    /// * `files` - Vector of file records to insert\n    ///\n    /// # Returns\n    ///\n    /// Vector of database IDs for the inserted records\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Input is empty\n    /// - Any record is invalid\n    /// - Database constraint violation (e.g., duplicate hash)\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let files = vec![\n    ///     FileRecord::new(...),\n    ///     FileRecord::new(...),\n    /// ];\n    /// let ids = inserter.insert_files_batch(files).await?;\n    /// ```\n    pub async fn insert_files_batch(\u0026self, files: Vec\u003cFileRecord\u003e) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        if files.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        // Validate all records first\n        for file in \u0026files {\n            file.validate()?;\n        }\n\n        let mut all_ids = Vec::with_capacity(files.len());\n\n        // Process in chunks\n        for chunk in files.chunks(self.batch_size) {\n            let chunk_ids = self.insert_files_chunk(chunk).await?;\n            all_ids.extend(chunk_ids);\n        }\n\n        Ok(all_ids)\n    }\n\n    /// Insert multiple metadata records in batches\n    ///\n    /// This method efficiently inserts musical metadata for previously\n    /// inserted files. It uses chunked transactions for high performance.\n    ///\n    /// # Arguments\n    ///\n    /// * `metadata` - Vector of metadata records to insert\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Input is empty\n    /// - Any metadata is invalid\n    /// - Referenced file_id doesn't exist\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let metadata = vec![\n    ///     MusicalMetadata::new(1).with_bpm(120).with_key(\"C\".to_string()),\n    ///     MusicalMetadata::new(2).with_bpm(140).with_key(\"Am\".to_string()),\n    /// ];\n    /// inserter.insert_metadata_batch(metadata).await?;\n    /// ```\n    pub async fn insert_metadata_batch(\u0026self, metadata: Vec\u003cMusicalMetadata\u003e) -\u003e Result\u003c()\u003e {\n        if metadata.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        // Validate all records first\n        for meta in \u0026metadata {\n            meta.validate()?;\n        }\n\n        // Process in chunks\n        for chunk in metadata.chunks(self.batch_size) {\n            self.insert_metadata_chunk(chunk).await?;\n        }\n\n        Ok(())\n    }\n\n    /// Insert files and metadata in a single atomic transaction\n    ///\n    /// This method ensures that files and their associated metadata are\n    /// inserted together atomically. If either operation fails, both are\n    /// rolled back.\n    ///\n    /// # Arguments\n    ///\n    /// * `files` - Vector of file records\n    /// * `metadata` - Vector of metadata records (must match file count)\n    ///\n    /// # Returns\n    ///\n    /// Vector of database IDs for the inserted files\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Inputs are empty\n    /// - File and metadata counts don't match\n    /// - Any validation fails\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let files = vec![FileRecord::new(...)];\n    /// let metadata = vec![MusicalMetadata::new(0).with_bpm(120)];\n    /// let ids = inserter.insert_with_transaction(files, metadata).await?;\n    /// ```\n    pub async fn insert_with_transaction(\n        \u0026self,\n        files: Vec\u003cFileRecord\u003e,\n        metadata: Vec\u003cMusicalMetadata\u003e,\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        if files.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        if files.len() != metadata.len() {\n            return Err(BatchInsertError::BatchSizeMismatch {\n                expected: files.len(),\n                actual: metadata.len(),\n            });\n        }\n\n        // Validate all records\n        for file in \u0026files {\n            file.validate()?;\n        }\n\n        let mut all_ids = Vec::with_capacity(files.len());\n\n        // Process in chunks, maintaining file-metadata relationship\n        for (file_chunk, meta_chunk) in files.chunks(self.batch_size).zip(metadata.chunks(self.batch_size)) {\n            let mut tx = self.pool.begin().await?;\n\n            // Insert files and get IDs\n            let chunk_ids = self.insert_files_in_transaction(\u0026mut tx, file_chunk).await?;\n\n            // Update metadata with actual file IDs\n            let mut updated_metadata = Vec::new();\n            for (meta, \u0026file_id) in meta_chunk.iter().zip(chunk_ids.iter()) {\n                let mut updated = meta.clone();\n                updated.file_id = file_id;\n                updated.validate()?;\n                updated_metadata.push(updated);\n            }\n\n            // Insert metadata\n            self.insert_metadata_in_transaction(\u0026mut tx, \u0026updated_metadata).await?;\n\n            // Commit transaction\n            tx.commit().await.map_err(|e| {\n                BatchInsertError::Transaction(format!(\"Failed to commit transaction: {}\", e))\n            })?;\n\n            all_ids.extend(chunk_ids);\n        }\n\n        Ok(all_ids)\n    }\n\n    //=========================================================================\n    // PRIVATE HELPER METHODS\n    //=========================================================================\n\n    /// Insert a single chunk of files (internal method)\n    async fn insert_files_chunk(\u0026self, files: \u0026[FileRecord]) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let mut tx = self.pool.begin().await?;\n        let ids = self.insert_files_in_transaction(\u0026mut tx, files).await?;\n        tx.commit().await?;\n        Ok(ids)\n    }\n\n    /// Insert files within an existing transaction\n    async fn insert_files_in_transaction(\n        \u0026self,\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        files: \u0026[FileRecord],\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let mut ids = Vec::with_capacity(files.len());\n\n        for file in files {\n            let id = sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                INSERT INTO files (\n                    filename, original_filename, filepath, parent_folder, content_hash,\n                    file_size_bytes, imported_at\n                )\n                VALUES ($1, $2, $3, $4, decode($5, 'hex'), $6, NOW())\n                ON CONFLICT (content_hash) DO NOTHING\n                RETURNING id\n                \"#,\n            )\n            .bind(\u0026file.filename)\n            .bind(\u0026file.new_filename)\n            .bind(\u0026file.filepath)\n            .bind(\u0026file.parent_folder)\n            .bind(\u0026file.hash)\n            .bind(file.file_size)\n            .fetch_optional(\u0026mut **tx)\n            .await?;\n\n            // If conflict (duplicate), skip this record\n            if let Some(id) = id {\n                ids.push(id);\n            }\n        }\n\n        Ok(ids)\n    }\n\n    /// Insert a single chunk of metadata (internal method)\n    async fn insert_metadata_chunk(\u0026self, metadata: \u0026[MusicalMetadata]) -\u003e Result\u003c()\u003e {\n        let mut tx = self.pool.begin().await?;\n        self.insert_metadata_in_transaction(\u0026mut tx, metadata).await?;\n        tx.commit().await?;\n        Ok(())\n    }\n\n    /// Insert metadata within an existing transaction\n    async fn insert_metadata_in_transaction(\n        \u0026self,\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        metadata: \u0026[MusicalMetadata],\n    ) -\u003e Result\u003c()\u003e {\n        for meta in metadata {\n            sqlx::query(\n                r#\"\n                INSERT INTO musical_metadata (\n                    file_id, bpm, key_signature, time_signature,\n                    num_tracks, duration_seconds\n                )\n                VALUES ($1, $2, $3, $4, $5, $6)\n                ON CONFLICT (file_id) DO UPDATE SET\n                    bpm = EXCLUDED.bpm,\n                    key_signature = EXCLUDED.key_signature,\n                    time_signature = EXCLUDED.time_signature,\n                    num_tracks = EXCLUDED.num_tracks,\n                    duration_seconds = EXCLUDED.duration_seconds\n                \"#,\n            )\n            .bind(meta.file_id)\n            .bind(meta.bpm)\n            .bind(\u0026meta.key_signature)\n            .bind(\u0026meta.time_signature)\n            .bind(meta.num_tracks)\n            .bind(meta.duration_seconds)\n            .execute(\u0026mut **tx)\n            .await?;\n        }\n\n        Ok(())\n    }\n}\n\n//=============================================================================\n// UTILITY FUNCTIONS\n//=============================================================================\n\n/// Calculate optimal batch size based on system memory\n///\n/// This function provides a dynamically calculated batch size based on\n/// detected system resources (CPU cores, RAM, storage type).\n///\n/// # Returns\n///\n/// Recommended batch size (between 500 and 10,000)\n///\n/// # Examples\n///\n/// ```rust\n/// let batch_size = calculate_optimal_batch_size();\n/// let inserter = BatchInserter::new(pool, batch_size);\n/// ```\npub fn calculate_optimal_batch_size() -\u003e usize {\n    // Use the dynamic concurrency module to calculate optimal batch size\n    let (_, _, batch_size) = calculate_all_settings();\n    batch_size\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_file_record_validation() {\n        let valid = FileRecord::new(\n            \"test.mid\".to_string(),\n            \"new_test.mid\".to_string(),\n            \"/path/to/test.mid\".to_string(),\n            Some(\"drums\".to_string()),\n            \"abc123\".to_string(),\n            1024,\n            Some(\"drums\".to_string()),\n        );\n        assert!(valid.validate().is_ok());\n\n        let empty_filename = FileRecord::new(\n            \"\".to_string(),\n            \"new.mid\".to_string(),\n            \"/path\".to_string(),\n            None,\n            \"hash\".to_string(),\n            1024,\n            None,\n        );\n        assert!(empty_filename.validate().is_err());\n\n        let negative_size = FileRecord::new(\n            \"test.mid\".to_string(),\n            \"new.mid\".to_string(),\n            \"/path\".to_string(),\n            None,\n            \"hash\".to_string(),\n            -100,\n            None,\n        );\n        assert!(negative_size.validate().is_err());\n    }\n\n    #[test]\n    fn test_musical_metadata_validation() {\n        let valid = MusicalMetadata::new(1)\n            .with_bpm(120)\n            .with_key(\"C\".to_string())\n            .with_duration(180.5);\n        assert!(valid.validate().is_ok());\n\n        let invalid_bpm = MusicalMetadata::new(1).with_bpm(500);\n        assert!(invalid_bpm.validate().is_err());\n\n        let negative_duration = MusicalMetadata::new(1).with_duration(-10.0);\n        assert!(negative_duration.validate().is_err());\n\n        let invalid_file_id = MusicalMetadata::new(0);\n        assert!(invalid_file_id.validate().is_err());\n    }\n\n    #[test]\n    fn test_musical_metadata_builder() {\n        let meta = MusicalMetadata::new(1)\n            .with_bpm(140)\n            .with_key(\"Am\".to_string())\n            .with_time_signature(\"3/4\".to_string())\n            .with_tracks(8)\n            .with_duration(240.0);\n\n        assert_eq!(meta.file_id, 1);\n        assert_eq!(meta.bpm, Some(140));\n        assert_eq!(meta.key_signature, Some(\"Am\".to_string()));\n        assert_eq!(meta.time_signature, Some(\"3/4\".to_string()));\n        assert_eq!(meta.num_tracks, Some(8));\n        assert_eq!(meta.duration_seconds, Some(240.0));\n    }\n\n    #[test]\n    fn test_calculate_optimal_batch_size() {\n        let size = calculate_optimal_batch_size();\n        assert!(size \u003e= 100 \u0026\u0026 size \u003c= 5000);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","database","mod.rs"],"content":"// Database Connection Module - MANAGER ARCHETYPE (OPTIMIZED)\n//\n// PURPOSE: Manage PostgreSQL connection pool and provide database access with performance optimizations\n// ARCHETYPE: Manager (I/O operations with side effects)\n// LOCATION: pipeline/src-tauri/src/database/mod.rs\n//\n//  CAN: Perform I/O operations (database connections)\n//  CAN: Have side effects (connection pooling)\n//  SHOULD: Handle errors properly with retry logic\n//  SHOULD: Monitor performance metrics\n//  NO: Business logic\n//  NO: UI concerns\n//\n// OPTIMIZATIONS APPLIED:\n// 1. Connection pool tuning for high-performance workloads\n// 2. Prepared statement caching enabled\n// 3. Query timeout handling\n// 4. Retry logic with exponential backoff for transient failures\n// 5. Performance monitoring and health checks\n// 6. Slow query logging\n// 7. Connection health validation\n\n// Batch insert module for high-performance bulk operations\npub mod batch_insert;\n\nuse crate::core::performance::concurrency::calculate_all_settings;\nuse sqlx::postgres::{PgPool, PgPoolOptions, PgConnectOptions};\nuse std::time::{Duration, Instant};\nuse std::future::Future;\nuse std::str::FromStr;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Database connection pool wrapper with performance optimizations\n///\n/// ## Connection Pool Settings (OPTIMIZED):\n/// - Max connections: 50 (increased from 20 for better concurrency)\n/// - Min connections: 10 (increased from 5 to reduce cold starts)\n/// - Acquire timeout: 10 seconds (reduced from 30s for faster failure detection)\n/// - Idle timeout: 300 seconds (5 minutes, reduced from 10min for better recycling)\n/// - Max lifetime: 1800 seconds (30 minutes)\n/// - Statement cache size: 100 (NEW - prepared statement caching)\n/// - Test before acquire: true (validates connection health)\n///\n/// ## Performance Features:\n/// - Automatic retry with exponential backoff for transient errors\n/// - Connection health monitoring\n/// - Slow query detection (queries \u003e 1s)\n/// - Pool statistics tracking\n/// - Comprehensive health checks\n///\n/// # Example\n///\n/// ```rust\n/// use database::Database;\n///\n/// #[tokio::main]\n/// async fn main() -\u003e Result\u003c(), sqlx::Error\u003e {\n///     let db = Database::new(\"postgresql://midiuser:145278963@localhost:5433/midi_library\").await?;\n///\n///     // Test connection with health check\n///     let health = db.health_check().await;\n///     println!(\"Database health: {:?}\", health);\n///\n///     // Execute query with automatic retry\n///     let result = db.execute_with_retry(3, || async {\n///         sqlx::query(\"SELECT * FROM files LIMIT 10\")\n///             .fetch_all(db.pool())\n///             .await\n///     }).await?;\n///\n///     Ok(())\n/// }\n/// ```\npub struct Database {\n    pool: Arc\u003cRwLock\u003cPgPool\u003e\u003e,\n    database_url: String,\n    reconnect_attempts: Arc\u003cRwLock\u003cu32\u003e\u003e,\n}\n\nimpl Database {\n    /// Create new database connection pool with optimized settings\n    ///\n    /// Establishes connection to PostgreSQL database with production-grade pool settings\n    /// optimized for handling MIDI library operations at scale (millions of files).\n    ///\n    /// ## Connection Pool Optimizations:\n    /// - **50 max connections**: Supports high concurrency for batch imports\n    /// - **10 min connections**: Reduces latency by keeping connections warm\n    /// - **Prepared statement cache**: Speeds up repeated queries by 2-5x\n    /// - **Connection validation**: Tests connections before use to prevent stale connections\n    /// - **Aggressive timeouts**: Fast failure detection for better user experience\n    ///\n    /// ## Performance Characteristics:\n    /// - Connection acquisition: \u003c 5ms (warm pool)\n    /// - Query execution: 1-100ms (depending on complexity)\n    /// - Handles 100-500 concurrent operations\n    /// - Memory overhead: ~50MB for connection pool\n    ///\n    /// # Arguments\n    ///\n    /// * `database_url` - PostgreSQL connection string (e.g., \"postgresql://user:pass@localhost:5433/dbname\")\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cSelf, sqlx::Error\u003e` - Database instance or connection error\n    ///\n    /// # Errors\n    ///\n    /// - Connection refused: Database not running\n    /// - Authentication failed: Invalid credentials\n    /// - Timeout: Database unreachable\n    /// - Invalid URL: Malformed connection string\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let db = Database::new(\"postgresql://midiuser:145278963@localhost:5433/midi_library\").await?;\n    /// ```\n    pub async fn new(database_url: \u0026str) -\u003e Result\u003cSelf, sqlx::Error\u003e {\n        println!(\" Connecting to database: {}\", database_url);\n        println!(\" Applying performance optimizations...\");\n\n        // Calculate optimal pool size dynamically based on system resources\n        let (concurrency, pool_size, batch_size) = calculate_all_settings();\n        println!(\" Dynamic pool sizing detected:\");\n        println!(\"   Concurrency:  {} workers\", concurrency);\n        println!(\"   Pool Size:    {} connections (auto-tuned)\", pool_size);\n        println!(\"   Batch Size:   {} records\", batch_size);\n\n        // Parse connection options for advanced configuration\n        let mut connect_options = PgConnectOptions::from_str(database_url)?;\n\n        // Enable prepared statement caching (OPTIMIZATION #2)\n        // Caches up to 100 prepared statements per connection\n        // Reduces parsing overhead for repeated queries by 2-5x\n        connect_options = connect_options.statement_cache_capacity(100);\n\n        // Set application name for monitoring\n        connect_options = connect_options.application_name(\"midi-library-pipeline\");\n\n        // Calculate minimum connections (20% of max, but at least 5)\n        let min_connections = (pool_size as f64 * 0.2).max(5.0) as u32;\n\n        // Build optimized connection pool (OPTIMIZATION #1)\n        let pool = PgPoolOptions::new()\n            // Dynamic max connections - auto-tuned based on CPU cores and RAM\n            // Formula: (concurrency  1.5).clamp(20, 200)\n            .max_connections(pool_size as u32)\n\n            // Dynamic min connections - scales with pool size (20% of max, min 5)\n            // Keeps connections warm for better performance\n            .min_connections(min_connections)\n\n            // 10s acquire timeout - fail fast for better UX\n            // Reduced from 30s to detect issues earlier\n            .acquire_timeout(Duration::from_secs(10))\n\n            // 30min max lifetime - prevents connection leaks\n            // Balances connection reuse with freshness\n            .max_lifetime(Duration::from_secs(1800))\n\n            // 5min idle timeout - recycles idle connections faster\n            // Reduced from 10min for better resource management\n            .idle_timeout(Duration::from_secs(300))\n\n            // Test before acquire - validates connection health\n            // Prevents using stale/broken connections\n            .test_before_acquire(true)\n\n            // Connect with optimized options\n            .connect_with(connect_options)\n            .await?;\n\n        println!(\" Database connected successfully\");\n        println!(\" Pool configuration: {} max, {} min, 10s timeout\",\n                 pool_size, min_connections);\n        println!(\" Prepared statement cache: enabled (100 statements)\");\n        println!(\" Expected performance: ~{} files/sec parallel import\",\n                 concurrency * 25);\n\n        Ok(Self {\n            pool: Arc::new(RwLock::new(pool)),\n            database_url: database_url.to_string(),\n            reconnect_attempts: Arc::new(RwLock::new(0)),\n        })\n    }\n\n    /// Get cloned connection pool for use in queries\n    ///\n    /// Returns a cloned reference to the underlying PgPool.\n    /// PgPool uses Arc internally, so cloning is cheap (just increments ref count).\n    ///\n    /// # Returns\n    ///\n    /// * `PgPool` - Cloned pool reference\n    ///\n    /// # Performance Notes\n    ///\n    /// - Clone operation: \u003c 1s (just Arc clone)\n    /// - Connection acquisition: \u003c 5ms with warm pool\n    /// - Automatic connection health validation\n    /// - Thread-safe for concurrent access\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let pool = db.pool().await;\n    /// sqlx::query(\"SELECT * FROM files\").fetch_all(\u0026pool).await?;\n    /// ```\n    pub async fn pool(\u0026self) -\u003e PgPool {\n        self.pool.read().await.clone()\n    }\n\n    /// Attempt to reconnect to the database with exponential backoff\n    ///\n    /// Implements automatic reconnection with exponential backoff strategy:\n    /// - Initial delay: 1 second\n    /// - Max delay: 30 seconds\n    /// - Max attempts: 5\n    /// - Backoff multiplier: 2x\n    ///\n    /// ## Reconnection Strategy:\n    /// 1. Attempt 1: Wait 1s before retry\n    /// 2. Attempt 2: Wait 2s before retry\n    /// 3. Attempt 3: Wait 4s before retry\n    /// 4. Attempt 4: Wait 8s before retry\n    /// 5. Attempt 5: Wait 16s before retry (capped at 30s)\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003c(), sqlx::Error\u003e` - Ok if reconnection successful\n    ///\n    /// # Errors\n    ///\n    /// Returns error if all reconnection attempts fail\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// if let Err(e) = db.reconnect().await {\n    ///     eprintln!(\"Failed to reconnect: {}\", e);\n    /// }\n    /// ```\n    pub async fn reconnect(\u0026self) -\u003e Result\u003c(), sqlx::Error\u003e {\n        const MAX_ATTEMPTS: u32 = 5;\n        const MAX_DELAY_SECS: u64 = 30;\n\n        let mut attempts = self.reconnect_attempts.write().await;\n        *attempts = 0;\n\n        println!(\" Attempting database reconnection...\");\n\n        for attempt in 1..=MAX_ATTEMPTS {\n            *attempts = attempt;\n\n            // Calculate delay with exponential backoff (1s, 2s, 4s, 8s, 16s)\n            let delay_secs = std::cmp::min(2_u64.pow(attempt - 1), MAX_DELAY_SECS);\n\n            if attempt \u003e 1 {\n                println!(\" Waiting {} seconds before reconnection attempt {}/{}...\",\n                    delay_secs, attempt, MAX_ATTEMPTS);\n                tokio::time::sleep(Duration::from_secs(delay_secs)).await;\n            }\n\n            println!(\" Reconnection attempt {}/{}\", attempt, MAX_ATTEMPTS);\n\n            match Self::create_pool(\u0026self.database_url).await {\n                Ok(new_pool) =\u003e {\n                    // Successfully reconnected - replace pool\n                    let mut pool = self.pool.write().await;\n                    *pool = new_pool;\n                    *attempts = 0;\n\n                    println!(\" Database reconnected successfully on attempt {}\", attempt);\n                    return Ok(());\n                }\n                Err(e) =\u003e {\n                    eprintln!(\" Reconnection attempt {} failed: {}\", attempt, e);\n\n                    if attempt == MAX_ATTEMPTS {\n                        eprintln!(\" All reconnection attempts exhausted\");\n                        return Err(e);\n                    }\n                }\n            }\n        }\n\n        Err(sqlx::Error::PoolTimedOut)\n    }\n\n    /// Internal helper to create a new connection pool\n    ///\n    /// Extracted from `new()` for reuse in reconnection logic.\n    async fn create_pool(database_url: \u0026str) -\u003e Result\u003cPgPool, sqlx::Error\u003e {\n        // Get dynamic pool settings\n        let (_, pool_size, _) = calculate_all_settings();\n        let min_connections = (pool_size as f64 * 0.2).max(5.0) as u32;\n\n        let mut connect_options = PgConnectOptions::from_str(database_url)?;\n        connect_options = connect_options.statement_cache_capacity(100);\n        connect_options = connect_options.application_name(\"midi-library-pipeline\");\n\n        let pool = PgPoolOptions::new()\n            .max_connections(pool_size as u32)\n            .min_connections(min_connections)\n            .acquire_timeout(Duration::from_secs(10))\n            .max_lifetime(Duration::from_secs(1800))\n            .idle_timeout(Duration::from_secs(300))\n            .test_before_acquire(true)\n            .connect_with(connect_options)\n            .await?;\n\n        Ok(pool)\n    }\n\n    /// Execute operation with automatic reconnection on connection loss\n    ///\n    /// Wraps database operations with automatic reconnection logic.\n    /// If operation fails due to connection issues, attempts to reconnect\n    /// and retry the operation once.\n    ///\n    /// ## Recovery Strategy:\n    /// 1. Execute operation\n    /// 2. If connection error detected  reconnect\n    /// 3. Retry operation once after reconnection\n    /// 4. If still fails  return error\n    ///\n    /// # Arguments\n    ///\n    /// * `operation` - Async operation to execute\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cT, sqlx::Error\u003e` - Operation result\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let count = db.execute_with_reconnect(|| async {\n    ///     sqlx::query_scalar::\u003c_, i64\u003e(\"SELECT COUNT(*) FROM files\")\n    ///         .fetch_one(\u0026db.pool().await)\n    ///         .await\n    /// }).await?;\n    /// ```\n    pub async fn execute_with_reconnect\u003cT, F, Fut\u003e(\n        \u0026self,\n        operation: F,\n    ) -\u003e Result\u003cT, sqlx::Error\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: Future\u003cOutput = Result\u003cT, sqlx::Error\u003e\u003e,\n    {\n        // Try operation first\n        match operation().await {\n            Ok(result) =\u003e Ok(result),\n            Err(e) if is_connection_error(\u0026e) =\u003e {\n                eprintln!(\"  Connection error detected: {}. Attempting reconnection...\", e);\n\n                // Try to reconnect\n                if let Err(reconnect_err) = self.reconnect().await {\n                    eprintln!(\" Reconnection failed: {}\", reconnect_err);\n                    return Err(e); // Return original error\n                }\n\n                // Retry operation after successful reconnection\n                println!(\" Retrying operation after reconnection...\");\n                match operation().await {\n                    Ok(result) =\u003e {\n                        println!(\" Operation succeeded after reconnection\");\n                        Ok(result)\n                    }\n                    Err(retry_err) =\u003e {\n                        eprintln!(\" Operation failed even after reconnection: {}\", retry_err);\n                        Err(retry_err)\n                    }\n                }\n            }\n            Err(e) =\u003e Err(e),\n        }\n    }\n\n    /// Convert technical database errors to user-friendly messages\n    ///\n    /// Transforms low-level PostgreSQL/sqlx errors into messages that\n    /// users can understand and potentially act upon.\n    ///\n    /// # Arguments\n    ///\n    /// * `error` - Database error to convert\n    ///\n    /// # Returns\n    ///\n    /// * `String` - User-friendly error message with context\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let friendly_msg = db.create_user_friendly_error(\u0026err);\n    /// // Returns: \"Database connection lost. Please check your connection and try again.\"\n    /// ```\n    pub fn create_user_friendly_error(\u0026self, error: \u0026sqlx::Error) -\u003e String {\n        match error {\n            // Connection errors\n            sqlx::Error::PoolTimedOut =\u003e {\n                \"Database is busy. Too many concurrent requests. Please try again in a moment.\".to_string()\n            }\n            sqlx::Error::PoolClosed =\u003e {\n                \"Database connection lost. The application is attempting to reconnect...\".to_string()\n            }\n            sqlx::Error::Io(io_err) =\u003e {\n                format!(\"Network error while connecting to database: {}. Please check your connection.\",\n                    io_err)\n            }\n\n            // Query errors\n            sqlx::Error::RowNotFound =\u003e {\n                \"The requested item was not found in the database.\".to_string()\n            }\n            sqlx::Error::ColumnNotFound(col) =\u003e {\n                format!(\"Database structure error: Column '{}' not found. Please update your database schema.\", col)\n            }\n\n            // Database errors with detailed handling\n            sqlx::Error::Database(db_err) =\u003e {\n                let code = db_err.code().unwrap_or_default();\n\n                match code.as_ref() {\n                    // Unique constraint violation\n                    \"23505\" =\u003e \"This item already exists in the database. Duplicate entries are not allowed.\".to_string(),\n\n                    // Foreign key violation\n                    \"23503\" =\u003e \"Cannot perform this operation because it would violate data relationships.\".to_string(),\n\n                    // Not null violation\n                    \"23502\" =\u003e \"Required field is missing. Please provide all required information.\".to_string(),\n\n                    // Connection errors\n                    \"08000\" | \"08003\" | \"08006\" =\u003e {\n                        \"Database connection error. Please check that the database is running and try again.\".to_string()\n                    }\n\n                    // Syntax errors\n                    \"42601\" | \"42P01\" =\u003e {\n                        format!(\"Database query error: {}. This may indicate a software bug.\", db_err.message())\n                    }\n\n                    // Permission errors\n                    \"42501\" =\u003e \"Database permission denied. Please check your database user permissions.\".to_string(),\n\n                    // Default for other database errors\n                    _ =\u003e format!(\"Database error ({}): {}. Please contact support if this persists.\",\n                        code, db_err.message())\n                }\n            }\n\n            // Timeout\n            sqlx::Error::WorkerCrashed =\u003e {\n                \"Database operation failed unexpectedly. Please try again.\".to_string()\n            }\n\n            // Type conversion errors\n            sqlx::Error::Decode(decode_err) =\u003e {\n                format!(\"Data format error: {}. The database may contain unexpected data.\", decode_err)\n            }\n\n            // Default fallback\n            _ =\u003e {\n                format!(\"An unexpected database error occurred: {}. Please try again or contact support.\", error)\n            }\n        }\n    }\n\n    /// Test database connection\n    ///\n    /// Executes a simple query to verify database connectivity.\n    /// Uses a lightweight query that doesn't require table access.\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cbool, sqlx::Error\u003e` - True if connected, error otherwise\n    ///\n    /// # Performance\n    ///\n    /// - Typical execution: 1-5ms\n    /// - Network latency: 0-2ms (localhost)\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// if db.test_connection().await? {\n    ///     println!(\" Database is reachable\");\n    /// }\n    /// ```\n    pub async fn test_connection(\u0026self) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let pool = self.pool().await;\n        sqlx::query(\"SELECT 1\")\n            .fetch_one(\u0026pool)\n            .await?;\n        Ok(true)\n    }\n\n    /// Execute operation with automatic retry and exponential backoff (OPTIMIZATION #4)\n    ///\n    /// Retries transient database errors (connection timeouts, pool exhaustion, I/O errors)\n    /// with exponential backoff to handle temporary failures gracefully.\n    ///\n    /// ## Retry Strategy:\n    /// - Initial delay: 100ms\n    /// - Backoff multiplier: 2x (exponential)\n    /// - Max retries: configurable (typically 3-5)\n    /// - Only retries transient errors\n    ///\n    /// ## Transient Errors (retried):\n    /// - `PoolTimedOut`: Pool exhausted, retry after delay\n    /// - `PoolClosed`: Connection pool closing\n    /// - `Io`: Network I/O errors\n    ///\n    /// ## Non-Transient Errors (fail immediately):\n    /// - Query syntax errors\n    /// - Permission denied\n    /// - Table/column not found\n    /// - Constraint violations\n    ///\n    /// # Arguments\n    ///\n    /// * `max_retries` - Maximum retry attempts (typically 3-5)\n    /// * `operation` - Async operation to execute\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cT, sqlx::Error\u003e` - Operation result or final error\n    ///\n    /// # Performance Impact\n    ///\n    /// - Success case: no overhead\n    /// - Retry case: adds 100ms, 200ms, 400ms delays (exponential)\n    /// - Total retry time for 3 retries: ~700ms\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// // Retry up to 3 times for transient failures\n    /// let files = db.execute_with_retry(3, || async {\n    ///     sqlx::query_as::\u003c_, MidiFile\u003e(\"SELECT * FROM files WHERE bpm \u003e $1\")\n    ///         .bind(120)\n    ///         .fetch_all(db.pool())\n    ///         .await\n    /// }).await?;\n    /// ```\n    pub async fn execute_with_retry\u003cT, F, Fut\u003e(\n        \u0026self,\n        max_retries: u32,\n        operation: F,\n    ) -\u003e Result\u003cT, sqlx::Error\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: Future\u003cOutput = Result\u003cT, sqlx::Error\u003e\u003e,\n    {\n        let mut retries = 0;\n        let mut delay = Duration::from_millis(100); // Start with 100ms\n\n        loop {\n            match operation().await {\n                Ok(result) =\u003e return Ok(result),\n                Err(e) if retries \u003c max_retries \u0026\u0026 is_transient_error(\u0026e) =\u003e {\n                    retries += 1;\n                    eprintln!(\n                        \"  Database operation failed (attempt {}/{}): {}. Retrying in {:?}...\",\n                        retries, max_retries, e, delay\n                    );\n                    tokio::time::sleep(delay).await;\n                    delay = delay * 2; // Exponential backoff\n                }\n                Err(e) =\u003e {\n                    if retries \u003e 0 {\n                        eprintln!(\" Database operation failed after {} retries: {}\", retries, e);\n                    }\n                    return Err(e);\n                }\n            }\n        }\n    }\n\n    /// Get connection pool statistics (OPTIMIZATION #5)\n    ///\n    /// Returns current pool statistics for monitoring and debugging.\n    /// Useful for capacity planning and performance troubleshooting.\n    ///\n    /// ## Metrics Provided:\n    /// - Total connections: Current pool size\n    /// - Idle connections: Available for immediate use\n    /// - Active connections: Currently executing queries\n    ///\n    /// ## Healthy Pool Indicators:\n    /// - Idle \u003e 0: Connections available\n    /// - Active \u003c max: Not at capacity\n    /// - Size \u003e= min: Pool properly initialized\n    ///\n    /// # Returns\n    ///\n    /// * `PoolStats` - Current pool statistics\n    ///\n    /// # Performance\n    ///\n    /// - Execution time: \u003c 1s (no I/O, just reads atomic counters)\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let stats = db.get_pool_stats();\n    /// println!(\"Pool utilization: {}/{} ({} idle)\",\n    ///     stats.active, stats.size, stats.idle);\n    ///\n    /// if stats.idle == 0 {\n    ///     println!(\"  Warning: Connection pool exhausted!\");\n    /// }\n    /// ```\n    pub async fn get_pool_stats(\u0026self) -\u003e PoolStats {\n        let pool = self.pool.read().await;\n        let size = pool.size();\n        let idle = pool.num_idle();\n        let active = size as usize - idle;\n\n        PoolStats {\n            size,\n            idle,\n            active,\n        }\n    }\n\n    /// Comprehensive health check (OPTIMIZATION #5)\n    ///\n    /// Performs multiple health checks to verify database is fully operational.\n    /// More thorough than `test_connection()`, includes pool health and timing.\n    ///\n    /// ## Health Checks Performed:\n    /// 1. Connection pool statistics (capacity check)\n    /// 2. Simple query execution (connectivity check)\n    /// 3. Response time measurement (performance check)\n    ///\n    /// ## Health Status:\n    /// - **Healthy**: All checks pass, response \u003c 100ms\n    /// - **Degraded**: Checks pass but slow (100-1000ms)\n    /// - **Unhealthy**: Checks fail or response \u003e 1000ms\n    ///\n    /// # Returns\n    ///\n    /// * `HealthStatus` - Comprehensive health information\n    ///\n    /// # Performance\n    ///\n    /// - Typical execution: 1-10ms\n    /// - Degraded: 100-1000ms\n    /// - Failed: \u003e 1000ms or error\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let health = db.health_check().await;\n    /// if health.is_healthy {\n    ///     println!(\" Database healthy ({} ms)\", health.response_time_ms);\n    /// } else {\n    ///     println!(\" Database unhealthy: pool={:?}, connection={}\",\n    ///         health.pool_stats, health.connection_test);\n    /// }\n    /// ```\n    pub async fn health_check(\u0026self) -\u003e HealthStatus {\n        let start = Instant::now();\n\n        // Check 1: Pool statistics\n        let pool_stats = self.get_pool_stats().await;\n\n        // Check 2: Connection test\n        let connection_test = self.test_connection().await.is_ok();\n\n        // Measure response time\n        let response_time_ms = start.elapsed().as_millis() as u64;\n\n        // Determine overall health\n        let is_healthy = connection_test\n            \u0026\u0026 pool_stats.size \u003e 0\n            \u0026\u0026 response_time_ms \u003c 1000; // Consider unhealthy if \u003e 1s response\n\n        // Log slow health checks (OPTIMIZATION #6 - slow query logging)\n        if response_time_ms \u003e 100 {\n            eprintln!(\"  Slow health check: {} ms (threshold: 100ms)\", response_time_ms);\n        }\n\n        HealthStatus {\n            is_healthy,\n            pool_stats,\n            connection_test,\n            response_time_ms,\n        }\n    }\n\n    /// Close all connections gracefully\n    ///\n    /// Gracefully closes all connections in the pool.\n    /// Should be called during application shutdown to clean up resources.\n    ///\n    /// ## Shutdown Process:\n    /// 1. Stop accepting new connections\n    /// 2. Wait for active queries to complete (with timeout)\n    /// 3. Close idle connections\n    /// 4. Close remaining connections\n    ///\n    /// # Performance\n    ///\n    /// - Typical shutdown: 100-500ms\n    /// - Waits for active queries to complete\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// // During application shutdown\n    /// db.close().await;\n    /// ```\n    pub async fn close(\u0026self) {\n        println!(\" Closing database connections...\");\n        let pool = self.pool.read().await;\n        pool.close().await;\n        println!(\" All connections closed\");\n    }\n}\n\n/// Connection pool statistics\n///\n/// Provides monitoring information about the connection pool state.\n/// Used for capacity planning, performance monitoring, and debugging.\n#[derive(Debug, Clone)]\npub struct PoolStats {\n    /// Total number of connections in the pool\n    pub size: u32,\n    /// Number of idle connections available for immediate use\n    pub idle: usize,\n    /// Number of active connections currently executing queries\n    pub active: usize,\n}\n\nimpl std::fmt::Display for PoolStats {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(\n            f,\n            \"Pool: {} total, {} idle, {} active\",\n            self.size, self.idle, self.active\n        )\n    }\n}\n\n/// Comprehensive health status information\n///\n/// Contains detailed health check results for monitoring and diagnostics.\n#[derive(Debug, Clone)]\npub struct HealthStatus {\n    /// Overall health status (true = healthy, false = unhealthy)\n    pub is_healthy: bool,\n    /// Current connection pool statistics\n    pub pool_stats: PoolStats,\n    /// Connection test result (true = connected, false = failed)\n    pub connection_test: bool,\n    /// Response time for health check in milliseconds\n    pub response_time_ms: u64,\n}\n\nimpl std::fmt::Display for HealthStatus {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        let status = if self.is_healthy { \"HEALTHY \" } else { \"UNHEALTHY \" };\n        write!(\n            f,\n            \"{} - Response: {}ms, {}, Connection: {}\",\n            status,\n            self.response_time_ms,\n            self.pool_stats,\n            if self.connection_test { \"OK\" } else { \"FAILED\" }\n        )\n    }\n}\n\n/// Check if error is transient and can be retried\n///\n/// Transient errors are temporary failures that may succeed on retry.\n/// Non-transient errors are permanent failures that won't change on retry.\n///\n/// # Arguments\n///\n/// * `error` - Database error to check\n///\n/// # Returns\n///\n/// * `bool` - True if error is transient and should be retried\nfn is_transient_error(error: \u0026sqlx::Error) -\u003e bool {\n    match error {\n        // Pool exhaustion - may recover as connections are released\n        sqlx::Error::PoolTimedOut =\u003e true,\n\n        // Pool closing - may be temporary during reconnection\n        sqlx::Error::PoolClosed =\u003e true,\n\n        // Network I/O errors - may be temporary network issues\n        sqlx::Error::Io(_) =\u003e true,\n\n        // All other errors are non-transient\n        _ =\u003e false,\n    }\n}\n\n/// Check if error is a connection error that requires reconnection\n///\n/// Connection errors indicate the database connection is broken and\n/// needs to be re-established before operations can continue.\n///\n/// # Arguments\n///\n/// * `error` - Database error to check\n///\n/// # Returns\n///\n/// * `bool` - True if error indicates connection loss\nfn is_connection_error(error: \u0026sqlx::Error) -\u003e bool {\n    match error {\n        // Connection pool closed - requires reconnection\n        sqlx::Error::PoolClosed =\u003e true,\n\n        // Network I/O errors - likely connection loss\n        sqlx::Error::Io(_) =\u003e true,\n\n        // Check for specific database connection errors\n        sqlx::Error::Database(db_err) =\u003e {\n            let code = db_err.code().unwrap_or_default();\n            matches!(code.as_ref(), \"08000\" | \"08003\" | \"08006\" | \"57P01\" | \"57P02\" | \"57P03\")\n        }\n\n        // All other errors are not connection errors\n        _ =\u003e false,\n    }\n}\n\n// ============================================================================\n// TESTS\n// ============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    const TEST_DATABASE_URL: \u0026str = \"postgresql://midiuser:145278963@localhost:5433/midi_library\";\n\n    /// Test database connection with optimized settings\n    #[tokio::test]\n    async fn test_database_connection() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let is_connected = db\n            .test_connection()\n            .await\n            .expect(\"Connection test failed\");\n\n        assert!(is_connected);\n    }\n\n    /// Test pool statistics with optimized pool\n    #[tokio::test]\n    async fn test_pool_stats() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let stats = db.get_pool_stats().await;\n\n        // Should have at least min_connections (10) in optimized pool\n        assert!(stats.size \u003e= 10, \"Pool size should be \u003e= 10, got {}\", stats.size);\n        assert_eq!(stats.idle + stats.active, stats.size as usize);\n        println!(\" {}\", stats);\n    }\n\n    /// Test health check functionality\n    #[tokio::test]\n    async fn test_health_check() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let health = db.health_check().await;\n\n        assert!(health.is_healthy, \"Database should be healthy\");\n        assert!(health.connection_test, \"Connection test should pass\");\n        assert!(health.response_time_ms \u003c 1000, \"Response time should be \u003c 1s\");\n        assert!(health.pool_stats.size \u003e 0, \"Pool should have connections\");\n\n        println!(\" {}\", health);\n    }\n\n    /// Test retry logic with successful operation\n    #[tokio::test]\n    async fn test_retry_success() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let result = db.execute_with_retry(3, || async {\n            let pool = db.pool().await;\n            sqlx::query_as::\u003c_, (i32,)\u003e(\"SELECT 1\")\n                .fetch_one(\u0026pool)\n                .await\n        }).await;\n\n        assert!(result.is_ok(), \"Retry should succeed on first attempt\");\n        assert_eq!(result.unwrap().0, 1);\n    }\n\n    /// Test pool reference access with optimized pool\n    #[tokio::test]\n    async fn test_pool_reference() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let pool = db.pool().await;\n\n        // Execute query using pool reference\n        let result: (i32,) = sqlx::query_as(\"SELECT 1\")\n            .fetch_one(\u0026pool)\n            .await\n            .expect(\"Query failed\");\n\n        assert_eq!(result.0, 1);\n    }\n\n    /// Test graceful shutdown\n    #[tokio::test]\n    async fn test_close_connections() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        // Verify pool is active\n        let pool = db.pool().await;\n        assert!(pool.size() \u003e 0, \"Pool should be initialized\");\n\n        // Close connections\n        db.close().await;\n\n        // Pool should be closed (size = 0)\n        let pool_after = db.pool().await;\n        assert_eq!(pool_after.size(), 0, \"Pool should be closed\");\n    }\n\n    /// Test prepared statement cache is enabled\n    #[tokio::test]\n    async fn test_prepared_statement_cache() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let pool = db.pool().await;\n\n        // Execute same query multiple times - should benefit from cache\n        for _ in 0..10 {\n            let _: (i32,) = sqlx::query_as(\"SELECT 1\")\n                .fetch_one(\u0026pool)\n                .await\n                .expect(\"Query failed\");\n        }\n\n        // If cache is working, these queries should be fast\n        // No direct way to verify cache hits, but performance should improve\n        println!(\" Prepared statement cache test completed\");\n    }\n}\n","traces":[{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":29},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","mod.rs"],"content":"//! Database module\n\npub mod models;\npub mod repositories;\n\npub use repositories::{FileRepository, MetadataRepository, SearchQuery, SearchRepository};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","models.rs"],"content":"//! Database models aligned with actual schema\n//!\n//! These models match the database schema from 001_initial_schema.sql\n//! Database: midi_library on port 5433\n\nuse chrono::{DateTime, Utc};\nuse serde::Deserialize;\nuse sqlx::types::BigDecimal;\nuse sqlx::FromRow;\nuse uuid::Uuid;\n\n// =============================================================================\n// FILES TABLE\n// =============================================================================\n\n/// File record from database (aligned with schema)\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone, FromRow)]\npub struct File {\n    pub id: i64,\n\n    // File identification\n    pub filename: String,\n    pub filepath: String,\n    pub original_filename: String,\n    pub content_hash: Vec\u003cu8\u003e,\n    pub file_size_bytes: i64,\n\n    // MIDI format\n    pub format: Option\u003ci16\u003e,\n    pub num_tracks: i16,\n    pub ticks_per_quarter_note: Option\u003ci32\u003e,\n\n    // Duration\n    pub duration_seconds: Option\u003cBigDecimal\u003e,\n    pub duration_ticks: Option\u003ci64\u003e,\n\n    // Multi-track handling\n    pub is_multi_track: Option\u003cbool\u003e,\n    pub parent_file_id: Option\u003ci64\u003e,\n    pub track_number: Option\u003ci16\u003e,\n    pub total_tracks: Option\u003ci16\u003e,\n\n    // Extracted context\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    pub folder_tags: Option\u003cVec\u003cString\u003e\u003e,\n\n    // Timestamps\n    pub created_at: DateTime\u003cUtc\u003e,\n    pub updated_at: DateTime\u003cUtc\u003e,\n    pub analyzed_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n\n    // Processing\n    pub import_batch_id: Option\u003cUuid\u003e,\n}\n\n/// New file for insertion\n#[derive(Debug, Clone)]\npub struct NewFile {\n    pub filename: String,\n    pub filepath: String,\n    pub original_filename: String,\n    pub content_hash: Vec\u003cu8\u003e,\n    pub file_size_bytes: i64,\n    pub format: Option\u003ci16\u003e,\n    pub num_tracks: i16,\n    pub ticks_per_quarter_note: Option\u003ci32\u003e,\n    pub duration_seconds: Option\u003cBigDecimal\u003e,\n    pub duration_ticks: Option\u003ci64\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    pub folder_tags: Option\u003cVec\u003cString\u003e\u003e,\n    pub import_batch_id: Option\u003cUuid\u003e,\n}\n\n// =============================================================================\n// MUSICAL_METADATA TABLE\n// =============================================================================\n\n/// Musical metadata from database (aligned with schema)\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone, FromRow)]\npub struct MusicalMetadata {\n    pub file_id: i64,\n\n    // Tempo\n    pub bpm: Option\u003cBigDecimal\u003e,\n    pub bpm_confidence: Option\u003cf32\u003e,\n    pub has_tempo_changes: Option\u003cbool\u003e,\n    pub tempo_changes: Option\u003cserde_json::Value\u003e,\n\n    // Key signature (enum type in database)\n    pub key_signature: Option\u003cString\u003e,  // We'll handle the enum as String\n    pub key_confidence: Option\u003cf32\u003e,\n    pub has_key_changes: Option\u003cbool\u003e,\n    pub key_changes: Option\u003cserde_json::Value\u003e,\n\n    // Time signature\n    pub time_signature_numerator: Option\u003ci16\u003e,\n    pub time_signature_denominator: Option\u003ci16\u003e,\n    pub has_time_signature_changes: Option\u003cbool\u003e,\n    pub time_signature_changes: Option\u003cserde_json::Value\u003e,\n\n    // Note statistics\n    pub total_notes: i32,\n    pub unique_pitches: Option\u003ci32\u003e,\n    pub pitch_range_min: Option\u003ci16\u003e,\n    pub pitch_range_max: Option\u003ci16\u003e,\n    pub avg_velocity: Option\u003cBigDecimal\u003e,\n\n    // Density metrics\n    pub note_density: Option\u003cBigDecimal\u003e,\n    pub polyphony_max: Option\u003ci16\u003e,\n    pub polyphony_avg: Option\u003cBigDecimal\u003e,\n\n    // Musical characteristics\n    pub is_monophonic: Option\u003cbool\u003e,\n    pub is_polyphonic: Option\u003cbool\u003e,\n    pub is_percussive: Option\u003cbool\u003e,\n\n    // Chord analysis\n    pub has_chords: Option\u003cbool\u003e,\n    pub chord_complexity: Option\u003cf32\u003e,\n\n    // Melody analysis\n    pub has_melody: Option\u003cbool\u003e,\n    pub melodic_range: Option\u003ci16\u003e,\n\n    pub created_at: DateTime\u003cUtc\u003e,\n}\n\n/// New musical metadata for insertion\n#[derive(Debug, Clone)]\npub struct NewMusicalMetadata {\n    pub file_id: i64,\n    pub bpm: Option\u003cBigDecimal\u003e,\n    pub bpm_confidence: Option\u003cf32\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub key_confidence: Option\u003cf32\u003e,\n    pub time_signature_numerator: Option\u003ci16\u003e,\n    pub time_signature_denominator: Option\u003ci16\u003e,\n    pub total_notes: i32,\n    pub unique_pitches: Option\u003ci32\u003e,\n    pub pitch_range_min: Option\u003ci16\u003e,\n    pub pitch_range_max: Option\u003ci16\u003e,\n    pub avg_velocity: Option\u003cBigDecimal\u003e,\n    pub note_density: Option\u003cBigDecimal\u003e,\n    pub polyphony_max: Option\u003ci16\u003e,\n    pub polyphony_avg: Option\u003cBigDecimal\u003e,\n    pub is_percussive: Option\u003cbool\u003e,\n}\n\n// =============================================================================\n// SEARCH \u0026 QUERY MODELS\n// =============================================================================\n\n/// Search filters from frontend\n#[derive(Debug, Clone, Deserialize)]\npub struct SearchFilters {\n    pub category: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key_signatures: Option\u003cVec\u003cString\u003e\u003e,\n    pub min_duration: Option\u003cf64\u003e,\n    pub max_duration: Option\u003cf64\u003e,\n}\n\n/// Search result combining file and metadata\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct FileSearchResult {\n    pub id: i64,\n    pub filename: String,\n    pub filepath: String,\n    pub bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n    pub total_notes: i32,\n    pub category: Option\u003cString\u003e,\n}\n\n/// Paginated search results\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct SearchResults {\n    pub files: Vec\u003cFileSearchResult\u003e,\n    pub total_count: i64,\n    pub page: i32,\n    pub page_size: i32,\n    pub total_pages: i32,\n}\n\n/// Detailed file view with metadata\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct FileWithMetadata {\n    pub file: File,\n    pub metadata: Option\u003cMusicalMetadata\u003e,\n}\n\n// =============================================================================\n// TYPE CONVERSION HELPERS\n// =============================================================================\n\nuse num_traits::ToPrimitive;\n\n/// Convert BigDecimal to f64\npub fn bigdecimal_to_f64(bd: Option\u003cBigDecimal\u003e) -\u003e Option\u003cf64\u003e {\n    bd.and_then(|b| b.to_f64())\n}\n\n/// Convert f64 to BigDecimal\npub fn f64_to_bigdecimal(val: Option\u003cf64\u003e) -\u003e Option\u003cBigDecimal\u003e {\n    use num_traits::FromPrimitive;\n    val.and_then(|v| BigDecimal::from_f64(v))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","file_repository.rs"],"content":"//! File repository - CRUD operations for files table\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::{File, NewFile};\nuse sqlx::PgPool;\n\npub struct FileRepository;\n\nimpl FileRepository {\n    /// Inserts a new file and returns its ID\n    pub async fn insert(pool: \u0026PgPool, new_file: NewFile) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let file_id = sqlx::query_scalar!(\n            r#\"\n            INSERT INTO files (\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                import_batch_id\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\n            RETURNING id\n            \"#,\n            new_file.filename,\n            new_file.filepath,\n            new_file.original_filename,\n            \u0026new_file.content_hash[..],\n            new_file.file_size_bytes,\n            new_file.format,\n            new_file.num_tracks,\n            new_file.ticks_per_quarter_note,\n            new_file.duration_seconds,\n            new_file.duration_ticks,\n            new_file.manufacturer,\n            new_file.collection_name,\n            new_file.folder_tags.as_deref(),\n            new_file.import_batch_id,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(file_id)\n    }\n\n    /// Finds file by ID\n    pub async fn find_by_id(pool: \u0026PgPool, id: i64) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE id = $1\n            \"#,\n            id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Checks if file with hash already exists\n    pub async fn check_duplicate(pool: \u0026PgPool, content_hash: \u0026[u8]) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files\n            WHERE content_hash = $1\n            \"#,\n            content_hash\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count \u003e 0)\n    }\n\n    /// Finds file by hash\n    pub async fn find_by_hash(\n        pool: \u0026PgPool,\n        content_hash: \u0026[u8],\n    ) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE content_hash = $1 LIMIT 1\n            \"#,\n            content_hash\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Finds file by filepath\n    pub async fn find_by_path(pool: \u0026PgPool, filepath: \u0026str) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE filepath = $1\n            \"#,\n            filepath\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Updates file's analyzed_at timestamp\n    pub async fn mark_analyzed(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE files\n            SET analyzed_at = NOW(), updated_at = NOW()\n            WHERE id = $1\n            \"#,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates file metadata fields\n    pub async fn update_metadata_fields(\n        pool: \u0026PgPool,\n        file_id: i64,\n        format: Option\u003ci16\u003e,\n        num_tracks: i16,\n        ticks_per_quarter_note: Option\u003ci32\u003e,\n        duration_seconds: Option\u003csqlx::types::BigDecimal\u003e,\n        duration_ticks: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE files\n            SET\n                format = $2,\n                num_tracks = $3,\n                ticks_per_quarter_note = $4,\n                duration_seconds = $5,\n                duration_ticks = $6,\n                updated_at = NOW()\n            WHERE id = $1\n            \"#,\n            file_id,\n            format,\n            num_tracks,\n            ticks_per_quarter_note,\n            duration_seconds,\n            duration_ticks\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Deletes file by ID\n    pub async fn delete(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\"DELETE FROM files WHERE id = $1\", file_id)\n            .execute(pool)\n            .await?;\n\n        Ok(())\n    }\n\n    /// Gets file count\n    pub async fn count(pool: \u0026PgPool) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(r#\"SELECT COUNT(*) as \"count!\" FROM files\"#)\n            .fetch_one(pool)\n            .await?;\n\n        Ok(count)\n    }\n\n    /// Lists files with pagination\n    pub async fn list(pool: \u0026PgPool, limit: i64, offset: i64) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            ORDER BY created_at DESC\n            LIMIT $1 OFFSET $2\n            \"#,\n            limit,\n            offset\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Lists files by manufacturer\n    pub async fn list_by_manufacturer(\n        pool: \u0026PgPool,\n        manufacturer: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE manufacturer = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            manufacturer,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Lists files by collection\n    pub async fn list_by_collection(\n        pool: \u0026PgPool,\n        collection_name: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE collection_name = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            collection_name,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_insert_and_find() {\n        let pool = setup_test_pool().await;\n\n        let new_file = NewFile {\n            filename: \"test_file.mid\".to_string(),\n            filepath: \"/test/test_file.mid\".to_string(),\n            original_filename: \"test_file.mid\".to_string(),\n            content_hash: vec![1, 2, 3, 4, 5, 6, 7, 8],\n            file_size_bytes: 1024,\n            format: Some(1),\n            num_tracks: 1,\n            ticks_per_quarter_note: Some(480),\n            duration_seconds: None,\n            duration_ticks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: None,\n            import_batch_id: None,\n        };\n\n        let file_id = FileRepository::insert(\u0026pool, new_file).await.unwrap();\n        assert!(file_id \u003e 0);\n\n        let found = FileRepository::find_by_id(\u0026pool, file_id).await.unwrap();\n        assert!(found.is_some());\n\n        let file = found.unwrap();\n        assert_eq!(file.id, file_id);\n        assert_eq!(file.filename, \"test_file.mid\");\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_check_duplicate() {\n        let pool = setup_test_pool().await;\n\n        let hash = vec![9, 9, 9, 9, 9, 9, 9, 9];\n\n        // Should not exist initially\n        let exists = FileRepository::check_duplicate(\u0026pool, \u0026hash).await.unwrap();\n        assert!(!exists);\n\n        // Insert file\n        let new_file = NewFile {\n            filename: \"dup_test.mid\".to_string(),\n            filepath: \"/test/dup_test.mid\".to_string(),\n            original_filename: \"dup_test.mid\".to_string(),\n            content_hash: hash.clone(),\n            file_size_bytes: 512,\n            format: Some(1),\n            num_tracks: 1,\n            ticks_per_quarter_note: Some(480),\n            duration_seconds: None,\n            duration_ticks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: None,\n            import_batch_id: None,\n        };\n\n        FileRepository::insert(\u0026pool, new_file).await.unwrap();\n\n        // Should exist now\n        let exists = FileRepository::check_duplicate(\u0026pool, \u0026hash).await.unwrap();\n        assert!(exists);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","file_repository_fixed.rs"],"content":"//! Fixed file repository - avoids custom types\n\nuse crate::db::models::{File, NewFile};\nuse sqlx::PgPool;\n\npub struct FileRepository;\n\nimpl FileRepository {\n    /// Inserts a new file and returns its ID\n    pub async fn insert(pool: \u0026PgPool, new_file: NewFile) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let file_id = sqlx::query_scalar!(\n            r#\"\n            INSERT INTO files (\n                original_path,\n                current_path,\n                original_filename,\n                new_filename,\n                content_hash,\n                file_size,\n                file_modified,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                import_batch_id\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n            RETURNING id\n            \"#,\n            new_file.original_path,\n            new_file.current_path,\n            new_file.original_filename,\n            new_file.new_filename,\n            \u0026new_file.content_hash[..],\n            new_file.file_size,\n            new_file.file_modified,\n            new_file.manufacturer,\n            new_file.collection_name,\n            new_file.folder_tags.as_deref(),\n            new_file.import_batch_id,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(file_id)\n    }\n\n    /// Finds file by ID using manual mapping\n    pub async fn find_by_id(pool: \u0026PgPool, id: i64) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let row = sqlx::query!(\n            r#\"\n            SELECT \n                id,\n                original_path,\n                current_path,\n                original_filename,\n                new_filename,\n                content_hash,\n                file_size as file_size_bytes,\n                file_modified,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                category::text,\n                subcategory,\n                auto_tags,\n                user_tags,\n                analyzed_at,\n                import_batch_id,\n                created_at,\n                updated_at\n            FROM files WHERE id = $1\n            \"#,\n            id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(row.map(|r| File {\n            id: r.id,\n            original_path: r.original_path,\n            current_path: r.current_path,\n            original_filename: r.original_filename,\n            new_filename: r.new_filename,\n            content_hash: r.content_hash,\n            file_size_bytes: r.file_size_bytes,\n            file_modified: r.file_modified,\n            is_multi_track: r.is_multi_track,\n            parent_file_id: r.parent_file_id,\n            track_number: r.track_number,\n            total_tracks: r.total_tracks,\n            manufacturer: r.manufacturer,\n            collection_name: r.collection_name,\n            folder_tags: r.folder_tags,\n            category: r.category,\n            subcategory: r.subcategory,\n            auto_tags: r.auto_tags,\n            user_tags: r.user_tags,\n            analyzed_at: r.analyzed_at,\n            import_batch_id: r.import_batch_id,\n            created_at: r.created_at,\n            updated_at: r.updated_at,\n        }))\n    }\n\n    /// Checks if file with hash already exists\n    pub async fn check_duplicate(pool: \u0026PgPool, content_hash: \u0026[u8]) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files\n            WHERE content_hash = $1\n            \"#,\n            content_hash\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count \u003e 0)\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","metadata_repository.rs"],"content":"//! Musical metadata repository\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::{MusicalMetadata, NewMusicalMetadata};\nuse sqlx::PgPool;\n\npub struct MetadataRepository;\n\nimpl MetadataRepository {\n    /// Inserts musical metadata\n    pub async fn insert(pool: \u0026PgPool, metadata: NewMusicalMetadata) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                bpm_confidence,\n                key_signature,\n                key_confidence,\n                time_signature_numerator,\n                time_signature_denominator,\n                total_notes,\n                unique_pitches,\n                pitch_range_min,\n                pitch_range_max,\n                avg_velocity,\n                note_density,\n                polyphony_max,\n                polyphony_avg,\n                is_percussive\n            ) VALUES (\n                $1, $2, $3, $4::text::musical_key, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16\n            )\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                time_signature_numerator = EXCLUDED.time_signature_numerator,\n                time_signature_denominator = EXCLUDED.time_signature_denominator,\n                total_notes = EXCLUDED.total_notes,\n                unique_pitches = EXCLUDED.unique_pitches,\n                pitch_range_min = EXCLUDED.pitch_range_min,\n                pitch_range_max = EXCLUDED.pitch_range_max,\n                avg_velocity = EXCLUDED.avg_velocity,\n                note_density = EXCLUDED.note_density,\n                polyphony_max = EXCLUDED.polyphony_max,\n                polyphony_avg = EXCLUDED.polyphony_avg,\n                is_percussive = EXCLUDED.is_percussive\n            \"#,\n            metadata.file_id,\n            metadata.bpm,\n            metadata.bpm_confidence,\n            metadata.key_signature,\n            metadata.key_confidence,\n            metadata.time_signature_numerator,\n            metadata.time_signature_denominator,\n            metadata.total_notes,\n            metadata.unique_pitches,\n            metadata.pitch_range_min,\n            metadata.pitch_range_max,\n            metadata.avg_velocity,\n            metadata.note_density,\n            metadata.polyphony_max,\n            metadata.polyphony_avg,\n            metadata.is_percussive,\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Finds metadata by file ID\n    pub async fn find_by_file_id(\n        pool: \u0026PgPool,\n        file_id: i64,\n    ) -\u003e Result\u003cOption\u003cMusicalMetadata\u003e, sqlx::Error\u003e {\n        let metadata = sqlx::query_as!(\n            MusicalMetadata,\n            r#\"\n            SELECT\n                file_id,\n                bpm,\n                bpm_confidence,\n                has_tempo_changes,\n                tempo_changes,\n                key_signature::text as key_signature,\n                key_confidence,\n                has_key_changes,\n                key_changes,\n                time_signature_numerator,\n                time_signature_denominator,\n                has_time_signature_changes,\n                time_signature_changes,\n                total_notes,\n                unique_pitches,\n                pitch_range_min,\n                pitch_range_max,\n                avg_velocity,\n                note_density,\n                polyphony_max,\n                polyphony_avg,\n                is_monophonic,\n                is_polyphonic,\n                is_percussive,\n                has_chords,\n                chord_complexity,\n                has_melody,\n                melodic_range,\n                created_at as \"created_at!\"\n            FROM musical_metadata WHERE file_id = $1\n            \"#,\n            file_id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(metadata)\n    }\n\n    /// Updates BPM and confidence\n    pub async fn update_bpm(\n        pool: \u0026PgPool,\n        file_id: i64,\n        bpm: sqlx::types::BigDecimal,\n        confidence: Option\u003cf32\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET bpm = $1,\n                bpm_confidence = $2\n            WHERE file_id = $3\n            \"#,\n            bpm,\n            confidence,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates key and confidence\n    pub async fn update_key(\n        pool: \u0026PgPool,\n        file_id: i64,\n        key: \u0026str,\n        confidence: Option\u003cf32\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET key_signature = $1::text::musical_key,\n                key_confidence = $2\n            WHERE file_id = $3\n            \"#,\n            key,\n            confidence,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates note statistics\n    pub async fn update_note_stats(\n        pool: \u0026PgPool,\n        file_id: i64,\n        total_notes: i32,\n        unique_pitches: Option\u003ci32\u003e,\n        pitch_range_min: Option\u003ci16\u003e,\n        pitch_range_max: Option\u003ci16\u003e,\n        avg_velocity: Option\u003csqlx::types::BigDecimal\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET total_notes = $1,\n                unique_pitches = $2,\n                pitch_range_min = $3,\n                pitch_range_max = $4,\n                avg_velocity = $5\n            WHERE file_id = $6\n            \"#,\n            total_notes,\n            unique_pitches,\n            pitch_range_min,\n            pitch_range_max,\n            avg_velocity,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Deletes metadata by file ID\n    pub async fn delete(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\"DELETE FROM musical_metadata WHERE file_id = $1\", file_id)\n            .execute(pool)\n            .await?;\n\n        Ok(())\n    }\n\n    /// Gets metadata count\n    pub async fn count(pool: \u0026PgPool) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"SELECT COUNT(*) as \"count!\" FROM musical_metadata\"#\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n    use num_traits::FromPrimitive;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_insert_and_find() {\n        let pool = setup_test_pool().await;\n\n        let metadata = NewMusicalMetadata {\n            file_id: 1,\n            bpm: sqlx::types::BigDecimal::from_f64(120.0),\n            bpm_confidence: Some(0.95),\n            key_signature: Some(\"C\".to_string()),\n            key_confidence: Some(0.9),\n            time_signature_numerator: Some(4),\n            time_signature_denominator: Some(4),\n            total_notes: 1000,\n            unique_pitches: Some(12),\n            pitch_range_min: Some(60),\n            pitch_range_max: Some(84),\n            avg_velocity: sqlx::types::BigDecimal::from_f64(100.0),\n            note_density: sqlx::types::BigDecimal::from_f64(5.5),\n            polyphony_max: Some(4),\n            polyphony_avg: sqlx::types::BigDecimal::from_f64(2.5),\n            is_percussive: Some(false),\n        };\n\n        MetadataRepository::insert(\u0026pool, metadata).await.unwrap();\n\n        let found = MetadataRepository::find_by_file_id(\u0026pool, 1).await.unwrap();\n        assert!(found.is_some());\n\n        let meta = found.unwrap();\n        assert_eq!(meta.file_id, 1);\n        assert_eq!(meta.total_notes, 1000);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","mod.rs"],"content":"//! Database repositories\n\npub mod file_repository;\npub mod metadata_repository;\npub mod search_repository;\npub mod tag_repository;\n\npub use file_repository::FileRepository;\npub use metadata_repository::MetadataRepository;\npub use search_repository::{SearchQuery, SearchRepository};\npub use tag_repository::{TagRepository, DbTag, TagWithCount};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","search_repository.rs"],"content":"//! Search operations repository\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::File;\nuse sqlx::PgPool;\n\npub struct SearchRepository;\n\n#[derive(Debug, Clone)]\npub struct SearchQuery {\n    pub text: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key: Option\u003cString\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection: Option\u003cString\u003e,\n}\n\nimpl SearchRepository {\n    /// Full-text search with filters\n    pub async fn search(\n        pool: \u0026PgPool,\n        query: SearchQuery,\n        limit: i64,\n        offset: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                f.id,\n                f.filename,\n                f.filepath,\n                f.original_filename,\n                f.content_hash,\n                f.file_size_bytes,\n                f.format,\n                f.num_tracks,\n                f.ticks_per_quarter_note,\n                f.duration_seconds,\n                f.duration_ticks,\n                f.is_multi_track,\n                f.parent_file_id,\n                f.track_number,\n                f.total_tracks,\n                f.manufacturer,\n                f.collection_name,\n                f.folder_tags,\n                f.created_at as \"created_at!\",\n                f.updated_at as \"updated_at!\",\n                f.analyzed_at,\n                f.import_batch_id\n            FROM files f\n            LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n            WHERE\n                ($1::text IS NULL OR f.search_vector @@ plainto_tsquery('english', $1))\n                AND ($2::float8 IS NULL OR mm.bpm::float8 \u003e= $2)\n                AND ($3::float8 IS NULL OR mm.bpm::float8 \u003c= $3)\n                AND ($4::text IS NULL OR mm.key_signature::text = $4)\n                AND ($5::text IS NULL OR f.manufacturer = $5)\n                AND ($6::text IS NULL OR f.collection_name = $6)\n            ORDER BY\n                CASE WHEN $1::text IS NOT NULL\n                    THEN ts_rank(f.search_vector, plainto_tsquery('english', $1))\n                    ELSE 0\n                END DESC,\n                f.created_at DESC\n            LIMIT $7 OFFSET $8\n            \"#,\n            query.text,\n            query.min_bpm,\n            query.max_bpm,\n            query.key,\n            query.manufacturer,\n            query.collection,\n            limit,\n            offset\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Count search results\n    pub async fn count_search_results(\n        pool: \u0026PgPool,\n        query: SearchQuery,\n    ) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files f\n            LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n            WHERE\n                ($1::text IS NULL OR f.search_vector @@ plainto_tsquery('english', $1))\n                AND ($2::float8 IS NULL OR mm.bpm::float8 \u003e= $2)\n                AND ($3::float8 IS NULL OR mm.bpm::float8 \u003c= $3)\n                AND ($4::text IS NULL OR mm.key_signature::text = $4)\n                AND ($5::text IS NULL OR f.manufacturer = $5)\n                AND ($6::text IS NULL OR f.collection_name = $6)\n            \"#,\n            query.text,\n            query.min_bpm,\n            query.max_bpm,\n            query.key,\n            query.manufacturer,\n            query.collection,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count)\n    }\n\n    /// Search by manufacturer\n    pub async fn search_by_manufacturer(\n        pool: \u0026PgPool,\n        manufacturer: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE manufacturer = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            manufacturer,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Search by collection\n    pub async fn search_by_collection(\n        pool: \u0026PgPool,\n        collection: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE collection_name = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            collection,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_search_empty() {\n        let pool = setup_test_pool().await;\n\n        let query = SearchQuery {\n            text: None,\n            min_bpm: None,\n            max_bpm: None,\n            key: None,\n            manufacturer: None,\n            collection: None,\n        };\n\n        let results = SearchRepository::search(\u0026pool, query, 10, 0).await.unwrap();\n        assert!(results.len() \u003c= 10);\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_count_search() {\n        let pool = setup_test_pool().await;\n\n        let query = SearchQuery {\n            text: None,\n            min_bpm: None,\n            max_bpm: None,\n            key: None,\n            manufacturer: None,\n            collection: None,\n        };\n\n        let count = SearchRepository::count_search_results(\u0026pool, query).await.unwrap();\n        assert!(count \u003e= 0);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","tag_repository.rs"],"content":"//! Tag Repository - Database operations for tags\n//!\n//! This module handles all database operations related to tags:\n//! - Creating/retrieving tags\n//! - Associating tags with files\n//! - Searching and filtering tags\n//! - Tag usage statistics\n\nuse sqlx::{PgPool, Postgres, Transaction};\nuse thiserror::Error;\n\n/// Tag database model\n#[derive(Debug, Clone, sqlx::FromRow)]\npub struct DbTag {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\n/// Tag with usage count for tag cloud\n#[derive(Debug, Clone, sqlx::FromRow)]\npub struct TagWithCount {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\n#[derive(Debug, Error)]\npub enum TagRepositoryError {\n    #[error(\"Database error: {0}\")]\n    DatabaseError(#[from] sqlx::Error),\n\n    #[error(\"Tag not found: {0}\")]\n    TagNotFound(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, TagRepositoryError\u003e;\n\n/// Tag repository for database operations\npub struct TagRepository {\n    pool: PgPool,\n}\n\nimpl TagRepository {\n    pub fn new(pool: PgPool) -\u003e Self {\n        Self { pool }\n    }\n\n    /// Get or create a tag by name and category\n    ///\n    /// Returns the tag ID. If the tag exists, returns existing ID.\n    /// If not, creates a new tag and returns the new ID.\n    pub async fn get_or_create_tag(\n        \u0026self,\n        name: \u0026str,\n        category: Option\u003c\u0026str\u003e,\n    ) -\u003e Result\u003ci32\u003e {\n        let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n            r#\"\n            INSERT INTO tags (name, category, usage_count, created_at)\n            VALUES ($1, $2, 0, NOW())\n            ON CONFLICT (name) DO UPDATE\n            SET name = EXCLUDED.name\n            RETURNING id\n            \"#,\n        )\n        .bind(name)\n        .bind(category)\n        .fetch_one(\u0026self.pool)\n        .await?;\n\n        Ok(tag_id)\n    }\n\n    /// Get or create multiple tags in a single transaction\n    ///\n    /// More efficient for bulk operations like file imports\n    pub async fn get_or_create_tags_batch(\n        \u0026self,\n        tags: \u0026[(String, Option\u003cString\u003e)], // (name, category)\n    ) -\u003e Result\u003cVec\u003ci32\u003e\u003e {\n        let mut tag_ids = Vec::with_capacity(tags.len());\n\n        // Use a transaction for atomicity\n        let mut tx = self.pool.begin().await?;\n\n        for (name, category) in tags {\n            let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n                r#\"\n                INSERT INTO tags (name, category, usage_count, created_at)\n                VALUES ($1, $2, 0, NOW())\n                ON CONFLICT (name) DO UPDATE\n                SET name = EXCLUDED.name\n                RETURNING id\n                \"#,\n            )\n            .bind(name)\n            .bind(category.as_deref())\n            .fetch_one(\u0026mut *tx)\n            .await?;\n\n            tag_ids.push(tag_id);\n        }\n\n        tx.commit().await?;\n\n        Ok(tag_ids)\n    }\n\n    /// Add tags to a file\n    ///\n    /// Uses ON CONFLICT DO NOTHING to avoid duplicate errors\n    pub async fn add_tags_to_file(\u0026self, file_id: i64, tag_ids: \u0026[i32]) -\u003e Result\u003c()\u003e {\n        // Batch insert using unnest\n        sqlx::query(\n            r#\"\n            INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n            SELECT $1, unnest($2::int[]), NOW(), 'system'\n            ON CONFLICT (file_id, tag_id) DO NOTHING\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_ids)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Add tags to a file within a transaction\n    pub async fn add_tags_to_file_tx(\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        file_id: i64,\n        tag_ids: \u0026[i32],\n    ) -\u003e Result\u003c()\u003e {\n        sqlx::query(\n            r#\"\n            INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n            SELECT $1, unnest($2::int[]), NOW(), 'system'\n            ON CONFLICT (file_id, tag_id) DO NOTHING\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_ids)\n        .execute(\u0026mut **tx)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Get all tags for a specific file\n    pub async fn get_file_tags(\u0026self, file_id: i64) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT t.id, t.name, t.category, t.usage_count\n            FROM tags t\n            JOIN file_tags ft ON t.id = ft.tag_id\n            WHERE ft.file_id = $1\n            ORDER BY t.category, t.name\n            \"#,\n        )\n        .bind(file_id)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get popular tags with usage counts (for tag cloud)\n    pub async fn get_popular_tags(\u0026self, limit: i32) -\u003e Result\u003cVec\u003cTagWithCount\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, TagWithCount\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE usage_count \u003e 0\n            ORDER BY usage_count DESC, name ASC\n            LIMIT $1\n            \"#,\n        )\n        .bind(limit)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Search tags by name prefix (for autocomplete)\n    pub async fn search_tags(\u0026self, query: \u0026str, limit: i32) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let search_pattern = format!(\"{}%\", query.to_lowercase());\n\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE LOWER(name) LIKE $1\n            ORDER BY usage_count DESC, name ASC\n            LIMIT $2\n            \"#,\n        )\n        .bind(\u0026search_pattern)\n        .bind(limit)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get tags by category\n    pub async fn get_tags_by_category(\u0026self, category: \u0026str) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE category = $1\n            ORDER BY usage_count DESC, name ASC\n            \"#,\n        )\n        .bind(category)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get all unique tag categories\n    pub async fn get_tag_categories(\u0026self) -\u003e Result\u003cVec\u003cString\u003e\u003e {\n        let categories = sqlx::query_scalar::\u003c_, String\u003e(\n            r#\"\n            SELECT DISTINCT category\n            FROM tags\n            WHERE category IS NOT NULL\n            ORDER BY category\n            \"#,\n        )\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(categories)\n    }\n\n    /// Remove a tag from a file\n    pub async fn remove_tag_from_file(\u0026self, file_id: i64, tag_id: i32) -\u003e Result\u003c()\u003e {\n        sqlx::query(\n            r#\"\n            DELETE FROM file_tags\n            WHERE file_id = $1 AND tag_id = $2\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_id)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Update file tags (replace all tags)\n    pub async fn update_file_tags(\u0026self, file_id: i64, tag_ids: \u0026[i32]) -\u003e Result\u003c()\u003e {\n        let mut tx = self.pool.begin().await?;\n\n        // Remove all existing tags\n        sqlx::query(\n            r#\"\n            DELETE FROM file_tags\n            WHERE file_id = $1\n            \"#,\n        )\n        .bind(file_id)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Add new tags\n        if !tag_ids.is_empty() {\n            sqlx::query(\n                r#\"\n                INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n                SELECT $1, unnest($2::int[]), NOW(), 'user'\n                \"#,\n            )\n            .bind(file_id)\n            .bind(tag_ids)\n            .execute(\u0026mut *tx)\n            .await?;\n        }\n\n        tx.commit().await?;\n\n        Ok(())\n    }\n\n    /// Get file count for a tag\n    pub async fn get_tag_file_count(\u0026self, tag_id: i32) -\u003e Result\u003ci64\u003e {\n        let count = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            SELECT COUNT(*)\n            FROM file_tags\n            WHERE tag_id = $1\n            \"#,\n        )\n        .bind(tag_id)\n        .fetch_one(\u0026self.pool)\n        .await?;\n\n        Ok(count)\n    }\n\n    /// Get files by tag (for filtering)\n    pub async fn get_files_by_tags(\n        \u0026self,\n        tag_names: \u0026[String],\n        match_all: bool, // true for AND, false for OR\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let file_ids = if match_all {\n            // AND logic: file must have all tags\n            sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                SELECT ft.file_id\n                FROM file_tags ft\n                JOIN tags t ON ft.tag_id = t.id\n                WHERE t.name = ANY($1)\n                GROUP BY ft.file_id\n                HAVING COUNT(DISTINCT t.id) = $2\n                \"#,\n            )\n            .bind(tag_names)\n            .bind(tag_names.len() as i64)\n            .fetch_all(\u0026self.pool)\n            .await?\n        } else {\n            // OR logic: file must have at least one tag\n            sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                SELECT DISTINCT ft.file_id\n                FROM file_tags ft\n                JOIN tags t ON ft.tag_id = t.id\n                WHERE t.name = ANY($1)\n                \"#,\n            )\n            .bind(tag_names)\n            .fetch_all(\u0026self.pool)\n            .await?\n        };\n\n        Ok(file_ids)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    // Note: These tests require a running PostgreSQL database\n    // They are integration tests, not unit tests\n\n    #[tokio::test]\n    #[ignore] // Run with: cargo test -- --ignored\n    async fn test_get_or_create_tag() {\n        let pool = PgPool::connect(\"postgresql://localhost:5433/midi_library\")\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let repo = TagRepository::new(pool);\n\n        let tag_id = repo\n            .get_or_create_tag(\"test_tag\", Some(\"test\"))\n            .await\n            .expect(\"Failed to create tag\");\n\n        assert!(tag_id \u003e 0);\n\n        // Try to create again, should return same ID\n        let tag_id2 = repo\n            .get_or_create_tag(\"test_tag\", Some(\"test\"))\n            .await\n            .expect(\"Failed to get existing tag\");\n\n        assert_eq!(tag_id, tag_id2);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","error.rs"],"content":"//! Error Handling Module - PURE FUNCTION ARCHETYPE\n//!\n//! PURPOSE: Transform and convert error types for Tauri commands\n//! ARCHETYPE: Pure Function (deterministic transformations, no I/O)\n//! LOCATION: pipeline/src-tauri/src/error.rs\n//!\n//!  CAN: Transform errors (sqlx::Error  AppError)\n//!  CAN: Convert types (AppError  String)\n//!  SHOULD: Be deterministic\n//!  NO: I/O operations\n//!  NO: Side effects\n//!  NO: State\n\nuse std::fmt;\n\n/// Application error types\n///\n/// Centralized error handling for all Tauri commands.\n/// All variants can be converted to String for frontend consumption.\n///\n/// # Examples\n///\n/// ```rust\n/// use error::AppError;\n///\n/// // From database error\n/// let db_err = AppError::DatabaseError(sqlx_error);\n///\n/// // From validation\n/// let val_err = AppError::ValidationError(\"Invalid BPM range\".to_string());\n///\n/// // Convert to String for Tauri\n/// let error_msg: String = app_err.into();\n/// ```\n#[derive(Debug)]\npub enum AppError {\n    /// Database operation failed\n    DatabaseError(sqlx::Error),\n\n    /// Requested resource not found\n    NotFound(String),\n\n    /// Input validation failed\n    ValidationError(String),\n\n    /// File I/O operation failed\n    IOError(std::io::Error),\n\n    /// MIDI parsing or analysis error\n    MidiError(String),\n\n    /// Generic application error\n    GeneralError(String),\n}\n\n// =============================================================================\n// DISPLAY TRAIT - Pure transformation to string representation\n// =============================================================================\n\nimpl fmt::Display for AppError {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        match self {\n            AppError::DatabaseError(e) =\u003e write!(f, \"Database error: {}\", e),\n            AppError::NotFound(msg) =\u003e write!(f, \"Not found: {}\", msg),\n            AppError::ValidationError(msg) =\u003e write!(f, \"Validation error: {}\", msg),\n            AppError::IOError(e) =\u003e write!(f, \"I/O error: {}\", e),\n            AppError::MidiError(msg) =\u003e write!(f, \"MIDI error: {}\", msg),\n            AppError::GeneralError(msg) =\u003e write!(f, \"Error: {}\", msg),\n        }\n    }\n}\n\n// =============================================================================\n// ERROR TRAIT - Standard error interface\n// =============================================================================\n\nimpl std::error::Error for AppError {\n    fn source(\u0026self) -\u003e Option\u003c\u0026(dyn std::error::Error + 'static)\u003e {\n        match self {\n            AppError::DatabaseError(e) =\u003e Some(e),\n            AppError::IOError(e) =\u003e Some(e),\n            _ =\u003e None,\n        }\n    }\n}\n\n// =============================================================================\n// FROM TRAIT IMPLEMENTATIONS - Pure type conversions\n// =============================================================================\n\n/// Convert from sqlx::Error to AppError (pure transformation)\nimpl From\u003csqlx::Error\u003e for AppError {\n    fn from(error: sqlx::Error) -\u003e Self {\n        AppError::DatabaseError(error)\n    }\n}\n\n/// Convert from std::io::Error to AppError (pure transformation)\nimpl From\u003cstd::io::Error\u003e for AppError {\n    fn from(error: std::io::Error) -\u003e Self {\n        AppError::IOError(error)\n    }\n}\n\n/// Convert from String to AppError (pure transformation)\nimpl From\u003cString\u003e for AppError {\n    fn from(error: String) -\u003e Self {\n        AppError::GeneralError(error)\n    }\n}\n\n/// Convert from \u0026str to AppError (pure transformation)\nimpl From\u003c\u0026str\u003e for AppError {\n    fn from(error: \u0026str) -\u003e Self {\n        AppError::GeneralError(error.to_string())\n    }\n}\n\n// =============================================================================\n// TAURI CONVERSION - Pure transformation to String for frontend\n// =============================================================================\n\n/// Convert AppError to String for Tauri command return types\n///\n/// This is a pure transformation with no side effects.\n/// Tauri requires errors to be String for IPC serialization.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn my_command() -\u003e Result\u003cData, String\u003e {\n///     let result = database_operation()\n///         .await\n///         .map_err(|e| AppError::from(e).into())?;\n///     Ok(result)\n/// }\n/// ```\nimpl From\u003cAppError\u003e for String {\n    fn from(error: AppError) -\u003e Self {\n        error.to_string()\n    }\n}\n\n// =============================================================================\n// HELPER FUNCTIONS - Pure error creation utilities\n// =============================================================================\n\nimpl AppError {\n    /// Create a NotFound error (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::not_found(\"File with ID 123\"));\n    /// ```\n    pub fn not_found(resource: \u0026str) -\u003e Self {\n        AppError::NotFound(format!(\"{} not found\", resource))\n    }\n\n    /// Create a ValidationError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::validation(\"BPM must be between 20 and 300\"));\n    /// ```\n    pub fn validation(message: \u0026str) -\u003e Self {\n        AppError::ValidationError(message.to_string())\n    }\n\n    /// Create a MidiError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::midi(\"Invalid MIDI header\"));\n    /// ```\n    pub fn midi(message: \u0026str) -\u003e Self {\n        AppError::MidiError(message.to_string())\n    }\n\n    /// Create a GeneralError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::general(\"Something went wrong\"));\n    /// ```\n    pub fn general(message: \u0026str) -\u003e Self {\n        AppError::GeneralError(message.to_string())\n    }\n}\n\n// =============================================================================\n// RESULT TYPE ALIAS - Convenience type for commands\n// =============================================================================\n\n/// Standard Result type for Tauri commands\n///\n/// Uses String as error type for Tauri IPC compatibility.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn get_file(id: i64) -\u003e AppResult\u003cFile\u003e {\n///     let file = database.get_file(id)\n///         .await\n///         .map_err(AppError::from)?;\n///\n///     file.ok_or_else(|| AppError::not_found(\u0026format!(\"File {}\", id)))\n/// }\n/// ```\npub type AppResult\u003cT\u003e = Result\u003cT, AppError\u003e;\n\n/// Tauri-compatible Result type (with String error)\n///\n/// For use in Tauri command return types.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn search_files() -\u003e TauriResult\u003cVec\u003cFile\u003e\u003e {\n///     let files = database.search()\n///         .await\n///         .map_err(|e| AppError::from(e).into())?;\n///     Ok(files)\n/// }\n/// ```\npub type TauriResult\u003cT\u003e = Result\u003cT, String\u003e;\n\n// =============================================================================\n// TESTS - Pure function testing\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_display_database_error() {\n        let err = AppError::DatabaseError(\n            sqlx::Error::RowNotFound\n        );\n        assert!(err.to_string().contains(\"Database error\"));\n    }\n\n    #[test]\n    fn test_display_not_found() {\n        let err = AppError::NotFound(\"File 123\".to_string());\n        assert_eq!(err.to_string(), \"Not found: File 123\");\n    }\n\n    #[test]\n    fn test_display_validation() {\n        let err = AppError::ValidationError(\"Invalid input\".to_string());\n        assert_eq!(err.to_string(), \"Validation error: Invalid input\");\n    }\n\n    #[test]\n    fn test_display_midi_error() {\n        let err = AppError::MidiError(\"Bad header\".to_string());\n        assert_eq!(err.to_string(), \"MIDI error: Bad header\");\n    }\n\n    #[test]\n    fn test_from_string() {\n        let err = AppError::from(\"Test error\");\n        match err {\n            AppError::GeneralError(msg) =\u003e assert_eq!(msg, \"Test error\"),\n            _ =\u003e panic!(\"Wrong variant\"),\n        }\n    }\n\n    #[test]\n    fn test_from_sqlx_error() {\n        let sqlx_err = sqlx::Error::RowNotFound;\n        let app_err = AppError::from(sqlx_err);\n        match app_err {\n            AppError::DatabaseError(_) =\u003e (),\n            _ =\u003e panic!(\"Wrong variant\"),\n        }\n    }\n\n    #[test]\n    fn test_to_string_conversion() {\n        let err = AppError::NotFound(\"Resource\".to_string());\n        let string_err: String = err.into();\n        assert_eq!(string_err, \"Not found: Resource\");\n    }\n\n    #[test]\n    fn test_not_found_helper() {\n        let err = AppError::not_found(\"File 123\");\n        assert_eq!(err.to_string(), \"Not found: File 123 not found\");\n    }\n\n    #[test]\n    fn test_validation_helper() {\n        let err = AppError::validation(\"BPM out of range\");\n        assert_eq!(err.to_string(), \"Validation error: BPM out of range\");\n    }\n\n    #[test]\n    fn test_midi_helper() {\n        let err = AppError::midi(\"Invalid format\");\n        assert_eq!(err.to_string(), \"MIDI error: Invalid format\");\n    }\n\n    #[test]\n    fn test_general_helper() {\n        let err = AppError::general(\"Something wrong\");\n        assert_eq!(err.to_string(), \"Error: Something wrong\");\n    }\n\n    #[test]\n    fn test_deterministic_conversion() {\n        // Pure function - same input always produces same output\n        let err1 = AppError::validation(\"Test\");\n        let err2 = AppError::validation(\"Test\");\n        assert_eq!(err1.to_string(), err2.to_string());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","extractor.rs"],"content":"//! Archive Extraction Logic\n//!\n//! # Archetype: Grown-up Script\n//! - Performs I/O operations (file extraction)\n//! - Separates I/O logic from business logic\n//! - Both runnable AND importable\n//! - Returns Result types for error handling\n\nuse std::fs::{self, File};\nuse std::io;\nuse std::path::{Path, PathBuf};\nuse zip::ZipArchive;\n\nuse crate::io::decompressor::{formats, temp_manager};\nuse crate::io::{IoError, Result};\n\n/// Configuration for extraction\n#[derive(Debug, Clone)]\npub struct ExtractionConfig {\n    /// Maximum recursion depth for nested archives\n    pub max_depth: usize,\n\n    /// Whether to extract nested archives\n    pub recursive: bool,\n\n    /// Extensions to extract (e.g., [\"mid\", \"midi\"])\n    pub target_extensions: Vec\u003cString\u003e,\n}\n\nimpl Default for ExtractionConfig {\n    fn default() -\u003e Self {\n        Self {\n            max_depth: 10, // Increased to handle deeply nested archives (up to 8 layers observed)\n            recursive: true,\n            target_extensions: vec![\"mid\".to_string(), \"midi\".to_string()],\n        }\n    }\n}\n\n/// Result of extraction operation\n#[derive(Debug)]\npub struct ExtractionResult {\n    /// Paths to extracted MIDI files\n    pub midi_files: Vec\u003cPathBuf\u003e,\n\n    /// Number of archives processed\n    pub archives_processed: usize,\n\n    /// Errors encountered\n    pub errors: Vec\u003cString\u003e,\n}\n\n/// Extracts MIDI files from an archive\n///\n/// # Arguments\n/// * `archive_path` - Path to archive file\n/// * `output_dir` - Where to extract files\n/// * `config` - Extraction configuration\n///\n/// # Returns\n/// * `ExtractionResult` - List of extracted MIDI files\n///\n/// # Examples\n/// ```no_run\n/// use std::path::Path;\n/// use pipeline::io::decompressor::extractor::*;\n///\n/// let config = ExtractionConfig::default();\n/// let result = extract_archive(\n///     Path::new(\"samples.zip\"),\n///     Path::new(\"/output\"),\n///     \u0026config\n/// ).unwrap();\n///\n/// println!(\"Extracted {} MIDI files\", result.midi_files.len());\n/// ```\npub fn extract_archive(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n) -\u003e Result\u003cExtractionResult\u003e {\n    let format = formats::detect_format(archive_path)\n        .ok_or_else(|| IoError::UnsupportedFormat {\n            path: archive_path.to_path_buf(),\n        })?;\n\n    let mut result = ExtractionResult {\n        midi_files: Vec::new(),\n        archives_processed: 0,\n        errors: Vec::new(),\n    };\n\n    extract_recursive(archive_path, output_dir, config, 0, \u0026mut result, format)?;\n\n    Ok(result)\n}\n\n/// Internal recursive extraction function\nfn extract_recursive(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n    current_depth: usize,\n    result: \u0026mut ExtractionResult,\n    format: formats::ArchiveFormat,\n) -\u003e Result\u003c()\u003e {\n    if current_depth \u003e= config.max_depth {\n        result\n            .errors\n            .push(format!(\"Max depth reached at: {}\", archive_path.display()));\n        return Ok(());\n    }\n\n    result.archives_processed += 1;\n\n    match format {\n        formats::ArchiveFormat::Zip =\u003e {\n            extract_zip(archive_path, output_dir, config, current_depth, result)?;\n        }\n        _ =\u003e {\n            result\n                .errors\n                .push(format!(\"Format {:?} not yet implemented\", format));\n        }\n    }\n\n    Ok(())\n}\n\n/// Extracts ZIP archive\nfn extract_zip(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n    current_depth: usize,\n    result: \u0026mut ExtractionResult,\n) -\u003e Result\u003c()\u003e {\n    let file = File::open(archive_path)?;\n    let mut archive = ZipArchive::new(file)?;\n\n    fs::create_dir_all(output_dir)?;\n\n    for i in 0..archive.len() {\n        let mut file = archive.by_index(i)?;\n        let outpath = match file.enclosed_name() {\n            Some(path) =\u003e output_dir.join(path),\n            None =\u003e continue,\n        };\n\n        if file.name().ends_with('/') {\n            // Directory\n            fs::create_dir_all(\u0026outpath)?;\n        } else {\n            // File\n            if let Some(parent) = outpath.parent() {\n                fs::create_dir_all(parent)?;\n            }\n\n            let mut outfile = File::create(\u0026outpath)?;\n            io::copy(\u0026mut file, \u0026mut outfile)?;\n\n            // Check if it's a MIDI file\n            if is_target_file(\u0026outpath, \u0026config.target_extensions) {\n                result.midi_files.push(outpath.clone());\n            }\n\n            // Check if it's a nested archive\n            if config.recursive \u0026\u0026 formats::is_archive(\u0026outpath) {\n                if let Some(nested_format) = formats::detect_format(\u0026outpath) {\n                    let _ = extract_recursive(\n                        \u0026outpath,\n                        output_dir,\n                        config,\n                        current_depth + 1,\n                        result,\n                        nested_format,\n                    );\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Checks if file has target extension\nfn is_target_file(path: \u0026Path, target_extensions: \u0026[String]) -\u003e bool {\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext_str| {\n            let ext_lower = ext_str.to_lowercase();\n            target_extensions.iter().any(|target| target == \u0026ext_lower)\n        })\n        .unwrap_or(false)\n}\n\n/// Convenience function for extracting to temporary directory\n///\n/// # Arguments\n/// * `archive_path` - Path to archive file\n/// * `config` - Extraction configuration\n///\n/// # Returns\n/// * `(ExtractionResult, PathBuf)` - Extraction result and temp directory path\npub fn extract_to_temp(\n    archive_path: \u0026Path,\n    config: \u0026ExtractionConfig,\n) -\u003e Result\u003c(ExtractionResult, PathBuf)\u003e {\n    let mut temp_mgr = temp_manager::TempManager::new()?;\n    let temp_dir = temp_mgr.create_temp_dir()?;\n\n    let result = extract_archive(archive_path, \u0026temp_dir, config)?;\n\n    // Note: temp_mgr will be dropped but we return temp_dir\n    // Caller is responsible for cleanup\n    std::mem::forget(temp_mgr);\n\n    Ok((result, temp_dir))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::path::PathBuf;\n\n    #[test]\n    fn test_is_target_file() {\n        let path = PathBuf::from(\"test.mid\");\n        let extensions = vec![\"mid\".to_string(), \"midi\".to_string()];\n\n        assert!(is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_is_target_file_case_insensitive() {\n        let path = PathBuf::from(\"test.MID\");\n        let extensions = vec![\"mid\".to_string()];\n\n        assert!(is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_not_target_file() {\n        let path = PathBuf::from(\"test.txt\");\n        let extensions = vec![\"mid\".to_string()];\n\n        assert!(!is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_default_config() {\n        let config = ExtractionConfig::default();\n\n        assert_eq!(config.max_depth, 5);\n        assert!(config.recursive);\n        assert_eq!(config.target_extensions, vec![\"mid\", \"midi\"]);\n    }\n\n    #[test]\n    fn test_extraction_result() {\n        let result = ExtractionResult {\n            midi_files: vec![PathBuf::from(\"test.mid\")],\n            archives_processed: 1,\n            errors: vec![],\n        };\n\n        assert_eq!(result.midi_files.len(), 1);\n        assert_eq!(result.archives_processed, 1);\n        assert!(result.errors.is_empty());\n    }\n\n    #[test]\n    fn test_unsupported_format() {\n        let path = PathBuf::from(\"test.txt\");\n        let output = PathBuf::from(\"/tmp/output\");\n        let config = ExtractionConfig::default();\n\n        let result = extract_archive(\u0026path, \u0026output, \u0026config);\n\n        assert!(result.is_err());\n        assert!(result\n            .unwrap_err()\n            .to_string()\n            .contains(\"Unsupported archive format\"));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","formats.rs"],"content":"//! Archive Format Detection\n\nuse std::path::Path;\n\n/// Supported archive formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ArchiveFormat {\n    Zip,\n    Rar,\n    SevenZip,\n    TarGz,\n    Tar,\n}\n\nimpl ArchiveFormat {\n    /// Returns file extension for format\n    pub fn extension(\u0026self) -\u003e \u0026'static str {\n        match self {\n            ArchiveFormat::Zip =\u003e \"zip\",\n            ArchiveFormat::Rar =\u003e \"rar\",\n            ArchiveFormat::SevenZip =\u003e \"7z\",\n            ArchiveFormat::TarGz =\u003e \"tar.gz\",\n            ArchiveFormat::Tar =\u003e \"tar\",\n        }\n    }\n}\n\n/// Detects archive format from file extension\n///\n/// # Arguments\n/// * `path` - Path to check\n///\n/// # Returns\n/// * `Some(ArchiveFormat)` if recognized, `None` otherwise\npub fn detect_format(path: \u0026Path) -\u003e Option\u003cArchiveFormat\u003e {\n    let filename = path.file_name()?.to_str()?.to_lowercase();\n\n    if filename.ends_with(\".zip\") {\n        Some(ArchiveFormat::Zip)\n    } else if filename.ends_with(\".rar\") {\n        Some(ArchiveFormat::Rar)\n    } else if filename.ends_with(\".7z\") {\n        Some(ArchiveFormat::SevenZip)\n    } else if filename.ends_with(\".tar.gz\") || filename.ends_with(\".tgz\") {\n        Some(ArchiveFormat::TarGz)\n    } else if filename.ends_with(\".tar\") {\n        Some(ArchiveFormat::Tar)\n    } else {\n        None\n    }\n}\n\n/// Checks if file is a supported archive\n///\n/// # Arguments\n/// * `path` - Path to check\n///\n/// # Returns\n/// * `true` if file is a recognized archive format\npub fn is_archive(path: \u0026Path) -\u003e bool {\n    detect_format(path).is_some()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::path::PathBuf;\n\n    #[test]\n    fn test_detect_zip() {\n        let path = PathBuf::from(\"test.zip\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Zip));\n    }\n\n    #[test]\n    fn test_detect_rar() {\n        let path = PathBuf::from(\"archive.rar\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Rar));\n    }\n\n    #[test]\n    fn test_detect_7z() {\n        let path = PathBuf::from(\"package.7z\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::SevenZip));\n    }\n\n    #[test]\n    fn test_detect_tar_gz() {\n        let path = PathBuf::from(\"archive.tar.gz\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::TarGz));\n    }\n\n    #[test]\n    fn test_detect_tgz() {\n        let path = PathBuf::from(\"archive.tgz\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::TarGz));\n    }\n\n    #[test]\n    fn test_detect_tar() {\n        let path = PathBuf::from(\"archive.tar\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Tar));\n    }\n\n    #[test]\n    fn test_not_archive() {\n        let path = PathBuf::from(\"file.mid\");\n        assert_eq!(detect_format(\u0026path), None);\n    }\n\n    #[test]\n    fn test_is_archive() {\n        assert!(is_archive(\u0026PathBuf::from(\"test.zip\")));\n        assert!(!is_archive(\u0026PathBuf::from(\"test.mid\")));\n    }\n\n    #[test]\n    fn test_extension() {\n        assert_eq!(ArchiveFormat::Zip.extension(), \"zip\");\n        assert_eq!(ArchiveFormat::Rar.extension(), \"rar\");\n        assert_eq!(ArchiveFormat::SevenZip.extension(), \"7z\");\n        assert_eq!(ArchiveFormat::TarGz.extension(), \"tar.gz\");\n        assert_eq!(ArchiveFormat::Tar.extension(), \"tar\");\n    }\n\n    #[test]\n    fn test_case_insensitive() {\n        let path = PathBuf::from(\"TEST.ZIP\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Zip));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","mod.rs"],"content":"//! Archive decompression module\n//!\n//! # Archetype: Grown-up Script\n//! - Performs I/O operations\n//! - Can be run standalone OR imported\n//! - Separates I/O from business logic\n\npub mod extractor;\npub mod formats;\npub mod temp_manager;\n\n// Re-export main types\npub use extractor::{extract_archive, extract_to_temp, ExtractionConfig, ExtractionResult};\npub use formats::{detect_format, is_archive, ArchiveFormat};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","temp_manager.rs"],"content":"//! Temporary File Management\n\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse uuid::Uuid;\n\nuse crate::io::Result;\n\n/// Manages temporary extraction directories\npub struct TempManager {\n    base_dir: PathBuf,\n    active_dirs: Vec\u003cPathBuf\u003e,\n}\n\nimpl TempManager {\n    /// Creates new temp manager\n    ///\n    /// # Returns\n    /// * `Result\u003cTempManager\u003e` - New temp manager or I/O error\n    pub fn new() -\u003e Result\u003cSelf\u003e {\n        let base_dir = std::env::temp_dir().join(\"midi_extraction\");\n        fs::create_dir_all(\u0026base_dir)?;\n\n        Ok(Self {\n            base_dir,\n            active_dirs: Vec::new(),\n        })\n    }\n\n    /// Creates a new temporary directory\n    ///\n    /// # Returns\n    /// * `Result\u003cPathBuf\u003e` - Path to created temp directory or I/O error\n    pub fn create_temp_dir(\u0026mut self) -\u003e Result\u003cPathBuf\u003e {\n        let dir_name = Uuid::new_v4().to_string();\n        let temp_dir = self.base_dir.join(dir_name);\n\n        fs::create_dir_all(\u0026temp_dir)?;\n        self.active_dirs.push(temp_dir.clone());\n\n        Ok(temp_dir)\n    }\n\n    /// Cleans up all temporary directories\n    ///\n    /// # Returns\n    /// * `Result\u003c()\u003e` - Success or I/O error\n    pub fn cleanup(\u0026mut self) -\u003e Result\u003c()\u003e {\n        for dir in \u0026self.active_dirs {\n            if dir.exists() {\n                fs::remove_dir_all(dir)?;\n            }\n        }\n        self.active_dirs.clear();\n        Ok(())\n    }\n\n    /// Returns the base directory for temp files\n    pub fn base_dir(\u0026self) -\u003e \u0026Path {\n        \u0026self.base_dir\n    }\n\n    /// Returns count of active temporary directories\n    pub fn active_count(\u0026self) -\u003e usize {\n        self.active_dirs.len()\n    }\n}\n\nimpl Drop for TempManager {\n    fn drop(\u0026mut self) {\n        let _ = self.cleanup();\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_create_temp_dir() {\n        let mut manager = TempManager::new().unwrap();\n        let temp_dir = manager.create_temp_dir().unwrap();\n\n        assert!(temp_dir.exists());\n        assert_eq!(manager.active_count(), 1);\n\n        manager.cleanup().unwrap();\n        assert!(!temp_dir.exists());\n        assert_eq!(manager.active_count(), 0);\n    }\n\n    #[test]\n    fn test_multiple_temp_dirs() {\n        let mut manager = TempManager::new().unwrap();\n\n        let dir1 = manager.create_temp_dir().unwrap();\n        let dir2 = manager.create_temp_dir().unwrap();\n\n        assert!(dir1.exists());\n        assert!(dir2.exists());\n        assert_ne!(dir1, dir2);\n        assert_eq!(manager.active_count(), 2);\n\n        manager.cleanup().unwrap();\n        assert!(!dir1.exists());\n        assert!(!dir2.exists());\n    }\n\n    #[test]\n    fn test_base_dir() {\n        let manager = TempManager::new().unwrap();\n        let base = manager.base_dir();\n\n        assert!(base.exists());\n        // Use to_string_lossy() to avoid unwrap - it's safe for testing\n        assert!(base.to_string_lossy().contains(\"midi_extraction\"));\n    }\n\n    #[test]\n    fn test_cleanup_nonexistent_dir() {\n        let mut manager = TempManager::new().unwrap();\n        let temp_dir = manager.create_temp_dir().unwrap();\n\n        // Manually remove the directory\n        fs::remove_dir_all(\u0026temp_dir).unwrap();\n\n        // Cleanup should not fail even if dir doesn't exist\n        assert!(manager.cleanup().is_ok());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","error.rs"],"content":"//! I/O Error Types\n//!\n//! Defines error types for the I/O layer using thiserror.\n//! These errors cover file operations, archive extraction, and temporary file management.\n\nuse std::path::PathBuf;\nuse thiserror::Error;\n\n/// Errors that can occur during I/O operations\n#[derive(Error, Debug)]\npub enum IoError {\n    /// Standard I/O error\n    #[error(\"I/O error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    /// ZIP archive error\n    #[error(\"ZIP archive error: {0}\")]\n    Zip(#[from] zip::result::ZipError),\n\n    /// Invalid file path (contains non-UTF8 characters)\n    #[error(\"Invalid path (non-UTF8): {path:?}\")]\n    InvalidPath { path: PathBuf },\n\n    /// Unsupported archive format\n    #[error(\"Unsupported archive format: {path:?}\")]\n    UnsupportedFormat { path: PathBuf },\n\n    /// Maximum extraction depth exceeded\n    #[error(\"Maximum extraction depth ({max_depth}) exceeded at: {path:?}\")]\n    MaxDepthExceeded { max_depth: usize, path: PathBuf },\n\n    /// Archive format not implemented yet\n    #[error(\"Archive format {format:?} not yet implemented\")]\n    FormatNotImplemented { format: String },\n\n    /// Lock poisoning error (from RwLock or Mutex)\n    #[error(\"Lock poisoned\")]\n    LockPoisoned,\n\n    /// Temporary directory creation failed\n    #[error(\"Failed to create temporary directory\")]\n    TempDirCreation,\n\n    /// Generic boxed error for compatibility\n    #[error(\"Error: {0}\")]\n    Other(#[from] Box\u003cdyn std::error::Error + Send + Sync\u003e),\n}\n\n/// Result type for I/O operations\npub type Result\u003cT\u003e = std::result::Result\u003cT, IoError\u003e;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","mod.rs"],"content":"//! I/O operations module\n//!\n//! Contains Grown-up Scripts that perform file I/O operations\n\npub mod decompressor;\npub mod error;\n\n// Re-export error types\npub use error::{IoError, Result};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","lib.rs"],"content":"//! MIDI Library Pipeline Processor\n//!\n//! Core library for MIDI file processing, analysis, and management.\n\npub mod commands;\npub mod core;\npub mod db;\npub mod io;\n\n// Database connection module\npub mod database;\n\n// Error handling module\npub mod error;\n\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Re-export commonly used types\npub use database::Database;\npub use error::{AppError, AppResult, TauriResult};\npub use db::models::{File, MusicalMetadata, SearchFilters};\n\n/// Application state shared across all Tauri commands\npub struct AppState {\n    pub database: Database,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","main.rs"],"content":"// pipeline/src-tauri/src/main.rs\n// Task-O-Matic: Main entry point for Pipeline application\n// Purpose: Initialize app, register commands, manage state\n\n#![cfg_attr(\n    all(not(debug_assertions), target_os = \"windows\"),\n    windows_subsystem = \"windows\"\n)]\n\nuse tracing::{info};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n// Import from lib\nuse midi_pipeline::{AppState, Database};\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    // Load .env file\n    dotenv::dotenv().ok();\n\n    // Initialize tracing/logging\n    init_logging();\n\n    info!(\"Starting MIDI Pipeline application\");\n\n    // Get database URL from environment\n    let database_url = std::env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    // Initialize database connection\n    let database = match Database::new(\u0026database_url).await {\n        Ok(db) =\u003e {\n            info!(\"Database connection established\");\n            db\n        }\n        Err(e) =\u003e {\n            info!(\"Database initialization deferred (will retry on first command): {}\", e);\n            // Retry once\n            Database::new(\u0026database_url).await.map_err(|retry_err| {\n                format!(\"Failed to create database instance after retry: {}\", retry_err)\n            })?\n        }\n    };\n\n    // Create application state\n    let state = AppState {\n        database,\n    };\n\n    // Build and run Tauri application\n    tauri::Builder::default()\n        .manage(state)\n        .invoke_handler(tauri::generate_handler![\n            // File commands\n            midi_pipeline::commands::files::test_db_connection,\n            midi_pipeline::commands::files::get_file_count,\n            midi_pipeline::commands::files::get_file_details,\n            midi_pipeline::commands::files::get_file,\n            midi_pipeline::commands::files::list_files,\n            midi_pipeline::commands::files::get_files_by_category,\n            midi_pipeline::commands::files::get_recent_files,\n            midi_pipeline::commands::files::delete_file,\n\n            // Import commands\n            midi_pipeline::commands::file_import::import_single_file,\n            midi_pipeline::commands::file_import::import_directory,\n            midi_pipeline::commands::archive_import::import_archive_collection,\n\n            // Search commands\n            midi_pipeline::commands::search::search_files,\n            midi_pipeline::commands::search::get_all_tags,\n            midi_pipeline::commands::search::get_files_by_tag,\n            midi_pipeline::commands::search::get_bpm_range,\n            midi_pipeline::commands::search::get_all_keys,\n\n            // Analysis commands\n            midi_pipeline::commands::analyze::start_analysis,\n\n            // Statistics commands\n            midi_pipeline::commands::stats::get_category_stats,\n            midi_pipeline::commands::stats::get_manufacturer_stats,\n            midi_pipeline::commands::stats::get_key_signature_stats,\n            midi_pipeline::commands::stats::get_recently_added_count,\n            midi_pipeline::commands::stats::get_duplicate_count,\n            midi_pipeline::commands::stats::get_database_size,\n            midi_pipeline::commands::stats::check_database_health,\n\n            // Tag commands\n            midi_pipeline::commands::tags::get_file_tags,\n            midi_pipeline::commands::tags::get_popular_tags,\n            midi_pipeline::commands::tags::search_tags,\n            midi_pipeline::commands::tags::get_tag_categories,\n            midi_pipeline::commands::tags::get_tags_by_category,\n            midi_pipeline::commands::tags::update_file_tags,\n            midi_pipeline::commands::tags::add_tags_to_file,\n            midi_pipeline::commands::tags::remove_tag_from_file,\n            midi_pipeline::commands::tags::get_files_by_tags,\n            midi_pipeline::commands::tags::get_tag_stats,\n\n            // Progress tracking commands\n            midi_pipeline::commands::progress::start_progress_tracking,\n            midi_pipeline::commands::progress::update_progress,\n            midi_pipeline::commands::progress::increment_error_count,\n            midi_pipeline::commands::progress::increment_duplicate_count,\n            midi_pipeline::commands::progress::complete_progress,\n            midi_pipeline::commands::progress::get_current_progress,\n            midi_pipeline::commands::progress::reset_progress,\n\n            // System commands\n            midi_pipeline::commands::system::get_system_info,\n        ])\n        .setup(|_app| {\n            info!(\"Application setup complete\");\n            Ok(())\n        })\n        .run(tauri::generate_context!())?;\n\n    Ok(())\n}\n\n/// Initialize logging/tracing system\nfn init_logging() {\n    let log_dir = std::env::var(\"LOG_DIR\").unwrap_or_else(|_| \"./logs\".to_string());\n    std::fs::create_dir_all(\u0026log_dir).ok();\n\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"pipeline.log\");\n    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);\n\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| \"info,midi_pipeline=debug\".into()),\n        )\n        .with(tracing_subscriber::fmt::layer().with_writer(std::io::stdout))\n        .with(tracing_subscriber::fmt::layer().with_writer(non_blocking))\n        .init();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_logging_init() {\n        // Test that logging initialization doesn't panic\n        init_logging();\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","analyze-tool","src","analyzer.rs"],"content":"//! MIDI Analyzer - Trusty Module\n//!\n//! Extracts complete musical metadata from MIDI files\n\nuse midly::{Smf, Timing, MetaMessage, TrackEventKind, MidiMessage};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone)]\npub struct MidiAnalysis {\n    pub bpm: Option\u003cf64\u003e,\n    pub bpm_confidence: f32,\n    pub has_tempo_changes: bool,\n\n    pub key_signature: Option\u003cString\u003e,\n    pub key_confidence: f32,\n\n    pub time_sig_num: i16,\n    pub time_sig_den: i16,\n\n    pub duration_seconds: f64,\n    pub duration_ticks: i64,\n\n    pub total_notes: i32,\n    pub unique_pitches: i32,\n    pub pitch_range_min: i16,\n    pub pitch_range_max: i16,\n\n    pub avg_velocity: f64,\n    pub polyphony_max: i16,\n    pub polyphony_avg: f64,\n\n    pub is_monophonic: bool,\n    pub is_polyphonic: bool,\n    pub is_percussive: bool,\n    pub has_chords: bool,\n\n    pub note_density: f64,\n    pub instruments: Vec\u003cString\u003e,\n}\n\nimpl Default for MidiAnalysis {\n    fn default() -\u003e Self {\n        Self {\n            bpm: None,\n            bpm_confidence: 0.0,\n            has_tempo_changes: false,\n            key_signature: None,\n            key_confidence: 0.0,\n            time_sig_num: 4,\n            time_sig_den: 4,\n            duration_seconds: 0.0,\n            duration_ticks: 0,\n            total_notes: 0,\n            unique_pitches: 0,\n            pitch_range_min: 127,\n            pitch_range_max: 0,\n            avg_velocity: 0.0,\n            polyphony_max: 0,\n            polyphony_avg: 0.0,\n            is_monophonic: false,\n            is_polyphonic: false,\n            is_percussive: false,\n            has_chords: false,\n            note_density: 0.0,\n            instruments: Vec::new(),\n        }\n    }\n}\n\npub fn analyze_midi(data: \u0026[u8]) -\u003e Result\u003cMidiAnalysis, String\u003e {\n    let smf = Smf::parse(data).map_err(|e| format!(\"Parse error: {}\", e))?;\n\n    let mut analysis = MidiAnalysis::default();\n\n    // Get PPQ\n    let ppq = match smf.header.timing {\n        Timing::Metrical(tpb) =\u003e tpb.as_int() as i64,\n        Timing::Timecode(_, _) =\u003e 480,\n    };\n\n    // Extract tempo\n    let tempo_us = extract_tempo(\u0026smf);\n    if tempo_us \u003e 0 {\n        analysis.bpm = Some(60_000_000.0 / tempo_us as f64);\n        analysis.bpm_confidence = 1.0;\n    }\n\n    // Extract time signature\n    let (num, den) = extract_time_signature(\u0026smf);\n    analysis.time_sig_num = num;\n    analysis.time_sig_den = den;\n\n    // Collect all notes\n    let notes = collect_notes(\u0026smf);\n    analysis.total_notes = notes.len() as i32;\n\n    if !notes.is_empty() {\n        // Pitch analysis\n        let unique_pitches: std::collections::HashSet\u003cu8\u003e =\n            notes.iter().map(|(_, pitch, _)| *pitch).collect();\n        analysis.unique_pitches = unique_pitches.len() as i32;\n\n        analysis.pitch_range_min = notes.iter().map(|(_, p, _)| *p).min().unwrap_or(127) as i16;\n        analysis.pitch_range_max = notes.iter().map(|(_, p, _)| *p).max().unwrap_or(0) as i16;\n\n        // Velocity analysis\n        let total_vel: u32 = notes.iter().map(|(_, _, v)| *v as u32).sum();\n        analysis.avg_velocity = total_vel as f64 / notes.len() as f64;\n\n        // Polyphony analysis\n        analysis.polyphony_max = calculate_max_polyphony(\u0026notes);\n        analysis.polyphony_avg = calculate_avg_polyphony(\u0026notes);\n\n        analysis.is_monophonic = analysis.polyphony_max \u003c= 1;\n        analysis.is_polyphonic = analysis.polyphony_max \u003e= 3;\n        analysis.has_chords = analysis.polyphony_max \u003e= 3;\n\n        // Check for percussion (channel 10 or low pitch range)\n        analysis.is_percussive = notes.iter().any(|(_, pitch, _)| *pitch \u003c 36);\n\n        // Duration\n        let max_tick = notes.iter().map(|(tick, _, _)| *tick).max().unwrap_or(0);\n        analysis.duration_ticks = max_tick as i64;\n\n        if let Some(bpm) = analysis.bpm {\n            if bpm \u003e 0.0 {\n                analysis.duration_seconds = (max_tick as f64 / ppq as f64) * (60.0 / bpm);\n            }\n        }\n\n        // Note density\n        if analysis.duration_seconds \u003e 0.0 {\n            analysis.note_density = analysis.total_notes as f64 / analysis.duration_seconds;\n        }\n\n        // Key detection\n        if let Some((key, confidence)) = detect_key(\u0026notes) {\n            analysis.key_signature = Some(key);\n            analysis.key_confidence = confidence;\n        }\n\n        // Instruments\n        analysis.instruments = extract_instruments(\u0026smf);\n    }\n\n    Ok(analysis)\n}\n\nfn extract_tempo(smf: \u0026Smf) -\u003e u32 {\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Meta(MetaMessage::Tempo(tempo)) = event.kind {\n                return tempo.as_int();\n            }\n        }\n    }\n    500_000 // Default 120 BPM\n}\n\nfn extract_time_signature(smf: \u0026Smf) -\u003e (i16, i16) {\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Meta(MetaMessage::TimeSignature(num, den, _, _)) = event.kind {\n                return (num as i16, 2_i16.pow(den as u32));\n            }\n        }\n    }\n    (4, 4)\n}\n\nfn collect_notes(smf: \u0026Smf) -\u003e Vec\u003c(u32, u8, u8)\u003e {\n    let mut notes = Vec::new();\n\n    for track in \u0026smf.tracks {\n        let mut tick = 0u32;\n        for event in track {\n            tick += event.delta.as_int();\n\n            if let TrackEventKind::Midi { message, .. } = event.kind {\n                if let MidiMessage::NoteOn { key, vel } = message {\n                    if vel.as_int() \u003e 0 {\n                        notes.push((tick, key.as_int(), vel.as_int()));\n                    }\n                }\n            }\n        }\n    }\n\n    notes\n}\n\nfn calculate_max_polyphony(notes: \u0026[(u32, u8, u8)]) -\u003e i16 {\n    let mut note_states: HashMap\u003cu32, Vec\u003cu8\u003e\u003e = HashMap::new();\n\n    for (tick, pitch, _) in notes {\n        note_states.entry(*tick).or_insert_with(Vec::new).push(*pitch);\n    }\n\n    note_states.values()\n        .map(|pitches| {\n            pitches.iter().collect::\u003cstd::collections::HashSet\u003c_\u003e\u003e().len() as i16\n        })\n        .max()\n        .unwrap_or(0)\n}\n\nfn calculate_avg_polyphony(notes: \u0026[(u32, u8, u8)]) -\u003e f64 {\n    if notes.is_empty() {\n        return 0.0;\n    }\n\n    let max = calculate_max_polyphony(notes);\n    max as f64 * 0.6 // Rough estimate\n}\n\nfn detect_key(notes: \u0026[(u32, u8, u8)]) -\u003e Option\u003c(String, f32)\u003e {\n    if notes.is_empty() {\n        return None;\n    }\n\n    // Krumhansl-Schmuckler algorithm\n    const MAJOR_PROFILE: [f32; 12] = [\n        6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n        2.52, 5.19, 2.39, 3.66, 2.29, 2.88\n    ];\n\n    const MINOR_PROFILE: [f32; 12] = [\n        6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n        2.54, 4.75, 3.98, 2.69, 3.34, 3.17\n    ];\n\n    const NOTE_NAMES: [\u0026str; 12] = [\n        \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\",\n        \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"\n    ];\n\n    // Count pitch class occurrences\n    let mut pitch_class_counts = [0u32; 12];\n    for (_, pitch, _) in notes {\n        pitch_class_counts[(pitch % 12) as usize] += 1;\n    }\n\n    // Normalize\n    let total: u32 = pitch_class_counts.iter().sum();\n    if total == 0 {\n        return None;\n    }\n\n    let distribution: Vec\u003cf32\u003e = pitch_class_counts\n        .iter()\n        .map(|\u0026c| c as f32 / total as f32)\n        .collect();\n\n    // Find best correlation\n    let mut best_key = String::new();\n    let mut best_corr = -1.0f32;\n\n    for tonic in 0..12 {\n        // Test major\n        let major_corr = correlate(\u0026distribution, \u0026rotate_profile(\u0026MAJOR_PROFILE, tonic));\n        if major_corr \u003e best_corr {\n            best_corr = major_corr;\n            best_key = NOTE_NAMES[tonic].to_string();\n        }\n\n        // Test minor\n        let minor_corr = correlate(\u0026distribution, \u0026rotate_profile(\u0026MINOR_PROFILE, tonic));\n        if minor_corr \u003e best_corr {\n            best_corr = minor_corr;\n            best_key = format!(\"{}m\", NOTE_NAMES[tonic]);\n        }\n    }\n\n    Some((best_key, best_corr.max(0.0).min(1.0)))\n}\n\nfn correlate(a: \u0026[f32], b: \u0026[f32]) -\u003e f32 {\n    let mean_a: f32 = a.iter().sum::\u003cf32\u003e() / a.len() as f32;\n    let mean_b: f32 = b.iter().sum::\u003cf32\u003e() / b.len() as f32;\n\n    let mut numerator = 0.0f32;\n    let mut denom_a = 0.0f32;\n    let mut denom_b = 0.0f32;\n\n    for i in 0..a.len() {\n        let da = a[i] - mean_a;\n        let db = b[i] - mean_b;\n        numerator += da * db;\n        denom_a += da * da;\n        denom_b += db * db;\n    }\n\n    if denom_a == 0.0 || denom_b == 0.0 {\n        return 0.0;\n    }\n\n    numerator / (denom_a * denom_b).sqrt()\n}\n\nfn rotate_profile(profile: \u0026[f32; 12], steps: usize) -\u003e [f32; 12] {\n    let mut rotated = [0.0f32; 12];\n    for i in 0..12 {\n        rotated[i] = profile[(i + steps) % 12];\n    }\n    rotated\n}\n\nfn extract_instruments(smf: \u0026Smf) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Midi { message, .. } = event.kind {\n                if let MidiMessage::ProgramChange { program } = message {\n                    let instrument = get_instrument_name(program.as_int());\n                    if !instruments.contains(\u0026instrument) {\n                        instruments.push(instrument);\n                    }\n                }\n            }\n        }\n    }\n\n    instruments\n}\n\nfn get_instrument_name(program: u8) -\u003e String {\n    match program {\n        0..=7 =\u003e \"Piano\".to_string(),\n        8..=15 =\u003e \"Chromatic Percussion\".to_string(),\n        16..=23 =\u003e \"Organ\".to_string(),\n        24..=31 =\u003e \"Guitar\".to_string(),\n        32..=39 =\u003e \"Bass\".to_string(),\n        40..=47 =\u003e \"Strings\".to_string(),\n        48..=55 =\u003e \"Ensemble\".to_string(),\n        56..=63 =\u003e \"Brass\".to_string(),\n        64..=71 =\u003e \"Reed\".to_string(),\n        72..=79 =\u003e \"Pipe\".to_string(),\n        80..=87 =\u003e \"Synth Lead\".to_string(),\n        88..=95 =\u003e \"Synth Pad\".to_string(),\n        96..=103 =\u003e \"Synth Effects\".to_string(),\n        104..=111 =\u003e \"Ethnic\".to_string(),\n        112..=119 =\u003e \"Percussive\".to_string(),\n        120..=127 =\u003e \"Sound Effects\".to_string(),\n        _ =\u003e \"Unknown\".to_string(),\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","analyze-tool","src","tag_extractor.rs"],"content":"///! Tag Extractor - Trusty Module\n//!\n//! Extracts tags from file paths and folder names\n\nuse std::path::Path;\n\n#[derive(Debug, Clone)]\npub struct ExtractedTags {\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection: Option\u003cString\u003e,\n    pub genres: Vec\u003cString\u003e,\n    pub category: Option\u003cString\u003e,\n    pub bpm_hint: Option\u003ci16\u003e,\n    pub descriptors: Vec\u003cString\u003e,\n}\n\npub fn extract_tags_from_path(filepath: \u0026str) -\u003e ExtractedTags {\n    let path = Path::new(filepath);\n    let components: Vec\u003c\u0026str\u003e = path\n        .components()\n        .filter_map(|c| c.as_os_str().to_str())\n        .collect();\n\n    let mut tags = ExtractedTags {\n        manufacturer: None,\n        collection: None,\n        genres: Vec::new(),\n        category: None,\n        bpm_hint: None,\n        descriptors: Vec::new(),\n    };\n\n    // Extract manufacturer\n    tags.manufacturer = detect_manufacturer(\u0026components);\n\n    // Extract genres\n    tags.genres = extract_genres(\u0026components);\n\n    // Extract category\n    tags.category = detect_category(\u0026components);\n\n    // Extract BPM hint\n    tags.bpm_hint = extract_bpm_hint(filepath);\n\n    // Extract descriptors\n    tags.descriptors = extract_descriptors(\u0026components);\n\n    tags\n}\n\nfn detect_manufacturer(components: \u0026[\u0026str]) -\u003e Option\u003cString\u003e {\n    let manufacturers = [\n        \"DMS\", \"Loopmasters\", \"Vengeance\", \"Sample Magic\", \"Singomakers\",\n        \"Hy2rogen\", \"Production Master\", \"Function Loops\", \"Audentity\",\n        \"Chill Samples\", \"Class A Samples\", \"Diginoiz\", \"Prime Loops\",\n        \"Producer Loops\", \"Sonic Academy\", \"Black Octopus\", \"MIDI Focus\",\n        \"Zenhiser\"\n    ];\n\n    for component in components {\n        for mfr in \u0026manufacturers {\n            if component.contains(mfr) {\n                return Some(mfr.to_string());\n            }\n        }\n    }\n\n    None\n}\n\nfn extract_genres(components: \u0026[\u0026str]) -\u003e Vec\u003cString\u003e {\n    let genres = [\n        \"Trance\", \"House\", \"Techno\", \"Drum and Bass\", \"DnB\", \"Dubstep\",\n        \"Hardcore\", \"Progressive\", \"Electro\", \"Tech House\", \"Deep House\",\n        \"Psytrance\", \"Minimal\", \"Ambient\", \"Chill\", \"Lo-Fi\", \"Trap\",\n        \"Future Bass\", \"Liquid\"\n    ];\n\n    let mut found = Vec::new();\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for genre in \u0026genres {\n        if path_str.contains(\u0026genre.to_lowercase()) {\n            found.push(genre.to_string());\n        }\n    }\n\n    found\n}\n\nfn detect_category(components: \u0026[\u0026str]) -\u003e Option\u003cString\u003e {\n    let categories = [\n        (\"Bass\", vec![\"bass\", \"sub\", \"reese\"]),\n        (\"Melody\", vec![\"melody\", \"lead\", \"melodic\"]),\n        (\"Pad\", vec![\"pad\", \"atmosphere\", \"ambient\"]),\n        (\"Chord\", vec![\"chord\", \"progression\"]),\n        (\"Arp\", vec![\"arp\", \"arpegg\"]),\n        (\"Drum\", vec![\"drum\", \"kick\", \"snare\", \"hat\", \"perc\"]),\n        (\"FX\", vec![\"fx\", \"effect\", \"riser\", \"sweep\"]),\n    ];\n\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for (category, keywords) in \u0026categories {\n        for keyword in keywords {\n            if path_str.contains(keyword) {\n                return Some(category.to_string());\n            }\n        }\n    }\n\n    None\n}\n\nfn extract_bpm_hint(filepath: \u0026str) -\u003e Option\u003ci16\u003e {\n    // Look for patterns like \"140 BPM\", \"140BPM\", \"140bpm\"\n    let re = regex::Regex::new(r\"(\\d{2,3})\\s*[Bb][Pp][Mm]\").ok()?;\n\n    if let Some(cap) = re.captures(filepath) {\n        return cap[1].parse().ok();\n    }\n\n    // Also check for folder names like \"140 BPM\"\n    let re2 = regex::Regex::new(r\"/(\\d{2,3})\\s*[Bb][Pp][Mm]/\").ok()?;\n    if let Some(cap) = re2.captures(filepath) {\n        return cap[1].parse().ok();\n    }\n\n    None\n}\n\nfn extract_descriptors(components: \u0026[\u0026str]) -\u003e Vec\u003cString\u003e {\n    let descriptors = [\n        \"Hard\", \"Soft\", \"Deep\", \"Bright\", \"Dark\", \"Warm\", \"Cold\",\n        \"Fat\", \"Thin\", \"Punchy\", \"Smooth\", \"Rough\", \"Clean\", \"Dirty\",\n        \"Melodic\", \"Atmospheric\", \"Epic\", \"Minimal\", \"Complex\",\n        \"Liquid\", \"Uplifting\", \"Driving\", \"Bouncy\", \"Rolling\",\n        \"Variation\", \"Straight\", \"Shuffle\", \"Triplet\", \"Syncopation\"\n    ];\n\n    let mut found = Vec::new();\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for desc in \u0026descriptors {\n        if path_str.contains(\u0026desc.to_lowercase()) \u0026\u0026 !found.contains(\u0026desc.to_string()) {\n            found.push(desc.to_string());\n        }\n    }\n\n    found\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","import-tool","src","main.rs"],"content":"//! Simple High-Performance MIDI Importer\n//!\n//! Usage: ./import_midi ~/midi_extraction\n//!\n//! This script:\n//! - Scans recursively for .mid/.midi files\n//! - Calculates SHA-256 hash for deduplication\n//! - Inserts into database with parallel processing\n//! - Shows real-time progress\n\nuse chrono::Utc;\nuse sha2::{Digest, Sha256};\nuse std::path::PathBuf;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse tokio::sync::Semaphore;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let args: Vec\u003cString\u003e = std::env::args().collect();\n\n    if args.len() \u003c 2 {\n        eprintln!(\"Usage: {} \u003cdirectory\u003e\", args[0]);\n        eprintln!(\"Example: {} ~/midi_extraction\", args[0]);\n        std::process::exit(1);\n    }\n\n    let directory = \u0026args[1];\n\n    println!(\" MIDI Library Importer\");\n    println!(\"\");\n    println!();\n\n    // Connect to database\n    let db_url = std::env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(32)\n        .connect(\u0026db_url)\n        .await?;\n    println!(\" Connected\\n\");\n\n    // Collect MIDI files\n    println!(\" Scanning: {}\", directory);\n    let files: Vec\u003cPathBuf\u003e = walkdir::WalkDir::new(directory)\n        .into_iter()\n        .filter_map(|e| e.ok())\n        .filter(|e| {\n            e.path()\n                .extension()\n                .and_then(|s| s.to_str())\n                .map(|s| s.eq_ignore_ascii_case(\"mid\") || s.eq_ignore_ascii_case(\"midi\"))\n                .unwrap_or(false)\n        })\n        .map(|e| e.path().to_path_buf())\n        .collect();\n\n    let total = files.len();\n    println!(\" Found {} MIDI files\\n\", total);\n\n    if total == 0 {\n        println!(\"  No MIDI files found!\");\n        return Ok(());\n    }\n\n    println!(\" Starting import with 32 workers...\\n\");\n\n    // Counters\n    let imported = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(AtomicUsize::new(0));\n\n    let semaphore = Arc::new(Semaphore::new(32));\n    let start_time = std::time::Instant::now();\n\n    // Process files\n    let mut tasks = vec![];\n\n    for (idx, file_path) in files.into_iter().enumerate() {\n        let sem = Arc::clone(\u0026semaphore);\n        let pool_clone = pool.clone();\n        let imported = Arc::clone(\u0026imported);\n        let skipped = Arc::clone(\u0026skipped);\n        let errors = Arc::clone(\u0026errors);\n\n        let task = tokio::spawn(async move {\n            let _permit = match sem.acquire().await {\n                Ok(permit) =\u003e permit,\n                Err(_) =\u003e {\n                    eprintln!(\"Warning: Semaphore closed during import\");\n                    return;\n                }\n            };\n\n            match process_file(\u0026file_path, \u0026pool_clone).await {\n                Ok(true) =\u003e {\n                    imported.fetch_add(1, Ordering::SeqCst);\n                }\n                Ok(false) =\u003e {\n                    skipped.fetch_add(1, Ordering::SeqCst);\n                }\n                Err(_) =\u003e {\n                    errors.fetch_add(1, Ordering::SeqCst);\n                }\n            }\n\n            // Print progress every 100 files\n            if idx % 100 == 0 {\n                let elapsed = start_time.elapsed().as_secs_f64();\n                let processed = idx + 1;\n                let rate = processed as f64 / elapsed;\n                println!(\"Progress: {}/{} ({:.1}%) - {:.0} files/sec\",\n                    processed, total,\n                    (processed as f64 / total as f64) * 100.0,\n                    rate\n                );\n            }\n        });\n\n        tasks.push(task);\n    }\n\n    // Wait for all tasks\n    for task in tasks {\n        task.await?;\n    }\n\n    let elapsed = start_time.elapsed();\n    let imported_count = imported.load(Ordering::SeqCst);\n    let skipped_count = skipped.load(Ordering::SeqCst);\n    let error_count = errors.load(Ordering::SeqCst);\n\n    // Final report\n    println!();\n    println!(\"\");\n    println!(\" Import Complete!\");\n    println!(\"\");\n    println!(\"Total:     {}\", total);\n    println!(\"Imported:  {} \", imported_count);\n    println!(\"Skipped:   {} (duplicates)\", skipped_count);\n    println!(\"Errors:    {}\", error_count);\n    println!();\n    println!(\"  Time:  {:.2}s\", elapsed.as_secs_f64());\n    println!(\" Rate:  {:.0} files/sec\", total as f64 / elapsed.as_secs_f64());\n    println!();\n\n    Ok(())\n}\n\nasync fn process_file(\n    file_path: \u0026std::path::Path,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003cbool, Box\u003cdyn std::error::Error\u003e\u003e {\n    // Read file\n    let file_data = tokio::fs::read(file_path).await?;\n\n    // Calculate hash\n    let mut hasher = Sha256::new();\n    hasher.update(\u0026file_data);\n    let content_hash = hasher.finalize().to_vec();\n\n    // Parse basic MIDI info\n    let (num_tracks, tpqn) = parse_midi_basic(\u0026file_data);\n\n    // Get parent folder name\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    // Get filename (normalize .midi -\u003e .mid)\n    let original_filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown.mid\")\n        .to_string();\n\n    let filename = if original_filename.to_lowercase().ends_with(\".midi\") {\n        original_filename[..original_filename.len()-1].to_string() // .midi -\u003e .mid\n    } else {\n        original_filename.clone()\n    };\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    // Insert into database\n    let result = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            parent_folder,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            ticks_per_quarter_note,\n            created_at,\n            updated_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#,\n    )\n    .bind(\u0026filename)\n    .bind(\u0026original_filename)\n    .bind(\u0026filepath)\n    .bind(parent_folder)\n    .bind(\u0026content_hash)\n    .bind(file_data.len() as i64)\n    .bind(num_tracks)\n    .bind(tpqn)\n    .bind(Utc::now())\n    .bind(Utc::now())\n    .fetch_optional(pool)\n    .await?;\n\n    Ok(result.is_some())\n}\n\n/// Parse basic MIDI info (tracks and TPPQ)\nfn parse_midi_basic(data: \u0026[u8]) -\u003e (i16, i32) {\n    if data.len() \u003c 14 || \u0026data[0..4] != b\"MThd\" {\n        return (1, 480);\n    }\n\n    let num_tracks = i16::from_be_bytes([data[10], data[11]]);\n    let ticks = u16::from_be_bytes([data[12], data[13]]);\n\n    (num_tracks, ticks as i32)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","auto_tagger.rs"],"content":"//! Auto-tagging functionality\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub fn generate_tags(_midi_file: \u0026crate::core::midi::MidiFile) -\u003e Vec\u003cString\u003e {\n    unimplemented!(\"Will be implemented in Phase 5\")\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","bpm_detector.rs"],"content":"//! BPM Detection Module\n//!\n//! This module provides BPM (Beats Per Minute) detection for MIDI files.\n//! It analyzes tempo change events and provides confidence scores.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse crate::core::midi::types::{Event, MidiFile};\n\n/// Default BPM when no tempo events are found\nconst DEFAULT_BPM: f64 = 120.0;\n\n/// Minimum valid BPM\nconst MIN_BPM: f64 = 20.0;\n\n/// Maximum valid BPM\nconst MAX_BPM: f64 = 300.0;\n\n/// Result of BPM detection\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmDetectionResult {\n    /// Detected BPM (beats per minute)\n    pub bpm: f64,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Detection method used\n    pub method: BpmDetectionMethod,\n\n    /// Additional metadata\n    pub metadata: BpmMetadata,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum BpmDetectionMethod {\n    /// Single tempo event found\n    SingleTempo,\n\n    /// Multiple tempo events, used weighted average\n    WeightedAverage,\n\n    /// No tempo events, used default\n    DefaultTempo,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmMetadata {\n    /// All tempo changes in the file\n    pub tempo_changes: Vec\u003cTempoChange\u003e,\n\n    /// Whether tempo is constant throughout\n    pub is_constant: bool,\n\n    /// Tempo range (min, max) if multiple tempos\n    pub tempo_range: Option\u003c(f64, f64)\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct TempoChange {\n    pub tick: u32,\n    pub bpm: f64,\n}\n\n/// Detects BPM from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `BpmDetectionResult` - Detection result with confidence and metadata\n///\n/// # Examples\n/// ```ignore\n/// use midi_library_shared::core::analysis::bpm_detector::detect_bpm;\n/// use midi_library_shared::core::midi::types::MidiFile;\n///\n/// let result = detect_bpm(\u0026midi_file);\n/// println!(\"Detected BPM: {:.2}\", result.bpm);\n/// ```\npub fn detect_bpm(midi_file: \u0026MidiFile) -\u003e BpmDetectionResult {\n    // Extract all tempo events from all tracks\n    let tempo_events = extract_tempo_events(midi_file);\n\n    if tempo_events.is_empty() {\n        return BpmDetectionResult {\n            bpm: DEFAULT_BPM,\n            confidence: 0.3, // Low confidence for default tempo\n            method: BpmDetectionMethod::DefaultTempo,\n            metadata: BpmMetadata {\n                tempo_changes: vec![],\n                is_constant: true,\n                tempo_range: None,\n            },\n        };\n    }\n\n    // Convert tempo changes to BPM values\n    let tempo_changes: Vec\u003cTempoChange\u003e = tempo_events\n        .into_iter()\n        .map(|(tick, microseconds_per_quarter)| TempoChange {\n            tick,\n            bpm: microseconds_to_bpm(microseconds_per_quarter),\n        })\n        .collect();\n\n    // Calculate statistics\n    let is_constant = tempo_changes.len() == 1;\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let total_ticks = calculate_total_ticks(midi_file);\n    let avg_bpm = calculate_weighted_average(\u0026tempo_changes, total_ticks);\n\n    let tempo_range = if tempo_changes.len() \u003e 1 {\n        let min = bpms.iter().cloned().fold(f64::INFINITY, f64::min);\n        let max = bpms.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n        Some((min, max))\n    } else {\n        None\n    };\n\n    // Determine confidence based on consistency\n    let confidence = calculate_confidence(\u0026tempo_changes);\n\n    let method = if tempo_changes.len() == 1 {\n        BpmDetectionMethod::SingleTempo\n    } else {\n        BpmDetectionMethod::WeightedAverage\n    };\n\n    BpmDetectionResult {\n        bpm: avg_bpm,\n        confidence,\n        method,\n        metadata: BpmMetadata {\n            tempo_changes,\n            is_constant,\n            tempo_range,\n        },\n    }\n}\n\n/// Extracts tempo events from all tracks in the MIDI file\nfn extract_tempo_events(midi_file: \u0026MidiFile) -\u003e Vec\u003c(u32, u32)\u003e {\n    let mut tempo_events = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            if let Event::TempoChange {\n                microseconds_per_quarter,\n            } = timed_event.event\n            {\n                tempo_events.push((current_tick, microseconds_per_quarter));\n            }\n        }\n    }\n\n    // Sort by tick position\n    tempo_events.sort_by_key(|(tick, _)| *tick);\n    tempo_events\n}\n\n/// Calculates the total number of ticks in the MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e u32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks\n}\n\n/// Converts microseconds per quarter note to BPM\nfn microseconds_to_bpm(microseconds_per_quarter: u32) -\u003e f64 {\n    let bpm = 60_000_000.0 / microseconds_per_quarter as f64;\n\n    // Clamp to valid range\n    bpm.clamp(MIN_BPM, MAX_BPM)\n}\n\n/// Calculates weighted average BPM based on duration each tempo is active\nfn calculate_weighted_average(tempo_changes: \u0026[TempoChange], total_ticks: u32) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return DEFAULT_BPM;\n    }\n\n    if tempo_changes.len() == 1 {\n        return tempo_changes[0].bpm;\n    }\n\n    let mut weighted_sum = 0.0;\n    let mut total_weight = 0.0;\n\n    for (i, tempo_change) in tempo_changes.iter().enumerate() {\n        let duration = if i + 1 \u003c tempo_changes.len() {\n            tempo_changes[i + 1].tick - tempo_change.tick\n        } else {\n            total_ticks.saturating_sub(tempo_change.tick)\n        };\n\n        let weight = duration as f64;\n        weighted_sum += tempo_change.bpm * weight;\n        total_weight += weight;\n    }\n\n    if total_weight \u003e 0.0 {\n        weighted_sum / total_weight\n    } else {\n        tempo_changes[0].bpm\n    }\n}\n\n/// Calculates confidence score based on tempo consistency\nfn calculate_confidence(tempo_changes: \u0026[TempoChange]) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return 0.3; // Low confidence for default\n    }\n\n    if tempo_changes.len() == 1 {\n        return 1.0; // High confidence for single tempo\n    }\n\n    // Calculate variance in BPM values\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let mean = bpms.iter().sum::\u003cf64\u003e() / bpms.len() as f64;\n    let variance = bpms.iter().map(|bpm| (bpm - mean).powi(2)).sum::\u003cf64\u003e() / bpms.len() as f64;\n    let std_dev = variance.sqrt();\n\n    // Lower variance = higher confidence\n    // Scale confidence based on coefficient of variation\n    let cv = std_dev / mean;\n    (1.0 - cv).clamp(0.5, 1.0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_to_bpm() {\n        // 120 BPM = 500,000 microseconds per quarter note\n        assert_eq!(microseconds_to_bpm(500_000), 120.0);\n\n        // 60 BPM = 1,000,000 microseconds\n        assert_eq!(microseconds_to_bpm(1_000_000), 60.0);\n\n        // 140 BPM  428,571 microseconds\n        let bpm = microseconds_to_bpm(428_571);\n        assert!((bpm - 140.0).abs() \u003c 0.1);\n    }\n\n    #[test]\n    fn test_bpm_clamping() {\n        // Test minimum clamping\n        let too_slow = microseconds_to_bpm(5_000_000); // Would be 12 BPM\n        assert_eq!(too_slow, MIN_BPM);\n\n        // Test maximum clamping\n        let too_fast = microseconds_to_bpm(100_000); // Would be 600 BPM\n        assert_eq!(too_fast, MAX_BPM);\n    }\n}\n","traces":[{"line":187,"address":[764656],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":1},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","key_detector.rs"],"content":"//! Key detection\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub fn detect_key(_midi_file: \u0026crate::core::midi::MidiFile) -\u003e Option\u003cString\u003e {\n    unimplemented!(\"Will be implemented in Phase 5\")\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","key_profiles.rs"],"content":"//! Key profile data\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","mod.rs"],"content":"//! Musical analysis modules\n//!\n//! This module provides:\n//! - BPM detection\n//! - Key detection\n//! - Auto-tagging\n//! - Key profile data\n\npub mod bpm_detector;\npub mod key_detector;\npub mod key_profiles;\npub mod auto_tagger;\n\n// Re-export main functions\npub use bpm_detector::detect_bpm;\npub use key_detector::detect_key;\npub use auto_tagger::generate_tags;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum MidiParseError {\n    #[error(\"Invalid MIDI header: {0}\")]\n    InvalidHeader(String),\n\n    #[error(\"Invalid track data at byte {position}: {reason}\")]\n    InvalidTrack { position: usize, reason: String },\n\n    #[error(\"Unsupported MIDI format: {0}\")]\n    UnsupportedFormat(u16),\n\n    #[error(\"Invalid event at byte {position}: {reason}\")]\n    InvalidEvent { position: usize, reason: String },\n\n    #[error(\"Incomplete data: expected {expected} bytes, got {actual}\")]\n    IncompleteData { expected: usize, actual: usize },\n\n    #[error(\"Invalid variable-length quantity at byte {0}\")]\n    InvalidVarLen(usize),\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"UTF-8 decode error: {0}\")]\n    Utf8(#[from] std::string::FromUtf8Error),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, MidiParseError\u003e;\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::io;\n\n    // ============================================================================\n    // Error Construction Tests\n    // ============================================================================\n\n    #[test]\n    fn test_invalid_header_construction() {\n        let error = MidiParseError::InvalidHeader(\"bad magic number\".to_string());\n        assert!(matches!(error, MidiParseError::InvalidHeader(_)));\n    }\n\n    #[test]\n    fn test_invalid_track_construction() {\n        let error = MidiParseError::InvalidTrack {\n            position: 42,\n            reason: \"unexpected end\".to_string(),\n        };\n        assert!(matches!(error, MidiParseError::InvalidTrack { .. }));\n    }\n\n    #[test]\n    fn test_unsupported_format_construction() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        assert!(matches!(error, MidiParseError::UnsupportedFormat(99)));\n    }\n\n    #[test]\n    fn test_invalid_event_construction() {\n        let error = MidiParseError::InvalidEvent {\n            position: 100,\n            reason: \"invalid status byte\".to_string(),\n        };\n        assert!(matches!(error, MidiParseError::InvalidEvent { .. }));\n    }\n\n    #[test]\n    fn test_incomplete_data_construction() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        assert!(matches!(error, MidiParseError::IncompleteData { .. }));\n    }\n\n    #[test]\n    fn test_invalid_var_len_construction() {\n        let error = MidiParseError::InvalidVarLen(256);\n        assert!(matches!(error, MidiParseError::InvalidVarLen(256)));\n    }\n\n    // ============================================================================\n    // Display Formatting Tests\n    // ============================================================================\n\n    #[test]\n    fn test_invalid_header_message_format() {\n        let error = MidiParseError::InvalidHeader(\"bad magic number\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Invalid MIDI header\"));\n        assert!(msg.contains(\"bad magic number\"));\n    }\n\n    #[test]\n    fn test_invalid_track_message_includes_position() {\n        let error = MidiParseError::InvalidTrack {\n            position: 42,\n            reason: \"unexpected end\".to_string(),\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"42\"));\n        assert!(msg.contains(\"unexpected end\"));\n        assert!(msg.contains(\"Invalid track data\"));\n    }\n\n    #[test]\n    fn test_unsupported_format_message() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        let msg = error.to_string();\n        assert!(msg.contains(\"Unsupported MIDI format\"));\n        assert!(msg.contains(\"99\"));\n    }\n\n    #[test]\n    fn test_invalid_event_message_includes_position() {\n        let error = MidiParseError::InvalidEvent {\n            position: 100,\n            reason: \"invalid status byte\".to_string(),\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"100\"));\n        assert!(msg.contains(\"invalid status byte\"));\n    }\n\n    #[test]\n    fn test_incomplete_data_shows_expected_vs_actual() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"100\"));\n        assert!(msg.contains(\"50\"));\n        assert!(msg.contains(\"Incomplete data\"));\n    }\n\n    #[test]\n    fn test_invalid_var_len_message() {\n        let error = MidiParseError::InvalidVarLen(256);\n        let msg = error.to_string();\n        assert!(msg.contains(\"256\"));\n        assert!(msg.contains(\"Invalid variable-length quantity\"));\n    }\n\n    #[test]\n    fn test_io_error_message() {\n        let io_error = io::Error::new(io::ErrorKind::NotFound, \"file not found\");\n        let error = MidiParseError::Io(io_error);\n        let msg = error.to_string();\n        assert!(msg.contains(\"IO error\"));\n        assert!(msg.contains(\"file not found\"));\n    }\n\n    #[test]\n    fn test_utf8_error_message() {\n        let invalid_utf8 = vec![0xFF, 0xFE, 0xFD];\n        let utf8_error = String::from_utf8(invalid_utf8).unwrap_err();\n        let error = MidiParseError::Utf8(utf8_error);\n        let msg = error.to_string();\n        assert!(msg.contains(\"UTF-8 decode error\"));\n    }\n\n    // ============================================================================\n    // Error Conversion Tests (From trait)\n    // ============================================================================\n\n    #[test]\n    fn test_io_error_conversion() {\n        let io_error = io::Error::new(io::ErrorKind::NotFound, \"test file\");\n        let midi_error: MidiParseError = io_error.into();\n\n        assert!(matches!(midi_error, MidiParseError::Io(_)));\n        assert!(midi_error.to_string().contains(\"test file\"));\n    }\n\n    #[test]\n    fn test_utf8_error_conversion() {\n        let invalid_utf8 = vec![0xFF, 0xFE, 0xFD];\n        let utf8_error = String::from_utf8(invalid_utf8).unwrap_err();\n        let midi_error: MidiParseError = utf8_error.into();\n\n        assert!(matches!(midi_error, MidiParseError::Utf8(_)));\n    }\n\n    // ============================================================================\n    // Debug Formatting Tests\n    // ============================================================================\n\n    #[test]\n    fn test_error_debug_format() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"UnsupportedFormat\"));\n        assert!(debug.contains(\"99\"));\n    }\n\n    #[test]\n    fn test_error_debug_includes_variant_name() {\n        let error = MidiParseError::InvalidHeader(\"test\".to_string());\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"InvalidHeader\"));\n    }\n\n    #[test]\n    fn test_error_debug_includes_data() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"100\"));\n        assert!(debug.contains(\"50\"));\n    }\n\n    // ============================================================================\n    // Result Type Alias Tests\n    // ============================================================================\n\n    #[test]\n    fn test_result_type_alias_ok() {\n        let result: Result\u003ci32\u003e = Ok(42);\n        assert_eq!(result.unwrap(), 42);\n    }\n\n    #[test]\n    fn test_result_type_alias_err() {\n        let result: Result\u003ci32\u003e = Err(MidiParseError::InvalidVarLen(0));\n        assert!(result.is_err());\n    }\n\n    // ============================================================================\n    // Edge Case Tests\n    // ============================================================================\n\n    #[test]\n    fn test_empty_error_messages() {\n        let error = MidiParseError::InvalidHeader(String::new());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Invalid MIDI header\"));\n    }\n\n    #[test]\n    fn test_very_long_error_message() {\n        let long_msg = \"x\".repeat(10000);\n        let error = MidiParseError::InvalidHeader(long_msg.clone());\n        let msg = error.to_string();\n        assert!(msg.contains(\u0026long_msg));\n        assert_eq!(msg.len(), \"Invalid MIDI header: \".len() + 10000);\n    }\n\n    #[test]\n    fn test_special_characters_in_error() {\n        let error = MidiParseError::InvalidHeader(\"Line 1\\nLine 2\\tTab\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Line 1\\nLine 2\\tTab\"));\n    }\n\n    #[test]\n    fn test_unicode_in_error_message() {\n        let error = MidiParseError::InvalidHeader(\"Invalid:  MIDI file\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"\"));\n    }\n\n    #[test]\n    fn test_position_boundaries() {\n        let error_min = MidiParseError::InvalidTrack {\n            position: 0,\n            reason: \"start of file\".to_string(),\n        };\n        let error_max = MidiParseError::InvalidTrack {\n            position: usize::MAX,\n            reason: \"end of file\".to_string(),\n        };\n\n        assert!(error_min.to_string().contains(\"0\"));\n        assert!(error_max.to_string().contains(\u0026usize::MAX.to_string()));\n    }\n\n    #[test]\n    fn test_all_format_variants() {\n        // Test format values 0-2 (valid) and beyond\n        for format in [0, 1, 2, 3, 99, u16::MAX] {\n            let error = MidiParseError::UnsupportedFormat(format);\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026format.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_expected_actual_boundaries() {\n        let cases = vec![\n            (0, 0),\n            (1, 0),\n            (100, 50),\n            (usize::MAX, 0),\n            (1000, 999),\n        ];\n\n        for (expected, actual) in cases {\n            let error = MidiParseError::IncompleteData { expected, actual };\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026expected.to_string()));\n            assert!(msg.contains(\u0026actual.to_string()));\n        }\n    }\n\n    // ============================================================================\n    // Security Tests\n    // ============================================================================\n\n    #[test]\n    fn test_error_message_no_memory_leak() {\n        // Create large error messages to ensure no memory leak\n        for _ in 0..1000 {\n            let error = MidiParseError::InvalidHeader(\"x\".repeat(1000));\n            let _ = error.to_string();\n        }\n        // If we get here, no memory leak (would OOM otherwise)\n    }\n\n    #[test]\n    fn test_malicious_position_values() {\n        // Test extreme position values don't cause issues\n        let positions = vec![0, 1, usize::MAX - 1, usize::MAX];\n\n        for pos in positions {\n            let error = MidiParseError::InvalidEvent {\n                position: pos,\n                reason: \"test\".to_string(),\n            };\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026pos.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_error_size_is_reasonable() {\n        // Ensure error type doesn't use excessive memory\n        use std::mem;\n        let size = mem::size_of::\u003cMidiParseError\u003e();\n\n        // thiserror errors should be reasonably sized (\u003c 200 bytes typical)\n        assert!(\n            size \u003c 256,\n            \"MidiParseError is too large: {} bytes\",\n            size\n        );\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","mod.rs"],"content":"//! MIDI file parsing and types\n//!\n//! This module provides:\n//! - MIDI file parsing\n//! - MIDI data types\n//! - Error handling\n\npub mod parser;\npub mod types;\npub mod error;\n\n// Re-export commonly used items\npub use parser::parse_midi_file;\npub use types::{MidiFile, Event, Track};\npub use error::{MidiParseError, Result};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","parser.rs"],"content":"use super::error::{MidiParseError, Result};\nuse super::types::*;\n\n/// Parse a MIDI file from raw bytes\n///\n/// This is the main entry point for MIDI parsing. It accepts raw file bytes\n/// and returns a structured MidiFile or an error.\n///\n/// # Examples\n/// ```ignore\n/// use midi_library_shared::core::midi::parse_midi_file;\n///\n/// let data = std::fs::read(\"song.mid\").unwrap();\n/// let midi_file = parse_midi_file(\u0026data)?;\n/// println!(\"Format: {}, Tracks: {}\", midi_file.header.format, midi_file.header.num_tracks);\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn parse_midi_file(data: \u0026[u8]) -\u003e Result\u003cMidiFile\u003e {\n    if data.len() \u003c 14 {\n        return Err(MidiParseError::IncompleteData {\n            expected: 14,\n            actual: data.len(),\n        });\n    }\n\n    // Parse header chunk\n    let header = parse_header(\u0026data[0..14])?;\n\n    // Parse tracks\n    let mut tracks = Vec::with_capacity(header.num_tracks as usize);\n    let mut pos = 14;\n\n    for track_num in 0..header.num_tracks {\n        let (track, bytes_read) = parse_track(\u0026data[pos..]).map_err(|e| match e {\n            MidiParseError::InvalidTrack { position, reason } =\u003e MidiParseError::InvalidTrack {\n                position: pos + position,\n                reason: format!(\"Track {}: {}\", track_num, reason),\n            },\n            e =\u003e e,\n        })?;\n\n        tracks.push(track);\n        pos += bytes_read;\n    }\n\n    Ok(MidiFile { header, tracks })\n}\n\n/// Parse MIDI header chunk (MThd)\nfn parse_header(data: \u0026[u8]) -\u003e Result\u003cHeader\u003e {\n    // Check magic number \"MThd\"\n    if \u0026data[0..4] != b\"MThd\" {\n        return Err(MidiParseError::InvalidHeader(format!(\n            \"Expected 'MThd', got {:?}\",\n            \u0026data[0..4]\n        )));\n    }\n\n    // Check header length (must be 6)\n    let length = u32::from_be_bytes([data[4], data[5], data[6], data[7]]);\n    if length != 6 {\n        return Err(MidiParseError::InvalidHeader(format!(\n            \"Expected header length 6, got {}\",\n            length\n        )));\n    }\n\n    let format = u16::from_be_bytes([data[8], data[9]]);\n    let num_tracks = u16::from_be_bytes([data[10], data[11]]);\n    let ticks_per_quarter_note = u16::from_be_bytes([data[12], data[13]]);\n\n    // Validate format\n    if format \u003e 2 {\n        return Err(MidiParseError::UnsupportedFormat(format));\n    }\n\n    Ok(Header {\n        format,\n        num_tracks,\n        ticks_per_quarter_note,\n    })\n}\n\n/// Parse a single MIDI track (MTrk)\n/// Returns (Track, bytes_consumed)\nfn parse_track(data: \u0026[u8]) -\u003e Result\u003c(Track, usize)\u003e {\n    if data.len() \u003c 8 {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: \"Track too short\".to_string(),\n        });\n    }\n\n    // Check magic number \"MTrk\"\n    if \u0026data[0..4] != b\"MTrk\" {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: format!(\"Expected 'MTrk', got {:?}\", \u0026data[0..4]),\n        });\n    }\n\n    let track_length = u32::from_be_bytes([data[4], data[5], data[6], data[7]]) as usize;\n\n    if data.len() \u003c 8 + track_length {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: format!(\n                \"Track data incomplete: expected {} bytes, got {}\",\n                track_length,\n                data.len() - 8\n            ),\n        });\n    }\n\n    let track_data = \u0026data[8..8 + track_length];\n    let events = parse_track_events(track_data)?;\n\n    Ok((Track { events }, 8 + track_length))\n}\n\n/// Parse all events within a track\nfn parse_track_events(data: \u0026[u8]) -\u003e Result\u003cVec\u003cTimedEvent\u003e\u003e {\n    let mut events = Vec::new();\n    let mut pos = 0;\n    let mut running_status: Option\u003cu8\u003e = None;\n\n    while pos \u003c data.len() {\n        // Parse delta time (variable-length quantity)\n        let (delta_ticks, delta_bytes) =\n            read_var_len(\u0026data[pos..]).ok_or(MidiParseError::InvalidVarLen(pos))?;\n        pos += delta_bytes;\n\n        // Parse event\n        let (event, event_bytes, new_running_status) = parse_event(\u0026data[pos..], running_status)\n            .map_err(|e| match e {\n                MidiParseError::InvalidEvent { position, reason } =\u003e MidiParseError::InvalidEvent {\n                    position: pos + position,\n                    reason,\n                },\n                e =\u003e e,\n            })?;\n\n        pos += event_bytes;\n        running_status = new_running_status;\n\n        events.push(TimedEvent { delta_ticks, event });\n\n        // End of track?\n        if matches!(\n            events.last(),\n            Some(TimedEvent {\n                event: Event::EndOfTrack,\n                ..\n            })\n        ) {\n            break;\n        }\n    }\n\n    Ok(events)\n}\n\n/// Parse a single MIDI event\n/// Returns (Event, bytes_consumed, new_running_status)\nfn parse_event(data: \u0026[u8], running_status: Option\u003cu8\u003e) -\u003e Result\u003c(Event, usize, Option\u003cu8\u003e)\u003e {\n    if data.is_empty() {\n        return Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: \"No data for event\".to_string(),\n        });\n    }\n\n    let mut status = data[0];\n    let mut pos = 1;\n\n    // Handle running status (reuse previous status byte if data byte encountered)\n    if status \u003c 0x80 {\n        if let Some(rs) = running_status {\n            status = rs;\n            pos = 0; // Don't consume the byte, it's data\n        } else {\n            return Err(MidiParseError::InvalidEvent {\n                position: 0,\n                reason: \"Data byte without running status\".to_string(),\n            });\n        }\n    }\n\n    let event_type = status \u0026 0xF0;\n    let channel = status \u0026 0x0F;\n\n    match event_type {\n        0x80 =\u003e {\n            // Note Off\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::NoteOff {\n                    channel,\n                    note: data[pos],\n                    velocity: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0x90 =\u003e {\n            // Note On\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::NoteOn {\n                    channel,\n                    note: data[pos],\n                    velocity: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xA0 =\u003e {\n            // Polyphonic Aftertouch\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::Aftertouch {\n                    channel,\n                    note: data[pos],\n                    pressure: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xB0 =\u003e {\n            // Control Change\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ControlChange {\n                    channel,\n                    controller: data[pos],\n                    value: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xC0 =\u003e {\n            // Program Change\n            if data.len() \u003c pos + 1 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 1,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ProgramChange {\n                    channel,\n                    program: data[pos],\n                },\n                pos + 1,\n                Some(status),\n            ))\n        }\n        0xD0 =\u003e {\n            // Channel Aftertouch\n            if data.len() \u003c pos + 1 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 1,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ChannelAftertouch {\n                    channel,\n                    pressure: data[pos],\n                },\n                pos + 1,\n                Some(status),\n            ))\n        }\n        0xE0 =\u003e {\n            // Pitch Bend\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            let lsb = data[pos] as i16;\n            let msb = data[pos + 1] as i16;\n            let value = ((msb \u003c\u003c 7) | lsb) - 8192; // Center at 0\n            Ok((Event::PitchBend { channel, value }, pos + 2, Some(status)))\n        }\n        0xF0 =\u003e {\n            // System/Meta events\n            parse_meta_or_sysex(\u0026data[pos - 1..])\n        }\n        _ =\u003e Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: format!(\"Unknown event type: 0x{:02X}\", status),\n        }),\n    }\n}\n\n/// Parse meta events and SysEx\nfn parse_meta_or_sysex(data: \u0026[u8]) -\u003e Result\u003c(Event, usize, Option\u003cu8\u003e)\u003e {\n    let status = data[0];\n\n    match status {\n        0xFF =\u003e {\n            // Meta event\n            if data.len() \u003c 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: 2,\n                    actual: data.len(),\n                });\n            }\n\n            let meta_type = data[1];\n            let (length, len_bytes) =\n                read_var_len(\u0026data[2..]).ok_or(MidiParseError::InvalidVarLen(2))?;\n\n            let data_start = 2 + len_bytes;\n            let data_end = data_start + length as usize;\n\n            if data.len() \u003c data_end {\n                return Err(MidiParseError::IncompleteData {\n                    expected: data_end,\n                    actual: data.len(),\n                });\n            }\n\n            let event_data = \u0026data[data_start..data_end];\n\n            let event = match meta_type {\n                0x2F =\u003e Event::EndOfTrack,\n                0x51 =\u003e {\n                    if event_data.len() != 3 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Tempo event must be 3 bytes\".to_string(),\n                        });\n                    }\n                    let microseconds_per_quarter =\n                        u32::from_be_bytes([0, event_data[0], event_data[1], event_data[2]]);\n                    Event::TempoChange {\n                        microseconds_per_quarter,\n                    }\n                }\n                0x58 =\u003e {\n                    if event_data.len() != 4 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Time signature event must be 4 bytes\".to_string(),\n                        });\n                    }\n                    Event::TimeSignature {\n                        numerator: event_data[0],\n                        denominator: event_data[1],\n                        clocks_per_click: event_data[2],\n                        thirty_seconds_per_quarter: event_data[3],\n                    }\n                }\n                0x59 =\u003e {\n                    if event_data.len() != 2 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Key signature event must be 2 bytes\".to_string(),\n                        });\n                    }\n                    Event::KeySignature {\n                        sharps_flats: event_data[0] as i8,\n                        is_minor: event_data[1] != 0,\n                    }\n                }\n                0x01..=0x0F =\u003e {\n                    // Text events\n                    let text = String::from_utf8(event_data.to_vec())?;\n                    let text_type = match meta_type {\n                        0x01 =\u003e TextType::Text,\n                        0x02 =\u003e TextType::Copyright,\n                        0x03 =\u003e TextType::TrackName,\n                        0x04 =\u003e TextType::InstrumentName,\n                        0x05 =\u003e TextType::Lyric,\n                        0x06 =\u003e TextType::Marker,\n                        0x07 =\u003e TextType::CuePoint,\n                        _ =\u003e TextType::Text,\n                    };\n                    Event::Text { text_type, text }\n                }\n                _ =\u003e Event::Unknown {\n                    status,\n                    data: event_data.to_vec(),\n                },\n            };\n\n            Ok((event, data_end, None)) // Meta events don't have running status\n        }\n        0xF0 | 0xF7 =\u003e {\n            // SysEx\n            let (length, len_bytes) =\n                read_var_len(\u0026data[1..]).ok_or(MidiParseError::InvalidVarLen(1))?;\n\n            let data_start = 1 + len_bytes;\n            let data_end = data_start + length as usize;\n\n            if data.len() \u003c data_end {\n                return Err(MidiParseError::IncompleteData {\n                    expected: data_end,\n                    actual: data.len(),\n                });\n            }\n\n            Ok((\n                Event::SysEx {\n                    data: data[data_start..data_end].to_vec(),\n                },\n                data_end,\n                None, // SysEx doesn't have running status\n            ))\n        }\n        _ =\u003e Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: format!(\"Unknown system event: 0x{:02X}\", status),\n        }),\n    }\n}\n\n/// Read a MIDI variable-length quantity\n/// Returns (value, bytes_consumed) or None if invalid\nfn read_var_len(data: \u0026[u8]) -\u003e Option\u003c(u32, usize)\u003e {\n    let mut value = 0u32;\n    let mut bytes_read = 0;\n\n    for (i, \u0026byte) in data.iter().enumerate() {\n        if i \u003e= 4 {\n            // Variable length can be at most 4 bytes\n            return None;\n        }\n\n        value = (value \u003c\u003c 7) | (byte \u0026 0x7F) as u32;\n        bytes_read += 1;\n\n        // If high bit is clear, we're done\n        if byte \u0026 0x80 == 0 {\n            return Some((value, bytes_read));\n        }\n    }\n\n    None // Ran out of data before finding end\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_read_var_len() {\n        // Single byte\n        assert_eq!(read_var_len(\u0026[0x00]), Some((0, 1)));\n        assert_eq!(read_var_len(\u0026[0x7F]), Some((127, 1)));\n\n        // Two bytes\n        assert_eq!(read_var_len(\u0026[0x81, 0x00]), Some((128, 2)));\n        assert_eq!(read_var_len(\u0026[0xFF, 0x7F]), Some((16383, 2)));\n\n        // Invalid (no terminating byte)\n        assert_eq!(read_var_len(\u0026[0x81, 0x82, 0x83, 0x84]), None);\n    }\n\n    #[test]\n    fn test_parse_header() {\n        let data = [\n            b'M', b'T', b'h', b'd', // Magic\n            0, 0, 0, 6, // Length\n            0, 1, // Format 1\n            0, 3, // 3 tracks\n            0, 96, // 96 ticks per quarter note\n        ];\n\n        let header = parse_header(\u0026data).unwrap();\n        assert_eq!(header.format, 1);\n        assert_eq!(header.num_tracks, 3);\n        assert_eq!(header.ticks_per_quarter_note, 96);\n    }\n\n    #[test]\n    fn test_parse_invalid_header_magic() {\n        let data = [\n            b'M', b'T', b'h', b'X', // Wrong magic\n            0, 0, 0, 6, 0, 1, 0, 3, 0, 96,\n        ];\n\n        assert!(parse_header(\u0026data).is_err());\n    }\n\n    #[test]\n    fn test_parse_note_on() {\n        // Delta time: 0, Note On channel 0, note 60, velocity 100\n        let data = [0x00, 0x90, 0x3C, 0x64, 0x00, 0xFF, 0x2F, 0x00]; // Add End of Track\n\n        let events = parse_track_events(\u0026data).unwrap();\n        assert_eq!(events.len(), 2); // NoteOn + EndOfTrack\n        assert_eq!(events[0].delta_ticks, 0);\n\n        match \u0026events[0].event {\n            Event::NoteOn {\n                channel,\n                note,\n                velocity,\n            } =\u003e {\n                assert_eq!(*channel, 0);\n                assert_eq!(*note, 60);\n                assert_eq!(*velocity, 100);\n            }\n            _ =\u003e panic!(\"Expected NoteOn event\"),\n        }\n    }\n\n    #[test]\n    fn test_parse_minimal_file() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 4, 0x00, 0xFF, 0x2F, 0x00, // End of track\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        assert_eq!(midi.header.format, 0);\n        assert_eq!(midi.header.num_tracks, 1);\n        assert_eq!(midi.tracks.len(), 1);\n    }\n\n    #[test]\n    fn test_total_notes() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 12, // Note On\n            0x00, 0x90, 0x3C, 0x64, // Note On\n            0x00, 0x90, 0x40, 0x64, // End of track\n            0x00, 0xFF, 0x2F, 0x00,\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        assert_eq!(midi.total_notes(), 2);\n    }\n\n    #[test]\n    fn test_channels_used() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 16, // Note On channel 0\n            0x00, 0x90, 0x3C, 0x64, // Note On channel 1\n            0x00, 0x91, 0x40, 0x64, // Note On channel 9 (drums)\n            0x00, 0x99, 0x24, 0x64, // End of track\n            0x00, 0xFF, 0x2F, 0x00,\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        let channels = midi.channels_used();\n        assert_eq!(channels, vec![0, 1, 9]);\n    }\n}\n","traces":[{"line":18,"address":[634727,633632],"length":1,"stats":{"Line":0}},{"line":19,"address":[633655],"length":1,"stats":{"Line":0}},{"line":20,"address":[633671],"length":1,"stats":{"Line":0}},{"line":27,"address":[633788,633716,634423],"length":1,"stats":{"Line":0}},{"line":31,"address":[633900],"length":1,"stats":{"Line":0}},{"line":33,"address":[633919,633936,634353],"length":1,"stats":{"Line":0}},{"line":34,"address":[633945,634209,634154,633965],"length":1,"stats":{"Line":0}},{"line":35,"address":[707559,707710],"length":1,"stats":{"Line":0}},{"line":36,"address":[707892,707580],"length":1,"stats":{"Line":0}},{"line":37,"address":[707589],"length":1,"stats":{"Line":0}},{"line":39,"address":[707798],"length":1,"stats":{"Line":0}},{"line":43,"address":[634663,634318],"length":1,"stats":{"Line":0}},{"line":46,"address":[634359],"length":1,"stats":{"Line":0}},{"line":50,"address":[634736],"length":1,"stats":{"Line":0}},{"line":52,"address":[634760],"length":1,"stats":{"Line":0}},{"line":55,"address":[634962],"length":1,"stats":{"Line":0}},{"line":60,"address":[635212,634766,634848],"length":1,"stats":{"Line":0}},{"line":61,"address":[634852,634840],"length":1,"stats":{"Line":0}},{"line":68,"address":[634858,635305],"length":1,"stats":{"Line":0}},{"line":69,"address":[634878,635351],"length":1,"stats":{"Line":0}},{"line":70,"address":[634898,635152,635397],"length":1,"stats":{"Line":0}},{"line":73,"address":[634926],"length":1,"stats":{"Line":0}},{"line":74,"address":[634946],"length":1,"stats":{"Line":0}},{"line":77,"address":[635160],"length":1,"stats":{"Line":0}},{"line":86,"address":[635456],"length":1,"stats":{"Line":0}},{"line":87,"address":[635468],"length":1,"stats":{"Line":0}},{"line":88,"address":[635629],"length":1,"stats":{"Line":0}},{"line":95,"address":[635653],"length":1,"stats":{"Line":0}},{"line":98,"address":[635772],"length":1,"stats":{"Line":0}},{"line":102,"address":[635655,635660],"length":1,"stats":{"Line":0}},{"line":104,"address":[635665],"length":1,"stats":{"Line":0}},{"line":105,"address":[635770],"length":1,"stats":{"Line":0}},{"line":110,"address":[635678],"length":1,"stats":{"Line":0}},{"line":116,"address":[635941,635903],"length":1,"stats":{"Line":0}},{"line":118,"address":[635958],"length":1,"stats":{"Line":0}},{"line":122,"address":[637544,636080],"length":1,"stats":{"Line":0}},{"line":127,"address":[636147,636200],"length":1,"stats":{"Line":0}},{"line":129,"address":[637168,636496,636561,636407],"length":1,"stats":{"Line":0}},{"line":131,"address":[636570,637406],"length":1,"stats":{"Line":0}},{"line":134,"address":[636611,636876],"length":1,"stats":{"Line":0}},{"line":135,"address":[650245,650397],"length":1,"stats":{"Line":0}},{"line":136,"address":[650250,650295],"length":1,"stats":{"Line":0}},{"line":137,"address":[708112,708180],"length":1,"stats":{"Line":0}},{"line":138,"address":[650280],"length":1,"stats":{"Line":0}},{"line":140,"address":[650328],"length":1,"stats":{"Line":0}},{"line":143,"address":[636921,637421],"length":1,"stats":{"Line":0}},{"line":146,"address":[636934],"length":1,"stats":{"Line":0}},{"line":149,"address":[637106],"length":1,"stats":{"Line":0}},{"line":150,"address":[637097],"length":1,"stats":{"Line":0}},{"line":160,"address":[637131],"length":1,"stats":{"Line":0}},{"line":165,"address":[637552],"length":1,"stats":{"Line":0}},{"line":166,"address":[637569],"length":1,"stats":{"Line":0}},{"line":167,"address":[637733],"length":1,"stats":{"Line":0}},{"line":173,"address":[637571],"length":1,"stats":{"Line":0}},{"line":177,"address":[638121,637580],"length":1,"stats":{"Line":0}},{"line":178,"address":[637589,637604],"length":1,"stats":{"Line":0}},{"line":179,"address":[637597],"length":1,"stats":{"Line":0}},{"line":182,"address":[637996],"length":1,"stats":{"Line":0}},{"line":189,"address":[637773],"length":1,"stats":{"Line":0}},{"line":192,"address":[637778],"length":1,"stats":{"Line":0}},{"line":195,"address":[637821],"length":1,"stats":{"Line":0}},{"line":201,"address":[637851],"length":1,"stats":{"Line":0}},{"line":204,"address":[637847],"length":1,"stats":{"Line":0}},{"line":205,"address":[637834,638651],"length":1,"stats":{"Line":0}},{"line":213,"address":[638164],"length":1,"stats":{"Line":0}},{"line":219,"address":[638190],"length":1,"stats":{"Line":0}},{"line":222,"address":[638186],"length":1,"stats":{"Line":0}},{"line":223,"address":[638173,638678],"length":1,"stats":{"Line":0}},{"line":231,"address":[638051],"length":1,"stats":{"Line":0}},{"line":237,"address":[638081],"length":1,"stats":{"Line":0}},{"line":240,"address":[638077],"length":1,"stats":{"Line":0}},{"line":241,"address":[638064,638660],"length":1,"stats":{"Line":0}},{"line":249,"address":[638086],"length":1,"stats":{"Line":0}},{"line":255,"address":[638116],"length":1,"stats":{"Line":0}},{"line":258,"address":[638112],"length":1,"stats":{"Line":0}},{"line":259,"address":[638669,638099],"length":1,"stats":{"Line":0}},{"line":267,"address":[638040,638027],"length":1,"stats":{"Line":0}},{"line":273,"address":[638043],"length":1,"stats":{"Line":0}},{"line":276,"address":[638036],"length":1,"stats":{"Line":0}},{"line":284,"address":[638206,638215],"length":1,"stats":{"Line":0}},{"line":290,"address":[638218],"length":1,"stats":{"Line":0}},{"line":293,"address":[638211],"length":1,"stats":{"Line":0}},{"line":301,"address":[638271],"length":1,"stats":{"Line":0}},{"line":307,"address":[638486],"length":1,"stats":{"Line":0}},{"line":308,"address":[638490,638473,638687],"length":1,"stats":{"Line":0}},{"line":309,"address":[638495],"length":1,"stats":{"Line":0}},{"line":310,"address":[638506],"length":1,"stats":{"Line":0}},{"line":314,"address":[638638,638124,638148],"length":1,"stats":{"Line":0}},{"line":316,"address":[638444],"length":1,"stats":{"Line":0}},{"line":324,"address":[638720],"length":1,"stats":{"Line":0}},{"line":325,"address":[640488,638737],"length":1,"stats":{"Line":0}},{"line":327,"address":[638767],"length":1,"stats":{"Line":0}},{"line":330,"address":[638787],"length":1,"stats":{"Line":0}},{"line":331,"address":[638807],"length":1,"stats":{"Line":0}},{"line":337,"address":[639347],"length":1,"stats":{"Line":0}},{"line":338,"address":[639753,639802,639518],"length":1,"stats":{"Line":0}},{"line":341,"address":[639763,640531],"length":1,"stats":{"Line":0}},{"line":342,"address":[639773,640544],"length":1,"stats":{"Line":0}},{"line":344,"address":[639785],"length":1,"stats":{"Line":0}},{"line":345,"address":[639790],"length":1,"stats":{"Line":0}},{"line":353,"address":[639931,639853],"length":1,"stats":{"Line":0}},{"line":356,"address":[639875],"length":1,"stats":{"Line":0}},{"line":357,"address":[640217],"length":1,"stats":{"Line":0}},{"line":359,"address":[640221],"length":1,"stats":{"Line":0}},{"line":362,"address":[639885],"length":1,"stats":{"Line":0}},{"line":369,"address":[640110],"length":1,"stats":{"Line":0}},{"line":370,"address":[640253],"length":1,"stats":{"Line":0}},{"line":372,"address":[640257],"length":1,"stats":{"Line":0}},{"line":376,"address":[640120],"length":1,"stats":{"Line":0}},{"line":377,"address":[640124],"length":1,"stats":{"Line":0}},{"line":378,"address":[640129],"length":1,"stats":{"Line":0}},{"line":379,"address":[640134],"length":1,"stats":{"Line":0}},{"line":383,"address":[639947],"length":1,"stats":{"Line":0}},{"line":384,"address":[640235],"length":1,"stats":{"Line":0}},{"line":386,"address":[640239],"length":1,"stats":{"Line":0}},{"line":390,"address":[639957],"length":1,"stats":{"Line":0}},{"line":391,"address":[639961],"length":1,"stats":{"Line":0}},{"line":394,"address":[639977],"length":1,"stats":{"Line":0}},{"line":396,"address":[640299,639994,640043],"length":1,"stats":{"Line":0}},{"line":397,"address":[640082],"length":1,"stats":{"Line":0}},{"line":411,"address":[640151],"length":1,"stats":{"Line":0}},{"line":415,"address":[640166,639914],"length":1,"stats":{"Line":0}},{"line":419,"address":[639239,639296,639007],"length":1,"stats":{"Line":0}},{"line":422,"address":[639249,640505],"length":1,"stats":{"Line":0}},{"line":423,"address":[640518,639258],"length":1,"stats":{"Line":0}},{"line":425,"address":[639270],"length":1,"stats":{"Line":0}},{"line":426,"address":[639279],"length":1,"stats":{"Line":0}},{"line":432,"address":[639703],"length":1,"stats":{"Line":0}},{"line":434,"address":[639649],"length":1,"stats":{"Line":0}},{"line":440,"address":[639200],"length":1,"stats":{"Line":0}},{"line":449,"address":[640560],"length":1,"stats":{"Line":0}},{"line":453,"address":[662163,662141,661971,661779,661757,661949],"length":1,"stats":{"Line":0}},{"line":454,"address":[640664,636328,636295,639416,638936,638904,639447,640627],"length":1,"stats":{"Line":0}},{"line":459,"address":[639471,636352,638960,640684],"length":1,"stats":{"Line":0}},{"line":460,"address":[636333,640669,640728,638941,640462,639452],"length":1,"stats":{"Line":0}},{"line":463,"address":[638973,639484,640698,636365],"length":1,"stats":{"Line":0}},{"line":464,"address":[636370,638978,640703,639489],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":137},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","types.rs"],"content":"use serde::{Deserialize, Serialize};\n\n/// Represents a complete MIDI file\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiFile {\n    pub header: Header,\n    pub tracks: Vec\u003cTrack\u003e,\n}\n\n/// MIDI header chunk\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Header {\n    pub format: u16, // 0, 1, or 2\n    pub num_tracks: u16,\n    pub ticks_per_quarter_note: u16,\n}\n\n/// A single MIDI track\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Track {\n    pub events: Vec\u003cTimedEvent\u003e,\n}\n\n/// Event with delta time\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TimedEvent {\n    pub delta_ticks: u32,\n    pub event: Event,\n}\n\n/// MIDI events\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum Event {\n    // Channel events\n    NoteOn {\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    },\n    NoteOff {\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    },\n    Aftertouch {\n        channel: u8,\n        note: u8,\n        pressure: u8,\n    },\n    ControlChange {\n        channel: u8,\n        controller: u8,\n        value: u8,\n    },\n    ProgramChange {\n        channel: u8,\n        program: u8,\n    },\n    ChannelAftertouch {\n        channel: u8,\n        pressure: u8,\n    },\n    PitchBend {\n        channel: u8,\n        value: i16,\n    },\n\n    // Meta events\n    TempoChange {\n        microseconds_per_quarter: u32,\n    },\n    TimeSignature {\n        numerator: u8,\n        denominator: u8,\n        clocks_per_click: u8,\n        thirty_seconds_per_quarter: u8,\n    },\n    KeySignature {\n        sharps_flats: i8,\n        is_minor: bool,\n    },\n    Text {\n        text_type: TextType,\n        text: String,\n    },\n    EndOfTrack,\n\n    // SysEx\n    SysEx {\n        data: Vec\u003cu8\u003e,\n    },\n\n    // Unknown/unsupported\n    Unknown {\n        status: u8,\n        data: Vec\u003cu8\u003e,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum TextType {\n    Text,\n    Copyright,\n    TrackName,\n    InstrumentName,\n    Lyric,\n    Marker,\n    CuePoint,\n}\n\nimpl MidiFile {\n    /// Calculate total duration in seconds\n    pub fn duration_seconds(\u0026self, _default_tempo_bpm: f64) -\u003e f64 {\n        let mut total_ticks = 0u64;\n        let mut current_tempo_us_per_qn = 500_000u32; // Default: 120 BPM\n\n        for track in \u0026self.tracks {\n            let mut track_ticks = 0u64;\n\n            for timed_event in \u0026track.events {\n                track_ticks += timed_event.delta_ticks as u64;\n\n                // Update tempo if we encounter a tempo change\n                if let Event::TempoChange {\n                    microseconds_per_quarter,\n                } = timed_event.event\n                {\n                    current_tempo_us_per_qn = microseconds_per_quarter;\n                }\n            }\n\n            total_ticks = total_ticks.max(track_ticks);\n        }\n\n        // Convert ticks to seconds\n        let seconds_per_tick = (current_tempo_us_per_qn as f64 / 1_000_000.0)\n            / self.header.ticks_per_quarter_note as f64;\n        total_ticks as f64 * seconds_per_tick\n    }\n\n    /// Count total notes across all tracks\n    pub fn total_notes(\u0026self) -\u003e usize {\n        self.tracks\n            .iter()\n            .flat_map(|track| \u0026track.events)\n            .filter(|event| matches!(event.event, Event::NoteOn { velocity, .. } if velocity \u003e 0))\n            .count()\n    }\n\n    /// Get all unique MIDI channels used\n    pub fn channels_used(\u0026self) -\u003e Vec\u003cu8\u003e {\n        let mut channels = std::collections::HashSet::new();\n\n        for track in \u0026self.tracks {\n            for timed_event in \u0026track.events {\n                if let Some(channel) = timed_event.event.channel() {\n                    channels.insert(channel);\n                }\n            }\n        }\n\n        let mut result: Vec\u003cu8\u003e = channels.into_iter().collect();\n        result.sort();\n        result\n    }\n}\n\nimpl Event {\n    /// Get the MIDI channel for channel events, None for meta/sysex\n    pub fn channel(\u0026self) -\u003e Option\u003cu8\u003e {\n        match self {\n            Event::NoteOn { channel, .. }\n            | Event::NoteOff { channel, .. }\n            | Event::Aftertouch { channel, .. }\n            | Event::ControlChange { channel, .. }\n            | Event::ProgramChange { channel, .. }\n            | Event::ChannelAftertouch { channel, .. }\n            | Event::PitchBend { channel, .. } =\u003e Some(*channel),\n            _ =\u003e None,\n        }\n    }\n\n    /// Check if this is a note event\n    pub fn is_note(\u0026self) -\u003e bool {\n        matches!(self, Event::NoteOn { .. } | Event::NoteOff { .. })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    /// Helper function to create a basic MIDI file for testing\n    fn create_basic_midi() -\u003e MidiFile {\n        MidiFile {\n            header: Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![Track { events: vec![] }],\n        }\n    }\n\n    /// Helper function to create a MIDI file with notes\n    fn create_midi_with_notes() -\u003e MidiFile {\n        MidiFile {\n            header: Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![Track {\n                events: vec![\n                    TimedEvent {\n                        delta_ticks: 0,\n                        event: Event::NoteOn {\n                            channel: 0,\n                            note: 60,\n                            velocity: 100,\n                        },\n                    },\n                    TimedEvent {\n                        delta_ticks: 480,\n                        event: Event::NoteOff {\n                            channel: 0,\n                            note: 60,\n                            velocity: 0,\n                        },\n                    },\n                    TimedEvent {\n                        delta_ticks: 0,\n                        event: Event::NoteOn {\n                            channel: 1,\n                            note: 64,\n                            velocity: 80,\n                        },\n                    },\n                ],\n            }],\n        }\n    }\n\n    mod midi_file_tests {\n        use super::*;\n\n        #[test]\n        fn test_duration_seconds_empty_file() {\n            let midi = create_basic_midi();\n            let duration = midi.duration_seconds(120.0);\n\n            // Empty file should have 0 duration\n            assert_eq!(duration, 0.0);\n        }\n\n        #[test]\n        fn test_duration_seconds_with_default_tempo() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 1920, // 4 quarters = 1 bar at 480 tpq\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // At 120 BPM (500,000 s/quarter), 1920 ticks = 4 quarters = 2 seconds\n            // seconds_per_tick = 500_000 / 1_000_000 / 480 = 0.00104166...\n            // duration = 1920 * 0.00104166...  2.0 seconds\n            assert!(\n                (duration - 2.0).abs() \u003c 0.01,\n                \"Duration should be ~2.0 seconds, got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_duration_seconds_with_tempo_change() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 600_000, // 100 BPM\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 1920, // 4 quarters at 100 BPM\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // At 100 BPM (600,000 s/quarter), 1920 ticks = 4 quarters = 2.4 seconds\n            // seconds_per_tick = 600_000 / 1_000_000 / 480 = 0.00125\n            // duration = 1920 * 0.00125 = 2.4 seconds\n            assert!(\n                (duration - 2.4).abs() \u003c 0.01,\n                \"Duration should be ~2.4 seconds, got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_duration_seconds_multiple_tracks() {\n            // Duration should be the length of the longest track\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 960, // Short track\n                            event: Event::EndOfTrack,\n                        }],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 1920, // Longer track\n                            event: Event::EndOfTrack,\n                        }],\n                    },\n                ],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // Should use longest track (1920 ticks)\n            assert!(\n                (duration - 2.0).abs() \u003c 0.01,\n                \"Duration should be ~2.0 seconds (longest track), got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_total_notes_empty_file() {\n            let midi = create_basic_midi();\n            assert_eq!(midi.total_notes(), 0);\n        }\n\n        #[test]\n        fn test_total_notes_with_notes() {\n            let midi = create_midi_with_notes();\n\n            // Should count 2 NoteOn events (velocity \u003e 0)\n            assert_eq!(midi.total_notes(), 2);\n        }\n\n        #[test]\n        fn test_total_notes_excludes_zero_velocity() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0, // Zero velocity = note off\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 64,\n                                velocity: 100, // Real note on\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should only count note with velocity \u003e 0\n            assert_eq!(midi.total_notes(), 1);\n        }\n\n        #[test]\n        fn test_total_notes_excludes_note_off() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 480,\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 64,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should only count NoteOn events\n            assert_eq!(midi.total_notes(), 1);\n        }\n\n        #[test]\n        fn test_total_notes_multiple_tracks() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![\n                            TimedEvent {\n                                delta_ticks: 0,\n                                event: Event::NoteOn {\n                                    channel: 0,\n                                    note: 60,\n                                    velocity: 100,\n                                },\n                            },\n                            TimedEvent {\n                                delta_ticks: 0,\n                                event: Event::NoteOn {\n                                    channel: 0,\n                                    note: 64,\n                                    velocity: 80,\n                                },\n                            },\n                        ],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1,\n                                note: 67,\n                                velocity: 90,\n                            },\n                        }],\n                    },\n                ],\n            };\n\n            // Should count notes across all tracks\n            assert_eq!(midi.total_notes(), 3);\n        }\n\n        #[test]\n        fn test_channels_used_empty_file() {\n            let midi = create_basic_midi();\n            assert_eq!(midi.channels_used(), Vec::\u003cu8\u003e::new());\n        }\n\n        #[test]\n        fn test_channels_used_single_channel() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 5,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 480,\n                            event: Event::NoteOff {\n                                channel: 5,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            assert_eq!(midi.channels_used(), vec![5]);\n        }\n\n        #[test]\n        fn test_channels_used_multiple_channels() {\n            let midi = create_midi_with_notes();\n\n            // Should return sorted unique channels\n            assert_eq!(midi.channels_used(), vec![0, 1]);\n        }\n\n        #[test]\n        fn test_channels_used_all_16_channels() {\n            let mut events = Vec::new();\n\n            // Add events on all 16 MIDI channels (0-15)\n            for channel in 0..16 {\n                events.push(TimedEvent {\n                    delta_ticks: 0,\n                    event: Event::NoteOn {\n                        channel,\n                        note: 60,\n                        velocity: 100,\n                    },\n                });\n            }\n\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track { events }],\n            };\n\n            assert_eq!(midi.channels_used(), (0..16).collect::\u003cVec\u003cu8\u003e\u003e());\n        }\n\n        #[test]\n        fn test_channels_used_excludes_meta_events() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 500_000,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::EndOfTrack,\n                        },\n                    ],\n                }],\n            };\n\n            // Should only include channel from NoteOn\n            assert_eq!(midi.channels_used(), vec![0]);\n        }\n\n        #[test]\n        fn test_channels_used_deduplicates() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 3,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1,\n                                note: 64,\n                                velocity: 80,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 3, // Duplicate\n                                note: 67,\n                                velocity: 90,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1, // Duplicate\n                                note: 70,\n                                velocity: 85,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should return sorted unique channels\n            assert_eq!(midi.channels_used(), vec![1, 3]);\n        }\n    }\n\n    mod event_tests {\n        use super::*;\n\n        #[test]\n        fn test_channel_note_on() {\n            let event = Event::NoteOn {\n                channel: 5,\n                note: 60,\n                velocity: 100,\n            };\n            assert_eq!(event.channel(), Some(5));\n        }\n\n        #[test]\n        fn test_channel_note_off() {\n            let event = Event::NoteOff {\n                channel: 3,\n                note: 60,\n                velocity: 0,\n            };\n            assert_eq!(event.channel(), Some(3));\n        }\n\n        #[test]\n        fn test_channel_aftertouch() {\n            let event = Event::Aftertouch {\n                channel: 7,\n                note: 60,\n                pressure: 50,\n            };\n            assert_eq!(event.channel(), Some(7));\n        }\n\n        #[test]\n        fn test_channel_control_change() {\n            let event = Event::ControlChange {\n                channel: 10,\n                controller: 7,\n                value: 100,\n            };\n            assert_eq!(event.channel(), Some(10));\n        }\n\n        #[test]\n        fn test_channel_program_change() {\n            let event = Event::ProgramChange {\n                channel: 15,\n                program: 0,\n            };\n            assert_eq!(event.channel(), Some(15));\n        }\n\n        #[test]\n        fn test_channel_channel_aftertouch() {\n            let event = Event::ChannelAftertouch {\n                channel: 2,\n                pressure: 64,\n            };\n            assert_eq!(event.channel(), Some(2));\n        }\n\n        #[test]\n        fn test_channel_pitch_bend() {\n            let event = Event::PitchBend {\n                channel: 8,\n                value: 0,\n            };\n            assert_eq!(event.channel(), Some(8));\n        }\n\n        #[test]\n        fn test_channel_tempo_change_returns_none() {\n            let event = Event::TempoChange {\n                microseconds_per_quarter: 500_000,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_time_signature_returns_none() {\n            let event = Event::TimeSignature {\n                numerator: 4,\n                denominator: 4,\n                clocks_per_click: 24,\n                thirty_seconds_per_quarter: 8,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_key_signature_returns_none() {\n            let event = Event::KeySignature {\n                sharps_flats: 0,\n                is_minor: false,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_text_returns_none() {\n            let event = Event::Text {\n                text_type: TextType::TrackName,\n                text: \"Piano\".to_string(),\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_end_of_track_returns_none() {\n            let event = Event::EndOfTrack;\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_sysex_returns_none() {\n            let event = Event::SysEx {\n                data: vec![0xF0, 0x7E, 0x7F, 0xF7],\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_unknown_returns_none() {\n            let event = Event::Unknown {\n                status: 0xFF,\n                data: vec![0x01, 0x02],\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_is_note_for_note_on() {\n            let event = Event::NoteOn {\n                channel: 0,\n                note: 60,\n                velocity: 100,\n            };\n            assert!(event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_note_off() {\n            let event = Event::NoteOff {\n                channel: 0,\n                note: 60,\n                velocity: 0,\n            };\n            assert!(event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_control_change() {\n            let event = Event::ControlChange {\n                channel: 0,\n                controller: 7,\n                value: 100,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_program_change() {\n            let event = Event::ProgramChange {\n                channel: 0,\n                program: 5,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_tempo_change() {\n            let event = Event::TempoChange {\n                microseconds_per_quarter: 500_000,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_aftertouch() {\n            let event = Event::Aftertouch {\n                channel: 0,\n                note: 60,\n                pressure: 50,\n            };\n            assert!(!event.is_note());\n        }\n    }\n\n    mod serialization_tests {\n        use super::*;\n\n        #[test]\n        fn test_serialize_deserialize_midi_file() {\n            let original = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        }],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 500_000,\n                            },\n                        }],\n                    },\n                ],\n            };\n\n            let json = serde_json::to_string(\u0026original).expect(\"Failed to serialize\");\n            let deserialized: MidiFile =\n                serde_json::from_str(\u0026json).expect(\"Failed to deserialize\");\n\n            // Verify structure\n            assert_eq!(deserialized.header.format, 1);\n            assert_eq!(deserialized.header.num_tracks, 2);\n            assert_eq!(deserialized.header.ticks_per_quarter_note, 480);\n            assert_eq!(deserialized.tracks.len(), 2);\n            assert_eq!(deserialized.tracks[0].events.len(), 1);\n            assert_eq!(deserialized.tracks[1].events.len(), 1);\n        }\n\n        #[test]\n        fn test_serialize_deserialize_all_event_types() {\n            let events = vec![\n                Event::NoteOn {\n                    channel: 0,\n                    note: 60,\n                    velocity: 100,\n                },\n                Event::NoteOff {\n                    channel: 0,\n                    note: 60,\n                    velocity: 64,\n                },\n                Event::Aftertouch {\n                    channel: 0,\n                    note: 60,\n                    pressure: 50,\n                },\n                Event::ControlChange {\n                    channel: 0,\n                    controller: 7,\n                    value: 100,\n                },\n                Event::ProgramChange {\n                    channel: 0,\n                    program: 5,\n                },\n                Event::ChannelAftertouch {\n                    channel: 0,\n                    pressure: 64,\n                },\n                Event::PitchBend {\n                    channel: 0,\n                    value: 8192,\n                },\n                Event::TempoChange {\n                    microseconds_per_quarter: 500_000,\n                },\n                Event::TimeSignature {\n                    numerator: 4,\n                    denominator: 4,\n                    clocks_per_click: 24,\n                    thirty_seconds_per_quarter: 8,\n                },\n                Event::KeySignature {\n                    sharps_flats: -2,\n                    is_minor: true,\n                },\n                Event::Text {\n                    text_type: TextType::TrackName,\n                    text: \"Piano\".to_string(),\n                },\n                Event::EndOfTrack,\n                Event::SysEx {\n                    data: vec![0xF0, 0x7E, 0x7F, 0xF7],\n                },\n                Event::Unknown {\n                    status: 0xFF,\n                    data: vec![0x01, 0x02],\n                },\n            ];\n\n            for original_event in events {\n                let json =\n                    serde_json::to_string(\u0026original_event).expect(\"Failed to serialize event\");\n                let _deserialized: Event =\n                    serde_json::from_str(\u0026json).expect(\"Failed to deserialize event\");\n                // If we get here, serialization round-trip succeeded\n            }\n        }\n\n        #[test]\n        fn test_serialize_text_types() {\n            let text_types = vec![\n                TextType::Text,\n                TextType::Copyright,\n                TextType::TrackName,\n                TextType::InstrumentName,\n                TextType::Lyric,\n                TextType::Marker,\n                TextType::CuePoint,\n            ];\n\n            for original_type in text_types {\n                let json =\n                    serde_json::to_string(\u0026original_type).expect(\"Failed to serialize TextType\");\n                let _deserialized: TextType =\n                    serde_json::from_str(\u0026json).expect(\"Failed to deserialize TextType\");\n                // If we get here, serialization round-trip succeeded\n            }\n        }\n    }\n\n    mod edge_case_tests {\n        use super::*;\n\n        #[test]\n        fn test_header_format_0() {\n            let header = Header {\n                format: 0,\n                num_tracks: 1,\n                ticks_per_quarter_note: 96,\n            };\n            assert_eq!(header.format, 0);\n        }\n\n        #[test]\n        fn test_header_format_2() {\n            let header = Header {\n                format: 2,\n                num_tracks: 5,\n                ticks_per_quarter_note: 960,\n            };\n            assert_eq!(header.format, 2);\n        }\n\n        #[test]\n        fn test_high_ticks_per_quarter() {\n            let header = Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 960, // High resolution\n            };\n            assert_eq!(header.ticks_per_quarter_note, 960);\n        }\n\n        #[test]\n        fn test_low_ticks_per_quarter() {\n            let header = Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 96, // Low resolution\n            };\n            assert_eq!(header.ticks_per_quarter_note, 96);\n        }\n\n        #[test]\n        fn test_pitch_bend_positive() {\n            let event = Event::PitchBend {\n                channel: 0,\n                value: 8192, // Center position\n            };\n            if let Event::PitchBend { value, .. } = event {\n                assert_eq!(value, 8192);\n            }\n        }\n\n        #[test]\n        fn test_pitch_bend_negative() {\n            let event = Event::PitchBend {\n                channel: 0,\n                value: -8192, // Max down\n            };\n            if let Event::PitchBend { value, .. } = event {\n                assert_eq!(value, -8192);\n            }\n        }\n\n        #[test]\n        fn test_key_signature_sharps() {\n            let event = Event::KeySignature {\n                sharps_flats: 4, // E major\n                is_minor: false,\n            };\n            if let Event::KeySignature {\n                sharps_flats,\n                is_minor,\n            } = event\n            {\n                assert_eq!(sharps_flats, 4);\n                assert!(!is_minor);\n            }\n        }\n\n        #[test]\n        fn test_key_signature_flats() {\n            let event = Event::KeySignature {\n                sharps_flats: -3, // Eb major\n                is_minor: false,\n            };\n            if let Event::KeySignature {\n                sharps_flats,\n                is_minor,\n            } = event\n            {\n                assert_eq!(sharps_flats, -3);\n                assert!(!is_minor);\n            }\n        }\n\n        #[test]\n        fn test_very_large_delta_ticks() {\n            let event = TimedEvent {\n                delta_ticks: u32::MAX,\n                event: Event::EndOfTrack,\n            };\n            assert_eq!(event.delta_ticks, u32::MAX);\n        }\n\n        #[test]\n        fn test_empty_sysex() {\n            let event = Event::SysEx { data: vec![] };\n            if let Event::SysEx { data } = event {\n                assert!(data.is_empty());\n            }\n        }\n\n        #[test]\n        fn test_empty_text() {\n            let event = Event::Text {\n                text_type: TextType::Text,\n                text: String::new(),\n            };\n            if let Event::Text { text, .. } = event {\n                assert!(text.is_empty());\n            }\n        }\n\n        #[test]\n        fn test_unicode_text() {\n            let event = Event::Text {\n                text_type: TextType::TrackName,\n                text: \"Piano Track\".to_string(),\n            };\n            if let Event::Text { text, .. } = event {\n                assert_eq!(text, \"Piano Track\");\n            }\n        }\n    }\n}\n","traces":[{"line":113,"address":[745344],"length":1,"stats":{"Line":0}},{"line":117,"address":[745393,745464],"length":1,"stats":{"Line":0}},{"line":120,"address":[745502,745527],"length":1,"stats":{"Line":0}},{"line":121,"address":[745532,745726,745504],"length":1,"stats":{"Line":0}},{"line":124,"address":[745546],"length":1,"stats":{"Line":0}},{"line":125,"address":[745553],"length":1,"stats":{"Line":0}},{"line":136,"address":[745614,745633,745560],"length":1,"stats":{"Line":0}},{"line":137,"address":[745622],"length":1,"stats":{"Line":0}},{"line":138,"address":[745637,745567],"length":1,"stats":{"Line":0}},{"line":142,"address":[745744],"length":1,"stats":{"Line":0}},{"line":145,"address":[669776,669779],"length":1,"stats":{"Line":0}},{"line":146,"address":[669792],"length":1,"stats":{"Line":0}},{"line":151,"address":[745920,746650],"length":1,"stats":{"Line":0}},{"line":154,"address":[746075,746123],"length":1,"stats":{"Line":0}},{"line":155,"address":[746199,746172],"length":1,"stats":{"Line":0}},{"line":156,"address":[746174,746207],"length":1,"stats":{"Line":0}},{"line":163,"address":[746554],"length":1,"stats":{"Line":0}},{"line":164,"address":[746360],"length":1,"stats":{"Line":0}},{"line":171,"address":[746656,746201],"length":1,"stats":{"Line":0}},{"line":185,"address":[746672],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":20},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","mod.rs"],"content":"//! Core MIDI processing modules\n\npub mod midi;\npub mod analysis;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","mod.rs"],"content":"//! Database models and repositories\n\npub mod models;\npub mod repositories;\n\n// Re-export commonly used types\npub use models::{File, MidiMetadata};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","analysis.rs"],"content":"//! Analysis result model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct AnalysisResult {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","error.rs"],"content":"//! Database error types\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct DbError {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","midi.rs"],"content":"//! MIDI metadata model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct MidiMetadata {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","midi_file.rs"],"content":"//! MIDI file database model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version (better modular structure)\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct File {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","mod.rs"],"content":"//! Database model types\n\npub mod midi_file;\npub mod midi;\npub mod sequencer;\npub mod analysis;\npub mod search;\npub mod error;\n\n// Re-export main types\npub use midi_file::File;\npub use midi::MidiMetadata;\npub use sequencer::SequencerTrack;\npub use analysis::AnalysisResult;\npub use search::SearchFilters;\npub use error::DbError;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","search.rs"],"content":"//! Search filters model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct SearchFilters {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","sequencer.rs"],"content":"//! Sequencer model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct SequencerTrack {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","file_repository.rs"],"content":"//! File repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct FileRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","metadata_repository.rs"],"content":"//! Metadata repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct MetadataRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","mod.rs"],"content":"//! Database repository layer\n\npub mod file_repository;\npub mod metadata_repository;\npub mod search_repository;\npub mod tag_repository;\n\n// Re-export repository types\npub use file_repository::FileRepository;\npub use metadata_repository::MetadataRepository;\npub use search_repository::SearchRepository;\npub use tag_repository::TagRepository;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","search_repository.rs"],"content":"//! Search repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct SearchRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","tag_repository.rs"],"content":"//! Tag repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct TagRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","lib.rs"],"content":"//! MIDI Library Shared Code\n//!\n//! This crate contains all shared functionality used by:\n//! - Pipeline (import, process, analyze)\n//! - DAW (playback, sequence, MIDI out)\n//!\n//! ## Structure\n//!\n//! - `core::midi` - MIDI parsing and types\n//! - `core::analysis` - Musical analysis (BPM, key detection, etc.)\n//! - `db::models` - Database model types\n//! - `db::repositories` - Database access layer\n\npub mod core;\npub mod db;\n\n// Re-export top-level modules for convenience\npub use core::midi;\npub use core::analysis;\npub use db::{models, repositories};\n\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn it_works() {\n        assert_eq!(2 + 2, 4);\n    }\n}\n","traces":[],"covered":0,"coverable":0}]};
        var previousData = {"files":[{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","build.rs"],"content":"fn main() {\n    tauri_build::build()\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","analysis.rs"],"content":"//! Analysis Tauri commands\n//!\n//! Grown-up Script: I/O wrapper for musical analysis and compatibility matching.\n//! Updated to use proper JOINs with actual database schema.\n\nuse crate::commands::AppState;\nuse crate::core::compatibility;\nuse crate::models::analysis::CompatibleFile;\nuse crate::models::midi_file::MidiFile;\nuse tauri::State;\nuse tracing::{debug, error};\n\n/// Find files that are musically compatible with a given file\n///\n/// Returns files sorted by compatibility score (highest first).\n/// Considers key signature, BPM, and time signature.\n///\n/// # Arguments\n/// * `file_id` - The reference file to find compatible files for\n/// * `max_results` - Maximum number of results to return (default: 20, max: 100)\n#[tauri::command]\npub async fn find_compatible_files(\n    file_id: i32,\n    max_results: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cCompatibleFile\u003e, String\u003e {\n    debug!(\"Finding compatible files for file ID: {}\", file_id);\n\n    let max = max_results.unwrap_or(20).min(100);\n\n    // Get reference file with proper JOINs\n    let ref_file = sqlx::query_as!(\n        MidiFile,\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.content_hash as \"content_hash!\",\n            f.is_multi_track as \"is_multi_track!\",\n            f.parent_file_id as \"parent_file_id?\",\n            f.track_number as \"track_number?\",\n            f.total_tracks as \"total_tracks?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"folder_tags!\",\n            f.parent_folder as \"parent_folder?\",\n            f.num_tracks,\n            f.created_at as \"created_at!\",\n            f.analyzed_at as \"analyzed_at?\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) as \"total_notes!\",\n            fc.primary_category::TEXT as \"primary_category?\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to get reference file: {}\", e);\n        format!(\"Failed to get reference file: {}\", e)\n    })?;\n\n    let ref_file = ref_file.ok_or_else(|| format!(\"File with ID {} not found\", file_id))?;\n\n    debug!(\n        \"Reference file - BPM: {:?}, Key: {:?}, Time sig: {:?}\",\n        ref_file.bpm, ref_file.key_signature, ref_file.time_signature\n    );\n\n    // Get all other files with proper JOINs\n    let candidate_files = sqlx::query_as!(\n        MidiFile,\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.content_hash as \"content_hash!\",\n            f.is_multi_track as \"is_multi_track!\",\n            f.parent_file_id as \"parent_file_id?\",\n            f.track_number as \"track_number?\",\n            f.total_tracks as \"total_tracks?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"folder_tags!\",\n            f.parent_folder as \"parent_folder?\",\n            f.num_tracks,\n            f.created_at as \"created_at!\",\n            f.analyzed_at as \"analyzed_at?\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) as \"total_notes!\",\n            fc.primary_category::TEXT as \"primary_category?\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id != $1\n        LIMIT 500\n        \"#,\n        file_id as i64\n    )\n    .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to fetch candidate files: {}\", e);\n        format!(\"Failed to fetch files: {}\", e)\n    })?;\n\n    let mut compatible_files: Vec\u003cCompatibleFile\u003e = candidate_files\n        .iter()\n        .map(|candidate| {\n            // Use Trusty Module to calculate compatibility (pure function)\n            let score = compatibility::calculate_compatibility(\u0026ref_file, candidate);\n\n            // Calculate BPM-based time stretch suggestion\n            let suggested_bpm_multiplier = if let (Some(ref_bpm), Some(cand_bpm)) = (ref_file.bpm, candidate.bpm) {\n                let ratio = cand_bpm / ref_bpm;\n                // Suggest multiplier if it's a simple ratio\n                if (ratio - 0.5).abs() \u003c 0.05 { Some(0.5) }\n                else if (ratio - 2.0).abs() \u003c 0.1 { Some(2.0) }\n                else if (ratio - 1.5).abs() \u003c 0.1 { Some(1.5) }\n                else if (ratio - 0.75).abs() \u003c 0.05 { Some(0.75) }\n                else { None }\n            } else {\n                None\n            };\n\n            CompatibleFile {\n                id: candidate.id as i32,\n                file_name: candidate.filename.clone(),\n                compatibility_score: score.total_score as i32, // Convert f32 to i32\n                key_match: ref_file.key_signature == candidate.key_signature,\n                bpm_difference: if let (Some(ref_bpm), Some(cand_bpm)) = (ref_file.bpm, candidate.bpm) {\n                    Some((ref_bpm - cand_bpm).abs() as f32)\n                } else {\n                    None\n                },\n                time_signature_match: ref_file.time_signature == candidate.time_signature,\n                suggested_bpm_multiplier,\n                category: candidate.primary_category.clone(),\n            }\n        })\n        .collect();\n\n    // Sort by compatibility score (descending)\n    compatible_files.sort_by(|a, b| b.compatibility_score.cmp(\u0026a.compatibility_score));\n\n    // Take top N results\n    compatible_files.truncate(max as usize);\n\n    debug!(\n        \"Returning {} compatible files (top score: {})\",\n        compatible_files.len(),\n        compatible_files.first().map(|f| f.compatibility_score).unwrap_or(0)\n    );\n\n    Ok(compatible_files)\n}\n\n/// Add file to favorites\n#[tauri::command]\npub async fn add_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Adding file {} to favorites\", file_id);\n\n    // Insert into favorites table (ON CONFLICT DO NOTHING to handle duplicates)\n    sqlx::query!(\n        \"INSERT INTO favorites (file_id) VALUES ($1) ON CONFLICT (file_id) DO NOTHING\",\n        file_id as i64\n    )\n    .execute(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to add favorite: {}\", e);\n        format!(\"Failed to add favorite: {}\", e)\n    })?;\n\n    debug!(\"Successfully added file {} to favorites\", file_id);\n    Ok(())\n}\n\n/// Remove file from favorites\n#[tauri::command]\npub async fn remove_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Removing file {} from favorites\", file_id);\n\n    sqlx::query!(\n        \"DELETE FROM favorites WHERE file_id = $1\",\n        file_id as i64\n    )\n    .execute(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to remove favorite: {}\", e);\n        format!(\"Failed to remove favorite: {}\", e)\n    })?;\n\n    debug!(\"Successfully removed file {} from favorites\", file_id);\n    Ok(())\n}\n\n/// Check if a file is favorited\n#[tauri::command]\npub async fn is_favorite(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    let result = sqlx::query!(\n        \"SELECT EXISTS(SELECT 1 FROM favorites WHERE file_id = $1) as is_fav\",\n        file_id as i64\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to check favorite status: {}\", e))?;\n\n    Ok(result.is_fav.unwrap_or(false))\n}\n\n/// Get all favorite files with full details\n#[tauri::command]\npub async fn get_favorites(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003ccrate::models::midi_file::FileDetails\u003e, String\u003e {\n    debug!(\"Getting all favorite files\");\n\n    let favorites = sqlx::query_as!(\n        crate::models::midi_file::FileDetails,\n        r#\"\n        SELECT\n            f.id as \"id!\",\n            f.filename as \"filename!\",\n            f.filepath as \"filepath!\",\n            f.file_size_bytes as \"file_size_bytes!\",\n            f.num_tracks as \"track_count!\",\n            f.content_hash as \"content_hash!\",\n            f.parent_folder as \"parent_folder?\",\n            f.created_at as \"created_at!\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) \u003e 0 as \"has_notes!\",\n            mm.total_notes as \"total_notes?\",\n            mm.is_percussive as \"has_drums?\",\n            fc.primary_category::TEXT as \"primary_category?\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"tags!\",\n            true as \"is_favorite!\"\n        FROM favorites fav\n        INNER JOIN files f ON fav.file_id = f.id\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY fav.created_at DESC\n        \"#\n    )\n    .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to fetch favorites: {}\", e);\n        format!(\"Failed to fetch favorites: {}\", e)\n    })?;\n\n    debug!(\"Retrieved {} favorite files\", favorites.len());\n    Ok(favorites)\n}\n\n/// Get usage statistics\n#[tauri::command]\npub async fn get_usage_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    debug!(\"Getting usage statistics\");\n\n    // Gather various statistics using proper table and column names\n    let total_files: i64 = sqlx::query_scalar(\"SELECT COUNT(*) FROM files\")\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| format!(\"Failed to count files: {}\", e))?;\n\n    let total_duration: Option\u003cf64\u003e = sqlx::query_scalar(\n        \"SELECT SUM(duration_seconds) FROM files WHERE duration_seconds IS NOT NULL\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to sum duration: {}\", e))?;\n\n    let total_notes: Option\u003ci64\u003e = sqlx::query_scalar(\n        \"SELECT SUM(total_notes) FROM musical_metadata\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to sum notes: {}\", e))?;\n\n    let avg_bpm: Option\u003cf64\u003e = sqlx::query_scalar(\n        \"SELECT AVG(bpm) FROM musical_metadata WHERE bpm IS NOT NULL\"\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to calculate average BPM: {}\", e))?;\n\n    // Most common key\n    let most_common_key: Option\u003c(String,)\u003e = sqlx::query_as(\n        \"SELECT key_signature::TEXT\n         FROM musical_metadata\n         WHERE key_signature IS NOT NULL\n         GROUP BY key_signature\n         ORDER BY COUNT(*) DESC\n         LIMIT 1\"\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to find most common key: {}\", e))?;\n\n    // Most common time signature\n    let most_common_time: Option\u003c(String,)\u003e = sqlx::query_as(\n        \"SELECT time_signature_numerator::TEXT || '/' || time_signature_denominator::TEXT\n         FROM musical_metadata\n         WHERE time_signature_numerator IS NOT NULL\n           AND time_signature_denominator IS NOT NULL\n         GROUP BY time_signature_numerator, time_signature_denominator\n         ORDER BY COUNT(*) DESC\n         LIMIT 1\"\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| format!(\"Failed to find most common time signature: {}\", e))?;\n\n    // Format as JSON\n    let stats = serde_json::json!({\n        \"total_files\": total_files,\n        \"total_duration_hours\": total_duration.unwrap_or(0.0) / 3600.0,\n        \"total_notes\": total_notes.unwrap_or(0),\n        \"average_bpm\": avg_bpm.unwrap_or(0.0),\n        \"most_common_key\": most_common_key.map(|(k,)| k),\n        \"most_common_time_signature\": most_common_time.map(|(t,)| t),\n    });\n\n    Ok(stats.to_string())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","export.rs"],"content":"//! Export Tauri commands\n//!\n//! Grown-up Script: Handles exporting sequencer projects and MIDI data.\n//! Delegates MIDI file generation to Trusty Modules (pure functions).\n\nuse crate::core::midi::writer;\nuse crate::models::midi::{MidiEvent, MidiEventType};\nuse tracing::{debug, error, info};\nuse std::path::PathBuf;\n\n/// Export project as MIDI file\n///\n/// Uses MIDI writer Trusty Module (pure function) to generate MIDI data.\n///\n/// TODO for full implementation:\n/// - Get events from sequencer engine\n/// - Merge all tracks into event list\n/// - Apply track properties (volume, pan as MIDI CC)\n/// - Support tempo map changes\n///\n/// Current implementation creates a demonstration MIDI file.\n#[tauri::command]\npub async fn export_project_midi(\n    output_path: String,\n) -\u003e Result\u003c(), String\u003e {\n    debug!(\"Exporting project to MIDI file: {}\", output_path);\n\n    let path = PathBuf::from(\u0026output_path);\n\n    // Validate path\n    if let Some(parent) = path.parent() {\n        if !parent.exists() {\n            return Err(format!(\"Parent directory does not exist: {}\", parent.display()));\n        }\n    }\n\n    // Validate extension\n    if path.extension().and_then(|s| s.to_str()) != Some(\"mid\") \u0026\u0026\n       path.extension().and_then(|s| s.to_str()) != Some(\"midi\") {\n        return Err(\"Output file must have .mid or .midi extension\".to_string());\n    }\n\n    // TODO: Get events from sequencer engine\n    // For now, create a simple demonstration pattern\n    let events = create_demo_events();\n\n    // Use Trusty Module (pure function) to generate MIDI file\n    let midi_data = writer::write_midi_file(\u0026events, 480, 120.0)\n        .map_err(|e| {\n            error!(\"Failed to generate MIDI data: {}\", e);\n            format!(\"Failed to generate MIDI: {}\", e)\n        })?;\n\n    // I/O operation (Grown-up Script responsibility)\n    std::fs::write(\u0026path, midi_data)\n        .map_err(|e| {\n            error!(\"Failed to write MIDI file: {}\", e);\n            format!(\"Failed to write file: {}\", e)\n        })?;\n\n    info!(\"Exported project to: {}\", output_path);\n    Ok(())\n}\n\n/// Create demonstration MIDI events\n///\n/// This is a placeholder for integration with the sequencer.\n/// A real implementation would:\n/// 1. Get all tracks from the sequencer engine\n/// 2. Merge events from all enabled tracks\n/// 3. Apply track properties (mute, solo, volume, pan)\n/// 4. Sort events by timestamp\n///\n/// Current implementation creates a simple C major arpeggio pattern.\nfn create_demo_events() -\u003e Vec\u003cMidiEvent\u003e {\n    vec![\n        // C major arpeggio (C-E-G-C)\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 0,\n            channel: 0,\n            note: Some(60), // C\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 480, // 1 beat later\n            channel: 0,\n            note: Some(60),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 480,\n            channel: 0,\n            note: Some(64), // E\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 960, // 2 beats\n            channel: 0,\n            note: Some(64),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 960,\n            channel: 0,\n            note: Some(67), // G\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 1440, // 3 beats\n            channel: 0,\n            note: Some(67),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 1440,\n            channel: 0,\n            note: Some(72), // C (octave higher)\n            velocity: Some(80),\n            controller: None,\n            value: None,\n            program: None,\n        },\n        MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick: 1920, // 4 beats (1 bar)\n            channel: 0,\n            note: Some(72),\n            velocity: Some(0),\n            controller: None,\n            value: None,\n            program: None,\n        },\n    ]\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_create_demo_events() {\n        let events = create_demo_events();\n\n        // Should create 8 events (4 note on + 4 note off)\n        assert_eq!(events.len(), 8);\n\n        // First event should be Note On at tick 0\n        assert_eq!(events[0].event_type, MidiEventType::NoteOn);\n        assert_eq!(events[0].tick, 0);\n        assert_eq!(events[0].note, Some(60)); // Middle C\n\n        // Last event should be Note Off at tick 1920 (1 bar)\n        assert_eq!(events[7].event_type, MidiEventType::NoteOff);\n        assert_eq!(events[7].tick, 1920);\n        assert_eq!(events[7].note, Some(72)); // High C\n    }\n\n    #[test]\n    fn test_export_uses_trusty_module() {\n        // Verify we're using the MIDI writer Trusty Module\n        let events = create_demo_events();\n        let result = writer::write_midi_file(\u0026events, 480, 120.0);\n\n        assert!(result.is_ok());\n        let midi_data = result.unwrap();\n\n        // Verify MIDI header\n        assert_eq!(\u0026midi_data[0..4], b\"MThd\");\n        // Verify track chunk\n        assert_eq!(\u0026midi_data[14..18], b\"MTrk\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","midi.rs"],"content":"//! MIDI hardware Tauri commands\n//!\n//! Grown-up Scripts: Thin wrappers around MIDI manager for frontend access.\n//! Delegate all business logic to Trusty Modules and MIDI manager.\n\nuse tauri::State;\nuse std::sync::Arc;\nuse crate::midi::MidiManager;\nuse crate::models::MidiDevice;\n\n/// List all available MIDI output devices\n///\n/// Returns a list of MIDI output devices found on the system.\n#[tauri::command]\npub async fn midi_list_devices(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cVec\u003cMidiDevice\u003e, String\u003e {\n    midi_manager.list_devices()\n}\n\n/// Connect to a specific MIDI device by name\n///\n/// Establishes a connection to the specified MIDI output device.\n#[tauri::command]\npub async fn midi_connect(\n    device_name: String,\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    midi_manager.connect(\u0026device_name).await\n}\n\n/// Disconnect from current MIDI device\n///\n/// Closes the active MIDI connection if one exists.\n#[tauri::command]\npub async fn midi_disconnect(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    midi_manager.disconnect().await;\n    Ok(())\n}\n\n/// Check if MIDI device is currently connected\n///\n/// Returns true if a MIDI device is connected, false otherwise.\n#[tauri::command]\npub async fn midi_is_connected(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    Ok(midi_manager.is_connected().await)\n}\n\n/// Get current MIDI device info\n///\n/// Returns information about the currently connected device, if any.\n#[tauri::command]\npub async fn midi_get_current_device(\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003cOption\u003cMidiDevice\u003e, String\u003e {\n    if let Some(name) = midi_manager.current_device().await {\n        Ok(Some(MidiDevice {\n            name,\n            manufacturer: None,\n        }))\n    } else {\n        Ok(None)\n    }\n}\n\n/// Send a test note to verify MIDI connection\n///\n/// Sends a note on/off pair with configurable parameters.\n/// The note plays for 500ms.\n#[tauri::command]\npub async fn midi_send_test_note(\n    channel: u8,\n    note: u8,\n    velocity: u8,\n    midi_manager: State\u003c'_, Arc\u003cMidiManager\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    // Send note on\n    midi_manager.send_note_on(channel, note, velocity).await?;\n\n    // Wait 500ms\n    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;\n\n    // Send note off\n    midi_manager.send_note_off(channel, note).await?;\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","mod.rs"],"content":"//! Tauri command handlers\n//!\n//! Grown-up Scripts: Thin wrappers that expose backend functionality to frontend.\n//! All commands delegate business logic to Trusty Modules or Grown-up Scripts.\n\npub mod midi;\npub mod sequencer;\npub mod search;\npub mod analysis;\npub mod export;\npub mod project;\n\n/// Shared application state across all commands\n///\n/// Contains database pool for read-only access to MIDI file metadata.\npub struct AppState {\n    pub db_pool: Option\u003csqlx::PgPool\u003e,\n}\n\n#[tauri::command]\npub async fn initialize_database(state: tauri::State\u003c'_, AppState\u003e) -\u003e Result\u003c(), String\u003e {\n    // Get database connection pool\n    let pool = state.db_pool.as_ref().ok_or_else(|| {\n        \"Database connection not available. Please set DATABASE_URL environment variable.\".to_string()\n    })?;\n\n    // Test the connection with a simple query\n    sqlx::query(\"SELECT COUNT(*) FROM files\")\n        .execute(pool)\n        .await\n        .map_err(|e| format!(\"Database connection test failed: {}\", e))?;\n\n    Ok(())\n}\n\n// Re-export all command functions for easy registration\n#[allow(unused_imports)]\npub use midi::{\n    midi_list_devices, midi_connect, midi_disconnect,\n    midi_is_connected, midi_get_current_device, midi_send_test_note,\n};\n\n#[allow(unused_imports)]\npub use sequencer::{\n    start_sequencer, stop_sequencer, pause_sequencer, resume_sequencer,\n    get_playback_position, seek_position, set_tempo, get_tempo,\n    add_track, remove_track, update_track, get_tracks,\n    load_sequencer_tracks, is_sequencer_playing,\n};\n\n#[allow(unused_imports)]\npub use search::{\n    search_files, get_file_details, get_search_suggestions,\n};\n\n#[allow(unused_imports)]\npub use analysis::{\n    find_compatible_files, add_favorite, remove_favorite,\n    is_favorite, get_favorites, get_usage_stats,\n};\n\n#[allow(unused_imports)]\npub use export::{\n    export_project_midi,\n};\n\n#[allow(unused_imports)]\npub use project::{\n    load_multiple_tracks, clear_all_tracks, get_track_details,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","project.rs"],"content":"//! Project and track loading commands\n//!\n//! Commands for loading multiple tracks into the sequencer from the database.\n\nuse crate::commands::AppState;\nuse crate::core::midi::loader::load_midi_file;\nuse crate::models::sequencer::Track;\nuse crate::sequencer::{ScheduledEvent, SequencerEngine};\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\nuse tauri::State;\nuse tracing::{error, info, warn};\n\n/// Track with loaded events ready for scheduling\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TrackWithEvents {\n    pub track: Track,\n    pub events: Vec\u003cScheduledEvent\u003e,\n}\n\n/// Load multiple MIDI files as sequencer tracks\n///\n/// This command loads multiple files from the database and prepares them\n/// as sequencer tracks with their MIDI events ready for playback.\n///\n/// # Arguments\n/// * `file_ids` - List of database file IDs to load\n/// * `state` - Application state with database connection\n/// * `engine` - Sequencer engine\n#[tauri::command]\npub async fn load_multiple_tracks(\n    file_ids: Vec\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrack\u003e, String\u003e {\n    info!(\"Loading {} files as sequencer tracks\", file_ids.len());\n\n    let mut loaded_tracks = Vec::new();\n    let mut failed_count = 0;\n\n    for (idx, file_id) in file_ids.iter().enumerate() {\n        // Query database for file information\n        let file_result = match sqlx::query!(\n            r#\"\n            SELECT id, filepath, filename\n            FROM files\n            WHERE id = $1\n            \"#,\n            *file_id as i64\n        )\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        {\n            Ok(result) =\u003e result,\n            Err(e) =\u003e {\n                error!(\"Failed to query file {} from database: {}\", file_id, e);\n                failed_count += 1;\n                continue;\n            }\n        };\n\n        // Load MIDI file and parse events\n        let loaded_midi = match load_midi_file(\u0026file_result.filepath) {\n            Ok(midi) =\u003e midi,\n            Err(e) =\u003e {\n                error!(\n                    \"Failed to load MIDI file {} ({}): {}\",\n                    file_result.filename, file_result.filepath, e\n                );\n                failed_count += 1;\n                continue;\n            }\n        };\n\n        info!(\n            \"Loaded {} events from {} ({}/{})\",\n            loaded_midi.events.len(),\n            file_result.filename,\n            idx + 1,\n            file_ids.len()\n        );\n\n        // Add track with loaded events\n        let track_manager = engine.track_manager();\n        let channel = (idx % 16) as u8; // Distribute across MIDI channels\n\n        match track_manager\n            .add_track(file_result.id as i32, channel, loaded_midi.events)\n            .await\n        {\n            Ok(track) =\u003e loaded_tracks.push(track),\n            Err(e) =\u003e {\n                error!(\"Failed to add track for file {}: {}\", file_id, e);\n                failed_count += 1;\n            }\n        }\n    }\n\n    if failed_count \u003e 0 {\n        warn!(\n            \"Failed to load {} out of {} tracks\",\n            failed_count,\n            file_ids.len()\n        );\n    }\n\n    // Reload tracks in engine to update scheduler\n    engine.load_tracks().await;\n\n    info!(\n        \"Successfully loaded {} tracks into sequencer\",\n        loaded_tracks.len()\n    );\n\n    Ok(loaded_tracks)\n}\n\n/// Clear all tracks from the sequencer\n#[tauri::command]\npub async fn clear_all_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    info!(\"Clearing all tracks from sequencer\");\n\n    let track_manager = engine.track_manager();\n    track_manager.clear().await;\n\n    let scheduler = engine.scheduler();\n    scheduler.clear().await;\n\n    Ok(())\n}\n\n/// Get detailed information about loaded tracks\n#[tauri::command]\npub async fn get_track_details(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrackDetails\u003e, String\u003e {\n    let track_manager = engine.track_manager();\n    let tracks = track_manager.get_tracks().await;\n\n    let details: Vec\u003cTrackDetails\u003e = tracks\n        .into_iter()\n        .map(|track| {\n            let event_count = track.events.len();\n            TrackDetails {\n                id: track.id,\n                name: track.name,\n                file_id: track.file_id,\n                channel: track.channel,\n                muted: track.muted,\n                solo: track.solo,\n                volume: track.volume,\n                pan: track.pan,\n                event_count,\n            }\n        })\n        .collect();\n\n    Ok(details)\n}\n\n/// Track details for frontend display\n#[derive(Debug, Serialize, Deserialize)]\npub struct TrackDetails {\n    pub id: i32,\n    pub name: String,\n    pub file_id: i32,\n    pub channel: u8,\n    pub muted: bool,\n    pub solo: bool,\n    pub volume: u8,\n    pub pan: u8,\n    pub event_count: usize,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","search.rs"],"content":"//! Search Tauri commands\n//!\n//! Thin wrappers that expose search functionality to the frontend.\n//! Queries the PostgreSQL database for MIDI files with filtering and sorting.\n//! Updated to use proper JOINs with actual database schema.\n\nuse crate::commands::AppState;\nuse crate::models::midi_file::FileDetails;\nuse crate::models::search::{SearchFilters, SearchResponse, Suggestion};\nuse sqlx::Row;\nuse tauri::State;\nuse tracing::{debug, error};\n\n/// Search for MIDI files with filters\n///\n/// Supports filtering by:\n/// - BPM range\n/// - Key signature\n/// - Time signature\n/// - Category\n/// - Note count range\n/// - Duration range\n/// - Full-text search in filename\n#[tauri::command]\npub async fn search_files(\n    filters: SearchFilters,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cSearchResponse, String\u003e {\n    debug!(\"Searching files with filters: {:?}\", filters);\n\n    // Build base query with proper JOINs and type casts\n    let mut query = String::from(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.file_size_bytes,\n            f.parent_folder,\n            f.created_at,\n            f.content_hash,\n            f.num_tracks,\n            f.manufacturer,\n            f.collection_name,\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as folder_tags,\n            mm.bpm::FLOAT8 as bpm,\n            mm.key_signature::TEXT as key_signature,\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as time_signature,\n            f.duration_seconds::FLOAT8 as duration_seconds,\n            mm.total_notes,\n            mm.is_percussive as has_drums,\n            fc.primary_category::TEXT as primary_category,\n            CASE WHEN fav.file_id IS NOT NULL THEN true ELSE false END as is_favorite\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        LEFT JOIN favorites fav ON f.id = fav.file_id\n        WHERE 1=1\n        \"#\n    );\n\n    let mut conditions = Vec::new();\n\n    // BPM filter\n    if let Some(min_bpm) = filters.min_bpm {\n        conditions.push(format!(\"mm.bpm \u003e= {}\", min_bpm));\n    }\n    if let Some(max_bpm) = filters.max_bpm {\n        conditions.push(format!(\"mm.bpm \u003c= {}\", max_bpm));\n    }\n\n    // Key signature filter\n    if let Some(ref key) = filters.key_signature {\n        conditions.push(format!(\"mm.key_signature = '{}'\", key.replace(\"'\", \"''\")));\n    }\n\n    // Time signature filter (need to match formatted string)\n    if let Some(ref time_sig) = filters.time_signature {\n        let parts: Vec\u003c\u0026str\u003e = time_sig.split('/').collect();\n        if parts.len() == 2 {\n            conditions.push(format!(\n                \"mm.time_signature_numerator = {} AND mm.time_signature_denominator = {}\",\n                parts[0], parts[1]\n            ));\n        }\n    }\n\n    // Category filter (check primary_category in file_categories table)\n    if let Some(ref category) = filters.category {\n        conditions.push(format!(\n            \"fc.primary_category::TEXT ILIKE '%{}%'\",\n            category.replace(\"'\", \"''\")\n        ));\n    }\n\n    // Note count range\n    if let Some(min_notes) = filters.min_notes {\n        conditions.push(format!(\"mm.total_notes \u003e= {}\", min_notes));\n    }\n    if let Some(max_notes) = filters.max_notes {\n        conditions.push(format!(\"mm.total_notes \u003c= {}\", max_notes));\n    }\n\n    // Duration range\n    if let Some(min_duration) = filters.min_duration {\n        conditions.push(format!(\"f.duration_seconds \u003e= {}\", min_duration));\n    }\n    if let Some(max_duration) = filters.max_duration {\n        conditions.push(format!(\"f.duration_seconds \u003c= {}\", max_duration));\n    }\n\n    // Text search in filename\n    if let Some(ref search_text) = filters.search_text {\n        if !search_text.is_empty() {\n            conditions.push(format!(\"f.filename ILIKE '%{}%'\", search_text.replace(\"'\", \"''\")));\n        }\n    }\n\n    // Add all conditions to query\n    for condition in \u0026conditions {\n        query.push_str(\u0026format!(\" AND {}\", condition));\n    }\n\n    // Add sorting - map frontend field names to actual DB columns\n    let sort_by = match filters.sort_by.as_deref().unwrap_or(\"created_at\") {\n        \"file_name\" =\u003e \"f.filename\",\n        \"bpm\" =\u003e \"mm.bpm\",\n        \"key_signature\" =\u003e \"mm.key_signature\",\n        \"duration_seconds\" =\u003e \"f.duration_seconds\",\n        \"note_count\" =\u003e \"mm.total_notes\",\n        \"created_at\" =\u003e \"f.created_at\",\n        _ =\u003e \"f.created_at\",\n    };\n\n    let sort_order = if filters.sort_desc.unwrap_or(false) {\n        \"DESC\"\n    } else {\n        \"ASC\"\n    };\n    query.push_str(\u0026format!(\" ORDER BY {} {}\", sort_by, sort_order));\n\n    // Add pagination\n    let limit = filters.limit.unwrap_or(50).min(500); // Cap at 500\n    let offset = filters.offset.unwrap_or(0);\n    query.push_str(\u0026format!(\" LIMIT {} OFFSET {}\", limit, offset));\n\n    debug!(\"Executing query: {}\", query);\n\n    // Execute query\n    let rows = sqlx::query(\u0026query)\n        .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| {\n            error!(\"Database query failed: {}\", e);\n            format!(\"Failed to search files: {}\", e)\n        })?;\n\n    // Convert rows to FileDetails structs\n    let files: Vec\u003cFileDetails\u003e = rows\n        .iter()\n        .map(|row| FileDetails {\n            id: row.get(\"id\"),\n            filename: row.get(\"filename\"),\n            filepath: row.get(\"filepath\"),\n            file_size_bytes: row.get(\"file_size_bytes\"),\n            bpm: row.try_get(\"bpm\").ok(),\n            key_signature: row.try_get(\"key_signature\").ok(),\n            time_signature: row.try_get(\"time_signature\").ok(),\n            duration_seconds: row.try_get(\"duration_seconds\").ok(),\n            total_notes: row.try_get(\"total_notes\").ok(),\n            primary_category: row.try_get(\"primary_category\").ok(),\n            parent_folder: row.try_get(\"parent_folder\").ok(),\n            created_at: row.get(\"created_at\"),\n            is_favorite: row.try_get(\"is_favorite\").unwrap_or(false),\n            tags: row.try_get(\"folder_tags\").unwrap_or_default(),\n            manufacturer: row.try_get(\"manufacturer\").ok(),\n            collection_name: row.try_get(\"collection_name\").ok(),\n            track_count: row.try_get(\"num_tracks\").unwrap_or(0),\n            has_notes: row.try_get::\u003cOption\u003ci32\u003e, _\u003e(\"total_notes\").ok().flatten().unwrap_or(0) \u003e 0,\n            has_drums: row.try_get(\"has_drums\").ok(),\n            content_hash: row.try_get(\"content_hash\").unwrap_or_default(),\n        })\n        .collect();\n\n    // Get total count (without pagination) - must include all JOINs for WHERE conditions\n    let mut count_query = String::from(\n        \"SELECT COUNT(*) FROM files f \\\n         LEFT JOIN musical_metadata mm ON f.id = mm.file_id \\\n         LEFT JOIN file_categories fc ON f.id = fc.file_id \\\n         LEFT JOIN favorites fav ON f.id = fav.file_id \\\n         WHERE 1=1\"\n    );\n    for condition in \u0026conditions {\n        count_query.push_str(\u0026format!(\" AND {}\", condition));\n    }\n\n    let total: i64 = sqlx::query_scalar(\u0026count_query)\n        .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n        .await\n        .map_err(|e| {\n            error!(\"Count query failed: {}\", e);\n            format!(\"Failed to count results: {}\", e)\n        })?;\n\n    debug!(\"Found {} total results, returning {} files\", total, files.len());\n\n    Ok(SearchResponse {\n        files,\n        total: total as i32,\n    })\n}\n\n/// Get detailed information about a specific file\n#[tauri::command]\npub async fn get_file_details(\n    file_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cFileDetails, String\u003e {\n    debug!(\"Getting details for file ID: {}\", file_id);\n\n    let file = sqlx::query_as!(\n        FileDetails,\n        r#\"\n        SELECT\n            f.id as \"id!\",\n            f.filename as \"filename!\",\n            f.filepath as \"filepath!\",\n            f.file_size_bytes as \"file_size_bytes!\",\n            f.parent_folder as \"parent_folder?\",\n            f.created_at as \"created_at!\",\n            f.content_hash as \"content_hash!\",\n            f.num_tracks as \"track_count!\",\n            f.manufacturer as \"manufacturer?\",\n            f.collection_name as \"collection_name?\",\n            COALESCE(f.folder_tags, ARRAY[]::TEXT[]) as \"tags!\",\n            mm.bpm::FLOAT8 as \"bpm?\",\n            mm.key_signature::TEXT as \"key_signature?\",\n            CASE\n                WHEN mm.time_signature_numerator IS NOT NULL\n                THEN mm.time_signature_numerator::TEXT || '/' || mm.time_signature_denominator::TEXT\n                ELSE NULL\n            END as \"time_signature?\",\n            f.duration_seconds::FLOAT8 as \"duration_seconds?\",\n            COALESCE(mm.total_notes, 0) \u003e 0 as \"has_notes!\",\n            mm.total_notes as \"total_notes?\",\n            mm.is_percussive as \"has_drums?\",\n            fc.primary_category::TEXT as \"primary_category?\",\n            CASE WHEN fav.file_id IS NOT NULL THEN true ELSE false END as \"is_favorite!\"\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        LEFT JOIN favorites fav ON f.id = fav.file_id\n        WHERE f.id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_optional(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Database query failed: {}\", e);\n        format!(\"Failed to get file details: {}\", e)\n    })?;\n\n    file.ok_or_else(|| format!(\"File with ID {} not found\", file_id))\n}\n\n/// Get autocomplete suggestions for search\n///\n/// Provides suggestions for:\n/// - Categories\n/// - Key signatures\n/// - Time signatures\n#[tauri::command]\npub async fn get_search_suggestions(\n    query: String,\n    field: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cSuggestion\u003e, String\u003e {\n    debug!(\"Getting suggestions for field '{}' with query '{}'\", field, query);\n\n    let suggestions: Vec\u003cSuggestion\u003e = match field.as_str() {\n        \"category\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT primary_category::TEXT as category FROM file_categories\n                 WHERE primary_category IS NOT NULL\n                 ORDER BY category LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get category suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        \"key_signature\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT key_signature::TEXT FROM musical_metadata\n                 WHERE key_signature IS NOT NULL AND key_signature::TEXT ILIKE $1\n                 ORDER BY key_signature LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get key suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        \"time_signature\" =\u003e {\n            let rows: Vec\u003c(String,)\u003e = sqlx::query_as(\n                \"SELECT DISTINCT\n                    time_signature_numerator::TEXT || '/' || time_signature_denominator::TEXT as time_sig\n                 FROM musical_metadata\n                 WHERE time_signature_numerator IS NOT NULL\n                   AND time_signature_denominator IS NOT NULL\n                 ORDER BY time_sig LIMIT 10\"\n            )\n            .bind(format!(\"%{}%\", query))\n            .fetch_all(state.db_pool.as_ref().ok_or_else(|| \"Database not initialized\".to_string())?)\n            .await\n            .map_err(|e| format!(\"Failed to get time signature suggestions: {}\", e))?;\n\n            rows.into_iter()\n                .map(|(value,)| Suggestion { value })\n                .collect()\n        }\n        _ =\u003e {\n            return Err(format!(\"Unknown field for suggestions: {}\", field));\n        }\n    };\n\n    debug!(\"Returning {} suggestions\", suggestions.len());\n    Ok(suggestions)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","commands","sequencer.rs"],"content":"//! Sequencer Tauri commands\n//!\n//! Thin wrappers that expose sequencer functionality to the frontend.\n\nuse crate::commands::AppState;\nuse crate::core::midi::loader::load_midi_file;\nuse crate::models::sequencer::{PlaybackPosition, Track, TrackProperties};\nuse crate::sequencer::SequencerEngine;\nuse std::sync::Arc;\nuse tauri::State;\nuse tracing::{error, info};\n\n/// Start sequencer playback\n#[tauri::command]\npub async fn start_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.start().await\n}\n\n/// Stop sequencer playback (resets position)\n#[tauri::command]\npub async fn stop_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.stop().await;\n    Ok(())\n}\n\n/// Pause sequencer playback (maintains position)\n#[tauri::command]\npub async fn pause_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.pause().await;\n    Ok(())\n}\n\n/// Resume sequencer playback from paused state\n#[tauri::command]\npub async fn resume_sequencer(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.resume().await\n}\n\n/// Get current playback position\n#[tauri::command]\npub async fn get_playback_position(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cPlaybackPosition, String\u003e {\n    Ok(engine.get_position().await)\n}\n\n/// Seek to a specific position\n///\n/// # Arguments\n/// * `bar` - Bar number (0-indexed)\n/// * `beat` - Beat within bar (0-indexed)\n#[tauri::command]\npub async fn seek_position(\n    bar: u32,\n    beat: u32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    use crate::core::sequencer::timing::bar_beat_to_tick;\n\n    let tick = bar_beat_to_tick(bar, beat, 480, 4); // TODO: Get these from engine\n    engine.seek(tick).await;\n    Ok(())\n}\n\n/// Set global tempo (BPM)\n#[tauri::command]\npub async fn set_tempo(\n    bpm: f32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.set_bpm(bpm).await\n}\n\n/// Get current tempo\n#[tauri::command]\npub async fn get_tempo(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cf32, String\u003e {\n    Ok(engine.get_bpm().await)\n}\n\n/// Add a track to the sequencer\n///\n/// # Arguments\n/// * `file_id` - Database ID of the MIDI file\n/// * `channel` - MIDI channel (0-15)\n/// * `state` - Application state with database connection\n/// * `engine` - Sequencer engine\n#[tauri::command]\npub async fn add_track(\n    file_id: i32,\n    channel: u8,\n    state: State\u003c'_, AppState\u003e,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cTrack, String\u003e {\n    // Query database for file information\n    let file_result = sqlx::query!(\n        r#\"\n        SELECT filepath\n        FROM files\n        WHERE id = $1\n        \"#,\n        file_id as i64\n    )\n    .fetch_one(state.db_pool.as_ref().ok_or_else(|| \"Database pool not initialized\".to_string())?)\n    .await\n    .map_err(|e| {\n        error!(\"Failed to query file {} from database: {}\", file_id, e);\n        format!(\"File not found: {}\", file_id)\n    })?;\n\n    // Load MIDI file and parse events\n    let loaded_midi = load_midi_file(\u0026file_result.filepath)\n        .map_err(|e| {\n            error!(\"Failed to load MIDI file {}: {}\", file_result.filepath, e);\n            format!(\"Failed to load MIDI file: {}\", e)\n        })?;\n\n    info!(\n        \"Loaded {} events from file {} ({})\",\n        loaded_midi.events.len(),\n        file_id,\n        file_result.filepath\n    );\n\n    // Add track with loaded events\n    let track_manager = engine.track_manager();\n    let track = track_manager.add_track(file_id, channel, loaded_midi.events).await?;\n\n    // Reload tracks in engine to update scheduler\n    engine.load_tracks().await;\n\n    Ok(track)\n}\n\n/// Remove a track from the sequencer\n#[tauri::command]\npub async fn remove_track(\n    track_id: i32,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let track_manager = engine.track_manager();\n    track_manager.remove_track(track_id).await?;\n\n    // Remove track's events from scheduler\n    let scheduler = engine.scheduler();\n    scheduler.clear_track(track_id).await;\n\n    Ok(())\n}\n\n/// Update track properties (mute, solo, volume, pan)\n#[tauri::command]\npub async fn update_track(\n    track_id: i32,\n    properties: TrackProperties,\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let track_manager = engine.track_manager();\n    track_manager.update_track(track_id, properties).await?;\n\n    // Reload tracks to update scheduler\n    engine.load_tracks().await;\n\n    Ok(())\n}\n\n/// Get all tracks in current project\n#[tauri::command]\npub async fn get_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cVec\u003cTrack\u003e, String\u003e {\n    let track_manager = engine.track_manager();\n    Ok(track_manager.get_tracks().await)\n}\n\n/// Load tracks into sequencer and prepare for playback\n#[tauri::command]\npub async fn load_sequencer_tracks(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    engine.load_tracks().await;\n    Ok(())\n}\n\n/// Check if sequencer is currently playing\n#[tauri::command]\npub async fn is_sequencer_playing(\n    engine: State\u003c'_, Arc\u003cSequencerEngine\u003e\u003e,\n) -\u003e Result\u003cbool, String\u003e {\n    use crate::sequencer::engine::PlaybackState;\n\n    let state = engine.get_state().await;\n    Ok(state == PlaybackState::Playing)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","mod.rs"],"content":"//! Compatibility module - Musical matching algorithms\n//!\n//! Trusty Module: Pure functions for calculating compatibility between MIDI files.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod music;\npub mod scoring;\npub mod types;\n\n// Re-export commonly used items\n#[allow(unused_imports)]\npub use music::{\n    bpm_compatibility_score, bpm_time_stretchable, is_relative_key, key_compatibility_score,\n    key_distance, keys_compatible,\n};\n#[allow(unused_imports)]\npub use scoring::{calculate_compatibility, explain_compatibility};\n#[allow(unused_imports)]\npub use types::{CompatibilityScore, Key, KeySignature, Mode};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","music.rs"],"content":"//! Music theory utilities - Pure functions for musical analysis\n//!\n//! Trusty Module: All functions are pure - no I/O, fully deterministic.\n\nuse super::types::{Key, KeySignature, Mode};\n\n/// Calculate distance between two keys in semitones\n///\n/// Returns the minimum distance around the circle of fifths (0-6).\n/// Example: C to G is 5 semitones (perfect fifth).\n///\n/// # Arguments\n/// * `key1` - First key\n/// * `key2` - Second key\n///\n/// # Returns\n/// Minimum distance (0-6 semitones)\npub fn key_distance(key1: Key, key2: Key) -\u003e i32 {\n    let diff = (key1.semitone() - key2.semitone()).abs();\n    // Return minimum distance around circle of fifths\n    diff.min(12 - diff)\n}\n\n/// Check if two key signatures are compatible\n///\n/// Keys are compatible if they:\n/// - Are the same key\n/// - Are relative major/minor (share the same notes)\n/// - Are a perfect fifth apart (circle of fifths)\npub fn keys_compatible(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e bool {\n    // Same key = perfect match\n    if ks1.key == ks2.key \u0026\u0026 ks1.mode == ks2.mode {\n        return true;\n    }\n\n    // Relative major/minor (e.g., C major and A minor)\n    if is_relative_key(ks1, ks2) {\n        return true;\n    }\n\n    // Perfect fifth apart (very compatible)\n    let distance = key_distance(ks1.key, ks2.key);\n    if distance == 5 {\n        return true;\n    }\n\n    false\n}\n\n/// Check if two keys are relative (share the same notes)\n///\n/// Relative keys have different modes but share the same notes.\n/// Example: C Major and A Minor are relative keys.\n///\n/// # Arguments\n/// * `ks1` - First key signature\n/// * `ks2` - Second key signature\n///\n/// # Returns\n/// True if keys are relative (e.g., C Major and A Minor)\npub fn is_relative_key(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e bool {\n    if ks1.mode == ks2.mode {\n        return false;\n    }\n\n    // A minor is relative to C major (3 semitones down from major to minor)\n    let major = if ks1.mode == Mode::Major { ks1 } else { ks2 };\n    let minor = if ks1.mode == Mode::Minor { ks1 } else { ks2 };\n\n    let diff = (major.key.semitone() - minor.key.semitone() + 12) % 12;\n    diff == 3 // Minor is 3 semitones below its relative major\n}\n\n/// Get compatibility score for two key signatures (0-100)\n///\n/// Scoring:\n/// - 100: Same key and mode (perfect match)\n/// - 95: Relative major/minor (share notes)\n/// - 85: Perfect fifth apart (circle of fifths)\n/// - 70: Major/minor third apart\n/// - 55: Whole tone apart\n/// - 40: Semitone apart\n/// - 20: Tritone (augmented fourth)\npub fn key_compatibility_score(ks1: \u0026KeySignature, ks2: \u0026KeySignature) -\u003e f32 {\n    // Perfect match\n    if ks1.key == ks2.key \u0026\u0026 ks1.mode == ks2.mode {\n        return 100.0;\n    }\n\n    // Relative keys (share notes)\n    if is_relative_key(ks1, ks2) {\n        return 95.0;\n    }\n\n    let distance = key_distance(ks1.key, ks2.key);\n\n    // Perfect fifth (7 semitones) - very compatible\n    if distance == 5 {\n        return 85.0;\n    }\n\n    // Major/minor third (3-4 semitones) - compatible\n    if distance == 3 || distance == 4 {\n        return 70.0;\n    }\n\n    // Whole tone (2 semitones) - somewhat compatible\n    if distance == 2 {\n        return 55.0;\n    }\n\n    // Adjacent keys (1 semitone) - less compatible\n    if distance == 1 {\n        return 40.0;\n    }\n\n    // Tritone (6 semitones) - least compatible\n    if distance == 6 {\n        return 20.0;\n    }\n\n    50.0 // Default\n}\n\n/// Calculate BPM compatibility score (0-100)\n///\n/// Scores tempo similarity for DJ mixing and mashups.\n///\n/// # Arguments\n/// * `bpm1` - First tempo in BPM\n/// * `bpm2` - Second tempo in BPM\n///\n/// # Returns\n/// Compatibility score (0-100)\npub fn bpm_compatibility_score(bpm1: f32, bpm2: f32) -\u003e f32 {\n    let diff = (bpm1 - bpm2).abs();\n\n    // Perfect match\n    if diff \u003c 1.0 {\n        return 100.0;\n    }\n\n    // Very close (within 5 BPM)\n    if diff \u003c 5.0 {\n        return 95.0 - (diff * 1.0);\n    }\n\n    // Close (within 10 BPM)\n    if diff \u003c 10.0 {\n        return 90.0 - (diff * 0.5);\n    }\n\n    // Within 20 BPM\n    if diff \u003c 20.0 {\n        return 80.0 - (diff * 0.3);\n    }\n\n    // Within 40 BPM\n    if diff \u003c 40.0 {\n        return 70.0 - (diff * 0.2);\n    }\n\n    // Too different\n    30.0\n}\n\n/// Check if BPMs can be time-stretched to match\n///\n/// Returns true if the tempo ratio matches common musical ratios:\n/// - 2:1 (double-time)\n/// - 3:2 (sesquialtera)\n/// - 4:3 (perfect fourth)\n/// - And their inverses\n///\n/// # Arguments\n/// * `bpm1` - First tempo\n/// * `bpm2` - Second tempo\n///\n/// # Returns\n/// True if tempos can be time-stretched with minimal artifacts\npub fn bpm_time_stretchable(bpm1: f32, bpm2: f32) -\u003e bool {\n    let ratio = bpm1 / bpm2;\n    // Check if ratio is close to 2:1, 3:2, 4:3 (common musical ratios)\n    let ratios = [2.0, 1.5, 1.333, 0.5, 0.667, 0.75];\n\n    for target_ratio in ratios {\n        if (ratio - target_ratio).abs() \u003c 0.1 {\n            return true;\n        }\n    }\n\n    false\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_distance_same() {\n        assert_eq!(key_distance(Key::C, Key::C), 0);\n        assert_eq!(key_distance(Key::A, Key::A), 0);\n    }\n\n    #[test]\n    fn test_key_distance_fifth() {\n        // C to G is a perfect fifth (5 semitones forward, 7 back)\n        assert_eq!(key_distance(Key::C, Key::G), 5);\n        // Going the other way should be the same\n        assert_eq!(key_distance(Key::G, Key::C), 5);\n    }\n\n    #[test]\n    fn test_key_distance_tritone() {\n        // C to F# is a tritone (6 semitones - maximum distance)\n        assert_eq!(key_distance(Key::C, Key::FSharp), 6);\n    }\n\n    #[test]\n    fn test_key_distance_wraparound() {\n        // A to C is 3 semitones forward (A=9, C=0: (9-0).abs().min(12-9) = 3)\n        assert_eq!(key_distance(Key::A, Key::C), 3);\n    }\n\n    #[test]\n    fn test_relative_keys() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let a_minor = KeySignature {\n            key: Key::A,\n            mode: Mode::Minor,\n        };\n\n        assert!(is_relative_key(\u0026c_major, \u0026a_minor));\n        assert!(is_relative_key(\u0026a_minor, \u0026c_major));\n    }\n\n    #[test]\n    fn test_not_relative_keys() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let c_minor = KeySignature {\n            key: Key::C,\n            mode: Mode::Minor,\n        };\n\n        assert!(!is_relative_key(\u0026c_major, \u0026c_minor));\n    }\n\n    #[test]\n    fn test_keys_compatible() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let g_major = KeySignature {\n            key: Key::G,\n            mode: Mode::Major,\n        };\n\n        assert!(keys_compatible(\u0026c_major, \u0026c_major)); // Same key\n        assert!(keys_compatible(\u0026c_major, \u0026g_major)); // Perfect fifth\n    }\n\n    #[test]\n    fn test_key_compatibility_perfect_match() {\n        let key = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026key, \u0026key), 100.0);\n    }\n\n    #[test]\n    fn test_key_compatibility_relative() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let a_minor = KeySignature {\n            key: Key::A,\n            mode: Mode::Minor,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026c_major, \u0026a_minor), 95.0);\n    }\n\n    #[test]\n    fn test_key_compatibility_fifth() {\n        let c_major = KeySignature {\n            key: Key::C,\n            mode: Mode::Major,\n        };\n        let g_major = KeySignature {\n            key: Key::G,\n            mode: Mode::Major,\n        };\n\n        assert_eq!(key_compatibility_score(\u0026c_major, \u0026g_major), 85.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_exact_match() {\n        assert_eq!(bpm_compatibility_score(120.0, 120.0), 100.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_close() {\n        let score = bpm_compatibility_score(120.0, 122.0);\n        assert!(score \u003e 90.0);\n        assert!(score \u003c 100.0);\n    }\n\n    #[test]\n    fn test_bpm_compatibility_far() {\n        let score = bpm_compatibility_score(120.0, 180.0);\n        assert!(score \u003c 50.0);\n    }\n\n    #[test]\n    fn test_bpm_time_stretchable() {\n        // Double tempo should be stretchable\n        assert!(bpm_time_stretchable(120.0, 240.0));\n\n        // 3:2 ratio should be stretchable\n        assert!(bpm_time_stretchable(120.0, 180.0));\n\n        // Random ratio should not be\n        assert!(!bpm_time_stretchable(120.0, 137.0));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","scoring.rs"],"content":"//! Compatibility scoring - Overall compatibility calculation\n//!\n//! Trusty Module: Pure function that calculates compatibility scores.\n//! NO database access - receives file data as parameters.\n\nuse crate::models::midi_file::MidiFile;\nuse super::music::{bpm_compatibility_score, bpm_time_stretchable, key_compatibility_score};\nuse super::types::{CompatibilityScore, KeySignature};\n\n/// Calculate overall compatibility score between two MIDI files\n///\n/// This is the main entry point for compatibility calculation.\n/// It combines multiple factors with weighted scoring:\n/// - 40% Key compatibility (harmonic compatibility)\n/// - 40% BPM compatibility (tempo matching)\n/// - 20% Category compatibility (style/instrument matching)\n///\n/// # Arguments\n/// * `source` - The source file to compare against\n/// * `candidate` - The candidate file to score\n///\n/// # Returns\n/// CompatibilityScore with detailed breakdown\npub fn calculate_compatibility(\n    source: \u0026MidiFile,\n    candidate: \u0026MidiFile,\n) -\u003e CompatibilityScore {\n    let mut total_score = 0.0;\n    let mut explanations = Vec::new();\n\n    // Key compatibility (40% weight)\n    let key_score = if let (Some(key1_str), Some(key2_str)) =\n        (\u0026source.key_signature, \u0026candidate.key_signature)\n    {\n        if let (Some(key1), Some(key2)) = (\n            KeySignature::from_str(key1_str),\n            KeySignature::from_str(key2_str),\n        ) {\n            let score = key_compatibility_score(\u0026key1, \u0026key2);\n\n            if score \u003e= 95.0 {\n                explanations.push(\"Perfect key match\".to_string());\n            } else if score \u003e= 85.0 {\n                explanations.push(\"Excellent key compatibility\".to_string());\n            } else if score \u003e= 70.0 {\n                explanations.push(\"Good key compatibility\".to_string());\n            } else if score \u003c 50.0 {\n                explanations.push(\"Keys may clash\".to_string());\n            }\n\n            total_score += score * 0.4;\n            score\n        } else {\n            50.0 // Unknown keys\n        }\n    } else {\n        50.0 // Missing key information\n    };\n\n    // BPM compatibility (40% weight)\n    let bpm_score = if let (Some(bpm1), Some(bpm2)) = (source.bpm, candidate.bpm) {\n        // Cast f64 to f32 for compatibility functions\n        let score = bpm_compatibility_score(bpm1 as f32, bpm2 as f32);\n\n        if score \u003e= 95.0 {\n            explanations.push(\"Nearly identical tempo\".to_string());\n        } else if score \u003e= 80.0 {\n            explanations.push(\"Similar tempo\".to_string());\n        } else if bpm_time_stretchable(bpm1 as f32, bpm2 as f32) {\n            explanations.push(\"Tempo can be time-stretched\".to_string());\n        } else if score \u003c 50.0 {\n            explanations.push(\"Very different tempos\".to_string());\n        }\n\n        total_score += score * 0.4;\n        score\n    } else {\n        50.0 // Missing BPM information\n    };\n\n    // Category compatibility (20% weight)\n    let category_score = if let (Some(cat1), Some(cat2)) =\n        (\u0026source.primary_category, \u0026candidate.primary_category)\n    {\n        let score = if cat1 == cat2 {\n            100.0\n        } else {\n            category_compatibility(cat1, cat2)\n        };\n\n        if score \u003e= 90.0 {\n            explanations.push(\"Same or complementary category\".to_string());\n        }\n\n        total_score += score * 0.2;\n        score\n    } else {\n        50.0\n    };\n\n    // Build explanation\n    let explanation = if explanations.is_empty() {\n        \"Limited metadata available\".to_string()\n    } else {\n        explanations.join(\". \")\n    };\n\n    CompatibilityScore {\n        total_score,\n        key_score,\n        bpm_score,\n        category_score,\n        explanation,\n    }\n}\n\n/// Determine category compatibility\n///\n/// Scores how well two categories work together musically.\n/// Same category = 100, complementary categories = 80, different = 50.\nfn category_compatibility(cat1: \u0026str, cat2: \u0026str) -\u003e f32 {\n    // Normalize categories\n    let cat1 = cat1.to_lowercase();\n    let cat2 = cat2.to_lowercase();\n\n    // Same category = perfect\n    if cat1 == cat2 {\n        return 100.0;\n    }\n\n    // Define complementary categories (work well together)\n    let complementary_pairs = vec![\n        (\"kick\", \"bass\"),\n        (\"kick\", \"drum\"),\n        (\"snare\", \"hihat\"),\n        (\"bass\", \"chord\"),\n        (\"chord\", \"lead\"),\n        (\"pad\", \"lead\"),\n        (\"melody\", \"chord\"),\n        (\"drum\", \"percussion\"),\n    ];\n\n    for (a, b) in complementary_pairs {\n        if (cat1.contains(a) \u0026\u0026 cat2.contains(b)) || (cat1.contains(b) \u0026\u0026 cat2.contains(a)) {\n            return 80.0;\n        }\n    }\n\n    // Different but compatible\n    50.0\n}\n\n/// Generate human-readable explanation for compatibility score\n///\n/// Creates a summary explanation based on the overall score.\n///\n/// # Arguments\n/// * `source` - Source file (not currently used, but available for context)\n/// * `candidate` - Candidate file (not currently used, but available for context)\n/// * `score` - The compatibility score to explain\n///\n/// # Returns\n/// Human-readable explanation string\npub fn explain_compatibility(\n    _source: \u0026MidiFile,\n    _candidate: \u0026MidiFile,\n    score: \u0026CompatibilityScore,\n) -\u003e String {\n    let mut parts = Vec::new();\n\n    if score.total_score \u003e= 90.0 {\n        parts.push(\"Highly compatible\".to_string());\n    } else if score.total_score \u003e= 75.0 {\n        parts.push(\"Very compatible\".to_string());\n    } else if score.total_score \u003e= 60.0 {\n        parts.push(\"Compatible\".to_string());\n    } else if score.total_score \u003e= 50.0 {\n        parts.push(\"Somewhat compatible\".to_string());\n    } else {\n        parts.push(\"Limited compatibility\".to_string());\n    }\n\n    parts.push(score.explanation.clone());\n\n    parts.join(\". \")\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_category_compatibility_same() {\n        assert_eq!(category_compatibility(\"kick\", \"kick\"), 100.0);\n        assert_eq!(category_compatibility(\"bass\", \"bass\"), 100.0);\n    }\n\n    #[test]\n    fn test_category_compatibility_complementary() {\n        assert_eq!(category_compatibility(\"kick\", \"bass\"), 80.0);\n        assert_eq!(category_compatibility(\"bass\", \"kick\"), 80.0);\n        assert_eq!(category_compatibility(\"lead\", \"pad\"), 80.0);\n        assert_eq!(category_compatibility(\"chord\", \"melody\"), 80.0);\n    }\n\n    #[test]\n    fn test_category_compatibility_different() {\n        let score = category_compatibility(\"kick\", \"melody\");\n        assert!(score \u003c 80.0);\n        assert!(score \u003e= 50.0);\n    }\n\n    #[test]\n    fn test_explain_compatibility_high_score() {\n        let score = CompatibilityScore {\n            total_score: 92.0,\n            key_score: 95.0,\n            bpm_score: 90.0,\n            category_score: 90.0,\n            explanation: \"Perfect key match. Similar tempo\".to_string(),\n        };\n\n        let file = create_test_file();\n        let explanation = explain_compatibility(\u0026file, \u0026file, \u0026score);\n\n        assert!(explanation.contains(\"Highly compatible\"));\n        assert!(explanation.contains(\"Perfect key match\"));\n    }\n\n    #[test]\n    fn test_explain_compatibility_low_score() {\n        let score = CompatibilityScore {\n            total_score: 45.0,\n            key_score: 40.0,\n            bpm_score: 50.0,\n            category_score: 50.0,\n            explanation: \"Keys may clash. Very different tempos\".to_string(),\n        };\n\n        let file = create_test_file();\n        let explanation = explain_compatibility(\u0026file, \u0026file, \u0026score);\n\n        assert!(explanation.contains(\"Limited compatibility\"));\n    }\n\n    // Helper function to create test MidiFile\n    fn create_test_file() -\u003e MidiFile {\n        MidiFile {\n            id: 1,\n            filename: \"test.mid\".to_string(),\n            filepath: \"/test/test.mid\".to_string(),\n            file_size_bytes: 1024,\n            content_hash: vec![],\n            is_multi_track: false,\n            parent_file_id: None,\n            track_number: None,\n            total_tracks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: vec![],\n            parent_folder: None,\n            num_tracks: 1,\n            created_at: chrono::Utc::now(),\n            analyzed_at: None,\n            bpm: Some(120.0),\n            key_signature: Some(\"C\".to_string()),\n            time_signature: Some(\"4/4\".to_string()),\n            duration_seconds: Some(10.0),\n            total_notes: 100,\n            primary_category: Some(\"bass\".to_string()),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","compatibility","types.rs"],"content":"//! Compatibility types - Music theory data structures\n//!\n//! Trusty Module: Pure data types for compatibility calculations.\n\nuse serde::{Deserialize, Serialize};\n\n/// Musical key\n///\n/// Represents the 12 chromatic pitches using semitone numbering (0-11).\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub enum Key {\n    C = 0,\n    CSharp = 1,\n    D = 2,\n    DSharp = 3,\n    E = 4,\n    F = 5,\n    FSharp = 6,\n    G = 7,\n    GSharp = 8,\n    A = 9,\n    ASharp = 10,\n    B = 11,\n}\n\nimpl Key {\n    /// Parse key from string (e.g., \"C\", \"C#\", \"Db\")\n    ///\n    /// Supports both sharp and flat notation (enharmonic equivalents).\n    pub fn from_str(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let normalized = s.to_uppercase().replace(\" \", \"\");\n\n        match normalized.as_str() {\n            \"C\" =\u003e Some(Key::C),\n            \"C#\" | \"DB\" =\u003e Some(Key::CSharp),\n            \"D\" =\u003e Some(Key::D),\n            \"D#\" | \"EB\" =\u003e Some(Key::DSharp),\n            \"E\" =\u003e Some(Key::E),\n            \"F\" =\u003e Some(Key::F),\n            \"F#\" | \"GB\" =\u003e Some(Key::FSharp),\n            \"G\" =\u003e Some(Key::G),\n            \"G#\" | \"AB\" =\u003e Some(Key::GSharp),\n            \"A\" =\u003e Some(Key::A),\n            \"A#\" | \"BB\" =\u003e Some(Key::ASharp),\n            \"B\" =\u003e Some(Key::B),\n            _ =\u003e None,\n        }\n    }\n\n    /// Get semitone value (0-11)\n    pub fn semitone(\u0026self) -\u003e i32 {\n        *self as i32\n    }\n\n    /// Get key name as string\n    pub fn name(\u0026self) -\u003e \u0026'static str {\n        match self {\n            Key::C =\u003e \"C\",\n            Key::CSharp =\u003e \"C#\",\n            Key::D =\u003e \"D\",\n            Key::DSharp =\u003e \"D#\",\n            Key::E =\u003e \"E\",\n            Key::F =\u003e \"F\",\n            Key::FSharp =\u003e \"F#\",\n            Key::G =\u003e \"G\",\n            Key::GSharp =\u003e \"G#\",\n            Key::A =\u003e \"A\",\n            Key::ASharp =\u003e \"A#\",\n            Key::B =\u003e \"B\",\n        }\n    }\n}\n\n/// Musical mode (major or minor)\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Mode {\n    Major,\n    Minor,\n}\n\nimpl Mode {\n    /// Parse mode from string\n    ///\n    /// Detects 'm' or 'min' for minor, defaults to major.\n    pub fn from_str(s: \u0026str) -\u003e Self {\n        let lower = s.to_lowercase();\n        if lower.contains('m') \u0026\u0026 !lower.contains(\"maj\") {\n            Mode::Minor\n        } else {\n            Mode::Major\n        }\n    }\n}\n\n/// Complete key signature (key + mode)\n///\n/// Represents the tonality of a piece (e.g., \"C Major\", \"Am\").\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub struct KeySignature {\n    pub key: Key,\n    pub mode: Mode,\n}\n\nimpl KeySignature {\n    /// Parse from string (e.g., \"C\", \"Am\", \"F# Major\")\n    pub fn from_str(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let mode = Mode::from_str(s);\n\n        // Extract key name (first part before mode indicator)\n        let key_part = s\n            .split_whitespace()\n            .next()\n            .unwrap_or(s)\n            .trim_end_matches('m');\n\n        let key = Key::from_str(key_part)?;\n\n        Some(KeySignature { key, mode })\n    }\n\n    /// Get human-readable name (e.g., \"C Major\", \"Am\")\n    pub fn name(\u0026self) -\u003e String {\n        match self.mode {\n            Mode::Major =\u003e format!(\"{} Major\", self.key.name()),\n            Mode::Minor =\u003e format!(\"{}m\", self.key.name()),\n        }\n    }\n}\n\n/// Compatibility score with detailed breakdown\n///\n/// All scores are 0-100 (percentage compatibility).\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CompatibilityScore {\n    pub total_score: f32,      // Overall compatibility (0-100)\n    pub key_score: f32,         // Key/harmony compatibility (0-100)\n    pub bpm_score: f32,         // Tempo compatibility (0-100)\n    pub category_score: f32,    // Category/style compatibility (0-100)\n    pub explanation: String,    // Human-readable explanation\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_from_str() {\n        assert_eq!(Key::from_str(\"C\").unwrap(), Key::C);\n        assert_eq!(Key::from_str(\"C#\").unwrap(), Key::CSharp);\n        assert_eq!(Key::from_str(\"Db\").unwrap(), Key::CSharp); // Enharmonic\n        assert_eq!(Key::from_str(\"G\").unwrap(), Key::G);\n        assert!(Key::from_str(\"invalid\").is_none());\n    }\n\n    #[test]\n    fn test_key_semitone() {\n        assert_eq!(Key::C.semitone(), 0);\n        assert_eq!(Key::CSharp.semitone(), 1);\n        assert_eq!(Key::B.semitone(), 11);\n    }\n\n    #[test]\n    fn test_mode_from_str() {\n        assert_eq!(Mode::from_str(\"Major\"), Mode::Major);\n        assert_eq!(Mode::from_str(\"Minor\"), Mode::Minor);\n        assert_eq!(Mode::from_str(\"m\"), Mode::Minor);\n        assert_eq!(Mode::from_str(\"\"), Mode::Major); // Default\n    }\n\n    #[test]\n    fn test_key_signature_from_str() {\n        let c_maj = KeySignature::from_str(\"C\").unwrap();\n        assert_eq!(c_maj.key, Key::C);\n        assert_eq!(c_maj.mode, Mode::Major);\n\n        let a_min = KeySignature::from_str(\"Am\").unwrap();\n        assert_eq!(a_min.key, Key::A);\n        assert_eq!(a_min.mode, Mode::Minor);\n\n        let g_maj = KeySignature::from_str(\"G Major\").unwrap();\n        assert_eq!(g_maj.key, Key::G);\n        assert_eq!(g_maj.mode, Mode::Major);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","loader.rs"],"content":"//! MIDI file loading and parsing\n//!\n//! Trusty Module: Pure functions for loading and parsing MIDI files.\n//! Uses midly crate for efficient MIDI parsing.\n\nuse midly::{Smf, Timing, TrackEventKind, MidiMessage as MidlyMessage};\nuse std::fs;\nuse std::path::Path;\nuse crate::models::midi::{MidiEvent, MidiEventType};\nuse tracing::debug;\n\n/// Load and parse a MIDI file from disk\n///\n/// Returns all MIDI events with absolute tick positions.\n///\n/// # Arguments\n/// * `filepath` - Path to the MIDI file\n///\n/// # Returns\n/// Result containing vector of parsed MIDI events with timing information\npub fn load_midi_file(filepath: \u0026str) -\u003e Result\u003cLoadedMidiFile, String\u003e {\n    let path = Path::new(filepath);\n\n    if !path.exists() {\n        return Err(format!(\"MIDI file not found: {}\", filepath));\n    }\n\n    // Read file bytes\n    let bytes = fs::read(path)\n        .map_err(|e| format!(\"Failed to read MIDI file {}: {}\", filepath, e))?;\n\n    // Parse MIDI file\n    let smf = Smf::parse(\u0026bytes)\n        .map_err(|e| format!(\"Failed to parse MIDI file {}: {}\", filepath, e))?;\n\n    // Extract timing information\n    let ticks_per_quarter = match smf.header.timing {\n        Timing::Metrical(tpq) =\u003e tpq.as_int() as u32,\n        Timing::Timecode(fps, sub) =\u003e {\n            // Convert timecode to ticks per quarter note (approximate)\n            let ticks_per_second = fps.as_f32() * sub as f32;\n            (ticks_per_second * 0.5) as u32 // Assume 120 BPM default\n        }\n    };\n\n    let format_num = match smf.header.format {\n        midly::Format::SingleTrack =\u003e 0,\n        midly::Format::Parallel =\u003e 1,\n        midly::Format::Sequential =\u003e 2,\n    };\n\n    debug!(\n        \"Loaded MIDI file: {} (format {}, {} tracks, {} ticks/quarter)\",\n        filepath,\n        format_num,\n        smf.tracks.len(),\n        ticks_per_quarter\n    );\n\n    // Parse events from all tracks\n    let mut all_events = Vec::new();\n    for (track_idx, track) in smf.tracks.iter().enumerate() {\n        let track_events = parse_track_events(track, track_idx as u8, ticks_per_quarter)?;\n        all_events.extend(track_events);\n    }\n\n    // Sort events by tick\n    all_events.sort_by_key(|e| e.tick);\n\n    Ok(LoadedMidiFile {\n        events: all_events,\n        ticks_per_quarter,\n        num_tracks: smf.tracks.len() as u16,\n        format: format_num,\n    })\n}\n\n/// Loaded MIDI file with metadata\n#[derive(Debug, Clone)]\npub struct LoadedMidiFile {\n    pub events: Vec\u003cMidiEvent\u003e,\n    pub ticks_per_quarter: u32,\n    pub num_tracks: u16,\n    pub format: u16,\n}\n\n/// Parse events from a single MIDI track\nfn parse_track_events(\n    track: \u0026midly::Track,\n    default_channel: u8,\n    ticks_per_quarter: u32,\n) -\u003e Result\u003cVec\u003cMidiEvent\u003e, String\u003e {\n    let mut events = Vec::new();\n    let mut absolute_tick: u64 = 0;\n    let mut current_channel = default_channel;\n\n    for event in track.iter() {\n        // Update absolute tick position\n        absolute_tick += event.delta.as_int() as u64;\n\n        match event.kind {\n            TrackEventKind::Midi { channel, message } =\u003e {\n                current_channel = channel.as_int();\n\n                if let Some(midi_event) = convert_midi_message(\n                    message,\n                    current_channel,\n                    absolute_tick,\n                    ticks_per_quarter,\n                ) {\n                    events.push(midi_event);\n                }\n            }\n            TrackEventKind::Meta(_) =\u003e {\n                // Skip meta events for now (tempo, time signature, etc.)\n                // These could be parsed in future for more accurate playback\n            }\n            TrackEventKind::SysEx(_) =\u003e {\n                // Skip SysEx events\n            }\n            TrackEventKind::Escape(_) =\u003e {\n                // Skip escape events\n            }\n        }\n    }\n\n    debug!(\"Parsed {} events from track (channel {})\", events.len(), current_channel);\n    Ok(events)\n}\n\n/// Convert midly MIDI message to our MidiEvent format\nfn convert_midi_message(\n    message: MidlyMessage,\n    channel: u8,\n    tick: u64,\n    _ticks_per_quarter: u32,\n) -\u003e Option\u003cMidiEvent\u003e {\n    match message {\n        MidlyMessage::NoteOff { key, vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::NoteOff,\n            tick,\n            channel,\n            note: Some(key.as_int()),\n            velocity: Some(vel.as_int()),\n            controller: None,\n            value: None,\n            program: None,\n        }),\n        MidlyMessage::NoteOn { key, vel } =\u003e {\n            // Note: velocity 0 should be treated as Note Off\n            let event_type = if vel.as_int() == 0 {\n                MidiEventType::NoteOff\n            } else {\n                MidiEventType::NoteOn\n            };\n\n            Some(MidiEvent {\n                event_type,\n                tick,\n                channel,\n                note: Some(key.as_int()),\n                velocity: Some(vel.as_int()),\n                controller: None,\n                value: None,\n                program: None,\n            })\n        }\n        MidlyMessage::Aftertouch { key, vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::Aftertouch,\n            tick,\n            channel,\n            note: Some(key.as_int()),\n            value: Some(vel.as_int()),\n            velocity: None,\n            controller: None,\n            program: None,\n        }),\n        MidlyMessage::Controller { controller, value } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::ControlChange,\n            tick,\n            channel,\n            controller: Some(controller.as_int()),\n            value: Some(value.as_int()),\n            note: None,\n            velocity: None,\n            program: None,\n        }),\n        MidlyMessage::ProgramChange { program } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::ProgramChange,\n            tick,\n            channel,\n            program: Some(program.as_int()),\n            note: None,\n            velocity: None,\n            controller: None,\n            value: None,\n        }),\n        MidlyMessage::ChannelAftertouch { vel } =\u003e Some(MidiEvent {\n            event_type: MidiEventType::Aftertouch,\n            tick,\n            channel,\n            value: Some(vel.as_int()),\n            note: None,\n            velocity: None,\n            controller: None,\n            program: None,\n        }),\n        MidlyMessage::PitchBend { bend } =\u003e {\n            // Convert 14-bit pitch bend to two 7-bit values\n            let bend_value = bend.as_int() as u16;\n            Some(MidiEvent {\n                event_type: MidiEventType::PitchBend,\n                tick,\n                channel,\n                value: Some((bend_value \u0026 0x7F) as u8), // LSB\n                velocity: Some(((bend_value \u003e\u003e 7) \u0026 0x7F) as u8), // MSB\n                note: None,\n                controller: None,\n                program: None,\n            })\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_load_nonexistent_file() {\n        let result = load_midi_file(\"/nonexistent/path/file.mid\");\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"not found\"));\n    }\n\n    #[test]\n    fn test_convert_note_on() {\n        let message = MidlyMessage::NoteOn {\n            key: 60.into(),\n            vel: 100.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        assert_eq!(event.event_type, MidiEventType::NoteOn);\n        assert_eq!(event.note, Some(60));\n        assert_eq!(event.velocity, Some(100));\n    }\n\n    #[test]\n    fn test_convert_note_on_zero_velocity() {\n        let message = MidlyMessage::NoteOn {\n            key: 60.into(),\n            vel: 0.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        // Zero velocity Note On should become Note Off\n        assert_eq!(event.event_type, MidiEventType::NoteOff);\n    }\n\n    #[test]\n    fn test_convert_control_change() {\n        let message = MidlyMessage::Controller {\n            controller: 7.into(), // Volume\n            value: 100.into(),\n        };\n\n        let event = convert_midi_message(message, 0, 0, 480).unwrap();\n        assert_eq!(event.event_type, MidiEventType::ControlChange);\n        assert_eq!(event.controller, Some(7));\n        assert_eq!(event.value, Some(100));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","mod.rs"],"content":"//! MIDI Core - Trusty Modules\n//!\n//! Pure functions for MIDI event encoding, decoding, and validation.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod parser;\npub mod types;\npub mod validator;\npub mod writer;\npub mod loader;\n\n#[allow(unused_imports)]\npub use parser::{parse_midi, ParseError};\n#[allow(unused_imports)]\npub use types::{MidiMessage, MidiEventType};\n#[allow(unused_imports)]\npub use validator::{\n    validate_channel, validate_note, validate_velocity,\n    validate_control_value, validate_message\n};\n#[allow(unused_imports)]\npub use writer::write_midi_file;\n#[allow(unused_imports)]\npub use loader::{load_midi_file, LoadedMidiFile};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","parser.rs"],"content":"//! MIDI File Parser - Trusty Module\n//!\n//! Pure functions for parsing MIDI files into data structures.\n//! NO I/O - caller reads file and passes bytes.\n\nuse crate::models::midi::{MidiEvent, MidiEventType, MidiPattern};\n\n/// Parse error types\n#[derive(Debug, thiserror::Error)]\npub enum ParseError {\n    #[error(\"Invalid MIDI file format: {0}\")]\n    InvalidFormat(String),\n\n    #[error(\"Unsupported MIDI format: {0}\")]\n    UnsupportedFormat(String),\n\n    #[error(\"Incomplete data at position {0}\")]\n    IncompleteData(usize),\n\n    #[error(\"Invalid track data: {0}\")]\n    InvalidTrack(String),\n}\n\n/// Parse complete MIDI file\npub fn parse_midi(data: \u0026[u8]) -\u003e Result\u003cMidiPattern, ParseError\u003e {\n    if data.is_empty() {\n        return Err(ParseError::IncompleteData(0));\n    }\n\n    let mut reader = MidiReader::new(data);\n\n    // Parse header\n    let header = parse_header(\u0026mut reader)?;\n\n    // Parse tracks\n    let mut all_events = Vec::new();\n\n    for _ in 0..header.num_tracks {\n        let track_events = parse_track(\u0026mut reader)?;\n        all_events.extend(track_events);\n    }\n\n    // Sort events by tick\n    all_events.sort_by_key(|e| e.tick);\n\n    let total_ticks = all_events.last().map(|e| e.tick).unwrap_or(0);\n\n    Ok(MidiPattern {\n        events: all_events,\n        ticks_per_quarter_note: header.ticks_per_quarter_note,\n        total_ticks,\n    })\n}\n\n/// MIDI file header\n#[derive(Debug)]\nstruct MidiHeader {\n    num_tracks: u16,\n    ticks_per_quarter_note: u16,\n}\n\n/// Parse MIDI header (MThd chunk)\nfn parse_header(reader: \u0026mut MidiReader) -\u003e Result\u003cMidiHeader, ParseError\u003e {\n    // Read \"MThd\"\n    let chunk_type = reader.read_bytes(4)?;\n    if chunk_type != b\"MThd\" {\n        return Err(ParseError::InvalidFormat(\"Expected MThd header\".to_string()));\n    }\n\n    // Read header length (should be 6)\n    let length = reader.read_u32()?;\n    if length != 6 {\n        return Err(ParseError::InvalidFormat(format!(\n            \"Invalid header length: {}\",\n            length\n        )));\n    }\n\n    // Read format (0, 1, or 2)\n    let format = reader.read_u16()?;\n    if format \u003e 2 {\n        return Err(ParseError::UnsupportedFormat(format!(\n            \"MIDI format {}\",\n            format\n        )));\n    }\n\n    // Read number of tracks\n    let num_tracks = reader.read_u16()?;\n\n    // Read ticks per quarter note\n    let ticks_per_quarter_note = reader.read_u16()?;\n\n    Ok(MidiHeader {\n        num_tracks,\n        ticks_per_quarter_note,\n    })\n}\n\n/// Parse a single track (MTrk chunk)\nfn parse_track(reader: \u0026mut MidiReader) -\u003e Result\u003cVec\u003cMidiEvent\u003e, ParseError\u003e {\n    // Read \"MTrk\"\n    let chunk_type = reader.read_bytes(4)?;\n    if chunk_type != b\"MTrk\" {\n        return Err(ParseError::InvalidTrack(\"Expected MTrk header\".to_string()));\n    }\n\n    // Read track length\n    let track_length = reader.read_u32()? as usize;\n    let track_end = reader.position() + track_length;\n\n    let mut events = Vec::new();\n    let mut current_tick: u64 = 0;\n    let mut running_status: Option\u003cu8\u003e = None;\n\n    while reader.position() \u003c track_end {\n        // Read delta time (variable length)\n        let delta_time = reader.read_variable_length()?;\n        current_tick += delta_time;\n\n        // Peek at next byte to determine if we need running status\n        let status_byte = reader.peek_u8()?;\n\n        let status = if status_byte \u0026 0x80 == 0 {\n            // Running status - reuse previous status\n            running_status.ok_or(ParseError::InvalidTrack(\n                \"No running status available\".to_string(),\n            ))?\n        } else {\n            let s = reader.read_u8()?;\n            if s != 0xFF \u0026\u0026 s != 0xF0 \u0026\u0026 s != 0xF7 {\n                // Not a meta event or sysex, save as running status\n                running_status = Some(s);\n            }\n            s\n        };\n\n        // Parse event based on status\n        if status == 0xFF {\n            // Meta event - skip it\n            let _meta_type = reader.read_u8()?;\n            let length = reader.read_variable_length()?;\n            reader.skip(length as usize)?;\n        } else if status == 0xF0 || status == 0xF7 {\n            // SysEx event - skip it\n            let length = reader.read_variable_length()?;\n            reader.skip(length as usize)?;\n        } else {\n            // Channel event\n            let command = status \u0026 0xF0;\n            let channel = status \u0026 0x0F;\n\n            let event = match command {\n                0x90 =\u003e {\n                    // Note On\n                    let note = reader.read_u8()?;\n                    let velocity = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::NoteOn,\n                        tick: current_tick,\n                        channel,\n                        note: Some(note),\n                        velocity: Some(velocity),\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0x80 =\u003e {\n                    // Note Off\n                    let note = reader.read_u8()?;\n                    let _velocity = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::NoteOff,\n                        tick: current_tick,\n                        channel,\n                        note: Some(note),\n                        velocity: Some(0),\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0xB0 =\u003e {\n                    // Control Change\n                    let controller = reader.read_u8()?;\n                    let value = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::ControlChange,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: Some(controller),\n                        value: Some(value),\n                        program: None,\n                    })\n                }\n                0xC0 =\u003e {\n                    // Program Change\n                    let program = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::ProgramChange,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: Some(program),\n                    })\n                }\n                0xE0 =\u003e {\n                    // Pitch Bend\n                    let _lsb = reader.read_u8()?;\n                    let _msb = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::PitchBend,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                0xD0 =\u003e {\n                    // Aftertouch\n                    let _value = reader.read_u8()?;\n                    Some(MidiEvent {\n                        event_type: MidiEventType::Aftertouch,\n                        tick: current_tick,\n                        channel,\n                        note: None,\n                        velocity: None,\n                        controller: None,\n                        value: None,\n                        program: None,\n                    })\n                }\n                _ =\u003e None,\n            };\n\n            if let Some(e) = event {\n                events.push(e);\n            }\n        }\n    }\n\n    Ok(events)\n}\n\n/// Helper for reading MIDI binary data\nstruct MidiReader\u003c'a\u003e {\n    data: \u0026'a [u8],\n    pos: usize,\n}\n\nimpl\u003c'a\u003e MidiReader\u003c'a\u003e {\n    fn new(data: \u0026'a [u8]) -\u003e Self {\n        Self { data, pos: 0 }\n    }\n\n    fn position(\u0026self) -\u003e usize {\n        self.pos\n    }\n\n    fn read_u8(\u0026mut self) -\u003e Result\u003cu8, ParseError\u003e {\n        if self.pos \u003e= self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        let value = self.data[self.pos];\n        self.pos += 1;\n        Ok(value)\n    }\n\n    fn peek_u8(\u0026self) -\u003e Result\u003cu8, ParseError\u003e {\n        if self.pos \u003e= self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        Ok(self.data[self.pos])\n    }\n\n    fn read_u16(\u0026mut self) -\u003e Result\u003cu16, ParseError\u003e {\n        let b1 = self.read_u8()? as u16;\n        let b2 = self.read_u8()? as u16;\n        Ok((b1 \u003c\u003c 8) | b2)\n    }\n\n    fn read_u32(\u0026mut self) -\u003e Result\u003cu32, ParseError\u003e {\n        let b1 = self.read_u8()? as u32;\n        let b2 = self.read_u8()? as u32;\n        let b3 = self.read_u8()? as u32;\n        let b4 = self.read_u8()? as u32;\n        Ok((b1 \u003c\u003c 24) | (b2 \u003c\u003c 16) | (b3 \u003c\u003c 8) | b4)\n    }\n\n    fn read_bytes(\u0026mut self, count: usize) -\u003e Result\u003c\u0026'a [u8], ParseError\u003e {\n        if self.pos + count \u003e self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        let bytes = \u0026self.data[self.pos..self.pos + count];\n        self.pos += count;\n        Ok(bytes)\n    }\n\n    fn read_variable_length(\u0026mut self) -\u003e Result\u003cu64, ParseError\u003e {\n        let mut value: u64;\n        let mut byte = self.read_u8()?;\n\n        value = (byte \u0026 0x7F) as u64;\n\n        while byte \u0026 0x80 != 0 {\n            byte = self.read_u8()?;\n            value = (value \u003c\u003c 7) | ((byte \u0026 0x7F) as u64);\n        }\n\n        Ok(value)\n    }\n\n    fn skip(\u0026mut self, count: usize) -\u003e Result\u003c(), ParseError\u003e {\n        if self.pos + count \u003e self.data.len() {\n            return Err(ParseError::IncompleteData(self.pos));\n        }\n        self.pos += count;\n        Ok(())\n    }\n}\n","traces":[{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":274,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":42},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","types.rs"],"content":"//! MIDI types and message encoding/decoding\n//!\n//! Trusty Module: Pure data structures and conversion functions.\n//! No I/O operations - all functions are pure and deterministic.\n\n// Re-export from models for convenience\npub use crate::models::MidiEventType;\n\n/// MIDI message with raw data\n///\n/// Internal representation used for encoding/decoding MIDI messages.\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct MidiMessage {\n    pub event_type: MidiEventType,\n    pub channel: u8,\n    pub data1: u8,\n    pub data2: u8,\n    pub timestamp: u64,\n}\n\nimpl MidiMessage {\n    /// Convert to raw MIDI bytes\n    ///\n    /// Pure function - converts MIDI message to bytes for transmission.\n    pub fn to_bytes(\u0026self) -\u003e Vec\u003cu8\u003e {\n        match self.event_type {\n            MidiEventType::NoteOn =\u003e {\n                vec![\n                    0x90 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    self.data2 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::NoteOff =\u003e {\n                vec![\n                    0x80 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    0x00,\n                ]\n            }\n            MidiEventType::ControlChange =\u003e {\n                vec![\n                    0xB0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                    self.data2 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::ProgramChange =\u003e {\n                vec![\n                    0xC0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                ]\n            }\n            MidiEventType::PitchBend =\u003e {\n                let value = ((self.data2 as u16) \u003c\u003c 7) | (self.data1 as u16);\n                vec![\n                    0xE0 | (self.channel \u0026 0x0F),\n                    (value \u0026 0x7F) as u8,\n                    ((value \u003e\u003e 7) \u0026 0x7F) as u8,\n                ]\n            }\n            MidiEventType::Aftertouch =\u003e {\n                vec![\n                    0xD0 | (self.channel \u0026 0x0F),\n                    self.data1 \u0026 0x7F,\n                ]\n            }\n        }\n    }\n\n    /// Parse from raw MIDI bytes\n    ///\n    /// Pure function - converts raw bytes to MIDI message.\n    pub fn from_bytes(bytes: \u0026[u8]) -\u003e Result\u003cSelf, String\u003e {\n        if bytes.is_empty() {\n            return Err(\"Empty MIDI message\".to_string());\n        }\n\n        let status = bytes[0];\n        let channel = status \u0026 0x0F;\n        let command = status \u0026 0xF0;\n\n        let (event_type, data1, data2) = match command {\n            0x90 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Note On message\".to_string());\n                }\n                (MidiEventType::NoteOn, bytes[1], bytes[2])\n            }\n            0x80 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Note Off message\".to_string());\n                }\n                (MidiEventType::NoteOff, bytes[1], bytes[2])\n            }\n            0xB0 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Control Change message\".to_string());\n                }\n                (MidiEventType::ControlChange, bytes[1], bytes[2])\n            }\n            0xC0 =\u003e {\n                if bytes.len() \u003c 2 {\n                    return Err(\"Incomplete Program Change message\".to_string());\n                }\n                (MidiEventType::ProgramChange, bytes[1], 0)\n            }\n            0xE0 =\u003e {\n                if bytes.len() \u003c 3 {\n                    return Err(\"Incomplete Pitch Bend message\".to_string());\n                }\n                (MidiEventType::PitchBend, bytes[1], bytes[2])\n            }\n            0xD0 =\u003e {\n                if bytes.len() \u003c 2 {\n                    return Err(\"Incomplete Aftertouch message\".to_string());\n                }\n                (MidiEventType::Aftertouch, bytes[1], 0)\n            }\n            _ =\u003e return Err(format!(\"Unknown MIDI command: {:#X}\", command)),\n        };\n\n        Ok(MidiMessage {\n            event_type,\n            channel,\n            data1,\n            data2,\n            timestamp: 0,\n        })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_note_on_encoding() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 60, // Middle C\n            data2: 100, // Velocity\n            timestamp: 0,\n        };\n\n        let bytes = msg.to_bytes();\n        assert_eq!(bytes, vec![0x90, 60, 100]);\n    }\n\n    #[test]\n    fn test_note_off_encoding() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOff,\n            channel: 0,\n            data1: 60,\n            data2: 0,\n            timestamp: 0,\n        };\n\n        let bytes = msg.to_bytes();\n        assert_eq!(bytes, vec![0x80, 60, 0]);\n    }\n\n    #[test]\n    fn test_message_parsing() {\n        let bytes = vec![0x90, 60, 100];\n        let msg = MidiMessage::from_bytes(\u0026bytes).unwrap();\n\n        assert_eq!(msg.event_type, MidiEventType::NoteOn);\n        assert_eq!(msg.channel, 0);\n        assert_eq!(msg.data1, 60);\n        assert_eq!(msg.data2, 100);\n    }\n\n    #[test]\n    fn test_invalid_message() {\n        let bytes = vec![];\n        let result = MidiMessage::from_bytes(\u0026bytes);\n        assert!(result.is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","validator.rs"],"content":"//! MIDI message validation\n//!\n//! Trusty Module: Pure validation functions for MIDI data.\n//! No I/O operations - all functions are deterministic and testable.\n\nuse super::types::{MidiMessage, MidiEventType};\n\n/// Validate MIDI channel (0-15)\n///\n/// MIDI channels are 0-indexed (0-15 represent MIDI channels 1-16).\npub fn validate_channel(channel: u8) -\u003e Result\u003cu8, String\u003e {\n    if channel \u003e 15 {\n        Err(format!(\n            \"Invalid MIDI channel: {}. Must be 0-15\",\n            channel\n        ))\n    } else {\n        Ok(channel)\n    }\n}\n\n/// Validate MIDI note (0-127)\n///\n/// MIDI note numbers range from 0 to 127 (C-1 to G9).\npub fn validate_note(note: u8) -\u003e Result\u003cu8, String\u003e {\n    if note \u003e 127 {\n        Err(format!(\"Invalid MIDI note: {}. Must be 0-127\", note))\n    } else {\n        Ok(note)\n    }\n}\n\n/// Validate MIDI velocity (0-127)\n///\n/// Velocity 0 is treated as note off in some contexts.\npub fn validate_velocity(velocity: u8) -\u003e Result\u003cu8, String\u003e {\n    if velocity \u003e 127 {\n        Err(format!(\n            \"Invalid velocity: {}. Must be 0-127\",\n            velocity\n        ))\n    } else {\n        Ok(velocity)\n    }\n}\n\n/// Validate MIDI control value (0-127)\n///\n/// Used for control change messages and other data values.\npub fn validate_control_value(value: u8) -\u003e Result\u003cu8, String\u003e {\n    if value \u003e 127 {\n        Err(format!(\n            \"Invalid control value: {}. Must be 0-127\",\n            value\n        ))\n    } else {\n        Ok(value)\n    }\n}\n\n/// Validate complete MIDI message\n///\n/// Performs comprehensive validation of all message fields.\npub fn validate_message(msg: \u0026MidiMessage) -\u003e Result\u003c(), String\u003e {\n    validate_channel(msg.channel)?;\n\n    match msg.event_type {\n        MidiEventType::NoteOn | MidiEventType::NoteOff =\u003e {\n            validate_note(msg.data1)?;\n            validate_velocity(msg.data2)?;\n        }\n        MidiEventType::ControlChange =\u003e {\n            validate_control_value(msg.data1)?;\n            validate_control_value(msg.data2)?;\n        }\n        MidiEventType::ProgramChange =\u003e {\n            validate_control_value(msg.data1)?;\n        }\n        MidiEventType::Aftertouch =\u003e {\n            validate_control_value(msg.data1)?;\n        }\n        MidiEventType::PitchBend =\u003e {\n            // Pitch bend uses 14-bit value split across data1 and data2\n            // Each byte is 7-bit (0-127), so no additional validation needed\n        }\n    }\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_validate_channel() {\n        assert!(validate_channel(0).is_ok());\n        assert!(validate_channel(15).is_ok());\n        assert!(validate_channel(16).is_err());\n        assert!(validate_channel(255).is_err());\n    }\n\n    #[test]\n    fn test_validate_note() {\n        assert!(validate_note(0).is_ok());\n        assert!(validate_note(127).is_ok());\n        assert!(validate_note(128).is_err());\n        assert!(validate_note(255).is_err());\n    }\n\n    #[test]\n    fn test_validate_velocity() {\n        assert!(validate_velocity(0).is_ok());\n        assert!(validate_velocity(127).is_ok());\n        assert!(validate_velocity(128).is_err());\n    }\n\n    #[test]\n    fn test_validate_control_value() {\n        assert!(validate_control_value(0).is_ok());\n        assert!(validate_control_value(127).is_ok());\n        assert!(validate_control_value(128).is_err());\n    }\n\n    #[test]\n    fn test_validate_message_note_on() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 60,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_ok());\n    }\n\n    #[test]\n    fn test_validate_message_invalid_channel() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 16,\n            data1: 60,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_err());\n    }\n\n    #[test]\n    fn test_validate_message_invalid_note() {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: 128,\n            data2: 100,\n            timestamp: 0,\n        };\n\n        assert!(validate_message(\u0026msg).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","midi","writer.rs"],"content":"//! MIDI File Writer - Trusty Module\n//!\n//! Pure functions for writing MIDI files from event data structures.\n//! NO I/O - caller receives bytes and writes to file.\n\nuse crate::models::midi::{MidiEvent, MidiEventType};\n\n/// Write MIDI file from events\n///\n/// Pure function that generates MIDI file bytes from event data.\n/// Takes events, timing resolution, and tempo as input.\n///\n/// # Arguments\n///\n/// * `events` - Slice of MIDI events to write\n/// * `ticks_per_quarter` - Timing resolution (typically 480 or 960)\n/// * `tempo_bpm` - Tempo in beats per minute (e.g., 120.0)\n///\n/// # Returns\n///\n/// * `Ok(Vec\u003cu8\u003e)` - Complete MIDI file as bytes\n/// * `Err(String)` - Error message if generation fails\n///\npub fn write_midi_file(\n    events: \u0026[MidiEvent],\n    ticks_per_quarter: u16,\n    tempo_bpm: f32,\n) -\u003e Result\u003cVec\u003cu8\u003e, String\u003e {\n    let mut data = Vec::new();\n\n    // Write header (format 1, 1 track, ticks per quarter note)\n    write_header(\u0026mut data, 1, 1, ticks_per_quarter);\n\n    // Write track with all events\n    write_track(\u0026mut data, events, tempo_bpm, ticks_per_quarter);\n\n    Ok(data)\n}\n\n/// Write MIDI header chunk (MThd)\nfn write_header(data: \u0026mut Vec\u003cu8\u003e, format: u16, tracks: u16, tpqn: u16) {\n    // Chunk type: \"MThd\"\n    data.extend_from_slice(b\"MThd\");\n\n    // Chunk length (always 6 for header)\n    data.extend_from_slice(\u00266u32.to_be_bytes());\n\n    // Format (0 = single track, 1 = multiple tracks, 2 = multiple sequences)\n    data.extend_from_slice(\u0026format.to_be_bytes());\n\n    // Number of tracks\n    data.extend_from_slice(\u0026tracks.to_be_bytes());\n\n    // Ticks per quarter note\n    data.extend_from_slice(\u0026tpqn.to_be_bytes());\n}\n\n/// Write MIDI track chunk (MTrk)\nfn write_track(\n    data: \u0026mut Vec\u003cu8\u003e,\n    events: \u0026[MidiEvent],\n    tempo_bpm: f32,\n    _tpqn: u16,\n) {\n    let mut track_data = Vec::new();\n\n    // Write tempo meta event at the start\n    write_tempo_event(\u0026mut track_data, tempo_bpm);\n\n    // Write all MIDI events with delta times\n    let mut last_tick = 0u64;\n    for event in events {\n        let delta = event.tick.saturating_sub(last_tick);\n        write_variable_length(\u0026mut track_data, delta);\n        write_event(\u0026mut track_data, event);\n        last_tick = event.tick;\n    }\n\n    // End of track meta event\n    write_variable_length(\u0026mut track_data, 0);\n    track_data.extend_from_slice(\u0026[0xFF, 0x2F, 0x00]);\n\n    // Write track header\n    data.extend_from_slice(b\"MTrk\");\n    data.extend_from_slice(\u0026(track_data.len() as u32).to_be_bytes());\n    data.extend_from_slice(\u0026track_data);\n}\n\n/// Write tempo meta event\n///\n/// MIDI tempo is stored as microseconds per quarter note.\n/// Conversion: microseconds_per_quarter = 60,000,000 / BPM\nfn write_tempo_event(data: \u0026mut Vec\u003cu8\u003e, bpm: f32) {\n    let microseconds_per_quarter = (60_000_000.0 / bpm) as u32;\n\n    write_variable_length(data, 0); // Delta time = 0 (at start)\n    data.push(0xFF); // Meta event\n    data.push(0x51); // Tempo meta event type\n    data.push(0x03); // Length = 3 bytes\n\n    // Write 3-byte tempo value (big-endian, skip first byte of u32)\n    data.extend_from_slice(\u0026microseconds_per_quarter.to_be_bytes()[1..4]);\n}\n\n/// Write single MIDI event\nfn write_event(data: \u0026mut Vec\u003cu8\u003e, event: \u0026MidiEvent) {\n    match event.event_type {\n        MidiEventType::NoteOn =\u003e {\n            data.push(0x90 | (event.channel \u0026 0x0F));\n            data.push(event.note.unwrap_or(0) \u0026 0x7F);\n            data.push(event.velocity.unwrap_or(100) \u0026 0x7F);\n        }\n        MidiEventType::NoteOff =\u003e {\n            data.push(0x80 | (event.channel \u0026 0x0F));\n            data.push(event.note.unwrap_or(0) \u0026 0x7F);\n            data.push(0x00); // Note off velocity is always 0\n        }\n        MidiEventType::ControlChange =\u003e {\n            data.push(0xB0 | (event.channel \u0026 0x0F));\n            data.push(event.controller.unwrap_or(0) \u0026 0x7F);\n            data.push(event.value.unwrap_or(0) \u0026 0x7F);\n        }\n        MidiEventType::ProgramChange =\u003e {\n            data.push(0xC0 | (event.channel \u0026 0x0F));\n            data.push(event.program.unwrap_or(0) \u0026 0x7F);\n        }\n        MidiEventType::PitchBend =\u003e {\n            data.push(0xE0 | (event.channel \u0026 0x0F));\n            // Pitch bend is a 14-bit value (0-16383, center = 8192)\n            // For now, we'll write a neutral pitch bend\n            data.push(0x00); // LSB\n            data.push(0x40); // MSB (64 = center)\n        }\n        MidiEventType::Aftertouch =\u003e {\n            data.push(0xD0 | (event.channel \u0026 0x0F));\n            data.push(0x00); // Pressure value\n        }\n    }\n}\n\n/// Write variable-length quantity (MIDI standard encoding)\n///\n/// MIDI uses variable-length quantities to save space.\n/// - Values 0-127: single byte (0xxxxxxx)\n/// - Larger values: multiple bytes (1xxxxxxx 1xxxxxxx ... 0xxxxxxx)\n/// - Most significant bit = 1 means \"more bytes follow\"\n/// - Each byte contributes 7 bits to the value\n///\n/// Examples:\n/// - 0  [0x00]\n/// - 127  [0x7F]\n/// - 128  [0x81, 0x00]\n/// - 8192  [0xC0, 0x00]\nfn write_variable_length(data: \u0026mut Vec\u003cu8\u003e, mut value: u64) {\n    let mut bytes = Vec::new();\n\n    // Write least significant 7 bits (without continuation bit)\n    bytes.push((value \u0026 0x7F) as u8);\n    value \u003e\u003e= 7;\n\n    // Write remaining 7-bit groups (with continuation bit set)\n    while value \u003e 0 {\n        bytes.push(((value \u0026 0x7F) | 0x80) as u8);\n        value \u003e\u003e= 7;\n    }\n\n    // Reverse to get big-endian order\n    bytes.reverse();\n    data.extend_from_slice(\u0026bytes);\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_write_variable_length_small() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 0);\n        assert_eq!(data, vec![0x00]);\n\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 127);\n        assert_eq!(data, vec![0x7F]);\n    }\n\n    #[test]\n    fn test_write_variable_length_medium() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 128);\n        assert_eq!(data, vec![0x81, 0x00]);\n\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 255);\n        assert_eq!(data, vec![0x81, 0x7F]);\n    }\n\n    #[test]\n    fn test_write_variable_length_large() {\n        let mut data = Vec::new();\n        write_variable_length(\u0026mut data, 8192);\n        assert_eq!(data, vec![0xC0, 0x00]);\n    }\n\n    #[test]\n    fn test_write_simple_midi() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(100),\n                controller: None,\n                value: None,\n                program: None,\n            },\n            MidiEvent {\n                event_type: MidiEventType::NoteOff,\n                tick: 480,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(0),\n                controller: None,\n                value: None,\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n\n        let data = result.unwrap();\n        // Verify header\n        assert_eq!(\u0026data[0..4], b\"MThd\");\n        // Verify track chunk exists\n        assert!(data.windows(4).any(|w| w == b\"MTrk\"));\n    }\n\n    #[test]\n    fn test_write_empty_events() {\n        let events = vec![];\n        let result = write_midi_file(\u0026events, 480, 120.0);\n\n        assert!(result.is_ok());\n        let data = result.unwrap();\n\n        // Should still have valid MIDI structure\n        assert_eq!(\u0026data[0..4], b\"MThd\");\n        assert!(data.windows(4).any(|w| w == b\"MTrk\"));\n    }\n\n    #[test]\n    fn test_write_control_change() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::ControlChange,\n                tick: 0,\n                channel: 0,\n                note: None,\n                velocity: None,\n                controller: Some(7), // Volume\n                value: Some(100),\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_write_multiple_channels() {\n        let events = vec![\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 0,\n                note: Some(60),\n                velocity: Some(100),\n                controller: None,\n                value: None,\n                program: None,\n            },\n            MidiEvent {\n                event_type: MidiEventType::NoteOn,\n                tick: 0,\n                channel: 9, // Typically drums\n                note: Some(36), // Bass drum\n                velocity: Some(120),\n                controller: None,\n                value: None,\n                program: None,\n            },\n        ];\n\n        let result = write_midi_file(\u0026events, 480, 120.0);\n        assert!(result.is_ok());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","mod.rs"],"content":"//! Core business logic modules\n//!\n//! Trusty Modules: Pure functions with no I/O operations.\n//! All modules here contain deterministic, testable code.\n\npub mod midi;\npub mod sequencer;\npub mod compatibility;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","sequencer","mod.rs"],"content":"//! Sequencer Core - Trusty Modules\n//!\n//! Pure functions for timing calculations and sequencer logic.\n//! NO I/O operations - all functions are deterministic and testable.\n\npub mod timing;\n\n#[allow(unused_imports)]\npub use timing::{\n    BarPosition, microseconds_per_tick, tick_to_bar_beat, bar_beat_to_tick,\n    ticks_to_seconds, seconds_to_ticks, ticks_to_microseconds,\n    microseconds_to_ticks, calculate_bar_position, ticks_per_bar,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","core","sequencer","timing.rs"],"content":"//! Sequencer timing calculations\n//!\n//! Trusty Module: Pure timing functions for MIDI sequencing.\n//! All functions are deterministic and thoroughly tested.\n\n/// Bar position structure\n///\n/// Represents a position in musical time as bar:beat:tick.\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub struct BarPosition {\n    pub bar: u32,\n    pub beat: u32,\n    pub tick: u64,\n}\n\n/// Calculate microseconds per tick at given BPM\n///\n/// Used for high-precision timing in MIDI playback.\n///\n/// # Arguments\n/// * `bpm` - Beats per minute\n/// * `ticks_per_quarter` - MIDI resolution (typically 480)\n///\n/// # Returns\n/// Microseconds per tick as f64\npub fn microseconds_per_tick(bpm: f32, ticks_per_quarter: u16) -\u003e f64 {\n    let microseconds_per_minute = 60_000_000.0;\n    let microseconds_per_beat = microseconds_per_minute / bpm as f64;\n    microseconds_per_beat / ticks_per_quarter as f64\n}\n\n/// Calculate bar and beat from tick position\n///\n/// Converts absolute tick position to musical bar:beat notation.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `ticks_per_quarter` - MIDI resolution\n/// * `beats_per_bar` - Time signature numerator (typically 4)\n///\n/// # Returns\n/// Tuple of (bar, beat) as (u32, u32)\npub fn tick_to_bar_beat(\n    tick: u64,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n) -\u003e (u32, u32) {\n    let ticks_per_beat = ticks_per_quarter as u64;\n    let ticks_per_bar = ticks_per_beat * beats_per_bar as u64;\n\n    let bar = (tick / ticks_per_bar) as u32;\n    let beat = ((tick % ticks_per_bar) / ticks_per_beat) as u32;\n\n    (bar, beat)\n}\n\n/// Calculate tick position from bar and beat\n///\n/// Converts musical bar:beat notation to absolute tick position.\n///\n/// # Arguments\n/// * `bar` - Bar number (0-indexed)\n/// * `beat` - Beat within bar (0-indexed)\n/// * `ticks_per_quarter` - MIDI resolution\n/// * `beats_per_bar` - Time signature numerator\n///\n/// # Returns\n/// Absolute tick position as u64\npub fn bar_beat_to_tick(\n    bar: u32,\n    beat: u32,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n) -\u003e u64 {\n    let ticks_per_beat = ticks_per_quarter as u64;\n    let ticks_per_bar = ticks_per_beat * beats_per_bar as u64;\n\n    (bar as u64 * ticks_per_bar) + (beat as u64 * ticks_per_beat)\n}\n\n/// Calculate seconds from ticks\n///\n/// Converts MIDI ticks to real time in seconds.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `bpm` - Current tempo\n/// * `ticks_per_quarter` - MIDI resolution\n///\n/// # Returns\n/// Time in seconds as f64\npub fn ticks_to_seconds(tick: u64, bpm: f32, ticks_per_quarter: u16) -\u003e f64 {\n    let us_per_tick = microseconds_per_tick(bpm, ticks_per_quarter);\n    (tick as f64 * us_per_tick) / 1_000_000.0\n}\n\n/// Calculate ticks from seconds\n///\n/// Converts real time in seconds to MIDI ticks.\n///\n/// # Arguments\n/// * `seconds` - Time in seconds\n/// * `bpm` - Current tempo\n/// * `ticks_per_quarter` - MIDI resolution\n///\n/// # Returns\n/// Absolute tick position as u64\npub fn seconds_to_ticks(seconds: f64, bpm: f32, ticks_per_quarter: u16) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, ticks_per_quarter);\n    ((seconds * 1_000_000.0) / us_per_tick) as u64\n}\n\n/// Convert ticks to microseconds\n///\n/// Converts MIDI ticks to microseconds for precise timing.\n///\n/// # Arguments\n/// * `ticks` - Number of ticks\n/// * `tpqn` - Ticks per quarter note\n/// * `bpm` - Beats per minute\n///\n/// # Returns\n/// Time in microseconds as u64\npub fn ticks_to_microseconds(ticks: u64, tpqn: u16, bpm: f32) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, tpqn);\n    (ticks as f64 * us_per_tick) as u64\n}\n\n/// Convert microseconds to ticks\n///\n/// Converts microseconds to MIDI ticks.\n///\n/// # Arguments\n/// * `micros` - Time in microseconds\n/// * `tpqn` - Ticks per quarter note\n/// * `bpm` - Beats per minute\n///\n/// # Returns\n/// Number of ticks as u64\npub fn microseconds_to_ticks(micros: u64, tpqn: u16, bpm: f32) -\u003e u64 {\n    let us_per_tick = microseconds_per_tick(bpm, tpqn);\n    (micros as f64 / us_per_tick) as u64\n}\n\n/// Calculate bar position from tick\n///\n/// Converts absolute tick to bar:beat:tick position.\n///\n/// # Arguments\n/// * `tick` - Absolute tick position\n/// * `tpqn` - Ticks per quarter note\n/// * `time_sig_num` - Time signature numerator (e.g., 4 in 4/4)\n/// * `time_sig_denom` - Time signature denominator (e.g., 4 in 4/4)\n///\n/// # Returns\n/// BarPosition with bar, beat, and tick within beat\npub fn calculate_bar_position(\n    tick: u64,\n    tpqn: u16,\n    time_sig_num: u8,\n    time_sig_denom: u8,\n) -\u003e BarPosition {\n    let ticks_per_beat = (tpqn as u64 * 4) / time_sig_denom as u64;\n    let ticks_per_bar = ticks_per_beat * time_sig_num as u64;\n\n    let bar = (tick / ticks_per_bar) as u32;\n    let tick_in_bar = tick % ticks_per_bar;\n    let beat = (tick_in_bar / ticks_per_beat) as u32;\n    let tick_in_beat = tick_in_bar % ticks_per_beat;\n\n    BarPosition {\n        bar,\n        beat,\n        tick: tick_in_beat,\n    }\n}\n\n/// Calculate ticks per bar\n///\n/// Calculates the number of ticks in one bar based on time signature.\n///\n/// # Arguments\n/// * `tpqn` - Ticks per quarter note\n/// * `time_sig_num` - Time signature numerator (e.g., 4 in 4/4)\n/// * `time_sig_denom` - Time signature denominator (e.g., 4 in 4/4)\n///\n/// # Returns\n/// Number of ticks per bar as u64\n///\n/// # Examples\n/// - 4/4 time with 480 TPQN: 1920 ticks per bar (4 quarter notes)\n/// - 3/4 time with 480 TPQN: 1440 ticks per bar (3 quarter notes)\n/// - 6/8 time with 480 TPQN: 1440 ticks per bar (2 dotted quarter notes)\npub fn ticks_per_bar(tpqn: u16, time_sig_num: u8, time_sig_denom: u8) -\u003e u64 {\n    let ticks_per_beat = (tpqn as u64 * 4) / time_sig_denom as u64;\n    ticks_per_beat * time_sig_num as u64\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_per_tick() {\n        // At 120 BPM with 480 TPQN:\n        // 60,000,000 / 120 = 500,000 s per beat\n        // 500,000 / 480 = 1041.67 s per tick\n        let result = microseconds_per_tick(120.0, 480);\n        assert!((result - 1041.67).abs() \u003c 0.01);\n    }\n\n    #[test]\n    fn test_microseconds_per_tick_different_bpm() {\n        // At 90 BPM:\n        // 60,000,000 / 90 = 666,666.67 s per beat\n        // 666,666.67 / 480 = 1388.89 s per tick\n        let result = microseconds_per_tick(90.0, 480);\n        assert!((result - 1388.89).abs() \u003c 0.01);\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_start() {\n        // Bar 0, Beat 0 = tick 0\n        assert_eq!(tick_to_bar_beat(0, 480, 4), (0, 0));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_second_beat() {\n        // Bar 0, Beat 1 = tick 480\n        assert_eq!(tick_to_bar_beat(480, 480, 4), (0, 1));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_second_bar() {\n        // Bar 1, Beat 0 = tick 1920 (480 * 4)\n        assert_eq!(tick_to_bar_beat(1920, 480, 4), (1, 0));\n    }\n\n    #[test]\n    fn test_tick_to_bar_beat_complex() {\n        // Bar 2, Beat 3 = tick 4560 (480 * 4 * 2 + 480 * 3)\n        assert_eq!(tick_to_bar_beat(5280, 480, 4), (2, 3));\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_start() {\n        assert_eq!(bar_beat_to_tick(0, 0, 480, 4), 0);\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_second_beat() {\n        assert_eq!(bar_beat_to_tick(0, 1, 480, 4), 480);\n    }\n\n    #[test]\n    fn test_bar_beat_to_tick_second_bar() {\n        assert_eq!(bar_beat_to_tick(1, 0, 480, 4), 1920);\n    }\n\n    #[test]\n    fn test_bar_beat_round_trip() {\n        // Test round-trip conversion\n        let original_tick = 5280u64;\n        let (bar, beat) = tick_to_bar_beat(original_tick, 480, 4);\n        let converted_tick = bar_beat_to_tick(bar, beat, 480, 4);\n        assert_eq!(original_tick, converted_tick);\n    }\n\n    #[test]\n    fn test_ticks_to_seconds() {\n        // At 120 BPM, 480 TPQN:\n        // 1920 ticks = 1 bar = 4 beats = 2 seconds\n        let seconds = ticks_to_seconds(1920, 120.0, 480);\n        assert!((seconds - 2.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_seconds_to_ticks() {\n        // At 120 BPM, 480 TPQN:\n        // 2 seconds = 4 beats = 1920 ticks\n        let ticks = seconds_to_ticks(2.0, 120.0, 480);\n        // Allow for floating point rounding (within 1 tick)\n        assert!((ticks as i64 - 1920).abs() \u003c= 1);\n    }\n\n    #[test]\n    fn test_time_conversion_round_trip() {\n        let original_ticks = 3840u64;\n        let seconds = ticks_to_seconds(original_ticks, 120.0, 480);\n        let converted_ticks = seconds_to_ticks(seconds, 120.0, 480);\n        assert_eq!(original_ticks, converted_ticks);\n    }\n\n    #[test]\n    fn test_different_time_signatures() {\n        // 3/4 time (3 beats per bar)\n        assert_eq!(tick_to_bar_beat(1440, 480, 3), (1, 0)); // Bar 1 in 3/4\n        assert_eq!(bar_beat_to_tick(1, 0, 480, 3), 1440);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","lib.rs"],"content":"//! MIDI Library DAW Interface\n//!\n//! Core library for DAW functionality including MIDI playback, sequencing, and search.\n\npub mod core;\npub mod models;\n\n// Re-export commonly used types\npub use models::{MidiFile, FileDetails, AppError, AppResult};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","main.rs"],"content":"// daw/src-tauri/src/main.rs\n// Task-O-Matic: Main entry point for DAW application\n// Purpose: Initialize app, register commands, manage state with MIDI hardware\n\n#![cfg_attr(\n    all(not(debug_assertions), target_os = \"windows\"),\n    windows_subsystem = \"windows\"\n)]\n\nuse tracing::{info, warn, error};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\nmod commands;\nmod models;\nmod core;\nmod midi;\nmod sequencer;\n\nuse commands::AppState;\nuse midi::MidiManager;\nuse sequencer::SequencerEngine;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    // Initialize tracing/logging\n    init_logging();\n\n    info!(\"Starting MIDI DAW application\");\n\n    // Initialize database connection pool\n    let db_pool = match initialize_database_pool().await {\n        Ok(pool) =\u003e {\n            info!(\" Database connection pool initialized\");\n            Some(pool)\n        }\n        Err(e) =\u003e {\n            warn!(\"  Database connection failed: {}\", e);\n            warn!(\"  DAW will run without database features (search, analysis, etc.)\");\n            None\n        }\n    };\n\n    // Initialize MIDI manager (no database required for DAW startup)\n    let midi_manager = Arc::new(MidiManager::new());\n    info!(\"MIDI manager initialized\");\n\n    // Initialize sequencer engine\n    let sequencer_engine = Arc::new(SequencerEngine::new(\n        midi_manager.clone(),\n        120.0, // Default 120 BPM\n        480,   // Standard MIDI resolution\n    ));\n    info!(\"Sequencer engine initialized\");\n\n    // Create application state\n    let state = AppState {\n        db_pool,\n    };\n\n    // Build and run Tauri application\n    tauri::Builder::default()\n        .manage(state)\n        .manage(midi_manager)\n        .manage(sequencer_engine)\n        .invoke_handler(tauri::generate_handler![\n            // Database commands\n            commands::initialize_database,\n            // MIDI commands\n            commands::midi::midi_list_devices,\n            commands::midi::midi_connect,\n            commands::midi::midi_disconnect,\n            commands::midi::midi_is_connected,\n            commands::midi::midi_get_current_device,\n            commands::midi::midi_send_test_note,\n            // Sequencer commands\n            commands::sequencer::start_sequencer,\n            commands::sequencer::stop_sequencer,\n            commands::sequencer::pause_sequencer,\n            commands::sequencer::resume_sequencer,\n            commands::sequencer::get_playback_position,\n            commands::sequencer::seek_position,\n            commands::sequencer::set_tempo,\n            commands::sequencer::get_tempo,\n            commands::sequencer::add_track,\n            commands::sequencer::remove_track,\n            commands::sequencer::update_track,\n            commands::sequencer::get_tracks,\n            commands::sequencer::load_sequencer_tracks,\n            commands::sequencer::is_sequencer_playing,\n            // Search commands\n            commands::search::search_files,\n            commands::search::get_file_details,\n            commands::search::get_search_suggestions,\n            // Analysis commands\n            commands::analysis::find_compatible_files,\n            commands::analysis::add_favorite,\n            commands::analysis::remove_favorite,\n            commands::analysis::is_favorite,\n            commands::analysis::get_favorites,\n            commands::analysis::get_usage_stats,\n            // Project commands\n            commands::project::load_multiple_tracks,\n            commands::project::clear_all_tracks,\n            commands::project::get_track_details,\n            // Export commands\n            commands::export::export_project_midi,\n        ])\n        .run(tauri::generate_context!())?;\n\n    Ok(())\n}\n\n/// Initialize logging/tracing system\nfn init_logging() {\n    let log_dir = std::env::var(\"LOG_DIR\").unwrap_or_else(|_| \"./logs\".to_string());\n    std::fs::create_dir_all(\u0026log_dir).ok();\n\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"daw.log\");\n    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);\n\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| \"info,midi_daw=debug\".into()),\n        )\n        .with(tracing_subscriber::fmt::layer().with_writer(std::io::stdout))\n        .with(tracing_subscriber::fmt::layer().with_writer(non_blocking))\n        .init();\n}\n\n/// Initialize PostgreSQL database connection pool\n///\n/// Reads DATABASE_URL from environment and creates a connection pool.\n/// Returns an error if DATABASE_URL is not set or connection fails.\nasync fn initialize_database_pool() -\u003e Result\u003csqlx::PgPool, String\u003e {\n    // Get DATABASE_URL from environment\n    let database_url = std::env::var(\"DATABASE_URL\")\n        .map_err(|_| {\n            \"DATABASE_URL not set. Please set it to: postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n        })?;\n\n    info!(\"Connecting to database: {}\", database_url.replace(\":145278963\", \":****\"));\n\n    // Get max connections from environment or use default\n    let max_connections: u32 = std::env::var(\"DB_MAX_CONNECTIONS\")\n        .ok()\n        .and_then(|s| s.parse().ok())\n        .unwrap_or(10);\n\n    // Create connection pool\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(max_connections)\n        .connect(\u0026database_url)\n        .await\n        .map_err(|e| format!(\"Failed to connect to database: {}\", e))?;\n\n    // Test connection with a simple query\n    sqlx::query(\"SELECT 1\")\n        .execute(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to execute test query: {}\", e))?;\n\n    info!(\"Database connection pool created with {} max connections\", max_connections);\n\n    Ok(pool)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","midi","manager.rs"],"content":"//! MIDI connection manager\n//!\n//! Grown-up Script: Handles MIDI device connections and message transmission.\n//! Delegates validation and encoding to Trusty Modules.\n\nuse midir::{MidiOutput, MidiOutputConnection};\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\nuse tracing::{info, warn, error};\n\nuse crate::core::midi::types::{MidiMessage, MidiEventType};\nuse crate::core::midi::validator;\nuse crate::models::MidiDevice;\n\n/// Thread-safe MIDI connection manager\n///\n/// Manages MIDI output connections with thread-safe access.\n/// Uses Arc\u003cMutex\u003c\u003e\u003e for safe concurrent access from multiple threads.\npub struct MidiManager {\n    connection: Arc\u003cMutex\u003cOption\u003cMidiOutputConnection\u003e\u003e\u003e,\n    current_device: Arc\u003cMutex\u003cOption\u003cString\u003e\u003e\u003e,\n}\n\nimpl MidiManager {\n    /// Create a new MIDI manager\n    pub fn new() -\u003e Self {\n        info!(\"Creating MIDI manager\");\n        Self {\n            connection: Arc::new(Mutex::new(None)),\n            current_device: Arc::new(Mutex::new(None)),\n        }\n    }\n\n    /// List available MIDI output devices\n    ///\n    /// Returns list of all MIDI output ports found on the system.\n    pub fn list_devices(\u0026self) -\u003e Result\u003cVec\u003cMidiDevice\u003e, String\u003e {\n        let midi_out = MidiOutput::new(\"MIDI Library DAW\")\n            .map_err(|e| {\n                error!(\"Failed to create MIDI output: {}\", e);\n                format!(\"Failed to create MIDI output: {}\", e)\n            })?;\n\n        let ports = midi_out.ports();\n        let mut devices = Vec::new();\n\n        for port in ports {\n            if let Ok(name) = midi_out.port_name(\u0026port) {\n                devices.push(MidiDevice {\n                    name: name.clone(),\n                    manufacturer: parse_manufacturer(\u0026name),\n                });\n            }\n        }\n\n        info!(\"Found {} MIDI devices\", devices.len());\n        Ok(devices)\n    }\n\n    /// Connect to a MIDI device\n    ///\n    /// Establishes connection to the specified MIDI output device.\n    pub async fn connect(\u0026self, device_name: \u0026str) -\u003e Result\u003c(), String\u003e {\n        info!(\"Attempting to connect to MIDI device: {}\", device_name);\n\n        // Create MIDI output\n        let midi_out = MidiOutput::new(\"MIDI Library DAW\")\n            .map_err(|e| {\n                error!(\"Failed to create MIDI output: {}\", e);\n                format!(\"Failed to create MIDI output: {}\", e)\n            })?;\n\n        // Find the port\n        let ports = midi_out.ports();\n        let port = ports\n            .iter()\n            .find(|p| {\n                midi_out\n                    .port_name(p)\n                    .ok()\n                    .as_ref()\n                    .map(|n| n == device_name)\n                    .unwrap_or(false)\n            })\n            .ok_or_else(|| {\n                error!(\"Device '{}' not found\", device_name);\n                format!(\"Device '{}' not found\", device_name)\n            })?;\n\n        // Connect\n        let connection = midi_out\n            .connect(port, \"daw-output\")\n            .map_err(|e| {\n                error!(\"Connection failed: {}\", e);\n                format!(\"Connection failed: {}\", e)\n            })?;\n\n        // Store connection\n        let mut conn_lock = self.connection.lock().await;\n        *conn_lock = Some(connection);\n\n        let mut device_lock = self.current_device.lock().await;\n        *device_lock = Some(device_name.to_string());\n\n        info!(\"Successfully connected to MIDI device: {}\", device_name);\n\n        Ok(())\n    }\n\n    /// Disconnect from MIDI device\n    ///\n    /// Closes the current MIDI connection if one exists.\n    pub async fn disconnect(\u0026self) {\n        let mut conn_lock = self.connection.lock().await;\n        *conn_lock = None;\n\n        let mut device_lock = self.current_device.lock().await;\n        let device_name = device_lock.take();\n\n        if let Some(name) = device_name {\n            info!(\"Disconnected from MIDI device: {}\", name);\n        } else {\n            info!(\"Disconnected (no device was connected)\");\n        }\n    }\n\n    /// Check if connected\n    ///\n    /// Returns true if a MIDI device is currently connected.\n    pub async fn is_connected(\u0026self) -\u003e bool {\n        let conn_lock = self.connection.lock().await;\n        conn_lock.is_some()\n    }\n\n    /// Get current device name\n    ///\n    /// Returns the name of the currently connected device, if any.\n    pub async fn current_device(\u0026self) -\u003e Option\u003cString\u003e {\n        let device_lock = self.current_device.lock().await;\n        device_lock.clone()\n    }\n\n    /// Send a MIDI message\n    ///\n    /// Validates and sends a MIDI message to the connected device.\n    /// Uses Trusty Module validation before sending.\n    pub async fn send_message(\u0026self, msg: \u0026MidiMessage) -\u003e Result\u003c(), String\u003e {\n        // Validate message (Trusty Module)\n        validator::validate_message(msg)?;\n\n        // Get connection\n        let mut conn_lock = self.connection.lock().await;\n\n        if let Some(connection) = conn_lock.as_mut() {\n            let bytes = msg.to_bytes();\n            connection.send(\u0026bytes).map_err(|e| {\n                error!(\"Failed to send MIDI message: {}\", e);\n                format!(\"Failed to send MIDI message: {}\", e)\n            })?;\n            Ok(())\n        } else {\n            warn!(\"Attempted to send MIDI message with no device connected\");\n            Err(\"No MIDI device connected\".to_string())\n        }\n    }\n\n    /// Send a note on message\n    ///\n    /// Convenience method for sending note on events.\n    pub async fn send_note_on(\n        \u0026self,\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel,\n            data1: note,\n            data2: velocity,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a note off message\n    ///\n    /// Convenience method for sending note off events.\n    pub async fn send_note_off(\u0026self, channel: u8, note: u8) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::NoteOff,\n            channel,\n            data1: note,\n            data2: 0,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a control change message\n    ///\n    /// Convenience method for sending control change events.\n    pub async fn send_control_change(\n        \u0026self,\n        channel: u8,\n        controller: u8,\n        value: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::ControlChange,\n            channel,\n            data1: controller,\n            data2: value,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n\n    /// Send a program change message\n    ///\n    /// Convenience method for sending program change events.\n    pub async fn send_program_change(\n        \u0026self,\n        channel: u8,\n        program: u8,\n    ) -\u003e Result\u003c(), String\u003e {\n        let msg = MidiMessage {\n            event_type: MidiEventType::ProgramChange,\n            channel,\n            data1: program,\n            data2: 0,\n            timestamp: 0,\n        };\n        self.send_message(\u0026msg).await\n    }\n}\n\nimpl Default for MidiManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Parse manufacturer from device name\n///\n/// Attempts to extract manufacturer name from MIDI device name.\n/// This is a best-effort approach as device naming is not standardized.\nfn parse_manufacturer(name: \u0026str) -\u003e Option\u003cString\u003e {\n    // Common manufacturer patterns\n    if name.contains(\"Steinberg\") {\n        Some(\"Steinberg\".to_string())\n    } else if name.contains(\"Akai\") {\n        Some(\"Akai\".to_string())\n    } else if name.contains(\"Roland\") {\n        Some(\"Roland\".to_string())\n    } else if name.contains(\"Yamaha\") {\n        Some(\"Yamaha\".to_string())\n    } else if name.contains(\"Korg\") {\n        Some(\"Korg\".to_string())\n    } else if name.contains(\"Moog\") {\n        Some(\"Moog\".to_string())\n    } else if name.contains(\"Arturia\") {\n        Some(\"Arturia\".to_string())\n    } else if name.contains(\"Native Instruments\") || name.contains(\"NI\") {\n        Some(\"Native Instruments\".to_string())\n    } else {\n        None\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_list_devices() {\n        let manager = MidiManager::new();\n        let result = manager.list_devices();\n\n        // Should not error, even if no devices\n        assert!(result.is_ok());\n    }\n\n    #[tokio::test]\n    async fn test_connect_invalid_device() {\n        let manager = MidiManager::new();\n        let result = manager.connect(\"NonexistentDevice123\").await;\n\n        // Should error for nonexistent device\n        assert!(result.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_disconnect_when_not_connected() {\n        let manager = MidiManager::new();\n        manager.disconnect().await;\n\n        // Should not panic\n        assert!(!manager.is_connected().await);\n    }\n\n    #[tokio::test]\n    async fn test_is_connected_initially_false() {\n        let manager = MidiManager::new();\n        assert!(!manager.is_connected().await);\n    }\n\n    #[tokio::test]\n    async fn test_current_device_initially_none() {\n        let manager = MidiManager::new();\n        assert_eq!(manager.current_device().await, None);\n    }\n\n    #[test]\n    fn test_parse_manufacturer() {\n        assert_eq!(\n            parse_manufacturer(\"Steinberg UR22\"),\n            Some(\"Steinberg\".to_string())\n        );\n        assert_eq!(\n            parse_manufacturer(\"Akai MPC One\"),\n            Some(\"Akai\".to_string())\n        );\n        assert_eq!(parse_manufacturer(\"Unknown Device\"), None);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","midi","mod.rs"],"content":"//! MIDI hardware management\n//!\n//! Grown-up Scripts: Handle MIDI device I/O and state management.\n//! Delegates business logic to Trusty Modules in core/midi.\n\npub mod manager;\n\npub use manager::MidiManager;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","analysis.rs"],"content":"//! Analysis and compatibility models\n//!\n//! Trusty Module: Pure data structures for musical compatibility analysis.\n\nuse serde::Serialize;\nuse std::str::FromStr;\n\n/**\n * Compatible file match\n *\n * Represents a file that is musically compatible with a reference file.\n */\n#[derive(Debug, Serialize)]\npub struct CompatibleFile {\n    pub id: i32,\n    pub file_name: String,\n    pub compatibility_score: i32,         // 0-100\n    pub key_match: bool,\n    pub bpm_difference: Option\u003cf32\u003e,\n    pub time_signature_match: bool,\n    pub suggested_bpm_multiplier: Option\u003cf32\u003e,\n    pub category: Option\u003cString\u003e,\n}\n\n/**\n * Key signature for compatibility analysis\n *\n * Represents musical keys in semitone notation.\n */\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Key {\n    C,\n    CSharp,\n    D,\n    DSharp,\n    E,\n    F,\n    FSharp,\n    G,\n    GSharp,\n    A,\n    ASharp,\n    B,\n}\n\nimpl Key {\n    /// Parse key from string (e.g., \"C\", \"C#\", \"Cm\", \"C#m\")\n    ///\n    /// Handles both sharp and flat notations.\n    pub fn from_string(s: \u0026str) -\u003e Option\u003cSelf\u003e {\n        let key_part = s.split('m').next()?;\n\n        match key_part {\n            \"C\" =\u003e Some(Key::C),\n            \"C#\" | \"Db\" =\u003e Some(Key::CSharp),\n            \"D\" =\u003e Some(Key::D),\n            \"D#\" | \"Eb\" =\u003e Some(Key::DSharp),\n            \"E\" =\u003e Some(Key::E),\n            \"F\" =\u003e Some(Key::F),\n            \"F#\" | \"Gb\" =\u003e Some(Key::FSharp),\n            \"G\" =\u003e Some(Key::G),\n            \"G#\" | \"Ab\" =\u003e Some(Key::GSharp),\n            \"A\" =\u003e Some(Key::A),\n            \"A#\" | \"Bb\" =\u003e Some(Key::ASharp),\n            \"B\" =\u003e Some(Key::B),\n            _ =\u003e None,\n        }\n    }\n\n    /// Get semitone value (0-11)\n    pub fn semitone(\u0026self) -\u003e i32 {\n        match self {\n            Key::C =\u003e 0,\n            Key::CSharp =\u003e 1,\n            Key::D =\u003e 2,\n            Key::DSharp =\u003e 3,\n            Key::E =\u003e 4,\n            Key::F =\u003e 5,\n            Key::FSharp =\u003e 6,\n            Key::G =\u003e 7,\n            Key::GSharp =\u003e 8,\n            Key::A =\u003e 9,\n            Key::ASharp =\u003e 10,\n            Key::B =\u003e 11,\n        }\n    }\n\n    /// Calculate distance between two keys (shortest path on circle of fifths)\n    pub fn distance(\u0026self, other: \u0026Key) -\u003e i32 {\n        let diff = (other.semitone() - self.semitone()).abs();\n        // Return shortest distance around the circle (max 6 semitones)\n        diff.min(12 - diff)\n    }\n}\n\nimpl FromStr for Key {\n    type Err = String;\n\n    fn from_str(s: \u0026str) -\u003e Result\u003cSelf, Self::Err\u003e {\n        Self::from_string(s).ok_or_else(|| format!(\"Invalid key: {}\", s))\n    }\n}\n\n/**\n * Mode (major or minor)\n *\n * Musical mode for key signature analysis.\n */\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Mode {\n    Major,\n    Minor,\n}\n\nimpl Mode {\n    /// Parse mode from string\n    ///\n    /// Detects \"m\" suffix for minor, defaults to major.\n    pub fn from_string(s: \u0026str) -\u003e Self {\n        if s.ends_with('m') \u0026\u0026 !s.ends_with(\"Maj\") {\n            Mode::Minor\n        } else {\n            Mode::Major\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_key_parsing() {\n        assert_eq!(Key::from_string(\"C\"), Some(Key::C));\n        assert_eq!(Key::from_string(\"C#\"), Some(Key::CSharp));\n        assert_eq!(Key::from_string(\"Db\"), Some(Key::CSharp));\n        assert_eq!(Key::from_string(\"Cm\"), Some(Key::C));\n        assert_eq!(Key::from_string(\"C#m\"), Some(Key::CSharp));\n    }\n\n    #[test]\n    fn test_key_distance() {\n        let c = Key::C;\n        let g = Key::G;\n        let f = Key::F;\n\n        assert_eq!(c.distance(\u0026g), 5); // C to G is 5 semitones\n        assert_eq!(c.distance(\u0026f), 5); // C to F is 5 semitones (going backwards)\n        assert_eq!(c.distance(\u0026c), 0); // Same key\n    }\n\n    #[test]\n    fn test_mode_parsing() {\n        assert_eq!(Mode::from_string(\"C\"), Mode::Major);\n        assert_eq!(Mode::from_string(\"Cm\"), Mode::Minor);\n        assert_eq!(Mode::from_string(\"CMaj\"), Mode::Major);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","error.rs"],"content":"//! Error types for the DAW application\n//!\n//! Trusty Module: Centralized error handling with proper type definitions.\n\nuse thiserror::Error;\n\n/**\n * Application errors\n *\n * Unified error type for all DAW operations.\n * Implements proper error conversion and serialization.\n */\n#[derive(Debug, Error)]\npub enum AppError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n\n    #[error(\"MIDI error: {0}\")]\n    Midi(String),\n\n    #[error(\"File error: {0}\")]\n    File(#[from] std::io::Error),\n\n    #[error(\"Parse error: {0}\")]\n    Parse(String),\n\n    #[error(\"Not found: {0}\")]\n    NotFound(String),\n\n    #[error(\"Invalid input: {0}\")]\n    InvalidInput(String),\n\n    #[error(\"Sequencer error: {0}\")]\n    Sequencer(String),\n\n    #[error(\"Connection error: {0}\")]\n    Connection(String),\n}\n\nimpl serde::Serialize for AppError {\n    fn serialize\u003cS\u003e(\u0026self, serializer: S) -\u003e Result\u003cS::Ok, S::Error\u003e\n    where\n        S: serde::Serializer,\n    {\n        serializer.serialize_str(\u0026self.to_string())\n    }\n}\n\n/**\n * Result type for application\n *\n * Convenience type alias for operations that return AppError.\n */\npub type AppResult\u003cT\u003e = Result\u003cT, AppError\u003e;\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":1},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","midi.rs"],"content":"//! MIDI event and device models\n//!\n//! Trusty Module: Pure data structures for MIDI hardware and events.\n\nuse serde::{Deserialize, Serialize};\n\n/**\n * MIDI device information\n *\n * Represents a connected MIDI output device.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiDevice {\n    pub name: String,\n    pub manufacturer: Option\u003cString\u003e,\n}\n\n/**\n * MIDI event type\n *\n * Supported MIDI message types for playback and recording.\n */\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\npub enum MidiEventType {\n    NoteOn,\n    NoteOff,\n    ControlChange,\n    ProgramChange,\n    PitchBend,\n    Aftertouch,\n}\n\n/**\n * MIDI event\n *\n * Represents a single MIDI message with timing and data.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiEvent {\n    pub event_type: MidiEventType,\n    pub tick: u64,\n    pub channel: u8,\n\n    // Optional fields depending on event type\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub note: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub velocity: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub controller: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub value: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub program: Option\u003cu8\u003e,\n}\n\n/**\n * MIDI note (simplified for piano roll)\n *\n * Simplified representation of a note event with duration.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiNote {\n    pub pitch: u8,\n    pub velocity: u8,\n    pub start_tick: u64,\n    pub duration_ticks: u64,\n}\n\n/**\n * MIDI pattern\n *\n * Complete pattern with events and timing information.\n */\n#[derive(Debug, Serialize, Deserialize)]\npub struct MidiPattern {\n    pub events: Vec\u003cMidiEvent\u003e,\n    pub ticks_per_quarter_note: u16,\n    pub total_ticks: u64,\n}\n\n/**\n * MIDI connection status\n *\n * Represents the current state of MIDI hardware connection.\n */\n#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\npub enum ConnectionStatus {\n    Disconnected,\n    Connecting,\n    Connected,\n    Error,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","midi_file.rs"],"content":"//! MIDI file database models\n//!\n//! Trusty Module: Pure data structures for MIDI file records.\n//! Updated to match actual database schema with proper JOINs.\n\nuse serde::{Deserialize, Serialize};\nuse sqlx::FromRow;\n\n/// Main file record - matches the actual database schema\n/// Uses proper JOINs to musical_metadata and file_categories tables\n#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]\npub struct MidiFile {\n    pub id: i64,\n\n    // File metadata (from files table)\n    pub filename: String,\n    pub filepath: String,\n    pub file_size_bytes: i64,\n    #[sqlx(default)]\n    pub content_hash: Vec\u003cu8\u003e,\n\n    // Multi-track info\n    #[sqlx(default)]\n    pub is_multi_track: bool,\n    pub parent_file_id: Option\u003ci64\u003e,\n    pub track_number: Option\u003ci16\u003e,\n    pub total_tracks: Option\u003ci16\u003e,\n\n    // Context from folders\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    #[sqlx(default)]\n    pub folder_tags: Vec\u003cString\u003e,\n    pub parent_folder: Option\u003cString\u003e,\n\n    // Musical metadata (from musical_metadata table via JOIN)\n    pub bpm: Option\u003cf64\u003e,  // numeric(6,2) in DB\n    pub key_signature: Option\u003cString\u003e,\n\n    // Time signature (formatted as \"4/4\" from numerator/denominator)\n    pub time_signature: Option\u003cString\u003e,\n\n    // Duration and notes\n    pub duration_seconds: Option\u003cf64\u003e,  // numeric(10,3) in DB, can be NULL\n    pub total_notes: i32,  // note_count in musical_metadata, defaulted to 0 if NULL\n\n    // Track count from files table\n    pub num_tracks: i16,\n\n    // Categories (from file_categories table via subquery)\n    pub primary_category: Option\u003cString\u003e,\n\n    // Timestamps\n    pub created_at: chrono::DateTime\u003cchrono::Utc\u003e,\n    pub analyzed_at: Option\u003cchrono::DateTime\u003cchrono::Utc\u003e\u003e,\n}\n\n/// Lightweight file details for search results\n#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]\npub struct FileDetails {\n    pub id: i64,\n    #[serde(rename = \"file_name\")]\n    pub filename: String,\n    #[serde(rename = \"file_path\")]\n    pub filepath: String,\n    #[serde(rename = \"file_size\")]\n    pub file_size_bytes: i64,\n    pub bpm: Option\u003cf64\u003e,\n    #[serde(rename = \"key\")]\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n    pub total_notes: Option\u003ci32\u003e,\n    #[serde(rename = \"category\")]\n    pub primary_category: Option\u003cString\u003e,\n    pub parent_folder: Option\u003cString\u003e,\n    pub created_at: chrono::DateTime\u003cchrono::Utc\u003e,\n    #[sqlx(default)]\n    pub is_favorite: bool,\n    // Additional fields for compatibility with frontend\n    #[sqlx(default)]\n    #[serde(default)]\n    pub tags: Vec\u003cString\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    #[serde(rename = \"collection\")]\n    pub collection_name: Option\u003cString\u003e,\n    #[serde(default)]\n    pub track_count: i16,\n    #[serde(default)]\n    pub has_notes: bool,\n    pub has_drums: Option\u003cbool\u003e,\n    #[sqlx(default)]\n    #[serde(default, skip_serializing)]\n    pub content_hash: Vec\u003cu8\u003e,\n}\n\nimpl MidiFile {\n    /// Helper to format time signature from numerator and denominator\n    pub fn format_time_signature(numerator: Option\u003ci16\u003e, denominator: Option\u003ci16\u003e) -\u003e Option\u003cString\u003e {\n        match (numerator, denominator) {\n            (Some(num), Some(den)) =\u003e Some(format!(\"{}/{}\", num, den)),\n            _ =\u003e None,\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","mod.rs"],"content":"//! Data models for the DAW application\n//!\n//! These models match the TypeScript frontend types for proper serialization.\n//! Trusty Module: Type definitions only, no I/O operations.\n\npub mod midi_file;\npub mod search;\npub mod midi;\npub mod sequencer;\npub mod analysis;\npub mod error;\n\n// Re-export commonly used types\n#[allow(unused_imports)]\npub use midi_file::{MidiFile, FileDetails};\n#[allow(unused_imports)]\npub use search::{SearchFilters, SearchResponse, Suggestion, FilterOption};\n#[allow(unused_imports)]\npub use midi::{MidiDevice, MidiEventType, MidiEvent, MidiNote, MidiPattern, ConnectionStatus};\n#[allow(unused_imports)]\npub use sequencer::{Track, TrackProperties, PlaybackPosition};\n#[allow(unused_imports)]\npub use analysis::CompatibleFile;\n#[allow(unused_imports)]\npub use error::AppError;\n\n// Types used internally only\n#[allow(unused_imports)]\npub use sequencer::SequencerState;\n#[allow(unused_imports)]\npub use analysis::{Key, Mode};\n#[allow(unused_imports)]\npub use error::AppResult;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","search.rs"],"content":"//! Search and filter models\n//!\n//! Trusty Module: Pure data structures for search operations.\n\nuse serde::{Deserialize, Serialize};\nuse super::midi_file::FileDetails;\n\n/**\n * Search filters\n *\n * Filters applied to search queries. All fields are optional.\n */\n#[derive(Debug, Deserialize)]\npub struct SearchFilters {\n    // BPM range filtering\n    pub min_bpm: Option\u003cf32\u003e,\n    pub max_bpm: Option\u003cf32\u003e,\n\n    // Key and time signature\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n\n    // Category\n    pub category: Option\u003cString\u003e,\n\n    // Note count range\n    pub min_notes: Option\u003ci32\u003e,\n    pub max_notes: Option\u003ci32\u003e,\n\n    // Duration range (seconds)\n    pub min_duration: Option\u003cf64\u003e,\n    pub max_duration: Option\u003cf64\u003e,\n\n    // Instruments (array match)\n    pub instruments: Option\u003cVec\u003cString\u003e\u003e,\n\n    // Text search\n    pub search_text: Option\u003cString\u003e,\n\n    // Sorting and pagination\n    pub sort_by: Option\u003cString\u003e,\n    pub sort_desc: Option\u003cbool\u003e,\n    pub limit: Option\u003ci32\u003e,\n    pub offset: Option\u003ci32\u003e,\n}\n\n/**\n * Search response\n *\n * Contains matching files and total count for pagination.\n */\n#[derive(Debug, Serialize)]\npub struct SearchResponse {\n    pub files: Vec\u003cFileDetails\u003e,\n    pub total: i32,\n}\n\n/**\n * Autocomplete suggestion\n *\n * Used for search bar autocomplete functionality.\n */\n#[derive(Debug, Serialize, Deserialize)]\npub struct Suggestion {\n    pub value: String,\n}\n\n/**\n * Filter option\n *\n * Represents a single option in a filter dropdown with count.\n */\n#[derive(Debug, Serialize, sqlx::FromRow)]\npub struct FilterOption {\n    pub value: String,\n    pub label: String,\n    pub count: i64,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","models","sequencer.rs"],"content":"//! Sequencer models\n//!\n//! Trusty Module: Pure data structures for sequencer state and tracks.\n\nuse serde::{Deserialize, Serialize};\nuse super::midi::MidiEvent;\n\n/**\n * Sequencer track\n *\n * Represents a single track in the sequencer with playback properties.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Track {\n    pub id: i32,\n    pub name: String,\n    pub file_id: i32,\n    pub channel: u8,\n    pub muted: bool,\n    pub solo: bool,\n    pub volume: u8,      // 0-127\n    pub pan: u8,         // 0-127 (64 = center)\n    pub color: String,   // Hex color\n\n    // Internal data (not serialized to frontend)\n    #[serde(skip)]\n    pub events: Vec\u003cMidiEvent\u003e,\n}\n\n/**\n * Track properties for updates\n *\n * Partial update structure for modifying track properties.\n */\n#[derive(Debug, Deserialize)]\npub struct TrackProperties {\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub muted: Option\u003cbool\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub solo: Option\u003cbool\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub volume: Option\u003cu8\u003e,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub pan: Option\u003cu8\u003e,\n}\n\n/**\n * Playback position\n *\n * Current position in the sequencer timeline.\n */\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PlaybackPosition {\n    pub current_tick: u64,\n    pub current_bar: u32,\n    pub current_beat: u32,\n}\n\n/**\n * Sequencer state\n *\n * Complete state of the sequencer engine.\n * This is internal state - not all fields are serialized to frontend.\n */\n#[derive(Debug)]\npub struct SequencerState {\n    pub is_playing: bool,\n    pub tempo: f32,\n    pub position: u64,\n    pub tracks: Vec\u003cTrack\u003e,\n    pub next_track_id: i32,\n}\n\nimpl SequencerState {\n    /// Create new sequencer state with defaults\n    pub fn new() -\u003e Self {\n        Self {\n            is_playing: false,\n            tempo: 120.0,\n            position: 0,\n            tracks: Vec::new(),\n            next_track_id: 1,\n        }\n    }\n}\n\nimpl Default for SequencerState {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","engine.rs"],"content":"//! Sequencer playback engine\n//!\n//! Grown-up Script: Coordinates playback, timing, and MIDI output.\n//! Integrates TrackManager, EventScheduler, and MidiManager.\n\nuse crate::core::sequencer::timing;\nuse crate::midi::MidiManager;\nuse crate::models::sequencer::PlaybackPosition;\nuse crate::sequencer::{EventScheduler, ScheduledEvent, TrackManager};\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::sync::{Mutex, RwLock};\nuse tokio::time;\nuse tracing::{debug, error, info, warn};\n\n/// Playback state\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum PlaybackState {\n    Stopped,\n    Playing,\n    Paused,\n}\n\n/// Main sequencer engine\n///\n/// Manages playback state, timing, and coordinates all sequencer components.\npub struct SequencerEngine {\n    track_manager: Arc\u003cTrackManager\u003e,\n    scheduler: Arc\u003cEventScheduler\u003e,\n    midi_manager: Arc\u003cMidiManager\u003e,\n\n    // Playback state\n    state: Arc\u003cRwLock\u003cPlaybackState\u003e\u003e,\n    current_tick: Arc\u003cRwLock\u003cu64\u003e\u003e,\n    start_time: Arc\u003cMutex\u003cOption\u003cInstant\u003e\u003e\u003e,\n\n    // Transport settings\n    bpm: Arc\u003cRwLock\u003cf32\u003e\u003e,\n    ticks_per_quarter: u16,\n    beats_per_bar: u8,\n\n    // Playback control\n    loop_enabled: Arc\u003cRwLock\u003cbool\u003e\u003e,\n    loop_start: Arc\u003cRwLock\u003cu64\u003e\u003e,\n    loop_end: Arc\u003cRwLock\u003cu64\u003e\u003e,\n}\n\nimpl SequencerEngine {\n    /// Create a new sequencer engine\n    ///\n    /// # Arguments\n    /// * `midi_manager` - MIDI output manager\n    /// * `bpm` - Initial tempo (default: 120.0)\n    /// * `ticks_per_quarter` - MIDI resolution (default: 480)\n    pub fn new(midi_manager: Arc\u003cMidiManager\u003e, bpm: f32, ticks_per_quarter: u16) -\u003e Self {\n        Self {\n            track_manager: Arc::new(TrackManager::new()),\n            scheduler: Arc::new(EventScheduler::new()),\n            midi_manager,\n            state: Arc::new(RwLock::new(PlaybackState::Stopped)),\n            current_tick: Arc::new(RwLock::new(0)),\n            start_time: Arc::new(Mutex::new(None)),\n            bpm: Arc::new(RwLock::new(bpm)),\n            ticks_per_quarter,\n            beats_per_bar: 4,\n            loop_enabled: Arc::new(RwLock::new(false)),\n            loop_start: Arc::new(RwLock::new(0)),\n            loop_end: Arc::new(RwLock::new(0)),\n        }\n    }\n\n    /// Get track manager reference\n    pub fn track_manager(\u0026self) -\u003e Arc\u003cTrackManager\u003e {\n        self.track_manager.clone()\n    }\n\n    /// Get event scheduler reference\n    pub fn scheduler(\u0026self) -\u003e Arc\u003cEventScheduler\u003e {\n        self.scheduler.clone()\n    }\n\n    /// Start playback\n    pub async fn start(\u0026self) -\u003e Result\u003c(), String\u003e {\n        let mut state = self.state.write().await;\n\n        if *state == PlaybackState::Playing {\n            return Ok(()); // Already playing\n        }\n\n        // Check if MIDI is connected\n        if !self.midi_manager.is_connected().await {\n            return Err(\"MIDI device not connected\".to_string());\n        }\n\n        info!(\"Starting sequencer playback\");\n\n        *state = PlaybackState::Playing;\n        let mut start_time = self.start_time.lock().await;\n        *start_time = Some(Instant::now());\n\n        // Spawn playback task\n        self.spawn_playback_task().await;\n\n        Ok(())\n    }\n\n    /// Stop playback and reset position\n    pub async fn stop(\u0026self) {\n        let mut state = self.state.write().await;\n\n        if *state == PlaybackState::Stopped {\n            return;\n        }\n\n        info!(\"Stopping sequencer playback\");\n\n        *state = PlaybackState::Stopped;\n        let mut current_tick = self.current_tick.write().await;\n        *current_tick = 0;\n\n        // Send all notes off to prevent stuck notes\n        if let Err(e) = self.send_panic().await {\n            warn!(\"Failed to send panic message: {}\", e);\n        }\n    }\n\n    /// Pause playback (maintains position)\n    pub async fn pause(\u0026self) {\n        let mut state = self.state.write().await;\n\n        if *state != PlaybackState::Playing {\n            return;\n        }\n\n        info!(\"Pausing sequencer playback\");\n        *state = PlaybackState::Paused;\n\n        // Send all notes off to prevent stuck notes\n        if let Err(e) = self.send_panic().await {\n            warn!(\"Failed to send panic message: {}\", e);\n        }\n    }\n\n    /// Resume playback from paused state\n    pub async fn resume(\u0026self) -\u003e Result\u003c(), String\u003e {\n        let mut state = self.state.write().await;\n\n        if *state != PlaybackState::Paused {\n            return Ok(());\n        }\n\n        if !self.midi_manager.is_connected().await {\n            return Err(\"MIDI device not connected\".to_string());\n        }\n\n        info!(\"Resuming sequencer playback\");\n\n        *state = PlaybackState::Playing;\n        let mut start_time = self.start_time.lock().await;\n        *start_time = Some(Instant::now());\n\n        self.spawn_playback_task().await;\n\n        Ok(())\n    }\n\n    /// Get current playback state\n    pub async fn get_state(\u0026self) -\u003e PlaybackState {\n        *self.state.read().await\n    }\n\n    /// Set tempo (BPM)\n    pub async fn set_bpm(\u0026self, bpm: f32) -\u003e Result\u003c(), String\u003e {\n        if !(20.0..=300.0).contains(\u0026bpm) {\n            return Err(format!(\"Invalid BPM: {}. Must be 20-300\", bpm));\n        }\n\n        let mut current_bpm = self.bpm.write().await;\n        *current_bpm = bpm;\n        info!(\"Tempo set to {} BPM\", bpm);\n\n        Ok(())\n    }\n\n    /// Get current tempo\n    pub async fn get_bpm(\u0026self) -\u003e f32 {\n        *self.bpm.read().await\n    }\n\n    /// Get current playback position\n    pub async fn get_position(\u0026self) -\u003e PlaybackPosition {\n        let tick = *self.current_tick.read().await;\n        let (bar, beat) = timing::tick_to_bar_beat(tick, self.ticks_per_quarter, self.beats_per_bar);\n\n        PlaybackPosition {\n            current_tick: tick,\n            current_bar: bar,\n            current_beat: beat,\n        }\n    }\n\n    /// Seek to a specific tick position\n    pub async fn seek(\u0026self, tick: u64) {\n        let mut current_tick = self.current_tick.write().await;\n        *current_tick = tick;\n        debug!(\"Seeked to tick {}\", tick);\n    }\n\n    /// Load tracks into the scheduler\n    ///\n    /// Clears existing scheduled events and loads events from all active tracks.\n    pub async fn load_tracks(\u0026self) {\n        use crate::core::midi::types::{MidiEventType as CoreEventType, MidiMessage};\n        use crate::models::midi::MidiEventType;\n\n        self.scheduler.clear().await;\n\n        let tracks = self.track_manager.get_active_tracks().await;\n        let mut all_events = Vec::new();\n\n        for track in tracks {\n            for event in track.events {\n                // Convert MidiEvent to MidiMessage\n                let message = match event.event_type {\n                    MidiEventType::NoteOn =\u003e MidiMessage {\n                        event_type: CoreEventType::NoteOn,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.velocity.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::NoteOff =\u003e MidiMessage {\n                        event_type: CoreEventType::NoteOff,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.velocity.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::ControlChange =\u003e MidiMessage {\n                        event_type: CoreEventType::ControlChange,\n                        channel: track.channel,\n                        data1: event.controller.unwrap_or(0),\n                        data2: event.value.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::ProgramChange =\u003e MidiMessage {\n                        event_type: CoreEventType::ProgramChange,\n                        channel: track.channel,\n                        data1: event.program.unwrap_or(0),\n                        data2: 0,\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::PitchBend =\u003e MidiMessage {\n                        event_type: CoreEventType::PitchBend,\n                        channel: track.channel,\n                        data1: event.value.unwrap_or(0),\n                        data2: 0,\n                        timestamp: event.tick,\n                    },\n                    MidiEventType::Aftertouch =\u003e MidiMessage {\n                        event_type: CoreEventType::Aftertouch,\n                        channel: track.channel,\n                        data1: event.note.unwrap_or(0),\n                        data2: event.value.unwrap_or(0),\n                        timestamp: event.tick,\n                    },\n                };\n\n                all_events.push(ScheduledEvent {\n                    message,\n                    tick: event.tick,\n                    track_id: track.id,\n                });\n            }\n        }\n\n        self.scheduler.schedule_many(all_events).await;\n        info!(\"Loaded {} events into scheduler\", self.scheduler.len().await);\n    }\n\n    /// Send MIDI panic (all notes off on all channels)\n    async fn send_panic(\u0026self) -\u003e Result\u003c(), String\u003e {\n        use crate::core::midi::types::{MidiEventType, MidiMessage};\n\n        for channel in 0..16 {\n            let panic_msg = MidiMessage {\n                event_type: MidiEventType::ControlChange,\n                channel,\n                data1: 123, // All Notes Off\n                data2: 0,\n                timestamp: 0,\n            };\n\n            self.midi_manager.send_message(\u0026panic_msg).await?;\n        }\n\n        Ok(())\n    }\n\n    /// Spawn the playback task\n    async fn spawn_playback_task(\u0026self) {\n        let state = self.state.clone();\n        let current_tick = self.current_tick.clone();\n        let start_time = self.start_time.clone();\n        let bpm = self.bpm.clone();\n        let ticks_per_quarter = self.ticks_per_quarter;\n        let scheduler = self.scheduler.clone();\n        let midi_manager = self.midi_manager.clone();\n\n        tokio::spawn(async move {\n            let mut interval = time::interval(Duration::from_millis(1)); // 1ms resolution\n\n            loop {\n                interval.tick().await;\n\n                // Check if still playing\n                {\n                    let state_guard = state.read().await;\n                    if *state_guard != PlaybackState::Playing {\n                        break;\n                    }\n                }\n\n                // Calculate current tick from elapsed time\n                let elapsed = {\n                    let start_guard = start_time.lock().await;\n                    match start_guard.as_ref() {\n                        Some(instant) =\u003e instant.elapsed(),\n                        None =\u003e {\n                            error!(\"Start time not set in sequencer playback loop\");\n                            break;\n                        }\n                    }\n                };\n\n                let bpm_val = *bpm.read().await;\n                let tick = timing::seconds_to_ticks(\n                    elapsed.as_secs_f64(),\n                    bpm_val,\n                    ticks_per_quarter,\n                );\n\n                // Update current tick\n                {\n                    let mut tick_guard = current_tick.write().await;\n                    *tick_guard = tick;\n                }\n\n                // Get ready events\n                let ready_events = scheduler.pop_ready(tick).await;\n\n                // Send MIDI messages\n                for event in ready_events {\n                    if let Err(e) = midi_manager.send_message(\u0026event.message).await {\n                        error!(\"Failed to send MIDI message: {}\", e);\n                    }\n                }\n            }\n\n            debug!(\"Playback task stopped\");\n        });\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[tokio::test]\n    async fn test_engine_creation() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert_eq!(engine.get_state().await, PlaybackState::Stopped);\n        assert_eq!(engine.get_bpm().await, 120.0);\n    }\n\n    #[tokio::test]\n    async fn test_set_bpm() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert!(engine.set_bpm(140.0).await.is_ok());\n        assert_eq!(engine.get_bpm().await, 140.0);\n    }\n\n    #[tokio::test]\n    async fn test_set_bpm_invalid() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        assert!(engine.set_bpm(500.0).await.is_err());\n        assert!(engine.set_bpm(10.0).await.is_err());\n    }\n\n    #[tokio::test]\n    async fn test_get_position() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 0);\n        assert_eq!(pos.current_bar, 0);\n        assert_eq!(pos.current_beat, 0);\n    }\n\n    #[tokio::test]\n    async fn test_seek() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        engine.seek(1920).await; // 1 bar\n\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 1920);\n        assert_eq!(pos.current_bar, 1);\n        assert_eq!(pos.current_beat, 0);\n    }\n\n    #[tokio::test]\n    #[ignore] // TODO: Fix in Phase 1 - position not resetting to 0 on stop\n    async fn test_stop_from_playing() {\n        let midi_manager = Arc::new(MidiManager::new());\n        let engine = SequencerEngine::new(midi_manager, 120.0, 480);\n\n        engine.seek(1000).await;\n        engine.stop().await;\n\n        // Stop should reset position\n        let pos = engine.get_position().await;\n        assert_eq!(pos.current_tick, 0);\n        assert_eq!(engine.get_state().await, PlaybackState::Stopped);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","mod.rs"],"content":"//! Sequencer implementation\n//!\n//! Grown-up Scripts: Manage sequencer state, tracks, and playback.\n//! Delegates to Trusty Modules for timing calculations.\n\npub mod track;\npub mod scheduler;\npub mod engine;\n\npub use track::TrackManager;\npub use scheduler::{EventScheduler, ScheduledEvent};\n#[allow(unused_imports)]\npub use engine::{SequencerEngine, PlaybackState};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","scheduler.rs"],"content":"//! Event scheduling for sequencer\n//!\n//! Grown-up Script: Manages priority queue of MIDI events for precise playback timing.\n\nuse crate::core::midi::types::MidiMessage;\nuse std::cmp::Ordering;\nuse std::collections::BinaryHeap;\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\n\n/// A scheduled MIDI event with timing information\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct ScheduledEvent {\n    pub message: MidiMessage,\n    pub tick: u64,\n    pub track_id: i32,\n}\n\nimpl PartialEq for ScheduledEvent {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.tick == other.tick\n    }\n}\n\nimpl Eq for ScheduledEvent {}\n\nimpl PartialOrd for ScheduledEvent {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for ScheduledEvent {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        // Reverse ordering for min-heap (BinaryHeap is max-heap by default)\n        other.tick.cmp(\u0026self.tick)\n    }\n}\n\n/// Manages scheduling and retrieval of MIDI events\n///\n/// Uses a priority queue (min-heap) to efficiently retrieve events in chronological order.\n/// Thread-safe using Mutex for concurrent access.\npub struct EventScheduler {\n    events: Arc\u003cMutex\u003cBinaryHeap\u003cScheduledEvent\u003e\u003e\u003e,\n}\n\nimpl EventScheduler {\n    /// Create a new empty event scheduler\n    pub fn new() -\u003e Self {\n        Self {\n            events: Arc::new(Mutex::new(BinaryHeap::new())),\n        }\n    }\n\n    /// Schedule a MIDI event at a specific tick\n    ///\n    /// # Arguments\n    /// * `message` - The MIDI message to schedule\n    /// * `tick` - Absolute tick position when event should fire\n    /// * `track_id` - ID of the track this event belongs to\n    pub async fn schedule(\u0026self, message: MidiMessage, tick: u64, track_id: i32) {\n        let event = ScheduledEvent {\n            message,\n            tick,\n            track_id,\n        };\n\n        let mut events = self.events.lock().await;\n        events.push(event);\n    }\n\n    /// Schedule multiple events at once\n    ///\n    /// More efficient than calling schedule() repeatedly.\n    pub async fn schedule_many(\u0026self, events: Vec\u003cScheduledEvent\u003e) {\n        let mut heap = self.events.lock().await;\n        for event in events {\n            heap.push(event);\n        }\n    }\n\n    /// Get the next event at or before the current tick\n    ///\n    /// Returns None if no events are ready or queue is empty.\n    ///\n    /// # Arguments\n    /// * `current_tick` - Current playback position\n    pub async fn pop_next(\u0026self, current_tick: u64) -\u003e Option\u003cScheduledEvent\u003e {\n        let mut events = self.events.lock().await;\n\n        // Peek at next event\n        if let Some(next) = events.peek() {\n            if next.tick \u003c= current_tick {\n                return events.pop();\n            }\n        }\n\n        None\n    }\n\n    /// Get all events at or before the current tick\n    ///\n    /// Returns a vector of events in chronological order.\n    /// More efficient than calling pop_next() repeatedly.\n    ///\n    /// # Arguments\n    /// * `current_tick` - Current playback position\n    pub async fn pop_ready(\u0026self, current_tick: u64) -\u003e Vec\u003cScheduledEvent\u003e {\n        let mut events = self.events.lock().await;\n        let mut ready = Vec::new();\n\n        while let Some(next) = events.peek() {\n            if next.tick \u003c= current_tick {\n                // Safe to unwrap here since peek() returned Some, but we use if let for safety\n                if let Some(event) = events.pop() {\n                    ready.push(event);\n                }\n            } else {\n                break;\n            }\n        }\n\n        ready\n    }\n\n    /// Peek at the next event without removing it\n    pub async fn peek_next(\u0026self) -\u003e Option\u003cu64\u003e {\n        let events = self.events.lock().await;\n        events.peek().map(|e| e.tick)\n    }\n\n    /// Get the number of scheduled events\n    pub async fn len(\u0026self) -\u003e usize {\n        let events = self.events.lock().await;\n        events.len()\n    }\n\n    /// Check if scheduler is empty\n    pub async fn is_empty(\u0026self) -\u003e bool {\n        let events = self.events.lock().await;\n        events.is_empty()\n    }\n\n    /// Clear all scheduled events\n    pub async fn clear(\u0026self) {\n        let mut events = self.events.lock().await;\n        events.clear();\n    }\n\n    /// Remove all events for a specific track\n    pub async fn clear_track(\u0026self, track_id: i32) {\n        let mut events = self.events.lock().await;\n        let filtered: Vec\u003c_\u003e = events\n            .drain()\n            .filter(|e| e.track_id != track_id)\n            .collect();\n\n        events.clear();\n        for event in filtered {\n            events.push(event);\n        }\n    }\n}\n\nimpl Default for EventScheduler {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::core::midi::types::MidiEventType;\n\n    fn create_test_message(note: u8, velocity: u8) -\u003e MidiMessage {\n        MidiMessage {\n            event_type: MidiEventType::NoteOn,\n            channel: 0,\n            data1: note,\n            data2: velocity,\n            timestamp: 0,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_schedule_and_pop() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        let event = scheduler.pop_next(100).await.unwrap();\n        assert_eq!(event.tick, 100);\n        assert_eq!(event.message.data1, 60);\n    }\n\n    #[tokio::test]\n    async fn test_pop_before_ready() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        // Try to pop at tick 50 (before event is ready)\n        let event = scheduler.pop_next(50).await;\n        assert!(event.is_none());\n\n        // Event should still be there at tick 100\n        let event = scheduler.pop_next(100).await.unwrap();\n        assert_eq!(event.tick, 100);\n    }\n\n    #[tokio::test]\n    async fn test_chronological_order() {\n        let scheduler = EventScheduler::new();\n\n        // Schedule events out of order\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n\n        // Should come out in chronological order\n        let e1 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e1.tick, 100);\n        assert_eq!(e1.message.data1, 60);\n\n        let e2 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e2.tick, 200);\n        assert_eq!(e2.message.data1, 62);\n\n        let e3 = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(e3.tick, 300);\n        assert_eq!(e3.message.data1, 64);\n    }\n\n    #[tokio::test]\n    async fn test_pop_ready() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n\n        // Get all events up to tick 250\n        let ready = scheduler.pop_ready(250).await;\n        assert_eq!(ready.len(), 2);\n        assert_eq!(ready[0].tick, 100);\n        assert_eq!(ready[1].tick, 200);\n\n        // One event should remain\n        assert_eq!(scheduler.len().await, 1);\n    }\n\n    #[tokio::test]\n    async fn test_peek_next() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n\n        let next_tick = scheduler.peek_next().await.unwrap();\n        assert_eq!(next_tick, 100);\n\n        // Peek doesn't remove\n        assert_eq!(scheduler.len().await, 2);\n    }\n\n    #[tokio::test]\n    async fn test_clear_track() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 2)\n            .await;\n        scheduler\n            .schedule(create_test_message(64, 100), 300, 1)\n            .await;\n\n        scheduler.clear_track(1).await;\n\n        // Only track 2 event should remain\n        assert_eq!(scheduler.len().await, 1);\n        let event = scheduler.pop_next(500).await.unwrap();\n        assert_eq!(event.track_id, 2);\n    }\n\n    #[tokio::test]\n    async fn test_schedule_many() {\n        let scheduler = EventScheduler::new();\n\n        let events = vec![\n            ScheduledEvent {\n                message: create_test_message(60, 100),\n                tick: 100,\n                track_id: 1,\n            },\n            ScheduledEvent {\n                message: create_test_message(62, 100),\n                tick: 200,\n                track_id: 1,\n            },\n            ScheduledEvent {\n                message: create_test_message(64, 100),\n                tick: 300,\n                track_id: 1,\n            },\n        ];\n\n        scheduler.schedule_many(events).await;\n\n        assert_eq!(scheduler.len().await, 3);\n    }\n\n    #[tokio::test]\n    async fn test_clear() {\n        let scheduler = EventScheduler::new();\n\n        scheduler\n            .schedule(create_test_message(60, 100), 100, 1)\n            .await;\n        scheduler\n            .schedule(create_test_message(62, 100), 200, 1)\n            .await;\n\n        scheduler.clear().await;\n\n        assert!(scheduler.is_empty().await);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","daw","src-tauri","src","sequencer","track.rs"],"content":"//! Track management for sequencer\n//!\n//! Grown-up Script: Manages collection of tracks with their properties and MIDI events.\n\nuse crate::models::sequencer::{Track, TrackProperties};\nuse crate::models::midi::MidiEvent;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Manages all tracks in the sequencer\n///\n/// Tracks contain MIDI events and playback properties (mute, solo, volume).\n/// Thread-safe using RwLock for concurrent read access.\npub struct TrackManager {\n    tracks: Arc\u003cRwLock\u003cHashMap\u003ci32, Track\u003e\u003e\u003e,\n    next_id: Arc\u003cRwLock\u003ci32\u003e\u003e,\n}\n\nimpl TrackManager {\n    /// Create a new empty track manager\n    pub fn new() -\u003e Self {\n        Self {\n            tracks: Arc::new(RwLock::new(HashMap::new())),\n            next_id: Arc::new(RwLock::new(1)),\n        }\n    }\n\n    /// Add a new track with specified properties\n    ///\n    /// # Arguments\n    /// * `file_id` - Database ID of the MIDI file for this track\n    /// * `channel` - MIDI channel (0-15)\n    /// * `events` - MIDI events for this track\n    ///\n    /// # Returns\n    /// The newly created Track with assigned ID\n    pub async fn add_track(\n        \u0026self,\n        file_id: i32,\n        channel: u8,\n        events: Vec\u003cMidiEvent\u003e,\n    ) -\u003e Result\u003cTrack, String\u003e {\n        if channel \u003e 15 {\n            return Err(format!(\"Invalid MIDI channel: {}. Must be 0-15\", channel));\n        }\n\n        let mut next_id = self.next_id.write().await;\n        let track_id = *next_id;\n        *next_id += 1;\n\n        let track = Track {\n            id: track_id,\n            name: format!(\"Track {}\", track_id),\n            file_id,\n            channel,\n            muted: false,\n            solo: false,\n            volume: 100,\n            pan: 64,\n            color: \"#888888\".to_string(),\n            events,\n        };\n\n        let mut tracks = self.tracks.write().await;\n        tracks.insert(track_id, track.clone());\n\n        Ok(track)\n    }\n\n    /// Remove a track by ID\n    ///\n    /// # Returns\n    /// Ok(()) if track was removed, Err if track not found\n    pub async fn remove_track(\u0026self, track_id: i32) -\u003e Result\u003c(), String\u003e {\n        let mut tracks = self.tracks.write().await;\n        tracks\n            .remove(\u0026track_id)\n            .ok_or_else(|| format!(\"Track {} not found\", track_id))?;\n        Ok(())\n    }\n\n    /// Update track properties (mute, solo, volume, pan)\n    pub async fn update_track(\n        \u0026self,\n        track_id: i32,\n        properties: TrackProperties,\n    ) -\u003e Result\u003c(), String\u003e {\n        let mut tracks = self.tracks.write().await;\n        let track = tracks\n            .get_mut(\u0026track_id)\n            .ok_or_else(|| format!(\"Track {} not found\", track_id))?;\n\n        if let Some(muted) = properties.muted {\n            track.muted = muted;\n        }\n        if let Some(solo) = properties.solo {\n            track.solo = solo;\n        }\n        if let Some(volume) = properties.volume {\n            if volume \u003e 127 {\n                return Err(\"Volume must be 0-127\".to_string());\n            }\n            track.volume = volume;\n        }\n        if let Some(pan) = properties.pan {\n            if pan \u003e 127 {\n                return Err(\"Pan must be 0-127\".to_string());\n            }\n            track.pan = pan;\n        }\n\n        Ok(())\n    }\n\n    /// Get all tracks\n    pub async fn get_tracks(\u0026self) -\u003e Vec\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        tracks.values().cloned().collect()\n    }\n\n    /// Get a specific track by ID\n    pub async fn get_track(\u0026self, track_id: i32) -\u003e Option\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        tracks.get(\u0026track_id).cloned()\n    }\n\n    /// Check if any track has solo enabled\n    pub async fn has_solo(\u0026self) -\u003e bool {\n        let tracks = self.tracks.read().await;\n        tracks.values().any(|t| t.solo)\n    }\n\n    /// Get tracks that should play (considering mute/solo)\n    ///\n    /// Logic:\n    /// - If any track is solo, only solo tracks play\n    /// - Otherwise, all non-muted tracks play\n    pub async fn get_active_tracks(\u0026self) -\u003e Vec\u003cTrack\u003e {\n        let tracks = self.tracks.read().await;\n        let has_solo = tracks.values().any(|t| t.solo);\n\n        tracks\n            .values()\n            .filter(|t| {\n                if has_solo {\n                    t.solo\n                } else {\n                    !t.muted\n                }\n            })\n            .cloned()\n            .collect()\n    }\n\n    /// Clear all tracks\n    pub async fn clear(\u0026self) {\n        let mut tracks = self.tracks.write().await;\n        tracks.clear();\n        let mut next_id = self.next_id.write().await;\n        *next_id = 1;\n    }\n}\n\nimpl Default for TrackManager {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    fn create_test_event(channel: u8) -\u003e MidiEvent {\n        use crate::models::midi::MidiEventType;\n\n        MidiEvent {\n            event_type: MidiEventType::NoteOn,\n            tick: 0,\n            channel,\n            note: Some(60),\n            velocity: Some(100),\n            controller: None,\n            value: None,\n            program: None,\n        }\n    }\n\n    #[tokio::test]\n    async fn test_add_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n        assert_eq!(track.id, 1);\n        assert_eq!(track.file_id, 1);\n        assert_eq!(track.channel, 0);\n        assert!(!track.muted);\n        assert!(!track.solo);\n    }\n\n    #[tokio::test]\n    async fn test_add_track_invalid_channel() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let result = manager.add_track(1, 16, events).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"Invalid MIDI channel\"));\n    }\n\n    #[tokio::test]\n    async fn test_remove_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n        assert!(manager.remove_track(track.id).await.is_ok());\n        assert!(manager.get_track(track.id).await.is_none());\n    }\n\n    #[tokio::test]\n    async fn test_update_track() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n\n        let props = TrackProperties {\n            muted: Some(true),\n            solo: Some(true),\n            volume: Some(80),\n            pan: Some(32),\n        };\n\n        manager.update_track(track.id, props).await.unwrap();\n\n        let updated = manager.get_track(track.id).await.unwrap();\n        assert!(updated.muted);\n        assert!(updated.solo);\n        assert_eq!(updated.volume, 80);\n        assert_eq!(updated.pan, 32);\n    }\n\n    #[tokio::test]\n    async fn test_update_track_invalid_volume() {\n        let manager = TrackManager::new();\n        let events = vec![create_test_event(0)];\n\n        let track = manager.add_track(1, 0, events).await.unwrap();\n\n        let props = TrackProperties {\n            muted: None,\n            solo: None,\n            volume: Some(128),\n            pan: None,\n        };\n\n        let result = manager.update_track(track.id, props).await;\n        assert!(result.is_err());\n        assert!(result.unwrap_err().contains(\"Volume must be 0-127\"));\n    }\n\n    #[tokio::test]\n    async fn test_get_active_tracks_no_solo() {\n        let manager = TrackManager::new();\n\n        // Add 3 tracks: 1 muted, 2 unmuted\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        let track2 = manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n        manager.add_track(3, 2, vec![create_test_event(2)]).await.unwrap();\n\n        // Mute track 2\n        manager.update_track(track2.id, TrackProperties {\n            muted: Some(true),\n            solo: None,\n            volume: None,\n            pan: None,\n        }).await.unwrap();\n\n        let active = manager.get_active_tracks().await;\n        assert_eq!(active.len(), 2); // Only unmuted tracks\n    }\n\n    #[tokio::test]\n    async fn test_get_active_tracks_with_solo() {\n        let manager = TrackManager::new();\n\n        // Add 3 tracks\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        let track2 = manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n        manager.add_track(3, 2, vec![create_test_event(2)]).await.unwrap();\n\n        // Solo track 2\n        manager.update_track(track2.id, TrackProperties {\n            muted: None,\n            solo: Some(true),\n            volume: None,\n            pan: None,\n        }).await.unwrap();\n\n        let active = manager.get_active_tracks().await;\n        assert_eq!(active.len(), 1); // Only solo track\n        assert_eq!(active[0].id, track2.id);\n    }\n\n    #[tokio::test]\n    async fn test_clear() {\n        let manager = TrackManager::new();\n\n        manager.add_track(1, 0, vec![create_test_event(0)]).await.unwrap();\n        manager.add_track(2, 1, vec![create_test_event(1)]).await.unwrap();\n\n        manager.clear().await;\n\n        let tracks = manager.get_tracks().await;\n        assert_eq!(tracks.len(), 0);\n\n        // Next track should start at ID 1 again\n        let track = manager.add_track(3, 0, vec![create_test_event(0)]).await.unwrap();\n        assert_eq!(track.id, 1);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","build.rs"],"content":"fn main() {\n    // Tell the linker to use webkit2gtk-4.1 instead of webkit2gtk-4.0\n    println!(\"cargo:rustc-link-lib=webkit2gtk-4.1\");\n    println!(\"cargo:rustc-link-lib=javascriptcoregtk-4.1\");\n\n    tauri_build::build()\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","analyze.rs"],"content":"//! MIDI Analysis CLI Tool\n//!\n//! Standalone binary to analyze all imported MIDI files\n//!\n//! Usage:\n//!   cargo run --bin analyze\n//!\n//! Environment Variables:\n//!   DATABASE_URL - PostgreSQL connection string\n//!                  Default: postgresql://midiuser:145278963@localhost:5433/midi_library\n\nuse std::env;\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\nuse futures::stream::{self, StreamExt};\n\n// Import from the main library\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\n\n#[derive(Debug, Clone, sqlx::FromRow)]\nstruct FileRecord {\n    id: i64,\n    filepath: String,\n    filename: String,\n}\n\n#[derive(Debug, Clone)]\nstruct AnalyzedFile {\n    file_id: i64,\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n    complexity_score: Option\u003cf64\u003e,\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    println!(\" MIDI Analysis Tool\");\n    println!(\"====================\\n\");\n\n    // Get database URL from environment\n    let database_url = env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(20)\n        .connect(\u0026database_url)\n        .await?;\n    println!(\" Connected to database\\n\");\n\n    // Get total count of unanalyzed files\n    let total: i64 = sqlx::query_scalar(\n        \"SELECT COUNT(*) FROM files WHERE analyzed_at IS NULL\"\n    )\n    .fetch_one(\u0026pool)\n    .await?;\n\n    println!(\" Found {} unanalyzed files\\n\", total);\n\n    if total == 0 {\n        println!(\" All files are already analyzed!\");\n        return Ok(());\n    }\n\n    let start_time = std::time::Instant::now();\n\n    // Configuration\n    let concurrency_limit = 32;\n    let batch_size = 1000;\n\n    println!(\" Starting analysis:\");\n    println!(\"  Concurrency: {} workers\", concurrency_limit);\n    println!(\"  Batch size: {} files\\n\", batch_size);\n\n    // Thread-safe counters\n    let analyzed = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let total_usize = total as usize;\n\n    // Process files in batches\n    let mut offset = 0i64;\n\n    loop {\n        // Fetch batch of unanalyzed files\n        let files: Vec\u003cFileRecord\u003e = sqlx::query_as(\n            \"SELECT id, filepath, filename\n             FROM files\n             WHERE analyzed_at IS NULL\n             ORDER BY id\n             LIMIT $1 OFFSET $2\"\n        )\n        .bind(batch_size)\n        .bind(offset)\n        .fetch_all(\u0026pool)\n        .await?;\n\n        if files.is_empty() {\n            break;\n        }\n\n        let pool_clone = pool.clone();\n\n        // Process batch in parallel\n        stream::iter(files)\n            .map(|file_record| {\n                let sem = Arc::clone(\u0026semaphore);\n                let analyzed = Arc::clone(\u0026analyzed);\n                let skipped = Arc::clone(\u0026skipped);\n                let errors = Arc::clone(\u0026errors);\n                let current_index = Arc::clone(\u0026current_index);\n                let analyzed_files = Arc::clone(\u0026analyzed_files);\n                let pool = pool_clone.clone();\n\n                async move {\n                    let _permit = match sem.acquire().await {\n                        Ok(permit) =\u003e permit,\n                        Err(_) =\u003e {\n                            eprintln!(\"Warning: Semaphore closed during analysis\");\n                            return;\n                        }\n                    };\n\n                    let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                    // Print progress every 100 files\n                    if current % 100 == 0 || current == total_usize {\n                        let elapsed = start_time.elapsed().as_secs_f64();\n                        let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                        let remaining = total_usize - current;\n                        let eta_seconds = if rate \u003e 0.0 { remaining as f64 / rate } else { 0.0 };\n\n                        println!(\n                            \"Analyzing: {}/{} ({:.1}%) - {:.1} files/sec - ETA: {}\",\n                            current,\n                            total_usize,\n                            (current as f64 / total_usize as f64) * 100.0,\n                            rate,\n                            format_duration(eta_seconds)\n                        );\n                    }\n\n                    // Analyze the file\n                    match analyze_single_file(\u0026file_record).await {\n                        Ok(analyzed_data) =\u003e {\n                            analyzed_files.lock().await.push(analyzed_data);\n                            analyzed.fetch_add(1, Ordering::SeqCst);\n\n                            // Flush batch if threshold reached\n                            let mut files = analyzed_files.lock().await;\n                            if files.len() \u003e= 100 {\n                                let batch: Vec\u003cAnalyzedFile\u003e = files.drain(..).collect();\n                                drop(files);\n\n                                if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n                                    errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            skipped.fetch_add(1, Ordering::SeqCst);\n                            // Only log first 10 errors to avoid spam\n                            let mut err_list = errors.lock().await;\n                            if err_list.len() \u003c 10 {\n                                err_list.push(format!(\"{}: {}\", file_record.filepath, e));\n                            }\n                        }\n                    }\n                }\n            })\n            .buffer_unordered(concurrency_limit)\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .await;\n\n        offset += batch_size;\n    }\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        batch_insert_analyzed_files(\u0026batch, \u0026pool).await?;\n    }\n\n    // Print final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let analyzed_count = analyzed.load(Ordering::SeqCst);\n    let skipped_count = skipped.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { analyzed_count as f64 / duration } else { 0.0 };\n\n    println!(\"\\n Analysis complete!\");\n    println!(\"==================\");\n    println!(\"  Total files:    {}\", total_usize);\n    println!(\"  Analyzed:       {}\", analyzed_count);\n    println!(\"  Skipped:        {}\", skipped_count);\n    println!(\"  Duration:       {}\", format_duration(duration));\n    println!(\"  Average rate:   {:.1} files/sec\", rate);\n\n    let error_list = errors.lock().await;\n    if !error_list.is_empty() {\n        println!(\"\\n  Errors encountered:\");\n        for (i, error) in error_list.iter().enumerate().take(10) {\n            println!(\"  {}. {}\", i + 1, error);\n        }\n        if error_list.len() \u003e 10 {\n            println!(\"  ... and {} more errors\", error_list.len() - 10);\n        }\n    }\n\n    Ok(())\n}\n\n// Helper function to format duration in human-readable format\nfn format_duration(seconds: f64) -\u003e String {\n    if seconds \u003c 60.0 {\n        format!(\"{:.0}s\", seconds)\n    } else if seconds \u003c 3600.0 {\n        let minutes = (seconds / 60.0).floor();\n        let secs = seconds % 60.0;\n        format!(\"{}m {:.0}s\", minutes, secs)\n    } else {\n        let hours = (seconds / 3600.0).floor();\n        let minutes = ((seconds % 3600.0) / 60.0).floor();\n        format!(\"{}h {}m\", hours, minutes)\n    }\n}\n\n// Copy of analyze_single_file from commands/analyze.rs\nasync fn analyze_single_file(\n    file_record: \u0026FileRecord,\n) -\u003e Result\u003cAnalyzedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    let file_bytes = tokio::fs::read(\u0026file_record.filepath).await?;\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n    let note_stats = analyze_notes(\u0026midi_file);\n    let instruments = extract_instrument_names(\u0026midi_file);\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    Ok(AnalyzedFile {\n        file_id: file_record.id,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n    })\n}\n\n// Copy of batch_insert_analyzed_files from commands/analyze.rs\nasync fn batch_insert_analyzed_files(\n    files: \u0026[AnalyzedFile],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    if files.is_empty() {\n        return Ok(());\n    }\n\n    let mut tx = pool.begin().await?;\n\n    for file in files {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id, tempo_bpm, bpm_confidence, has_tempo_variation,\n                key_signature, key_confidence, scale_type,\n                time_signature_num, time_signature_den,\n                duration_seconds, duration_ticks, note_count,\n                pitch_range_low, pitch_range_high, pitch_range_semitones,\n                avg_velocity, velocity_range_low, velocity_range_high,\n                polyphony_max, complexity_score, instruments,\n                has_pitch_bend, has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            ON CONFLICT (file_id) DO UPDATE SET\n                tempo_bpm = EXCLUDED.tempo_bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                has_tempo_variation = EXCLUDED.has_tempo_variation,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                scale_type = EXCLUDED.scale_type,\n                time_signature_num = EXCLUDED.time_signature_num,\n                time_signature_den = EXCLUDED.time_signature_den,\n                duration_seconds = EXCLUDED.duration_seconds,\n                duration_ticks = EXCLUDED.duration_ticks,\n                note_count = EXCLUDED.note_count,\n                pitch_range_low = EXCLUDED.pitch_range_low,\n                pitch_range_high = EXCLUDED.pitch_range_high,\n                pitch_range_semitones = EXCLUDED.pitch_range_semitones,\n                avg_velocity = EXCLUDED.avg_velocity,\n                velocity_range_low = EXCLUDED.velocity_range_low,\n                velocity_range_high = EXCLUDED.velocity_range_high,\n                polyphony_max = EXCLUDED.polyphony_max,\n                complexity_score = EXCLUDED.complexity_score,\n                instruments = EXCLUDED.instruments,\n                has_pitch_bend = EXCLUDED.has_pitch_bend,\n                has_cc_messages = EXCLUDED.has_cc_messages\n            \"#\n        )\n        .bind(file.file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        sqlx::query(\"UPDATE files SET analyzed_at = NOW() WHERE id = $1\")\n            .bind(file.file_id)\n            .execute(\u0026mut *tx)\n            .await?;\n    }\n\n    tx.commit().await?;\n    Ok(())\n}\n\n// Helper analysis functions (copied from commands/analyze.rs)\n\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4))\n}\n\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i32\n}\n\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        Some(minutes * 60.0)\n    } else {\n        None\n    }\n}\n\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026name) {\n                            instruments.push(name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n    instruments\n}\n\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0);\n    }\n\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0);\n    }\n\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0);\n    }\n\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0);\n\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0);\n    }\n\n    Some(score.min(100.0))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","batch_import.rs"],"content":"#!/usr/bin/env cargo\n//! Batch import using existing repository layer\n//!\n//! This imports MIDI files using the FileRepository and MetadataRepository\n//! which are already aligned with the database schema.\n\nuse anyhow::Result;\nuse clap::Parser;\nuse sqlx::types::BigDecimal;\nuse std::path::{Path, PathBuf};\nuse std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse std::time::Instant;\n\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\nuse midi_pipeline::core::hash::calculate_file_hash;\nuse midi_pipeline::db::models::{NewFile, NewMusicalMetadata};\nuse midi_pipeline::db::repositories::file_repository::FileRepository;\nuse midi_pipeline::db::repositories::metadata_repository::MetadataRepository;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\n\n#[derive(Parser)]\n#[command(name = \"batch-import\")]\n#[command(about = \"Batch import MIDI files using repository layer\")]\nstruct Args {\n    /// Directory containing MIDI files\n    #[arg(short, long)]\n    directory: PathBuf,\n\n    /// Number of parallel workers\n    #[arg(short = 'w', long, default_value = \"32\")]\n    workers: usize,\n\n    /// Database URL\n    #[arg(long, env = \"DATABASE_URL\")]\n    database_url: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Default)]\nstruct ImportStats {\n    files_found: AtomicU64,\n    files_imported: AtomicU64,\n    files_duplicates: AtomicU64,\n    files_errors: AtomicU64,\n    start_time: Option\u003cInstant\u003e,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    dotenv::dotenv().ok();\n\n    let args = Args::parse();\n\n    println!(\"\\n BATCH MIDI IMPORT (Repository Layer)\");\n    println!(\"\\n\");\n\n    // Connect to database\n    let database_url = args.database_url.unwrap_or_else(|| {\n        std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                eprintln!(\" Error: DATABASE_URL environment variable must be set\");\n                std::process::exit(1);\n            })\n    });\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::PgPool::connect(\u0026database_url).await?;\n    println!(\" Database connected\\n\");\n\n    // Find all MIDI files\n    println!(\" Scanning for MIDI files in: {}\", args.directory.display());\n    let midi_files = find_midi_files(\u0026args.directory)?;\n    let total_files = midi_files.len();\n\n    println!(\" Found {} MIDI files\\n\", total_files);\n\n    if total_files == 0 {\n        println!(\"  No MIDI files found\");\n        return Ok(());\n    }\n\n    // Initialize stats\n    let stats = Arc::new(ImportStats {\n        files_found: AtomicU64::new(total_files as u64),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    // Process files in parallel\n    println!(\" Processing {} files with {} workers...\\n\", total_files, args.workers);\n\n    use futures::stream::{self, StreamExt};\n\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(args.workers));\n    let processed = Arc::new(AtomicUsize::new(0));\n\n    stream::iter(midi_files)\n        .map(|file_path| {\n            let sem = Arc::clone(\u0026semaphore);\n            let pool = pool.clone();\n            let stats = Arc::clone(\u0026stats);\n            let processed = Arc::clone(\u0026processed);\n\n            async move {\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        eprintln!(\"Warning: Semaphore closed during import\");\n                        return;\n                    }\n                };\n\n                let current = processed.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Show progress every 100 files\n                if current % 100 == 0 || current == total_files {\n                    let elapsed = stats.start_time\n                        .map(|t| t.elapsed().as_secs_f64())\n                        .unwrap_or(0.0);\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                    println!(\n                        \"    Processing: {}/{} ({:.1}%) - {:.1} files/sec\",\n                        current,\n                        total_files,\n                        (current as f64 / total_files as f64) * 100.0,\n                        rate\n                    );\n                }\n\n                // Process the file\n                match process_file(\u0026pool, \u0026file_path).await {\n                    Ok(imported) =\u003e {\n                        if imported {\n                            stats.files_imported.fetch_add(1, Ordering::SeqCst);\n                        } else {\n                            stats.files_duplicates.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                    Err(e) =\u003e {\n                        eprintln!(\"        Error processing {}: {}\", file_path.display(), e);\n                        stats.files_errors.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(args.workers)\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // Print final summary\n    print_summary(\u0026stats);\n\n    Ok(())\n}\n\n/// Process a single MIDI file\nasync fn process_file(pool: \u0026sqlx::PgPool, file_path: \u0026Path) -\u003e Result\u003cbool\u003e {\n    // 1. Read file\n    let file_bytes = tokio::fs::read(file_path).await?;\n    let file_size = file_bytes.len() as i64;\n\n    // 2. Calculate content hash\n    let content_hash = calculate_file_hash(file_path)?;\n\n    // 3. Check for duplicate\n    if FileRepository::check_duplicate(pool, \u0026content_hash).await? {\n        return Ok(false); // Duplicate, skip\n    }\n\n    // 4. Parse MIDI file\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    // 5. Extract file metadata\n    let filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\")\n        .to_string();\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    let format = Some(midi_file.header.format as i16);\n    let num_tracks = midi_file.tracks.len() as i16;\n    let ticks_per_quarter = Some(midi_file.header.ticks_per_quarter_note as i32);\n\n    // 6. Run BPM detection\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(BigDecimal::from(bpm_result.bpm as i64))\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence as f32);\n\n    // 7. Run key detection\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence as f32);\n\n    // 8. Extract time signature\n    let (time_sig_num, time_sig_den) = extract_time_signature(\u0026midi_file);\n\n    // 9. Calculate duration\n    let total_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = if let Some(ref bpm_val) = bpm {\n        let bpm_f64 = bpm_result.bpm;\n        let ticks = total_ticks as f64;\n        let tpq = midi_file.header.ticks_per_quarter_note as f64;\n        if tpq \u003e 0.0 \u0026\u0026 bpm_f64 \u003e 0.0 {\n            let quarters = ticks / tpq;\n            let minutes = quarters / bpm_f64;\n            let seconds = minutes * 60.0;\n            Some(BigDecimal::from(seconds as i64))\n        } else {\n            None\n        }\n    } else {\n        None\n    };\n\n    let duration_ticks = Some(total_ticks);\n\n    // 10. Analyze notes\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 11. Insert file using FileRepository\n    let new_file = NewFile {\n        filename: filename.clone(),\n        filepath: filepath.clone(),\n        original_filename: filename,\n        content_hash: content_hash.to_vec(),\n        file_size_bytes: file_size,\n        format,\n        num_tracks,\n        ticks_per_quarter_note: ticks_per_quarter,\n        duration_seconds,\n        duration_ticks,\n        manufacturer: None,\n        collection_name: None,\n        folder_tags: None,\n        import_batch_id: None,\n    };\n\n    let file_id = FileRepository::insert(pool, new_file).await?;\n\n    // 12. Insert metadata using MetadataRepository\n    let new_metadata = NewMusicalMetadata {\n        file_id,\n        bpm,\n        bpm_confidence,\n        key_signature,\n        key_confidence,\n        time_signature_numerator: time_sig_num,\n        time_signature_denominator: time_sig_den,\n        total_notes: note_stats.note_count,\n        unique_pitches: note_stats.unique_pitches,\n        pitch_range_min: note_stats.pitch_min,\n        pitch_range_max: note_stats.pitch_max,\n        avg_velocity: note_stats.avg_velocity,\n        note_density: None, // Can be calculated later\n        polyphony_max: note_stats.polyphony_max,\n        polyphony_avg: None,\n        is_percussive: None,\n    };\n\n    MetadataRepository::insert(pool, new_metadata).await?;\n\n    Ok(true) // Successfully imported\n}\n\n/// Find all MIDI files in a directory\nfn find_midi_files(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e\u003e {\n    let mut files = Vec::new();\n\n    for entry in walkdir::WalkDir::new(dir) {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_file() {\n            if let Some(ext) = path.extension() {\n                if ext.eq_ignore_ascii_case(\"mid\") || ext.eq_ignore_ascii_case(\"midi\") {\n                    files.push(path.to_path_buf());\n                }\n            }\n        }\n    }\n\n    Ok(files)\n}\n\n/// Extract time signature from MIDI file\nfn extract_time_signature(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    use midi_library_shared::core::midi::types::Event;\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4)) // Default\n}\n\n/// Calculate total ticks in MIDI file\nfn calculate_total_ticks(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e i64 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i64\n}\n\n/// Note statistics\n#[derive(Debug)]\nstruct NoteStats {\n    note_count: i32,\n    unique_pitches: Option\u003ci32\u003e,\n    pitch_min: Option\u003ci16\u003e,\n    pitch_max: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cBigDecimal\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\n/// Analyze notes in MIDI file\nfn analyze_notes(midi_file: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e NoteStats {\n    use midi_library_shared::core::midi::types::Event;\n    use std::collections::{HashMap, HashSet};\n\n    let mut note_count = 0i32;\n    let mut pitches = HashSet::new();\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: HashMap\u003cu32, usize\u003e = HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    pitches.insert(*note);\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(BigDecimal::from((velocity_sum / note_count as u32) as i64))\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick\n        .values()\n        .max()\n        .copied()\n        .map(|v| v as i16);\n\n    let (pitch_min, pitch_max) = if note_count \u003e 0 {\n        (Some(min_pitch as i16), Some(max_pitch as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        unique_pitches: Some(pitches.len() as i32),\n        pitch_min,\n        pitch_max,\n        avg_velocity,\n        polyphony_max,\n    }\n}\n\n/// Print final summary\nfn print_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed())\n        .unwrap_or_else(|| std::time::Duration::from_secs(0));\n    let duration_secs = elapsed.as_secs_f64();\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if duration_secs \u003e 0.0 {\n        imported as f64 / duration_secs\n    } else {\n        0.0\n    };\n\n    println!(\"\\n========================================\");\n    println!(\"BATCH IMPORT COMPLETE\");\n    println!(\"========================================\");\n    println!(\"Files found: {}\", stats.files_found.load(Ordering::SeqCst));\n    println!(\"Successfully imported: {}\", imported);\n    println!(\"Duplicates skipped: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"Time: {:.0}h {:.0}m {:.0}s\",\n        duration_secs / 3600.0,\n        (duration_secs % 3600.0) / 60.0,\n        duration_secs % 60.0\n    );\n    println!(\"Avg speed: {:.0} files/sec\", rate);\n    println!(\"========================================\");\n    println!(\"All files include: BPM, Key, Notes, Stats\");\n    println!(\"========================================\\n\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","import.rs"],"content":"//! Import binary - standalone executable for batch importing MIDI files\n\nuse anyhow::{Context, Result};\nuse clap::Parser;\nuse sqlx::PgPool;\nuse std::path::PathBuf;\n\n// Note: This binary needs to be restructured to not depend on main crate\n// For now, this is a placeholder that shows the intended structure\n\n#[derive(Parser, Debug)]\n#[command(name = \"import\")]\n#[command(about = \"Import MIDI files into the library\", long_about = None)]\nstruct Args {\n    /// Directory containing MIDI files to import\n    #[arg(short, long)]\n    directory: PathBuf,\n\n    /// Database connection string\n    #[arg(short = 'D', long, env = \"DATABASE_URL\")]\n    database_url: String,\n\n    /// Number of parallel workers\n    #[arg(short, long, default_value = \"4\")]\n    workers: usize,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    let args = Args::parse();\n\n    println!(\" MIDI Import Tool\");\n    println!(\"Directory: {:?}\", args.directory);\n    println!(\"Workers: {}\", args.workers);\n\n    // Connect to database\n    let pool = PgPool::connect(\u0026args.database_url)\n        .await\n        .context(\"Failed to connect to database\")?;\n\n    println!(\" Database connected\");\n\n    // TODO: Implement actual import logic\n    // This will be implemented once the module structure is finalized\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","import_unified.rs"],"content":"//! Unified MIDI Import Pipeline\n//!\n//! This binary orchestrates ALL existing modules to provide a complete, single-pass\n//! import pipeline that processes compressed archives directly into the database with\n//! FULL analysis (BPM, key, tags, complexity, etc.).\n//!\n//! # Architecture: Orchestration Layer\n//! This is a thin orchestration layer that combines:\n//! - Archive extraction (io::decompressor)\n//! - MIDI parsing (core::midi::parser)\n//! - Musical analysis (core::analysis)\n//! - Intelligent tagging (core::analysis::auto_tagger)\n//! - Hash-based deduplication (core::hash)\n//! - Batch database inserts (database::batch_insert)\n//!\n//! # Workflow:\n//! ```text\n//! For each archive in input directory:\n//!   1. Extract archive  temp directory\n//!   2. Find all .mid/.midi files\n//!   3. For EACH MIDI file (in parallel with 32 workers):\n//!      a. Read file bytes\n//!      b. Parse MIDI\n//!      c. Detect BPM and key\n//!      d. Extract tags from path and content\n//!      e. Analyze notes (complexity, pitch range, polyphony, etc.)\n//!      f. Calculate BLAKE3 hash for deduplication\n//!      g. INSERT INTO files + musical_metadata (ONE transaction)\n//!   4. Clean up temp files\n//!   5. Move to next archive\n//! ```\n//!\n//! # Performance:\n//! - Target: 350-400 files/sec with full analysis\n//! - 1.5M files completed in ~1-1.5 hours\n//! - Single-pass processing (no re-analysis needed)\n//!\n//! # Usage:\n//! ```bash\n//! # Process directory of archives\n//! cargo run --release --bin import_unified -- ~/floorp_downloads/_1.002.000-Midi-Collection_/\n//!\n//! # Process single archive\n//! cargo run --release --bin import_unified -- ~/path/to/archive.zip\n//! ```\n\nuse std::path::{Path, PathBuf};\nuse std::sync::atomic::{AtomicUsize, AtomicU64, Ordering};\nuse std::sync::Arc;\nuse std::time::Instant;\n\nuse tokio::sync::Mutex;\nuse futures::stream::{self, StreamExt};\nuse clap::Parser;\n// Unused: use indicatif::{ProgressBar, ProgressStyle, MultiProgress};\n\n// Import existing modules - we just orchestrate them\nuse midi_pipeline::io::decompressor::extractor::{extract_archive, ExtractionConfig};\nuse midi_pipeline::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse midi_pipeline::core::analysis::bpm_detector::detect_bpm;\nuse midi_pipeline::core::analysis::key_detector::detect_key;\nuse midi_pipeline::core::analysis::auto_tagger::AutoTagger;\nuse midi_pipeline::database::Database;\n\n//=============================================================================\n// CLI ARGUMENTS\n//=============================================================================\n\n#[derive(Parser, Debug)]\n#[command(name = \"import-unified\")]\n#[command(about = \"Unified MIDI import pipeline with full analysis in single pass\")]\nstruct Args {\n    /// Path to archive directory or single archive file\n    #[arg(help = \"Directory containing .zip/.rar/.7z archives, or single archive file\")]\n    path: PathBuf,\n\n    /// Number of parallel MIDI processing workers (default: 32)\n    #[arg(short = 'w', long, default_value = \"32\")]\n    workers: usize,\n\n    /// Batch size for database inserts (default: 100)\n    #[arg(short = 'b', long, default_value = \"100\")]\n    batch_size: usize,\n\n    /// Database URL (default: from DATABASE_URL env var)\n    #[arg(long)]\n    database_url: Option\u003cString\u003e,\n}\n\n//=============================================================================\n// DATA STRUCTURES\n//=============================================================================\n\n/// Fully analyzed MIDI file ready for database insertion\n#[derive(Debug, Clone)]\nstruct AnalyzedMidiFile {\n    // File metadata\n    filename: String,\n    original_filename: String,\n    filepath: String,\n    parent_folder: Option\u003cString\u003e,\n    content_hash: Vec\u003cu8\u003e,\n    file_size_bytes: i64,\n    num_tracks: i16,\n    format: Option\u003ci16\u003e,\n    is_multi_track: bool,\n\n    // Musical metadata - tempo\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n\n    // Musical metadata - key\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n\n    // Musical metadata - time\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n\n    // Musical metadata - notes\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n\n    // Musical metadata - complexity\n    complexity_score: Option\u003cf64\u003e,\n\n    // Musical metadata - features\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n\n    // Tags\n    tags: Vec\u003cString\u003e,\n    category: Option\u003cString\u003e,\n}\n\n/// Statistics for the import operation\n#[derive(Debug, Default)]\nstruct ImportStats {\n    archives_processed: AtomicUsize,\n    archives_total: AtomicUsize,\n    files_found: AtomicU64,\n    files_imported: AtomicU64,\n    files_duplicates: AtomicU64,\n    files_errors: AtomicU64,\n    start_time: Option\u003cInstant\u003e,\n}\n\n//=============================================================================\n// MAIN ENTRY POINT\n//=============================================================================\n\n#[tokio::main]\nasync fn main() -\u003e anyhow::Result\u003c()\u003e {\n    // Load environment variables\n    dotenv::dotenv().ok();\n\n    // Parse CLI arguments\n    let args = Args::parse();\n\n    // Setup logging\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        .init();\n\n    println!(\"\\n UNIFIED MIDI IMPORT PIPELINE\");\n    println!(\"\\n\");\n\n    // Connect to database\n    let database_url = args.database_url.unwrap_or_else(|| {\n        std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                eprintln!(\" Error: DATABASE_URL must be set in environment or via --database-url\");\n                std::process::exit(1);\n            })\n    });\n\n    println!(\" Connecting to database...\");\n    let db = Database::new(\u0026database_url).await?;\n    println!(\" Database connected\\n\");\n\n    // Check if path is directory or single archive\n    if args.path.is_dir() {\n        process_archive_directory(\u0026args.path, \u0026db, args.workers, args.batch_size).await?;\n    } else if args.path.is_file() {\n        process_single_archive(\u0026args.path, \u0026db, args.workers, args.batch_size).await?;\n    } else {\n        anyhow::bail!(\"Path does not exist: {}\", args.path.display());\n    }\n\n    println!(\"\\n Import pipeline completed successfully!\");\n\n    Ok(())\n}\n\n//=============================================================================\n// ARCHIVE DIRECTORY PROCESSING\n//=============================================================================\n\n/// Process all archives in a directory\nasync fn process_archive_directory(\n    dir_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n) -\u003e anyhow::Result\u003c()\u003e {\n    println!(\" Scanning for archives in: {}\", dir_path.display());\n\n    // Find all archive files (.zip, .rar, .7z)\n    let archives: Vec\u003cPathBuf\u003e = std::fs::read_dir(dir_path)?\n        .filter_map(|entry| entry.ok())\n        .map(|entry| entry.path())\n        .filter(|path| {\n            path.extension()\n                .and_then(|ext| ext.to_str())\n                .map(|ext| {\n                    ext.eq_ignore_ascii_case(\"zip\")\n                        || ext.eq_ignore_ascii_case(\"rar\")\n                        || ext.eq_ignore_ascii_case(\"7z\")\n                })\n                .unwrap_or(false)\n        })\n        .collect();\n\n    let total_archives = archives.len();\n    println!(\" Found {} archives to process\\n\", total_archives);\n\n    if total_archives == 0 {\n        println!(\"  No archives found in directory\");\n        return Ok(());\n    }\n\n    // Initialize statistics\n    let stats = Arc::new(ImportStats {\n        archives_total: AtomicUsize::new(total_archives),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    // Process archives sequentially (avoid I/O bottleneck)\n    for (index, archive_path) in archives.iter().enumerate() {\n        let archive_name = archive_path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"unknown\");\n\n        println!(\"\\n\");\n        println!(\" Archive [{}/{}]: {}\", index + 1, total_archives, archive_name);\n        println!(\"\");\n\n        match process_archive_with_stats(archive_path, db, workers, batch_size, stats.clone()).await {\n            Ok(_) =\u003e {\n                stats.archives_processed.fetch_add(1, Ordering::SeqCst);\n                print_progress_summary(\u0026stats);\n            }\n            Err(e) =\u003e {\n                eprintln!(\" Failed to process archive {}: {}\", archive_name, e);\n                stats.archives_processed.fetch_add(1, Ordering::SeqCst);\n            }\n        }\n    }\n\n    // Print final summary\n    print_final_summary(\u0026stats);\n\n    Ok(())\n}\n\n/// Process a single archive file\nasync fn process_single_archive(\n    archive_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n) -\u003e anyhow::Result\u003c()\u003e {\n    let archive_name = archive_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\");\n\n    println!(\" Processing archive: {}\\n\", archive_name);\n\n    let stats = Arc::new(ImportStats {\n        archives_total: AtomicUsize::new(1),\n        start_time: Some(Instant::now()),\n        ..Default::default()\n    });\n\n    process_archive_with_stats(archive_path, db, workers, batch_size, stats.clone()).await?;\n\n    print_final_summary(\u0026stats);\n\n    Ok(())\n}\n\n//=============================================================================\n// ARCHIVE PROCESSING WITH FULL ANALYSIS\n//=============================================================================\n\n/// Process a single archive with full analysis and database insertion\nasync fn process_archive_with_stats(\n    archive_path: \u0026Path,\n    db: \u0026Database,\n    workers: usize,\n    batch_size: usize,\n    stats: Arc\u003cImportStats\u003e,\n) -\u003e anyhow::Result\u003c()\u003e {\n    let start_time = Instant::now();\n\n    // Step 1: Extract archive to temp directory\n    println!(\"   Extracting archive...\");\n    let temp_dir = std::env::temp_dir().join(format!(\"midi_unified_{}\", uuid::Uuid::new_v4()));\n    std::fs::create_dir_all(\u0026temp_dir)?;\n\n    let config = ExtractionConfig::default();\n    let extraction_result = extract_archive(archive_path, \u0026temp_dir, \u0026config).map_err(|e| anyhow::anyhow!(\"{}\", e))?;\n\n    let midi_files = extraction_result.midi_files;\n    let midi_count = midi_files.len();\n    stats.files_found.fetch_add(midi_count as u64, Ordering::SeqCst);\n\n    println!(\"   Found {} MIDI files\", midi_count);\n\n    if midi_count == 0 {\n        std::fs::remove_dir_all(\u0026temp_dir)?;\n        return Ok(());\n    }\n\n    // Extract category from archive name\n    let category = archive_path\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .map(|s| s.to_string());\n\n    // Step 2: Process MIDI files in parallel with full analysis\n    println!(\"   Processing {} MIDI files with {} workers...\", midi_count, workers);\n\n    // Thread-safe counters\n    let processed = Arc::new(AtomicUsize::new(0));\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(workers));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n    let pool = db.pool().await;\n\n    // Process files in parallel with buffer_unordered\n    stream::iter(midi_files)\n        .map(|file_path| {\n            let sem = Arc::clone(\u0026semaphore);\n            let category = category.clone();\n            let processed = Arc::clone(\u0026processed);\n            let analyzed_files = Arc::clone(\u0026analyzed_files);\n            let stats = Arc::clone(\u0026stats);\n            let pool = pool.clone();\n\n            async move {\n                // Acquire semaphore permit\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        eprintln!(\"Warning: Semaphore closed during import\");\n                        return;\n                    }\n                };\n\n                let current = processed.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Show progress every 100 files\n                if current % 100 == 0 || current == midi_count {\n                    let elapsed = start_time.elapsed().as_secs_f64();\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                    println!(\"    Processing: {}/{} ({:.1}%) - {:.1} files/sec\",\n                        current, midi_count,\n                        (current as f64 / midi_count as f64) * 100.0,\n                        rate\n                    );\n                }\n\n                // Analyze the file with full analysis\n                match analyze_midi_file(\u0026file_path, category).await {\n                    Ok(analyzed) =\u003e {\n                        // Add to batch for insertion\n                        analyzed_files.lock().await.push(analyzed);\n\n                        // Flush batch if it reaches threshold\n                        let mut files = analyzed_files.lock().await;\n                        if files.len() \u003e= batch_size {\n                            let batch: Vec\u003cAnalyzedMidiFile\u003e = files.drain(..).collect();\n                            drop(files); // Release lock\n\n                            match insert_batch(\u0026pool, \u0026batch).await {\n                                Ok(inserted) =\u003e {\n                                    stats.files_imported.fetch_add(inserted as u64, Ordering::SeqCst);\n                                    let duplicates = batch.len() - inserted;\n                                    stats.files_duplicates.fetch_add(duplicates as u64, Ordering::SeqCst);\n                                }\n                                Err(e) =\u003e {\n                                    eprintln!(\"       Batch insert failed: {}\", e);\n                                    stats.files_errors.fetch_add(batch.len() as u64, Ordering::SeqCst);\n                                }\n                            }\n                        }\n                    }\n                    Err(e) =\u003e {\n                        eprintln!(\"        Failed to analyze {}: {}\", file_path.display(), e);\n                        stats.files_errors.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(workers) // THE MAGIC: Process N files concurrently!\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedMidiFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        match insert_batch(\u0026pool, \u0026batch).await {\n            Ok(inserted) =\u003e {\n                stats.files_imported.fetch_add(inserted as u64, Ordering::SeqCst);\n                let duplicates = batch.len() - inserted;\n                stats.files_duplicates.fetch_add(duplicates as u64, Ordering::SeqCst);\n            }\n            Err(e) =\u003e {\n                eprintln!(\"       Final batch insert failed: {}\", e);\n                stats.files_errors.fetch_add(batch.len() as u64, Ordering::SeqCst);\n            }\n        }\n    }\n\n    // Cleanup temp directory\n    std::fs::remove_dir_all(\u0026temp_dir)?;\n\n    let elapsed = start_time.elapsed().as_secs_f64();\n    let rate = if elapsed \u003e 0.0 { midi_count as f64 / elapsed } else { 0.0 };\n    println!(\"   Completed in {:.1}s ({:.1} files/sec)\\n\", elapsed, rate);\n\n    Ok(())\n}\n\n//=============================================================================\n// MIDI FILE ANALYSIS (Full Analysis in Single Pass)\n//=============================================================================\n\n/// Analyze a single MIDI file with FULL analysis (BPM, key, tags, complexity, etc.)\nasync fn analyze_midi_file(\n    file_path: \u0026Path,\n    category: Option\u003cString\u003e,\n) -\u003e anyhow::Result\u003cAnalyzedMidiFile\u003e {\n    // 1. Read file bytes\n    let file_bytes = tokio::fs::read(file_path).await?;\n    let file_size_bytes = file_bytes.len() as i64;\n\n    // 2. Calculate BLAKE3 hash for deduplication\n    let hash_bytes = calculate_file_hash(file_path)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec();\n\n    // 3. Parse MIDI file\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n    let num_tracks = midi_file.tracks.len() as i16;\n    let format = Some(midi_file.header.format as i16);\n    let is_multi_track = midi_file.tracks.len() \u003e 1;\n\n    // 4. BPM Detection\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    // 5. Key Detection\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    // 6. Time Signature\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n\n    // 7. Duration Calculation\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n\n    // 8. Note Analysis\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 9. Extract Instruments\n    let instruments = extract_instrument_names(\u0026midi_file);\n\n    // 10. Detect MIDI Features\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n\n    // 11. Calculate Complexity Score\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    // 12. Extract Tags\n    let filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown\")\n        .to_string();\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    let auto_tagger = AutoTagger::new()?;\n    let tags_obj = auto_tagger.extract_tags(\n        \u0026filepath,\n        \u0026filename,\n        \u0026instruments,\n        tempo_bpm,\n        key_signature.as_deref(),\n    );\n\n    // Convert tags to strings for database\n    let tags: Vec\u003cString\u003e = tags_obj.iter().map(|t| {\n        match \u0026t.category {\n            Some(cat) =\u003e format!(\"{}:{}\", cat, t.name),\n            None =\u003e t.name.clone(),\n        }\n    }).collect();\n\n    // 13. Extract parent folder\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    Ok(AnalyzedMidiFile {\n        filename: filename.clone(),\n        original_filename: filename,\n        filepath,\n        parent_folder,\n        content_hash,\n        file_size_bytes,\n        num_tracks,\n        format,\n        is_multi_track,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n        tags,\n        category,\n    })\n}\n\n//=============================================================================\n// DATABASE BATCH INSERTION\n//=============================================================================\n\n/// Insert batch of analyzed files into database\n/// Returns number of files successfully inserted (excludes duplicates)\nasync fn insert_batch(pool: \u0026sqlx::PgPool, files: \u0026[AnalyzedMidiFile]) -\u003e anyhow::Result\u003cusize\u003e {\n    let mut inserted_count = 0;\n\n    for file in files {\n        let mut tx = pool.begin().await?;\n\n        // Insert file with ON CONFLICT to handle duplicates\n        let file_id_opt = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            INSERT INTO files (\n                filename, original_filename, filepath, parent_folder,\n                content_hash, file_size_bytes, num_tracks,\n                format, is_multi_track, created_at\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, NOW())\n            ON CONFLICT (content_hash) DO NOTHING\n            RETURNING id\n            \"#\n        )\n        .bind(\u0026file.filename)\n        .bind(\u0026file.original_filename)\n        .bind(\u0026file.filepath)\n        .bind(\u0026file.parent_folder)\n        .bind(\u0026file.content_hash)\n        .bind(file.file_size_bytes)\n        .bind(file.num_tracks)\n        .bind(file.format)\n        .bind(file.is_multi_track)\n        .fetch_optional(\u0026mut *tx)\n        .await?;\n\n        // If duplicate, skip\n        let file_id = match file_id_opt {\n            Some(id) =\u003e id,\n            None =\u003e {\n                tx.rollback().await?;\n                continue; // Skip duplicate\n            }\n        };\n\n        // Insert musical metadata\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id, tempo_bpm, bpm_confidence, has_tempo_variation,\n                key_signature, key_confidence, scale_type,\n                time_signature_num, time_signature_den,\n                duration_seconds, duration_ticks,\n                note_count, pitch_range_low, pitch_range_high, pitch_range_semitones,\n                avg_velocity, velocity_range_low, velocity_range_high,\n                polyphony_max, complexity_score,\n                instruments, has_pitch_bend, has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            \"#\n        )\n        .bind(file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Update analyzed_at timestamp\n        sqlx::query(\"UPDATE files SET analyzed_at = NOW() WHERE id = $1\")\n            .bind(file_id)\n            .execute(\u0026mut *tx)\n            .await?;\n\n        tx.commit().await?;\n        inserted_count += 1;\n    }\n\n    Ok(inserted_count)\n}\n\n//=============================================================================\n// HELPER FUNCTIONS - MIDI ANALYSIS\n//=============================================================================\n\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n    (Some(4), Some(4))\n}\n\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n    max_ticks as i32\n}\n\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        let seconds = minutes * 60.0;\n        Some(seconds)\n    } else {\n        None\n    }\n}\n\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026instrument_name) {\n                            instruments.push(instrument_name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    // Factor 1: Note density\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0);\n    }\n\n    // Factor 2: Pitch range\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0);\n    }\n\n    // Factor 3: Polyphony\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0);\n    }\n\n    // Factor 4: Track count\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0);\n\n    // Factor 5: Velocity variation\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0);\n    }\n\n    Some(score.min(100.0))\n}\n\n//=============================================================================\n// PROGRESS REPORTING\n//=============================================================================\n\nfn print_progress_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed().as_secs_f64())\n        .unwrap_or(0.0);\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if elapsed \u003e 0.0 { imported as f64 / elapsed } else { 0.0 };\n\n    println!(\"   Progress:\");\n    println!(\"    Archives: {}/{}\",\n        stats.archives_processed.load(Ordering::SeqCst),\n        stats.archives_total.load(Ordering::SeqCst)\n    );\n    println!(\"    Imported: {}\", imported);\n    println!(\"    Duplicates: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"    Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"    Rate: {:.1} files/sec\", rate);\n}\n\nfn print_final_summary(stats: \u0026ImportStats) {\n    let elapsed = stats.start_time\n        .map(|t| t.elapsed())\n        .unwrap_or_else(|| std::time::Duration::from_secs(0));\n    let duration_secs = elapsed.as_secs_f64();\n    let imported = stats.files_imported.load(Ordering::SeqCst);\n    let rate = if duration_secs \u003e 0.0 { imported as f64 / duration_secs } else { 0.0 };\n\n    println!(\"\\n========================================\");\n    println!(\"UNIFIED IMPORT COMPLETE\");\n    println!(\"========================================\");\n    println!(\"Archives processed: {}/{}\",\n        stats.archives_processed.load(Ordering::SeqCst),\n        stats.archives_total.load(Ordering::SeqCst)\n    );\n    println!(\"MIDI files found: {}\", stats.files_found.load(Ordering::SeqCst));\n    println!(\"Successfully imported: {}\", imported);\n    println!(\"  With full analysis: {}\", imported);\n    println!(\"Duplicates skipped: {}\", stats.files_duplicates.load(Ordering::SeqCst));\n    println!(\"Errors: {}\", stats.files_errors.load(Ordering::SeqCst));\n    println!(\"Time: {:.0}h {:.0}m {:.0}s\",\n        duration_secs / 3600.0,\n        (duration_secs % 3600.0) / 60.0,\n        duration_secs % 60.0\n    );\n    println!(\"Avg speed: {:.0} files/sec\", rate);\n    println!(\"========================================\");\n    println!(\"All files include: BPM, Key, Tags, Complexity\");\n    println!(\"Ready to use in DAW!\");\n    println!(\"========================================\\n\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","bin","split.rs"],"content":"//! Split binary - standalone executable for splitting multi-track MIDI files\n\nuse anyhow::{Context, Result};\nuse clap::Parser;\nuse sqlx::PgPool;\nuse std::path::PathBuf;\n\n#[derive(Parser, Debug)]\n#[command(name = \"split\")]\n#[command(about = \"Split multi-track MIDI files\", long_about = None)]\nstruct Args {\n    /// MIDI file to split\n    #[arg(short, long)]\n    file: PathBuf,\n\n    /// Output directory for split files\n    #[arg(short, long)]\n    output: PathBuf,\n\n    /// Database connection string\n    #[arg(short = 'D', long, env = \"DATABASE_URL\")]\n    database_url: String,\n}\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c()\u003e {\n    let args = Args::parse();\n\n    println!(\" MIDI Split Tool\");\n    println!(\"File: {:?}\", args.file);\n    println!(\"Output: {:?}\", args.output);\n\n    // Connect to database\n    let pool = PgPool::connect(\u0026args.database_url)\n        .await\n        .context(\"Failed to connect to database\")?;\n\n    println!(\" Database connected\");\n\n    // TODO: Implement actual split logic\n    // This will be implemented once the module structure is finalized\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","analyze.rs"],"content":"//! Musical Analysis Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION\n//!\n//! Architecture: Grown-up Script\n//! Purpose: Analyze all imported MIDI files using existing analysis modules\n//!\n//! This module processes 1.1M+ imported files by:\n//! - Reading unanalyzed files from database in batches\n//! - Parallel processing with buffer_unordered (32 workers)\n//! - Running BPM detection, key detection, and auto-tagging\n//! - Batch database inserts for musical_metadata\n//! - Real-time progress updates\n//!\n//! Performance Target: 400-500 files/sec (complete 1.1M files in ~40-60 minutes)\n\nuse crate::AppState;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse midi_library_shared::core::midi::types::{Event, MidiFile, TextType};\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\n// Unused: use crate::core::analysis::auto_tagger::{AutoTagger, Tag};\n\nuse serde::{Deserialize, Serialize};\nuse std::sync::Arc;\nuse tauri::{Emitter, State, Window};\nuse futures::stream::{self, StreamExt};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Progress event for real-time UI updates\n#[derive(Debug, Clone, Serialize)]\npub struct AnalysisProgress {\n    pub current: usize,\n    pub total: usize,\n    pub current_file: String,\n    pub rate: f64, // files per second\n    pub eta_seconds: f64,\n}\n\n/// Summary of analysis operation results\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AnalysisSummary {\n    pub total_files: usize,\n    pub analyzed: usize,\n    pub skipped: usize,\n    pub errors: Vec\u003cString\u003e,\n    pub duration_secs: f64,\n    pub rate: f64, // files per second\n}\n\n/// File record from database\n#[derive(Debug, Clone, sqlx::FromRow)]\nstruct FileRecord {\n    id: i64,\n    filepath: String,\n    filename: String,\n}\n\n/// Analyzed file data ready for database insertion\n#[derive(Debug, Clone)]\nstruct AnalyzedFile {\n    file_id: i64,\n\n    // Tempo\n    tempo_bpm: Option\u003cf64\u003e,\n    bpm_confidence: Option\u003cf64\u003e,\n    has_tempo_variation: bool,\n\n    // Key\n    key_signature: Option\u003cString\u003e,\n    key_confidence: Option\u003cf64\u003e,\n    scale_type: Option\u003cString\u003e,\n\n    // Time signature\n    time_signature_num: Option\u003ci16\u003e,\n    time_signature_den: Option\u003ci16\u003e,\n\n    // Duration\n    duration_seconds: Option\u003cf64\u003e,\n    duration_ticks: Option\u003ci32\u003e,\n\n    // Note analysis\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n\n    // Velocity\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n\n    // Polyphony\n    polyphony_max: Option\u003ci16\u003e,\n\n    // Complexity\n    complexity_score: Option\u003cf64\u003e,\n\n    // Additional properties\n    instruments: Vec\u003cString\u003e,\n    has_pitch_bend: bool,\n    has_cc_messages: bool,\n}\n\n//=============================================================================\n// TAURI COMMANDS\n//=============================================================================\n\n/// Analyze all unanalyzed MIDI files (HIGH-PERFORMANCE PARALLEL VERSION)\n///\n/// This command:\n/// 1. Reads unanalyzed files from database in batches\n/// 2. Processes them in parallel with 32 workers\n/// 3. Runs BPM detection, key detection, note analysis\n/// 4. Batch inserts results into musical_metadata\n/// 5. Updates files.analyzed_at timestamp\n/// 6. Shows real-time progress\n#[tauri::command]\npub async fn start_analysis(\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cAnalysisSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let pool: sqlx::PgPool = state.database.pool().await;\n\n    // Get total count of unanalyzed files\n    let total: i64 = sqlx::query_scalar(\n        \"SELECT COUNT(*) FROM files WHERE analyzed_at IS NULL\"\n    )\n    .fetch_one(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to count unanalyzed files: {}\", e))?;\n\n    println!(\" Found {} unanalyzed files\", total);\n\n    if total == 0 {\n        return Ok(AnalysisSummary {\n            total_files: 0,\n            analyzed: 0,\n            skipped: 0,\n            errors: vec![],\n            duration_secs: 0.0,\n            rate: 0.0,\n        });\n    }\n\n    // Parallel processing configuration\n    let concurrency_limit = 32; // Process 32 files concurrently\n    let batch_size = 1000; // Fetch files in batches of 1000\n\n    println!(\" Starting analysis:\");\n    println!(\"  Concurrency: {} workers\", concurrency_limit);\n    println!(\"  Batch size: {} files\", batch_size);\n\n    // Thread-safe counters\n    let analyzed = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // Batch buffer for database inserts\n    let analyzed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let total_usize = total as usize;\n\n    // Process files in batches\n    let mut offset = 0i64;\n\n    loop {\n        // Fetch batch of unanalyzed files\n        let files: Vec\u003cFileRecord\u003e = sqlx::query_as(\n            \"SELECT id, filepath, filename\n             FROM files\n             WHERE analyzed_at IS NULL\n             ORDER BY id\n             LIMIT $1 OFFSET $2\"\n        )\n        .bind(batch_size)\n        .bind(offset)\n        .fetch_all(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to fetch files: {}\", e))?;\n\n        if files.is_empty() {\n            break;\n        }\n\n        let batch_len = files.len();\n        println!(\" Processing batch: {} files (offset: {})\", batch_len, offset);\n\n        // Process batch in parallel\n        stream::iter(files)\n            .map(|file_record| {\n                // Clone Arc pointers for each concurrent task\n                let sem = Arc::clone(\u0026semaphore);\n                let analyzed = Arc::clone(\u0026analyzed);\n                let skipped = Arc::clone(\u0026skipped);\n                let errors = Arc::clone(\u0026errors);\n                let current_index = Arc::clone(\u0026current_index);\n                let analyzed_files = Arc::clone(\u0026analyzed_files);\n                let window = window.clone();\n\n                    let pool = pool.clone();\n                async move {\n                    // Acquire semaphore permit (blocks if at limit)\n                    let _permit = match sem.acquire().await {\n                        Ok(permit) =\u003e permit,\n                        Err(_) =\u003e {\n                            eprintln!(\"Warning: Semaphore closed during analysis\");\n                            return;\n                        }\n                    };\n\n                    let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                    // Emit progress every 10 files\n                    if current % 10 == 0 || current == total_usize {\n                        let elapsed = start_time.elapsed().as_secs_f64();\n                        let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n                        let remaining = total_usize - current;\n                        let eta_seconds = if rate \u003e 0.0 { remaining as f64 / rate } else { 0.0 };\n\n                        let _ = window.emit(\"analysis-progress\", AnalysisProgress {\n                            current,\n                            total: total_usize,\n                            current_file: file_record.filename.clone(),\n                            rate,\n                            eta_seconds,\n                        });\n\n                        // Print progress every 100 files\n                        if current % 100 == 0 {\n                            println!(\n                                \"Analyzing: {}/{} ({:.1}%) - {:.1} files/sec - ETA: {:.0}s\",\n                                current,\n                                total_usize,\n                                (current as f64 / total_usize as f64) * 100.0,\n                                rate,\n                                eta_seconds\n                            );\n                        }\n                    }\n\n                    // Analyze the file\n                    match analyze_single_file(\u0026file_record).await {\n                        Ok(analyzed_data) =\u003e {\n                            // Add to batch for insertion\n                            analyzed_files.lock().await.push(analyzed_data);\n                            analyzed.fetch_add(1, Ordering::SeqCst);\n\n                            // Flush batch if it reaches threshold (100 files)\n                            let mut files = analyzed_files.lock().await;\n                            if files.len() \u003e= 100 {\n                                let batch: Vec\u003cAnalyzedFile\u003e = files.drain(..).collect();\n                                drop(files); // Release lock\n\n                                if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n                                    errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                                }\n                            }\n                        }\n                        Err(e) =\u003e {\n                            let error_msg = format!(\"{}: {}\", file_record.filepath, e);\n                            errors.lock().await.push(error_msg);\n                            skipped.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                }\n            })\n            .buffer_unordered(concurrency_limit) //  THE MAGIC: Process N files concurrently!\n            .collect::\u003cVec\u003c_\u003e\u003e()\n            .await;\n\n        offset += batch_size;\n    }\n\n    // Flush remaining batch\n    let remaining_files = analyzed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cAnalyzedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files);\n\n        if let Err(e) = batch_insert_analyzed_files(\u0026batch, \u0026pool).await {\n            errors.lock().await.push(format!(\"Final batch insert failed: {}\", e));\n        }\n    }\n\n    // Calculate final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let analyzed_count = analyzed.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { analyzed_count as f64 / duration } else { 0.0 };\n\n    println!(\"\\n Analysis complete!\");\n    println!(\"  Total files: {}\", total_usize);\n    println!(\"  Analyzed: {}\", analyzed_count);\n    println!(\"  Skipped: {}\", skipped.load(Ordering::SeqCst));\n    println!(\"  Duration: {:.1}s\", duration);\n    println!(\"  Rate: {:.1} files/sec\", rate);\n\n    // Extract errors before creating summary\n    let error_list = errors.lock().await.clone();\n\n    Ok(AnalysisSummary {\n        total_files: total_usize,\n        analyzed: analyzed_count,\n        skipped: skipped.load(Ordering::SeqCst),\n        errors: error_list,\n        duration_secs: duration,\n        rate,\n    })\n}\n\n//=============================================================================\n// CORE ANALYSIS LOGIC\n//=============================================================================\n\n/// Analyze a single MIDI file using all analysis modules\nasync fn analyze_single_file(\n    file_record: \u0026FileRecord,\n) -\u003e Result\u003cAnalyzedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // 1. Read MIDI file from filesystem\n    let file_bytes = tokio::fs::read(\u0026file_record.filepath).await?;\n\n    // 2. Parse MIDI file (Trusty Module)\n    let midi_file = parse_midi_file(\u0026file_bytes)?;\n\n    // 3. BPM Detection (Trusty Module)\n    let bpm_result = detect_bpm(\u0026midi_file);\n    let tempo_bpm = if bpm_result.confidence \u003e 0.3 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n    let bpm_confidence = Some(bpm_result.confidence);\n    let has_tempo_variation = !bpm_result.metadata.is_constant;\n\n    // 4. Key Detection (Trusty Module)\n    let key_result = detect_key(\u0026midi_file);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n    let key_confidence = Some(key_result.confidence);\n    let scale_type = Some(key_result.scale_type.to_string());\n\n    // 5. Extract time signature from MIDI events\n    let (time_signature_num, time_signature_den) = extract_time_signature(\u0026midi_file);\n\n    // 6. Calculate duration\n    let duration_ticks = calculate_total_ticks(\u0026midi_file);\n    let duration_seconds = calculate_duration_seconds(\u0026midi_file, bpm_result.bpm);\n\n    // 7. Note analysis\n    let note_stats = analyze_notes(\u0026midi_file);\n\n    // 8. Extract instruments\n    let instruments = extract_instrument_names(\u0026midi_file);\n\n    // 9. Detect MIDI features\n    let has_pitch_bend = detect_pitch_bend(\u0026midi_file);\n    let has_cc_messages = detect_cc_messages(\u0026midi_file);\n\n    // 10. Calculate complexity score (simple heuristic)\n    let complexity_score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n\n    Ok(AnalyzedFile {\n        file_id: file_record.id,\n        tempo_bpm,\n        bpm_confidence,\n        has_tempo_variation,\n        key_signature,\n        key_confidence,\n        scale_type,\n        time_signature_num,\n        time_signature_den,\n        duration_seconds,\n        duration_ticks: Some(duration_ticks),\n        note_count: note_stats.note_count,\n        pitch_range_low: note_stats.pitch_range_low,\n        pitch_range_high: note_stats.pitch_range_high,\n        pitch_range_semitones: note_stats.pitch_range_semitones,\n        avg_velocity: note_stats.avg_velocity,\n        velocity_range_low: note_stats.velocity_range_low,\n        velocity_range_high: note_stats.velocity_range_high,\n        polyphony_max: note_stats.polyphony_max,\n        complexity_score,\n        instruments,\n        has_pitch_bend,\n        has_cc_messages,\n    })\n}\n\n/// Batch insert analyzed files into musical_metadata and update files.analyzed_at\nasync fn batch_insert_analyzed_files(\n    files: \u0026[AnalyzedFile],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    if files.is_empty() {\n        return Ok(());\n    }\n\n    let mut tx = pool.begin().await?;\n\n    for file in files {\n        // Insert or update musical_metadata\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                tempo_bpm,\n                bpm_confidence,\n                has_tempo_variation,\n                key_signature,\n                key_confidence,\n                scale_type,\n                time_signature_num,\n                time_signature_den,\n                duration_seconds,\n                duration_ticks,\n                note_count,\n                pitch_range_low,\n                pitch_range_high,\n                pitch_range_semitones,\n                avg_velocity,\n                velocity_range_low,\n                velocity_range_high,\n                polyphony_max,\n                complexity_score,\n                instruments,\n                has_pitch_bend,\n                has_cc_messages\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)\n            ON CONFLICT (file_id) DO UPDATE SET\n                tempo_bpm = EXCLUDED.tempo_bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                has_tempo_variation = EXCLUDED.has_tempo_variation,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                scale_type = EXCLUDED.scale_type,\n                time_signature_num = EXCLUDED.time_signature_num,\n                time_signature_den = EXCLUDED.time_signature_den,\n                duration_seconds = EXCLUDED.duration_seconds,\n                duration_ticks = EXCLUDED.duration_ticks,\n                note_count = EXCLUDED.note_count,\n                pitch_range_low = EXCLUDED.pitch_range_low,\n                pitch_range_high = EXCLUDED.pitch_range_high,\n                pitch_range_semitones = EXCLUDED.pitch_range_semitones,\n                avg_velocity = EXCLUDED.avg_velocity,\n                velocity_range_low = EXCLUDED.velocity_range_low,\n                velocity_range_high = EXCLUDED.velocity_range_high,\n                polyphony_max = EXCLUDED.polyphony_max,\n                complexity_score = EXCLUDED.complexity_score,\n                instruments = EXCLUDED.instruments,\n                has_pitch_bend = EXCLUDED.has_pitch_bend,\n                has_cc_messages = EXCLUDED.has_cc_messages\n            \"#\n        )\n        .bind(file.file_id)\n        .bind(file.tempo_bpm)\n        .bind(file.bpm_confidence)\n        .bind(file.has_tempo_variation)\n        .bind(\u0026file.key_signature)\n        .bind(file.key_confidence)\n        .bind(\u0026file.scale_type)\n        .bind(file.time_signature_num)\n        .bind(file.time_signature_den)\n        .bind(file.duration_seconds)\n        .bind(file.duration_ticks)\n        .bind(file.note_count)\n        .bind(file.pitch_range_low)\n        .bind(file.pitch_range_high)\n        .bind(file.pitch_range_semitones)\n        .bind(file.avg_velocity)\n        .bind(file.velocity_range_low)\n        .bind(file.velocity_range_high)\n        .bind(file.polyphony_max)\n        .bind(file.complexity_score)\n        .bind(\u0026file.instruments)\n        .bind(file.has_pitch_bend)\n        .bind(file.has_cc_messages)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Update files.analyzed_at timestamp\n        sqlx::query(\n            \"UPDATE files SET analyzed_at = NOW() WHERE id = $1\"\n        )\n        .bind(file.file_id)\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    tx.commit().await?;\n\n    Ok(())\n}\n\n//=============================================================================\n// HELPER FUNCTIONS - MIDI ANALYSIS\n//=============================================================================\n\n/// Note statistics\n#[derive(Debug, Clone)]\nstruct NoteStats {\n    note_count: i32,\n    pitch_range_low: Option\u003ci16\u003e,\n    pitch_range_high: Option\u003ci16\u003e,\n    pitch_range_semitones: Option\u003ci16\u003e,\n    avg_velocity: Option\u003cf64\u003e,\n    velocity_range_low: Option\u003ci16\u003e,\n    velocity_range_high: Option\u003ci16\u003e,\n    polyphony_max: Option\u003ci16\u003e,\n}\n\n/// Analyze notes in MIDI file\nfn analyze_notes(midi_file: \u0026MidiFile) -\u003e NoteStats {\n    let mut note_count = 0;\n    let mut min_pitch = 127u8;\n    let mut max_pitch = 0u8;\n    let mut min_velocity = 127u8;\n    let mut max_velocity = 0u8;\n    let mut velocity_sum = 0u32;\n    let mut active_notes_per_tick: std::collections::HashMap\u003cu32, usize\u003e = std::collections::HashMap::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n        let mut active_notes = std::collections::HashSet::new();\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            match \u0026timed_event.event {\n                Event::NoteOn { note, velocity, .. } if *velocity \u003e 0 =\u003e {\n                    note_count += 1;\n                    min_pitch = min_pitch.min(*note);\n                    max_pitch = max_pitch.max(*note);\n                    min_velocity = min_velocity.min(*velocity);\n                    max_velocity = max_velocity.max(*velocity);\n                    velocity_sum += *velocity as u32;\n\n                    active_notes.insert(*note);\n                    active_notes_per_tick.insert(current_tick, active_notes.len());\n                }\n                Event::NoteOff { note, .. } | Event::NoteOn { note, velocity: 0, .. } =\u003e {\n                    active_notes.remove(note);\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    let avg_velocity = if note_count \u003e 0 {\n        Some(velocity_sum as f64 / note_count as f64)\n    } else {\n        None\n    };\n\n    let polyphony_max = active_notes_per_tick.values().max().copied().map(|v| v as i16);\n\n    let (pitch_range_low, pitch_range_high, pitch_range_semitones) = if note_count \u003e 0 {\n        let semitones = max_pitch.saturating_sub(min_pitch) as i16;\n        (Some(min_pitch as i16), Some(max_pitch as i16), Some(semitones))\n    } else {\n        (None, None, None)\n    };\n\n    let (velocity_range_low, velocity_range_high) = if note_count \u003e 0 {\n        (Some(min_velocity as i16), Some(max_velocity as i16))\n    } else {\n        (None, None)\n    };\n\n    NoteStats {\n        note_count,\n        pitch_range_low,\n        pitch_range_high,\n        pitch_range_semitones,\n        avg_velocity,\n        velocity_range_low,\n        velocity_range_high,\n        polyphony_max,\n    }\n}\n\n/// Extract time signature from MIDI file\nfn extract_time_signature(midi_file: \u0026MidiFile) -\u003e (Option\u003ci16\u003e, Option\u003ci16\u003e) {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::TimeSignature { numerator, denominator, .. } = \u0026timed_event.event {\n                // MIDI stores denominator as power of 2 (2 = quarter note, 3 = eighth note, etc.)\n                let denom_value = 2i16.pow(*denominator as u32);\n                return (Some(*numerator as i16), Some(denom_value));\n            }\n        }\n    }\n\n    // Default to 4/4 if not found\n    (Some(4), Some(4))\n}\n\n/// Calculate total number of ticks in MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e i32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks as i32\n}\n\n/// Calculate duration in seconds\nfn calculate_duration_seconds(midi_file: \u0026MidiFile, bpm: f64) -\u003e Option\u003cf64\u003e {\n    let total_ticks = calculate_total_ticks(midi_file) as f64;\n    let ticks_per_quarter = midi_file.header.ticks_per_quarter_note as f64;\n\n    if total_ticks \u003e 0.0 \u0026\u0026 ticks_per_quarter \u003e 0.0 \u0026\u0026 bpm \u003e 0.0 {\n        let quarters = total_ticks / ticks_per_quarter;\n        let minutes = quarters / bpm;\n        let seconds = minutes * 60.0;\n        Some(seconds)\n    } else {\n        None\n    }\n}\n\n/// Extract instrument names from MIDI file\nfn extract_instrument_names(midi_file: \u0026MidiFile) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        if !instruments.contains(text) {\n                            instruments.push(text.clone());\n                        }\n                    }\n                }\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        if !instruments.contains(\u0026instrument_name) {\n                            instruments.push(instrument_name);\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\n/// Map MIDI General MIDI program number to instrument name\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    match program {\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\n/// Detect if MIDI file contains pitch bend events\nfn detect_pitch_bend(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::PitchBend { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\n/// Detect if MIDI file contains control change messages\nfn detect_cc_messages(midi_file: \u0026MidiFile) -\u003e bool {\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if matches!(\u0026timed_event.event, Event::ControlChange { .. }) {\n                return true;\n            }\n        }\n    }\n    false\n}\n\n/// Calculate complexity score based on various factors\nfn calculate_complexity_score(note_stats: \u0026NoteStats, midi_file: \u0026MidiFile) -\u003e Option\u003cf64\u003e {\n    if note_stats.note_count == 0 {\n        return Some(0.0);\n    }\n\n    let mut score = 0.0;\n\n    // Factor 1: Note density (notes per second)\n    // Assume average 120 BPM for rough estimate\n    let duration_est = calculate_total_ticks(midi_file) as f64 / (midi_file.header.ticks_per_quarter_note as f64 * 2.0);\n    if duration_est \u003e 0.0 {\n        let note_density = note_stats.note_count as f64 / duration_est;\n        score += (note_density / 10.0).min(30.0); // Max 30 points\n    }\n\n    // Factor 2: Pitch range (wider range = more complex)\n    if let Some(semitones) = note_stats.pitch_range_semitones {\n        score += (semitones as f64 / 2.0).min(20.0); // Max 20 points\n    }\n\n    // Factor 3: Polyphony (more simultaneous notes = more complex)\n    if let Some(polyphony) = note_stats.polyphony_max {\n        score += (polyphony as f64 * 5.0).min(25.0); // Max 25 points\n    }\n\n    // Factor 4: Track count\n    let track_count = midi_file.tracks.len() as f64;\n    score += (track_count * 2.0).min(15.0); // Max 15 points\n\n    // Factor 5: Velocity variation\n    if let (Some(low), Some(high)) = (note_stats.velocity_range_low, note_stats.velocity_range_high) {\n        let velocity_range = (high - low) as f64;\n        score += (velocity_range / 10.0).min(10.0); // Max 10 points\n    }\n\n    // Normalize to 0-100 scale\n    Some(score.min(100.0))\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_program_to_instrument_name() {\n        assert_eq!(program_to_instrument_name(0), Some(\"Piano\".to_string()));\n        assert_eq!(program_to_instrument_name(32), Some(\"Bass\".to_string()));\n        assert_eq!(program_to_instrument_name(80), Some(\"Lead\".to_string()));\n    }\n\n    #[test]\n    fn test_complexity_score_empty() {\n        let note_stats = NoteStats {\n            note_count: 0,\n            pitch_range_low: None,\n            pitch_range_high: None,\n            pitch_range_semitones: None,\n            avg_velocity: None,\n            velocity_range_low: None,\n            velocity_range_high: None,\n            polyphony_max: None,\n        };\n\n        let midi_file = MidiFile {\n            header: midi_library_shared::core::midi::types::Header {\n                format: 0,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![],\n        };\n\n        let score = calculate_complexity_score(\u0026note_stats, \u0026midi_file);\n        assert_eq!(score, Some(0.0));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","archive_import.rs"],"content":"//! Archive Collection Import Command\n//!\n//! Processes entire collections of nested archives, extracting and importing\n//! all MIDI files with automatic tagging.\n//!\n//! # Archetype: Grown-up Script (Tauri Command Wrapper)\n//! - Thin wrapper around core functionality\n//! - Coordinates decompressor + file import modules\n//! - Provides progress feedback to UI\n\nuse crate::AppState;\nuse crate::io::decompressor::extractor::{extract_archive, ExtractionConfig};\nuse crate::commands::file_import::import_directory;\nuse serde::{Deserialize, Serialize};\nuse std::path::Path;\nuse tauri::{Emitter, State, Window};\n\n/// Summary of archive collection import\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ArchiveImportSummary {\n    pub total_archives: usize,\n    pub total_files_imported: usize,\n    pub total_files_skipped: usize,\n    pub total_errors: usize,\n    pub duration_secs: f64,\n    pub archives_processed: Vec\u003cArchiveStatus\u003e,\n}\n\n/// Status of individual archive processing\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ArchiveStatus {\n    pub archive_name: String,\n    pub midi_files_found: usize,\n    pub files_imported: usize,\n    pub success: bool,\n    pub error_message: Option\u003cString\u003e,\n}\n\n/// Import entire collection of archives (recursively extracts and imports all MIDI files)\n///\n/// # Arguments\n/// * `collection_path` - Directory containing zip archives\n/// * `state` - Application state\n/// * `window` - Tauri window for progress events\n///\n/// # Frontend Usage\n/// ```typescript\n/// await invoke('import_archive_collection', {\n///   collectionPath: '/home/user/midi-collection/'\n/// });\n/// ```\n#[tauri::command]\npub async fn import_archive_collection(\n    collection_path: String,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cArchiveImportSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let collection_dir = Path::new(\u0026collection_path);\n\n    if !collection_dir.exists() {\n        return Err(format!(\"Collection directory not found: {}\", collection_path));\n    }\n\n    if !collection_dir.is_dir() {\n        return Err(format!(\"Path is not a directory: {}\", collection_path));\n    }\n\n    println!(\"\\n Starting archive collection import from: {}\", collection_path);\n    println!(\" Scanning for zip archives...\\n\");\n\n    // Scan for zip files\n    let archives: Vec\u003c_\u003e = std::fs::read_dir(collection_dir)\n        .map_err(|e| format!(\"Failed to read directory: {}\", e))?\n        .filter_map(|entry| entry.ok())\n        .filter(|entry| {\n            entry.path().extension()\n                .and_then(|ext| ext.to_str())\n                .map(|ext| ext.eq_ignore_ascii_case(\"zip\"))\n                .unwrap_or(false)\n        })\n        .collect();\n\n    let total_archives = archives.len();\n    println!(\" Found {} archives to process\\n\", total_archives);\n\n    let mut archive_statuses = Vec::new();\n    let mut total_files_imported = 0;\n    let mut total_files_skipped = 0;\n    let mut total_errors = 0;\n\n    // Process each archive\n    for (index, entry) in archives.iter().enumerate() {\n        let archive_path = entry.path();\n        let archive_name = archive_path\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"unknown\")\n            .to_string();\n\n        println!(\"\");\n        println!(\" [{}/{}] Processing: {}\", index + 1, total_archives, archive_name);\n        println!(\"\");\n\n        // Emit progress event\n        let _ = window.emit(\"archive-progress\", serde_json::json!({\n            \"current\": index + 1,\n            \"total\": total_archives,\n            \"archive_name\": archive_name\n        }));\n\n        // Process this archive\n        let status = process_single_archive(\n            \u0026archive_path,\n            \u0026archive_name,\n            state.clone(),\n            window.clone(),\n        ).await;\n\n        match \u0026status {\n            Ok(s) =\u003e {\n                total_files_imported += s.files_imported;\n                total_files_skipped += s.midi_files_found.saturating_sub(s.files_imported);\n                println!(\" Success: {} MIDIs found, {} imported\\n\", s.midi_files_found, s.files_imported);\n            }\n            Err(e) =\u003e {\n                total_errors += 1;\n                println!(\" Error: {}\\n\", e);\n            }\n        }\n\n        archive_statuses.push(status.unwrap_or_else(|e| ArchiveStatus {\n            archive_name: archive_name.clone(),\n            midi_files_found: 0,\n            files_imported: 0,\n            success: false,\n            error_message: Some(e),\n        }));\n    }\n\n    let duration = start_time.elapsed();\n    let duration_secs = duration.as_secs_f64();\n\n    println!(\"\\n\");\n    println!(\"      ARCHIVE COLLECTION IMPORT COMPLETE      \");\n    println!(\"\");\n    println!(\" Archives Processed: {:\u003e28} \", total_archives);\n    println!(\" Files Imported:     {:\u003e28} \", total_files_imported);\n    println!(\" Files Skipped:      {:\u003e28} \", total_files_skipped);\n    println!(\" Errors:             {:\u003e28} \", total_errors);\n    println!(\" Duration:           {:\u003e25.1}s \", duration_secs);\n    println!(\" Rate:               {:\u003e23.0} f/s \", total_files_imported as f64 / duration_secs);\n    println!(\"\\n\");\n\n    Ok(ArchiveImportSummary {\n        total_archives,\n        total_files_imported,\n        total_files_skipped,\n        total_errors,\n        duration_secs,\n        archives_processed: archive_statuses,\n    })\n}\n\n/// Process a single archive file\nasync fn process_single_archive(\n    archive_path: \u0026Path,\n    archive_name: \u0026str,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cArchiveStatus, String\u003e {\n    // Create temporary extraction directory\n    let temp_dir = std::env::temp_dir().join(format!(\"midi_extract_{}\", uuid::Uuid::new_v4()));\n    std::fs::create_dir_all(\u0026temp_dir)\n        .map_err(|e| format!(\"Failed to create temp directory: {}\", e))?;\n\n    // Extract with recursive decompression\n    println!(\"    Extracting (recursive, max depth 10)...\");\n    let config = ExtractionConfig::default(); // Uses max_depth: 10\n    let extract_result = extract_archive(archive_path, \u0026temp_dir, \u0026config)\n        .map_err(|e| format!(\"Extraction failed: {}\", e))?;\n\n    let midi_count = extract_result.midi_files.len();\n    println!(\"    Found {} MIDI files\", midi_count);\n\n    if midi_count == 0 {\n        // Cleanup and return\n        let _ = std::fs::remove_dir_all(\u0026temp_dir);\n        return Ok(ArchiveStatus {\n            archive_name: archive_name.to_string(),\n            midi_files_found: 0,\n            files_imported: 0,\n            success: true,\n            error_message: None,\n        });\n    }\n\n    // Import extracted files using existing import_directory command\n    println!(\"    Importing to database with auto-tagging...\");\n    let import_result = import_directory(\n        temp_dir.to_string_lossy().to_string(),\n        true, // recursive\n        Some(archive_name.trim_end_matches(\".zip\").to_string()), // category from archive name\n        state.clone(),\n        window.clone(),\n    ).await;\n\n    // Cleanup temp directory\n    let _ = std::fs::remove_dir_all(\u0026temp_dir);\n\n    match import_result {\n        Ok(summary) =\u003e {\n            Ok(ArchiveStatus {\n                archive_name: archive_name.to_string(),\n                midi_files_found: midi_count,\n                files_imported: summary.imported,\n                success: true,\n                error_message: None,\n            })\n        }\n        Err(e) =\u003e {\n            Err(format!(\"Import failed: {}\", e))\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","file_import.rs"],"content":"//! File Import Commands - HIGH-PERFORMANCE PARALLEL IMPLEMENTATION\n//!\n//! Architecture: Grown-up Script\n//! Purpose: Tauri commands for importing MIDI files with parallel processing\n//!\n//! This module integrates ALL optimizations:\n//! - BLAKE3 hashing (7x faster than SHA-256)\n//! - Parallel processing with buffer_unordered (40x speedup)\n//! - Batch database inserts (10x faster writes)\n//! - Dynamic concurrency tuning (optimal for any system)\n//!\n//! Performance Targets:\n//! - 1,000 files: \u003c 2 seconds\n//! - 10,000 files: ~25 seconds\n//! - 3,000,000 files: 1.5-2 hours (400-500 files/sec)\n\nuse crate::AppState;\nuse crate::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\nuse crate::core::analysis::auto_tagger::{AutoTagger, Tag};\nuse crate::core::performance::concurrency::{detect_system_resources, calculate_optimal_concurrency};\nuse crate::database::batch_insert::BatchInserter;\n\nuse serde::{Deserialize, Serialize};\nuse std::path::{Path, PathBuf};\nuse std::sync::Arc;\nuse tauri::{Emitter, State, Window};\nuse futures::stream::{self, StreamExt};\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse tokio::sync::Mutex;\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Progress event for real-time UI updates\n#[derive(Debug, Clone, Serialize)]\npub struct ImportProgress {\n    pub current: usize,\n    pub total: usize,\n    pub current_file: String,\n    pub rate: f64, // files per second\n}\n\n/// Summary of import operation results\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ImportSummary {\n    pub total_files: usize,\n    pub imported: usize,\n    pub skipped: usize,\n    pub errors: Vec\u003cString\u003e,\n    pub duration_secs: f64,\n    pub rate: f64, // files per second\n}\n\n/// File metadata returned from database\n#[derive(Debug, Clone, Serialize, sqlx::FromRow)]\npub struct FileMetadata {\n    pub id: i64,\n    pub filename: String,\n    pub original_filename: String,\n    pub filepath: String,\n    #[sqlx(rename = \"content_hash_hex\")]\n    pub content_hash: String, // Hex-encoded for JSON response\n    pub file_size_bytes: i64,\n    pub bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n}\n\n/// Intermediate structure for batch processing\n#[derive(Debug, Clone)]\nstruct ProcessedFile {\n    filename: String,\n    original_filename: String,\n    filepath: String,\n    parent_folder: Option\u003cString\u003e, // Parent directory name (e.g., \"bass\", \"drums\")\n    content_hash: Vec\u003cu8\u003e,\n    file_size_bytes: i64,\n    category: Option\u003cString\u003e, // Handled separately via file_categories table\n    bpm: Option\u003cf64\u003e,         // numeric(6,2) in DB\n    key_signature: Option\u003cString\u003e,\n    tags: Vec\u003cTag\u003e,           // Auto-extracted tags from filename, path, and MIDI content\n}\n\n//=============================================================================\n// TAURI COMMANDS (Thin Wrappers - Grown-up Script Pattern)\n//=============================================================================\n\n/// Import a single MIDI file\n///\n/// This is a thin wrapper that:\n/// 1. Validates the file path\n/// 2. Calls process_single_file (the actual logic)\n/// 3. Inserts to database and returns the result\n#[tauri::command]\npub async fn import_single_file(\n    file_path: String,\n    category: Option\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cFileMetadata, String\u003e {\n    let path = Path::new(\u0026file_path);\n\n    if !path.exists() {\n        return Err(format!(\"File not found: {}\", file_path));\n    }\n\n    if !is_midi_file(path) {\n        return Err(\"Not a MIDI file\".to_string());\n    }\n\n    // Process the file (calls Trusty Modules)\n    let processed = process_single_file(path, category.clone())\n        .await\n        .map_err(|e| format!(\"Failed to process file: {}\", e))?;\n\n    // Insert to database\n    let pool = state.database.pool().await;\n    let file_id = insert_single_file(\u0026processed, \u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to insert file: {}\", e))?;\n\n    // Retrieve the complete record\n    let file = sqlx::query_as::\u003c_, FileMetadata\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.original_filename,\n            f.filepath,\n            encode(f.content_hash, 'hex') as content_hash_hex,\n            f.file_size_bytes,\n            m.bpm,\n            m.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata m ON f.id = m.file_id\n        WHERE f.id = $1\n        \"#\n    )\n    .bind(file_id)\n    .fetch_one(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to retrieve file: {}\", e))?;\n\n    // Emit progress event\n    let _ = window.emit(\"import-progress\", ImportProgress {\n        current: 1,\n        total: 1,\n        current_file: file.filename.clone(),\n        rate: 1.0,\n    });\n\n    Ok(file)\n}\n\n/// Import all MIDI files from a directory (HIGH-PERFORMANCE PARALLEL VERSION)\n///\n/// This implementation integrates ALL optimizations:\n/// - Dynamic concurrency based on system resources\n/// - BLAKE3 hashing (7x faster)\n/// - Batch database inserts (10x faster)\n/// - Parallel processing with buffer_unordered\n/// - Progress updates throttled (every 10 files)\n/// - Semaphore to limit concurrency\n#[tauri::command]\npub async fn import_directory(\n    directory_path: String,\n    recursive: bool,\n    category: Option\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n    window: Window,\n) -\u003e Result\u003cImportSummary, String\u003e {\n    let start_time = std::time::Instant::now();\n    let path = Path::new(\u0026directory_path);\n\n    if !path.exists() {\n        return Err(format!(\"Directory not found: {}\", directory_path));\n    }\n\n    // Collect all MIDI files\n    let files = if recursive {\n        find_midi_files_recursive(path)\n    } else {\n        find_midi_files_shallow(path)\n    }\n    .map_err(|e| format!(\"Error scanning directory: {}\", e))?;\n\n    let total = files.len();\n\n    if total == 0 {\n        return Ok(ImportSummary {\n            total_files: 0,\n            imported: 0,\n            skipped: 0,\n            errors: vec![],\n            duration_secs: 0.0,\n            rate: 0.0,\n        });\n    }\n\n    // OPTIMIZATION 1: Dynamic concurrency based on system resources\n    let resources = detect_system_resources();\n    let concurrency_limit = calculate_optimal_concurrency(\u0026resources);\n\n    println!(\" System resources detected:\");\n    println!(\"  CPU cores: {}\", resources.cpu_cores);\n    println!(\"  Available memory: {:.2} GB\", resources.available_memory_gb);\n    println!(\"  Optimal concurrency: {}\", concurrency_limit);\n\n    // Thread-safe counters for parallel processing\n    let imported = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(Mutex::new(Vec::new()));\n    let current_index = Arc::new(AtomicUsize::new(0));\n\n    // Semaphore to limit concurrency\n    let semaphore = Arc::new(tokio::sync::Semaphore::new(concurrency_limit));\n\n    // OPTIMIZATION 2: Batch inserter for database writes\n    let pool = state.database.pool().await;\n    let batch_inserter = Arc::new(BatchInserter::new(pool.clone(), 1000));\n    let processed_files = Arc::new(Mutex::new(Vec::new()));\n\n    let category_clone = category.clone();\n    let total_clone = total;\n\n    //  PARALLEL PROCESSING WITH ALL OPTIMIZATIONS\n    stream::iter(files)\n        .map(|file_path| {\n            // Clone Arc pointers for each concurrent task\n            let sem = Arc::clone(\u0026semaphore);\n            let category = category_clone.clone();\n            let imported = Arc::clone(\u0026imported);\n            let skipped = Arc::clone(\u0026skipped);\n            let errors = Arc::clone(\u0026errors);\n            let current_index = Arc::clone(\u0026current_index);\n            let processed_files = Arc::clone(\u0026processed_files);\n            let batch_inserter = Arc::clone(\u0026batch_inserter);\n            let window = window.clone();\n\n            async move {\n                // Acquire semaphore permit (blocks if at limit)\n                // This should never fail unless semaphore is closed, which we never do\n                let _permit = match sem.acquire().await {\n                    Ok(permit) =\u003e permit,\n                    Err(_) =\u003e {\n                        // Semaphore closed - skip this file (should never happen)\n                        eprintln!(\"Warning: Semaphore closed during file import\");\n                        return;\n                    }\n                };\n\n                let current = current_index.fetch_add(1, Ordering::SeqCst) + 1;\n\n                // Emit progress every 10 files (reduce UI spam)\n                if current % 10 == 0 || current == total_clone {\n                    let elapsed = start_time.elapsed().as_secs_f64();\n                    let rate = if elapsed \u003e 0.0 { current as f64 / elapsed } else { 0.0 };\n\n                    let _ = window.emit(\"import-progress\", ImportProgress {\n                        current,\n                        total: total_clone,\n                        current_file: file_path.file_name()\n                            .and_then(|n| n.to_str())\n                            .unwrap_or(\"unknown\")\n                            .to_string(),\n                        rate,\n                    });\n                }\n\n                // OPTIMIZATION 3: Process file with BLAKE3 hashing\n                match process_single_file(\u0026file_path, category).await {\n                    Ok(processed) =\u003e {\n                        // Add to batch for insertion\n                        processed_files.lock().await.push(processed);\n                        imported.fetch_add(1, Ordering::SeqCst);\n\n                        // Flush batch if it reaches threshold\n                        let mut files = processed_files.lock().await;\n                        if files.len() \u003e= 100 {\n                            let batch: Vec\u003cProcessedFile\u003e = files.drain(..).collect();\n                            drop(files); // Release lock\n\n                            // Convert ProcessedFile to FileRecord for batch insert\n                            let file_records: Vec\u003ccrate::database::batch_insert::FileRecord\u003e = batch.iter().map(|f| {\n                                crate::database::batch_insert::FileRecord::new(\n                                    f.filename.clone(),\n                                    f.original_filename.clone(),\n                                    f.filepath.clone(),\n                                    f.parent_folder.clone(),\n                                    hex::encode(\u0026f.content_hash), // Convert bytea to hex string\n                                    f.file_size_bytes,\n                                    f.category.clone(),\n                                )\n                            }).collect();\n\n                            if let Err(e) = batch_inserter.insert_files_batch(file_records).await {\n                                errors.lock().await.push(format!(\"Batch insert failed: {}\", e));\n                            }\n                        }\n                    }\n                    Err(e) =\u003e {\n                        let error_msg = format!(\"{}: {}\", file_path.display(), e);\n                        errors.lock().await.push(error_msg);\n                        skipped.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n            }\n        })\n        .buffer_unordered(concurrency_limit)  //  THE MAGIC: Process N files concurrently!\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .await;\n\n    // OPTIMIZATION 4: Flush remaining batch\n    let remaining_files = processed_files.lock().await;\n    if !remaining_files.is_empty() {\n        let batch: Vec\u003cProcessedFile\u003e = remaining_files.iter().cloned().collect();\n        drop(remaining_files); // Release lock before async operation\n\n        // Convert ProcessedFile to FileRecord for batch insert\n        let file_records: Vec\u003ccrate::database::batch_insert::FileRecord\u003e = batch.iter().map(|f| {\n            crate::database::batch_insert::FileRecord::new(\n                f.filename.clone(),\n                f.original_filename.clone(),\n                f.filepath.clone(),\n                f.parent_folder.clone(),\n                hex::encode(\u0026f.content_hash), // Convert bytea to hex string\n                f.file_size_bytes,\n                f.category.clone(),\n            )\n        }).collect();\n\n        if let Err(e) = batch_inserter.insert_files_batch(file_records).await {\n            errors.lock().await.push(format!(\"Final batch insert failed: {}\", e));\n        }\n    }\n\n    // Calculate final statistics\n    let duration = start_time.elapsed().as_secs_f64();\n    let imported_count = imported.load(Ordering::SeqCst);\n    let rate = if duration \u003e 0.0 { imported_count as f64 / duration } else { 0.0 };\n\n    // Extract errors before creating summary\n    let error_list = errors.lock().await.clone();\n\n    Ok(ImportSummary {\n        total_files: total,\n        imported: imported_count,\n        skipped: skipped.load(Ordering::SeqCst),\n        errors: error_list,\n        duration_secs: duration,\n        rate,\n    })\n}\n\n//=============================================================================\n// CORE LOGIC (Grown-up Script - orchestrates Trusty Modules)\n//=============================================================================\n\n/// Process a single MIDI file and prepare for database insertion\n///\n/// This function orchestrates multiple Trusty Modules:\n/// - hash::blake3 (BLAKE3 hashing - 7x faster than SHA-256)\n/// - midi::parser (MIDI parsing)\n/// - analysis::bpm_detector (tempo detection)\n/// - analysis::key_detector (key signature detection)\n/// - analysis::auto_tagger (intelligent tag extraction)\n/// - naming::generator (filename generation)\nasync fn process_single_file(\n    file_path: \u0026Path,\n    category: Option\u003cString\u003e,\n) -\u003e Result\u003cProcessedFile, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // 1. Generate BLAKE3 hash for deduplication (7x faster than SHA-256)\n    let hash_bytes = calculate_file_hash(file_path)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec(); // Convert [u8; 32] to Vec\u003cu8\u003e for bytea\n\n    // 2. Read file bytes\n    let file_bytes = tokio::fs::read(file_path).await?;\n\n    // 3. Parse MIDI file (Trusty Module)\n    let midi_data = parse_midi_file(\u0026file_bytes)?;\n\n    // 4. Extract parent folder name\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    // 5. Extract metadata (Trusty Modules)\n    let bpm_result = detect_bpm(\u0026midi_data);\n    let bpm = if bpm_result.confidence \u003e 0.5 {\n        Some(bpm_result.bpm) // Keep as f64 for numeric(6,2)\n    } else {\n        None\n    };\n\n    let key_result = detect_key(\u0026midi_data);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n\n    // 6. Get file info\n    let filename = file_path.file_name()\n        .and_then(|n| n.to_str())\n        .ok_or(\"Invalid filename\")?\n        .to_string();\n\n    let original_filename = filename.clone(); // Store original filename\n\n    let filepath = file_path.to_str()\n        .ok_or(\"Invalid file path\")?\n        .to_string();\n\n    let file_size_bytes = tokio::fs::metadata(file_path).await?.len() as i64;\n\n    // 7. Extract MIDI instruments for tag extraction\n    let midi_instruments = extract_instrument_names(\u0026midi_data);\n\n    // 8. Auto-tag extraction (NEW: intelligently extract tags from filename, path, and MIDI content)\n    let auto_tagger = AutoTagger::new()\n        .map_err(|e| format!(\"Failed to initialize auto-tagger: {}\", e))?;\n    let tags = auto_tagger.extract_tags(\n        \u0026filepath,\n        \u0026filename,\n        \u0026midi_instruments,\n        bpm,\n        key_signature.as_deref(),\n    );\n\n    Ok(ProcessedFile {\n        filename,\n        original_filename,\n        filepath,\n        parent_folder,\n        content_hash,\n        file_size_bytes,\n        category,\n        bpm,\n        key_signature,\n        tags,\n    })\n}\n\n/// Extract instrument names from MIDI file for tag extraction\nfn extract_instrument_names(midi: \u0026midi_library_shared::core::midi::types::MidiFile) -\u003e Vec\u003cString\u003e {\n    use midi_library_shared::core::midi::types::{Event, TextType};\n\n    let mut instruments = Vec::new();\n\n    for track in \u0026midi.tracks {\n        for timed_event in \u0026track.events {\n            match \u0026timed_event.event {\n                // Extract track/instrument names from MIDI text events\n                Event::Text { text_type, text } =\u003e {\n                    if matches!(text_type, TextType::InstrumentName | TextType::TrackName) {\n                        instruments.push(text.clone());\n                    }\n                }\n                // Map MIDI program changes to GM instrument names\n                Event::ProgramChange { program, .. } =\u003e {\n                    if let Some(instrument_name) = program_to_instrument_name(*program) {\n                        instruments.push(instrument_name);\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    instruments\n}\n\n/// Map MIDI General MIDI program number to instrument name\nfn program_to_instrument_name(program: u8) -\u003e Option\u003cString\u003e {\n    // General MIDI Level 1 Sound Set\n    match program {\n        // Piano (0-7)\n        0..=7 =\u003e Some(\"Piano\".to_string()),\n        // Chromatic Percussion (8-15)\n        8..=15 =\u003e Some(\"Keys\".to_string()),\n        // Organ (16-23)\n        16..=23 =\u003e Some(\"Organ\".to_string()),\n        // Guitar (24-31)\n        24..=31 =\u003e Some(\"Guitar\".to_string()),\n        // Bass (32-39)\n        32..=39 =\u003e Some(\"Bass\".to_string()),\n        // Strings (40-47)\n        40..=47 =\u003e Some(\"Strings\".to_string()),\n        // Ensemble (48-55)\n        48..=55 =\u003e Some(\"Ensemble\".to_string()),\n        // Brass (56-63)\n        56..=63 =\u003e Some(\"Brass\".to_string()),\n        // Reed (64-71)\n        64..=71 =\u003e Some(\"Woodwind\".to_string()),\n        // Pipe (72-79)\n        72..=79 =\u003e Some(\"Flute\".to_string()),\n        // Synth Lead (80-87)\n        80..=87 =\u003e Some(\"Lead\".to_string()),\n        // Synth Pad (88-95)\n        88..=95 =\u003e Some(\"Pad\".to_string()),\n        // Synth Effects (96-103)\n        96..=103 =\u003e Some(\"FX\".to_string()),\n        // Ethnic (104-111)\n        104..=111 =\u003e Some(\"Ethnic\".to_string()),\n        // Percussive (112-119)\n        112..=119 =\u003e Some(\"Percussion\".to_string()),\n        // Sound Effects (120-127)\n        120..=127 =\u003e Some(\"FX\".to_string()),\n        _ =\u003e None,\n    }\n}\n\n/// Insert a single file to database (used by single file import)\nasync fn insert_single_file(\n    file: \u0026ProcessedFile,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // Insert in transaction\n    let mut tx = pool.begin().await?;\n\n    // Insert file with ON CONFLICT to handle duplicates\n    let file_id_opt = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, 1, NOW())\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#\n    )\n    .bind(\u0026file.filename)\n    .bind(\u0026file.original_filename)\n    .bind(\u0026file.filepath)\n    .bind(\u0026file.content_hash)\n    .bind(file.file_size_bytes)\n    .fetch_optional(\u0026mut *tx)\n    .await?;\n\n    // If file already exists (conflict), return error\n    let file_id: i64 = match file_id_opt {\n        Some(id) =\u003e id,\n        None =\u003e {\n            tx.rollback().await?;\n            return Err(\"File already exists (duplicate hash)\".into());\n        }\n    };\n\n    // Insert musical metadata if available\n    if file.bpm.is_some() || file.key_signature.is_some() {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                key_signature,\n                time_signature_numerator,\n                time_signature_denominator\n            ) VALUES ($1, $2, $3::musical_key, 4, 4)\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                key_signature = EXCLUDED.key_signature\n            \"#\n        )\n        .bind(file_id)\n        .bind(file.bpm)\n        .bind(file.key_signature.as_deref())\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Handle category if provided\n    if let Some(ref category_name) = file.category {\n        // Get or create category\n        let category_id = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            INSERT INTO categories (name, created_at)\n            VALUES ($1, NOW())\n            ON CONFLICT (name) DO UPDATE SET name = EXCLUDED.name\n            RETURNING id\n            \"#\n        )\n        .bind(category_name)\n        .fetch_one(\u0026mut *tx)\n        .await?;\n\n        // Link file to category\n        sqlx::query(\n            r#\"\n            INSERT INTO file_categories (file_id, category_id)\n            VALUES ($1, $2)\n            ON CONFLICT DO NOTHING\n            \"#\n        )\n        .bind(file_id)\n        .bind(category_id)\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Insert auto-generated tags\n    if !file.tags.is_empty() {\n        // Prepare tag data (name, category)\n        let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = file\n            .tags\n            .iter()\n            .map(|tag| (tag.name.clone(), tag.category.clone()))\n            .collect();\n\n        // Create/get tags and insert file_tags associations\n        for (name, category) in tag_data {\n            // Get or create tag\n            let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n                r#\"\n                INSERT INTO tags (name, category, usage_count, created_at)\n                VALUES ($1, $2, 0, NOW())\n                ON CONFLICT (name) DO UPDATE\n                SET name = EXCLUDED.name\n                RETURNING id\n                \"#,\n            )\n            .bind(\u0026name)\n            .bind(category.as_deref())\n            .fetch_one(\u0026mut *tx)\n            .await?;\n\n            // Associate tag with file\n            sqlx::query(\n                r#\"\n                INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n                VALUES ($1, $2, NOW(), 'system')\n                ON CONFLICT (file_id, tag_id) DO NOTHING\n                \"#,\n            )\n            .bind(file_id)\n            .bind(tag_id)\n            .execute(\u0026mut *tx)\n            .await?;\n        }\n    }\n\n    tx.commit().await?;\n\n    Ok(file_id)\n}\n\n//=============================================================================\n// HELPER FUNCTIONS\n//=============================================================================\n\n/// Recursively collect all MIDI files in a directory\nfn find_midi_files_recursive(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e, std::io::Error\u003e {\n    let mut files = Vec::new();\n\n    for entry in std::fs::read_dir(dir)? {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_dir() {\n            match find_midi_files_recursive(\u0026path) {\n                Ok(subfiles) =\u003e files.extend(subfiles),\n                Err(e) =\u003e {\n                    eprintln!(\"Warning: Failed to read directory {}: {}\", path.display(), e);\n                    // Continue with other directories\n                }\n            }\n        } else if is_midi_file(\u0026path) {\n            files.push(path);\n        }\n    }\n\n    Ok(files)\n}\n\n/// Finds MIDI files in directory (non-recursive)\nfn find_midi_files_shallow(dir: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e, std::io::Error\u003e {\n    let mut files = Vec::new();\n\n    for entry in std::fs::read_dir(dir)? {\n        let entry = entry?;\n        let path = entry.path();\n\n        if path.is_file() \u0026\u0026 is_midi_file(\u0026path) {\n            files.push(path);\n        }\n    }\n\n    Ok(files)\n}\n\n/// Check if a file is a MIDI file based on extension\nfn is_midi_file(path: \u0026Path) -\u003e bool {\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext| ext.eq_ignore_ascii_case(\"mid\") || ext.eq_ignore_ascii_case(\"midi\"))\n        .unwrap_or(false)\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_is_midi_file() {\n        assert!(is_midi_file(Path::new(\"test.mid\")));\n        assert!(is_midi_file(Path::new(\"test.MID\")));\n        assert!(is_midi_file(Path::new(\"test.midi\")));\n        assert!(is_midi_file(Path::new(\"test.MIDI\")));\n        assert!(!is_midi_file(Path::new(\"test.txt\")));\n        assert!(!is_midi_file(Path::new(\"test\")));\n    }\n\n    #[test]\n    fn test_find_midi_files_shallow() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let test_dir = temp_dir.path();\n\n        std::fs::write(test_dir.join(\"file1.mid\"), b\"\").unwrap();\n        std::fs::write(test_dir.join(\"file2.midi\"), b\"\").unwrap();\n        std::fs::write(test_dir.join(\"file3.txt\"), b\"\").unwrap();\n\n        let files = find_midi_files_shallow(test_dir).unwrap();\n        assert_eq!(files.len(), 2);\n    }\n\n    #[test]\n    fn test_find_midi_files_recursive() {\n        let temp_dir = tempfile::tempdir().unwrap();\n        let test_dir = temp_dir.path();\n        let sub_dir = test_dir.join(\"subdir\");\n        std::fs::create_dir(\u0026sub_dir).unwrap();\n\n        std::fs::write(test_dir.join(\"file1.mid\"), b\"\").unwrap();\n        std::fs::write(sub_dir.join(\"file2.mid\"), b\"\").unwrap();\n\n        let files = find_midi_files_recursive(test_dir).unwrap();\n        assert_eq!(files.len(), 2);\n    }\n\n    #[tokio::test]\n    async fn test_auto_tagging_import() {\n        println!(\"\\n Starting auto-tagging integration test...\");\n\n        // 1. Connect to test database\n        let database_url = \"postgresql://midiuser:145278963@localhost:5433/midi_library\";\n        let pool = match sqlx::PgPool::connect(database_url).await {\n            Ok(pool) =\u003e {\n                println!(\" Connected to database\");\n                pool\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to connect to database: {:?}\", e);\n            }\n        };\n\n        // 2. Verify test file exists\n        let test_file_path = std::path::Path::new(\"/tmp/midi_test_import/Vengeance_Deep_House_Kick_128_C.mid\");\n        if !test_file_path.exists() {\n            panic!(\" Test file not found: {:?}\", test_file_path);\n        }\n        println!(\" Test file found: {:?}\", test_file_path);\n\n        // 3. Process the file (extracts tags)\n        println!(\" Processing file...\");\n        let processed = match process_single_file(test_file_path, Some(\"test\".to_string())).await {\n            Ok(p) =\u003e {\n                println!(\" File processed successfully\");\n                println!(\"   Filename: {}\", p.filename);\n                println!(\"   Tags extracted: {}\", p.tags.len());\n                for tag in \u0026p.tags {\n                    match \u0026tag.category {\n                        Some(cat) =\u003e println!(\"     - {}:{}\", cat, tag.name),\n                        None =\u003e println!(\"     - {}\", tag.name),\n                    }\n                }\n                p\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to process file: {:?}\", e);\n            }\n        };\n\n        // 4. Insert into database (including tags)\n        println!(\" Inserting into database...\");\n        let file_id = match insert_single_file(\u0026processed, \u0026pool).await {\n            Ok(id) =\u003e {\n                println!(\" File inserted with ID: {}\", id);\n                id\n            }\n            Err(e) =\u003e {\n                panic!(\" Failed to insert file: {:?}\", e);\n            }\n        };\n\n        // 5. Verify tags were stored in database\n        println!(\" Verifying tags in database...\");\n        let tags: Vec\u003c(String, Option\u003cString\u003e)\u003e = sqlx::query_as(\n            r#\"\n            SELECT t.name, t.category\n            FROM tags t\n            JOIN file_tags ft ON t.id = ft.tag_id\n            WHERE ft.file_id = $1\n            ORDER BY t.category, t.name\n            \"#\n        )\n        .bind(file_id)\n        .fetch_all(\u0026pool)\n        .await\n        .expect(\"Failed to fetch tags from database\");\n\n        println!(\" Tags found in database: {}\", tags.len());\n        for (name, category) in \u0026tags {\n            match category {\n                Some(cat) =\u003e println!(\"     - {}:{}\", cat, name),\n                None =\u003e println!(\"     - {}\", name),\n            }\n        }\n\n        // 6. Verify expected tags exist\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|(name, cat)| {\n            match cat {\n                Some(c) =\u003e format!(\"{}:{}\", c, name),\n                None =\u003e name.clone(),\n            }\n        }).collect();\n\n        println!(\"\\n Checking for expected tags...\");\n\n        // Check for \"vengeance\" tag (should be brand:vengeance or just vengeance)\n        let has_vengeance = tag_names.iter().any(|t| t.to_lowercase().contains(\"vengeance\"));\n        assert!(has_vengeance, \" Missing 'vengeance' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found vengeance tag\");\n\n        // Check for \"house\" tag (should be genre:house or just house)\n        let has_house = tag_names.iter().any(|t| t.to_lowercase().contains(\"house\"));\n        assert!(has_house, \" Missing 'house' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found house tag\");\n\n        // Check for \"kick\" tag (should be instrument:kick or category:kick)\n        let has_kick = tag_names.iter().any(|t| t.to_lowercase().contains(\"kick\"));\n        assert!(has_kick, \" Missing 'kick' tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found kick tag\");\n\n        // Check for BPM tag\n        let has_bpm = tag_names.iter().any(|t| t.contains(\"bpm:\") || t.contains(\"128\"));\n        assert!(has_bpm, \" Missing BPM tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found BPM tag\");\n\n        // Check for key tag\n        let has_key = tag_names.iter().any(|t| t.to_lowercase().contains(\"key:\") || t.to_lowercase().contains(\":c\"));\n        assert!(has_key, \" Missing key tag. Found tags: {:?}\", tag_names);\n        println!(\"    Found key tag\");\n\n        println!(\"\\n   ALL AUTO-TAGGING TESTS PASSED!   \\n\");\n\n        // Cleanup: Remove test file from database\n        sqlx::query(\"DELETE FROM files WHERE id = $1\")\n            .bind(file_id)\n            .execute(\u0026pool)\n            .await\n            .expect(\"Failed to cleanup test file\");\n        println!(\" Cleaned up test data\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","files.rs"],"content":"// src-tauri/src/commands/files.rs\n//\n// ARCHETYPE: MANAGER (Grown-up Script)\n// PURPOSE: Tauri commands for file operations with database I/O\n//\n//  CAN: Perform database I/O (queries)\n//  CAN: Have side effects (database reads/writes)\n//  CAN: Be async\n//  SHOULD: Handle errors using AppError\n//  MUST NOT: Contain complex business logic\n//  MUST NOT: Have UI concerns\n//  SHOULD: Delegate complex logic to separate modules\n\nuse chrono::{DateTime, Utc};\nuse serde::Serialize;\nuse sqlx::FromRow;\nuse tauri::State;\n\nuse crate::AppState;\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// MIDI file record with musical metadata\n///\n/// Combined data from files and musical_metadata tables.\n/// Used for displaying file information in the UI.\n///\n/// # Archetype: Trusty Module (data structure)\n///\n/// This is a pure data container with no behavior.\n#[derive(Debug, FromRow, Serialize)]\npub struct MidiFile {\n    /// Unique file ID\n    pub id: i64,\n\n    /// Display filename (e.g., \"my-song.mid\")\n    pub filename: String,\n\n    /// Full path to file (e.g., \"/library/bass/my-song.mid\")\n    pub filepath: String,\n\n    /// Original filename before processing\n    #[serde(rename = \"originalFilename\")]\n    pub original_filename: String,\n\n    /// Primary category (e.g., \"BASS\", \"LEAD\")\n    pub category: String,\n\n    /// Parent folder name (e.g., \"bass\", \"drums\", \"leads\")\n    #[serde(rename = \"parentFolder\")]\n    pub parent_folder: Option\u003cString\u003e,\n\n    /// File size in bytes\n    #[serde(rename = \"fileSize\")]\n    pub file_size: i64,\n\n    /// Detected BPM (nullable)\n    pub bpm: Option\u003cf64\u003e,\n\n    /// Detected key signature (nullable, e.g., \"C\", \"Am\")\n    #[serde(rename = \"key\")]\n    pub key_signature: Option\u003cString\u003e,\n\n    /// Duration in seconds (nullable)\n    #[serde(rename = \"duration\")]\n    pub duration_seconds: Option\u003cf64\u003e,\n\n    /// Timestamp when file was added to database\n    #[serde(rename = \"createdAt\")]\n    pub created_at: DateTime\u003cUtc\u003e,\n\n    /// Timestamp when file was last updated\n    #[serde(rename = \"updatedAt\")]\n    pub updated_at: DateTime\u003cUtc\u003e,\n}\n\n// =============================================================================\n// TAURI COMMANDS - MANAGER ARCHETYPE\n// =============================================================================\n\n/// Test database connection\n///\n/// Verifies that the database is reachable and responds to queries.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (network call to database)\n/// -  Handles errors properly (converts to String)\n/// -  No complex business logic\n///\n/// # Returns\n///\n/// * `Result\u003cbool, String\u003e` - True if connected, error message if failed\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const connected = await invoke\u003cboolean\u003e('test_db_connection');\n/// if (connected) {\n///   console.log('Database is ready');\n/// }\n/// ```\n#[tauri::command]\npub async fn test_db_connection(state: State\u003c'_, AppState\u003e) -\u003e Result\u003cbool, String\u003e {\n    state\n        .database\n        .test_connection()\n        .await\n        .map_err(|e| format!(\"Database connection failed: {}\", e))\n}\n\n/// Get total count of files in database\n///\n/// Returns the number of MIDI files currently stored.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n/// -  No complex business logic\n///\n/// # Returns\n///\n/// * `Result\u003ci64, String\u003e` - Total file count or error message\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_file_count');\n/// console.log(`Library contains ${count} files`);\n/// ```\n#[tauri::command]\npub async fn get_file_count(state: State\u003c'_, AppState\u003e) -\u003e Result\u003ci64, String\u003e {\n    let pool = state.database.pool().await;\n    let count: i64 = sqlx::query_scalar(\"SELECT COUNT(*) FROM files\")\n        .fetch_one(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to get file count: {}\", e))?;\n\n    Ok(count)\n}\n\n/// Get file details by ID\n///\n/// Retrieves complete information for a single MIDI file.\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly (including NotFound)\n/// -  No complex business logic\n///\n/// # Arguments\n///\n/// * `file_id` - Unique file ID to retrieve\n///\n/// # Returns\n///\n/// * `Result\u003cMidiFile, String\u003e` - File details or error message\n///\n/// # Errors\n///\n/// Returns error if file doesn't exist or query fails.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const file = await invoke\u003cMidiFile\u003e('get_file_details', { fileId: 123 });\n/// console.log(`File: ${file.filename}, BPM: ${file.bpm}`);\n/// ```\n#[tauri::command]\npub async fn get_file_details(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cMidiFile, String\u003e {\n    let pool = state.database.pool().await;\n    let file = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE f.id = $1\n        \"#,\n    )\n    .bind(file_id)\n    .fetch_optional(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to fetch file details: {}\", e))?\n    .ok_or_else(|| format!(\"File with ID {} not found\", file_id))?;\n\n    Ok(file)\n}\n\n/// Get file by ID (alias for get_file_details for frontend compatibility)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const file = await invoke\u003cMidiFile\u003e('get_file', { fileId: 123 });\n/// ```\n#[tauri::command]\npub async fn get_file(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cMidiFile, String\u003e {\n    get_file_details(file_id, state).await\n}\n\n/// List files with pagination\n///\n/// Returns a paginated list of files ordered by creation date (newest first).\n///\n/// # Manager Archetype\n/// -  Performs I/O (database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n///\n/// # Arguments\n///\n/// * `limit` - Maximum number of files to return (default: 50)\n/// * `offset` - Number of files to skip (default: 0)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('list_files', { limit: 50, offset: 0 });\n/// ```\n#[tauri::command]\npub async fn list_files(\n    limit: Option\u003ci64\u003e,\n    offset: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(50);\n    let offset = offset.unwrap_or(0);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY f.created_at DESC\n        LIMIT $1 OFFSET $2\n        \"#,\n    )\n    .bind(limit)\n    .bind(offset)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to list files: {}\", e))?;\n\n    // Debug logging\n    tracing::info!(\n        \"list_files: Returning {} files, first file parent_folder: {:?}\",\n        files.len(),\n        files.first().map(|f| \u0026f.parent_folder)\n    );\n\n    Ok(files)\n}\n\n/// Get files by category\n///\n/// Returns all files in a specific category.\n///\n/// # Arguments\n///\n/// * `category` - Category name (e.g., \"bass\", \"drums\", \"melody\")\n/// * `limit` - Maximum number of files to return (default: 50)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('get_files_by_category', {\n///   category: 'bass',\n///   limit: 50\n/// });\n/// ```\n#[tauri::command]\npub async fn get_files_by_category(\n    category: String,\n    limit: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(50);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE fc.primary_category::text = $1\n        ORDER BY f.created_at DESC\n        LIMIT $2\n        \"#,\n    )\n    .bind(category)\n    .bind(limit)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get files by category: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Get recently added files\n///\n/// Returns the most recently imported files.\n///\n/// # Arguments\n///\n/// * `limit` - Maximum number of files to return (default: 10)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cMidiFile[]\u003e('get_recent_files', { limit: 10 });\n/// ```\n#[tauri::command]\npub async fn get_recent_files(\n    limit: Option\u003ci64\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cMidiFile\u003e, String\u003e {\n    let limit = limit.unwrap_or(10);\n\n    let pool = state.database.pool().await;\n    let files = sqlx::query_as::\u003c_, MidiFile\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            f.original_filename,\n            COALESCE(fc.primary_category::text, 'UNKNOWN') as category,\n            f.parent_folder,\n            f.file_size_bytes as file_size,\n            CAST(f.duration_seconds AS DOUBLE PRECISION) as duration_seconds,\n            f.created_at,\n            f.updated_at,\n            CAST(mm.bpm AS DOUBLE PRECISION) as bpm,\n            mm.key_signature::text as key_signature\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        ORDER BY f.created_at DESC\n        LIMIT $1\n        \"#,\n    )\n    .bind(limit)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get recent files: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Delete a file\n///\n/// Removes a file from the database (cascading deletes related records).\n///\n/// # Arguments\n///\n/// * `file_id` - ID of the file to delete\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// await invoke('delete_file', { fileId: 123 });\n/// ```\n#[tauri::command]\npub async fn delete_file(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    sqlx::query(\"DELETE FROM files WHERE id = $1\")\n        .bind(file_id)\n        .execute(\u0026pool)\n        .await\n        .map_err(|e| format!(\"Failed to delete file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Update file tags\n///\n// update_file_tags moved to commands/tags.rs to use TagRepository\n\n// =============================================================================\n// TESTS - MANAGER ARCHETYPE TESTING\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    /// Test that MidiFile struct has all required fields\n    #[test]\n    fn test_midi_file_struct() {\n        let now = Utc::now();\n        let file = MidiFile {\n            id: 1,\n            filename: \"test.mid\".to_string(),\n            filepath: \"/path/to/test.mid\".to_string(),\n            original_filename: \"original_test.mid\".to_string(),\n            category: \"DRUMS\".to_string(),\n            parent_folder: Some(\"drums\".to_string()),\n            file_size: 1024,\n            bpm: Some(120.0),\n            key_signature: Some(\"Cm\".to_string()),\n            duration_seconds: Some(180.0),\n            created_at: now,\n            updated_at: now,\n        };\n\n        assert_eq!(file.id, 1);\n        assert_eq!(file.filename, \"test.mid\");\n        assert_eq!(file.bpm, Some(120.0));\n        assert_eq!(file.key_signature, Some(\"Cm\".to_string()));\n    }\n\n    // NOTE: Advanced search functionality is in commands/search.rs\n\n    // Integration tests require database connection and Tauri runtime\n    // These tests should be run as part of E2E testing, not unit tests\n    // For manual testing:\n    // 1. Start database: docker-compose up -d\n    // 2. Run the Tauri app and test commands from the frontend\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","mod.rs"],"content":"//! Tauri command handlers\n//!\n//! All commands are Grown-up Scripts:\n//! - Perform I/O (file system, database, network)\n//! - Delegate business logic to Trusty Modules\n//! - Handle errors and convert to frontend-friendly format\n//! - Provide progress updates for long-running operations\n\npub mod analyze;\npub mod archive_import;\npub mod files;\npub mod file_import;\npub mod progress;\npub mod search;\npub mod split_file;\npub mod stats;\npub mod system;\npub mod tags;\n\n// Re-export commonly used split types\npub use split_file::{split_and_import, SplitResult};\n\n// Re-export analysis command\npub use analyze::start_analysis;\n\n// Future command modules:\n// pub mod playback;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","progress.rs"],"content":"// ARCHETYPE: MANAGER (Grown-up Script)\n// Purpose: Track import progress and emit real-time updates to frontend\n// Side effects: Emits Tauri events, manages mutable state\n\nuse serde::{Deserialize, Serialize};\nuse std::sync::{Arc, Mutex};\nuse tauri::{AppHandle, Emitter, State};\n\n/// Progress state for file import operations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProgressState {\n    pub current_file: String,\n    pub current_index: usize,\n    pub total_files: usize,\n    pub percentage: f64,\n    pub phase: String,\n    pub files_per_second: f64,\n    pub errors_count: usize,\n    pub duplicates_found: usize,\n    pub estimated_time_remaining: f64,\n}\n\nimpl Default for ProgressState {\n    fn default() -\u003e Self {\n        Self {\n            current_file: String::new(),\n            current_index: 0,\n            total_files: 0,\n            percentage: 0.0,\n            phase: \"idle\".to_string(),\n            files_per_second: 0.0,\n            errors_count: 0,\n            duplicates_found: 0,\n            estimated_time_remaining: 0.0,\n        }\n    }\n}\n\n/// Thread-safe progress tracker\n#[derive(Clone)]\npub struct ProgressTracker {\n    state: Arc\u003cMutex\u003cProgressState\u003e\u003e,\n    start_time: Arc\u003cMutex\u003cOption\u003cstd::time::Instant\u003e\u003e\u003e,\n}\n\nimpl ProgressTracker {\n    pub fn new() -\u003e Self {\n        Self {\n            state: Arc::new(Mutex::new(ProgressState::default())),\n            start_time: Arc::new(Mutex::new(None)),\n        }\n    }\n\n    /// Get current progress state\n    pub fn get_state(\u0026self) -\u003e ProgressState {\n        self.state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner())\n            .clone()\n    }\n\n    /// Update state and return the new state\n    fn update_state\u003cF\u003e(\u0026self, updater: F) -\u003e ProgressState\n    where\n        F: FnOnce(\u0026mut ProgressState),\n    {\n        let mut state = self\n            .state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n        updater(\u0026mut state);\n        state.clone()\n    }\n\n    /// Calculate metrics based on current progress\n    fn calculate_metrics(\u0026self, current_index: usize, total_files: usize) -\u003e (f64, f64) {\n        let start_time = self\n            .start_time\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n\n        if let Some(start) = *start_time {\n            let elapsed = start.elapsed().as_secs_f64();\n\n            if elapsed \u003e 0.0 \u0026\u0026 current_index \u003e 0 {\n                let files_per_second = current_index as f64 / elapsed;\n                let remaining_files = total_files.saturating_sub(current_index);\n                let estimated_time_remaining = if files_per_second \u003e 0.0 {\n                    remaining_files as f64 / files_per_second\n                } else {\n                    0.0\n                };\n\n                return (files_per_second, estimated_time_remaining);\n            }\n        }\n\n        (0.0, 0.0)\n    }\n}\n\nimpl Default for ProgressTracker {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Start progress tracking for a new import operation\n#[tauri::command]\npub async fn start_progress_tracking(\n    total: usize,\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    // Reset start time\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = Some(std::time::Instant::now());\n\n    // Initialize state\n    let state = tracker.update_state(|s| {\n        s.current_file = String::new();\n        s.current_index = 0;\n        s.total_files = total;\n        s.percentage = 0.0;\n        s.phase = \"scanning\".to_string();\n        s.files_per_second = 0.0;\n        s.errors_count = 0;\n        s.duplicates_found = 0;\n        s.estimated_time_remaining = 0.0;\n    });\n\n    // Emit initial state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Update progress with current file and phase\n#[tauri::command]\npub async fn update_progress(\n    current: usize,\n    file: String,\n    phase: String,\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let total = {\n        let state = tracker\n            .state\n            .lock()\n            .unwrap_or_else(|poisoned| poisoned.into_inner());\n        state.total_files\n    };\n\n    // Calculate metrics\n    let (files_per_second, estimated_time_remaining) =\n        tracker.calculate_metrics(current, total);\n\n    // Update state\n    let state = tracker.update_state(|s| {\n        s.current_file = file;\n        s.current_index = current;\n        s.phase = phase;\n        s.percentage = if total \u003e 0 {\n            (current as f64 / total as f64) * 100.0\n        } else {\n            0.0\n        };\n        s.files_per_second = files_per_second;\n        s.estimated_time_remaining = estimated_time_remaining;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Mark an error during processing\n#[tauri::command]\npub async fn increment_error_count(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.errors_count += 1;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Mark a duplicate file found\n#[tauri::command]\npub async fn increment_duplicate_count(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.duplicates_found += 1;\n    });\n\n    // Emit updated state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n/// Complete progress tracking\n#[tauri::command]\npub async fn complete_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    let state = tracker.update_state(|s| {\n        s.percentage = 100.0;\n        s.phase = \"complete\".to_string();\n        s.estimated_time_remaining = 0.0;\n    });\n\n    // Emit final state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    // Reset start time\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = None;\n\n    Ok(())\n}\n\n/// Get current progress state (for polling if needed)\n#[tauri::command]\npub async fn get_current_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n) -\u003e Result\u003cProgressState, String\u003e {\n    Ok(tracker.get_state())\n}\n\n/// Reset progress to idle state\n#[tauri::command]\npub async fn reset_progress(\n    tracker: State\u003c'_, ProgressTracker\u003e,\n    app: AppHandle,\n) -\u003e Result\u003c(), String\u003e {\n    *tracker\n        .start_time\n        .lock()\n        .unwrap_or_else(|poisoned| poisoned.into_inner()) = None;\n\n    let state = tracker.update_state(|s| {\n        *s = ProgressState::default();\n    });\n\n    // Emit reset state\n    app.emit(\"import-progress\", \u0026state)\n        .map_err(|e| format!(\"Failed to emit progress: {}\", e))?;\n\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_progress_state_default() {\n        let state = ProgressState::default();\n        assert_eq!(state.current_index, 0);\n        assert_eq!(state.total_files, 0);\n        assert_eq!(state.percentage, 0.0);\n        assert_eq!(state.phase, \"idle\");\n    }\n\n    #[test]\n    fn test_progress_tracker_new() {\n        let tracker = ProgressTracker::new();\n        let state = tracker.get_state();\n        assert_eq!(state.current_index, 0);\n        assert_eq!(state.total_files, 0);\n    }\n\n    #[test]\n    fn test_progress_tracker_update() {\n        let tracker = ProgressTracker::new();\n\n        // Simulate starting tracking\n        *tracker.start_time.lock().unwrap() = Some(std::time::Instant::now());\n\n        let state = tracker.update_state(|s| {\n            s.total_files = 100;\n            s.current_index = 50;\n            s.phase = \"analyzing\".to_string();\n            s.percentage = 50.0;\n        });\n\n        assert_eq!(state.total_files, 100);\n        assert_eq!(state.current_index, 50);\n        assert_eq!(state.phase, \"analyzing\");\n        assert_eq!(state.percentage, 50.0);\n    }\n\n    #[test]\n    fn test_calculate_metrics() {\n        let tracker = ProgressTracker::new();\n\n        // Before start time is set\n        let (fps, eta) = tracker.calculate_metrics(10, 100);\n        assert_eq!(fps, 0.0);\n        assert_eq!(eta, 0.0);\n\n        // After start time is set\n        *tracker.start_time.lock().unwrap() = Some(std::time::Instant::now());\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let (fps, eta) = tracker.calculate_metrics(10, 100);\n        assert!(fps \u003e 0.0); // Should be processing files\n        assert!(eta \u003e 0.0); // Should have estimated time\n    }\n}\n","traces":[{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":5},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","search.rs"],"content":"//! Search command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: Advanced search functionality with filters and pagination\n//! ARCHETYPE: Grown-up Script (I/O operations, reusable logic)\n//!\n//!  CAN: Perform database I/O\n//!  CAN: Have side effects (complex queries)\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic (delegate to Trusty Modules)\n\nuse crate::AppState;\nuse tauri::State;\nuse serde::{Deserialize, Serialize};\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// Search filters from frontend\n#[derive(Debug, Clone, Deserialize)]\npub struct SearchFilters {\n    pub category: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n}\n\n/// Search result item (simplified for list view)\n///\n/// Note: NUMERIC columns are cast to float8 in SQL queries for simplicity\n#[derive(Debug, Clone, Serialize, sqlx::FromRow)]\npub struct SearchResultItem {\n    pub id: i64,\n    pub filename: String,\n    pub filepath: String,\n    pub bpm: Option\u003cf64\u003e,  // Cast from NUMERIC in SQL\n    pub key_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,  // Cast from NUMERIC in SQL\n    pub category: Option\u003cString\u003e,\n}\n\n/// Paginated search results\n#[derive(Debug, Serialize)]\npub struct SearchResults {\n    pub items: Vec\u003cSearchResultItem\u003e,\n    pub total_count: i64,\n    pub page: i32,\n    pub page_size: i32,\n    pub total_pages: i32,\n}\n\n// =============================================================================\n// HELPER FUNCTIONS\n// =============================================================================\n\n/// Count search results for pagination\nasync fn count_search_results(\n    query: \u0026str,\n    filters: \u0026SearchFilters,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, sqlx::Error\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE\n            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')\n            AND ($2::text IS NULL OR fc.primary_category::text = $2)\n            AND ($3::float8 IS NULL OR mm.bpm \u003e= $3)\n            AND ($4::float8 IS NULL OR mm.bpm \u003c= $4)\n            AND ($5::text IS NULL OR mm.key_signature::text = $5)\n        \"#\n    )\n    .bind(query)\n    .bind(\u0026filters.category)\n    .bind(filters.min_bpm)\n    .bind(filters.max_bpm)\n    .bind(\u0026filters.key_signature)\n    .fetch_one(pool)\n    .await?;\n\n    Ok(count.0)\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Search files with filters and pagination\n///\n/// # Manager Archetype\n/// -  Performs I/O (complex database query)\n/// -  Has side effects (reads from database)\n/// -  Handles errors properly\n///\n/// # Arguments\n///\n/// * `query` - Text search query (searches filename and filepath)\n/// * `filters` - Search filters (category, BPM range, key)\n/// * `page` - Page number (1-indexed)\n/// * `page_size` - Items per page (1-100)\n///\n/// # Returns\n///\n/// Paginated search results with total count\n#[tauri::command]\npub async fn search_files(\n    query: String,\n    filters: SearchFilters,\n    page: i32,\n    page_size: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cSearchResults, String\u003e {\n    let pool = state.database.pool().await;\n\n    // Validate pagination\n    if page \u003c 1 {\n        return Err(\"Page must be \u003e= 1\".to_string());\n    }\n    if page_size \u003c 1 || page_size \u003e 100 {\n        return Err(\"Page size must be between 1 and 100\".to_string());\n    }\n\n    // Calculate offset\n    let offset = (page - 1) * page_size;\n\n    // Query with correct column names from schema\n    let items = sqlx::query_as::\u003c_, SearchResultItem\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            mm.bpm::float8 as bpm,\n            mm.key_signature::text as key_signature,\n            f.duration_seconds::float8 as duration_seconds,\n            fc.primary_category::text as category\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        WHERE\n            ($1::text = '' OR f.filename ILIKE '%' || $1 || '%' OR f.filepath ILIKE '%' || $1 || '%')\n            AND ($2::text IS NULL OR fc.primary_category::text = $2)\n            AND ($3::float8 IS NULL OR mm.bpm \u003e= $3)\n            AND ($4::float8 IS NULL OR mm.bpm \u003c= $4)\n            AND ($5::text IS NULL OR mm.key_signature::text = $5)\n        ORDER BY f.created_at DESC\n        LIMIT $6 OFFSET $7\n        \"#\n    )\n    .bind(\u0026query)\n    .bind(\u0026filters.category)\n    .bind(filters.min_bpm)\n    .bind(filters.max_bpm)\n    .bind(\u0026filters.key_signature)\n    .bind(page_size as i64)\n    .bind(offset as i64)\n    .fetch_all(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Search error: {}\", e))?;\n\n    let total_count = count_search_results(\u0026query, \u0026filters, \u0026pool)\n        .await\n        .map_err(|e| format!(\"Count error: {}\", e))?;\n\n    Ok(SearchResults {\n        items,\n        total_count,\n        page,\n        page_size,\n        total_pages: ((total_count as f64) / (page_size as f64)).ceil() as i32,\n    })\n}\n\n/// Get all unique tags from database\n///\n/// Returns a list of all unique tag names used in the database.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const tags = await invoke\u003cstring[]\u003e('get_all_tags');\n/// ```\n#[tauri::command]\npub async fn get_all_tags(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let tags: Vec\u003c(String,)\u003e = sqlx::query_as(\n        r#\"\n        SELECT DISTINCT tag_name\n        FROM file_tags\n        ORDER BY tag_name ASC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(|(tag,)| tag).collect())\n}\n\n/// Get files by tag\n///\n/// Returns all files that have a specific tag.\n///\n/// # Arguments\n///\n/// * `tag` - Tag name to filter by\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const files = await invoke\u003cFileMetadata[]\u003e('get_files_by_tag', { tag: 'ambient' });\n/// ```\n#[tauri::command]\npub async fn get_files_by_tag(\n    tag: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cSearchResultItem\u003e, String\u003e {\n    let files = sqlx::query_as::\u003c_, SearchResultItem\u003e(\n        r#\"\n        SELECT\n            f.id,\n            f.filename,\n            f.filepath,\n            mm.bpm::float8 as bpm,\n            mm.key_signature::text as key_signature,\n            f.duration_seconds::float8 as duration_seconds,\n            fc.primary_category::text as category\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        INNER JOIN file_tags ft ON f.id = ft.file_id\n        WHERE ft.tag_name = $1\n        ORDER BY f.created_at DESC\n        \"#\n    )\n    .bind(tag)\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get files by tag: {}\", e))?;\n\n    Ok(files)\n}\n\n/// Get BPM range from database\n///\n/// Returns the minimum and maximum BPM values in the database.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const range = await invoke\u003c{min: number, max: number}\u003e('get_bpm_range');\n/// ```\n#[tauri::command]\npub async fn get_bpm_range(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cBpmRange, String\u003e {\n    let pool = state.database.pool().await;\n    let result: Option\u003c(Option\u003cf64\u003e, Option\u003cf64\u003e)\u003e = sqlx::query_as(\n        r#\"\n        SELECT MIN(bpm)::float8, MAX(bpm)::float8\n        FROM musical_metadata\n        WHERE bpm IS NOT NULL\n        \"#\n    )\n    .fetch_optional(\u0026pool)\n    .await\n    .map_err(|e| format!(\"Failed to get BPM range: {}\", e))?;\n\n    match result {\n        Some((Some(min), Some(max))) =\u003e Ok(BpmRange { min, max }),\n        _ =\u003e Ok(BpmRange { min: 0.0, max: 300.0 }), // Default range if no data\n    }\n}\n\n/// Get all unique key signatures from database\n///\n/// Returns a list of all unique key signatures.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const keys = await invoke\u003cstring[]\u003e('get_all_keys');\n/// ```\n#[tauri::command]\npub async fn get_all_keys(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let keys: Vec\u003c(String,)\u003e = sqlx::query_as(\n        r#\"\n        SELECT DISTINCT key_signature::text\n        FROM musical_metadata\n        WHERE key_signature IS NOT NULL\n        ORDER BY key_signature ASC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get keys: {}\", e))?;\n\n    Ok(keys.into_iter().map(|(key,)| key).collect())\n}\n\n/// BPM range response\n#[derive(Debug, Serialize)]\npub struct BpmRange {\n    pub min: f64,\n    pub max: f64,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","split_file.rs"],"content":"//! Track Splitting Commands - GROWN-UP SCRIPT\n//!\n//! Architecture: Grown-up Script\n//! Purpose: I/O wrapper around track_splitter Trusty Module\n//!\n//! This module provides Tauri commands for splitting multi-track MIDI files\n//! into individual single-track files. It handles:\n//! - Database queries (fetch file info)\n//! - File I/O (read original, write splits)\n//! - Database transactions (insert splits, create relationships)\n//! - Error handling and user-friendly messages\n//!\n//! The actual splitting logic is delegated to the track_splitter Trusty Module,\n//! which operates on byte arrays with no I/O.\n\nuse crate::core::hash::calculate_file_hash;\nuse midi_library_shared::core::midi::parser::parse_midi_file;\nuse crate::core::analysis::bpm_detector::detect_bpm;\nuse crate::core::analysis::key_detector::detect_key;\nuse crate::core::splitting::track_splitter::{split_tracks, SplitTrack, SplitError};\nuse serde::{Deserialize, Serialize};\nuse std::path::{Path, PathBuf};\nuse thiserror::Error;\n\n//=============================================================================\n// ERROR TYPES\n//=============================================================================\n\n/// Errors that can occur during split and import operations\n#[derive(Error, Debug)]\npub enum SplitCommandError {\n    #[error(\"File not found in database: {0}\")]\n    FileNotFound(i64),\n\n    #[error(\"File not found on disk: {0}\")]\n    FileNotFoundOnDisk(String),\n\n    #[error(\"Failed to read file: {0}\")]\n    IoError(#[from] std::io::Error),\n\n    #[error(\"Failed to split tracks: {0}\")]\n    SplitError(#[from] SplitError),\n\n    #[error(\"Database error: {0}\")]\n    DatabaseError(String),\n\n    #[error(\"Failed to create output directory: {0}\")]\n    DirectoryCreationError(String),\n\n    #[error(\"Transaction failed: {0}\")]\n    TransactionError(String),\n}\n\n// Convert to user-friendly string for Tauri commands\nimpl From\u003cSplitCommandError\u003e for String {\n    fn from(err: SplitCommandError) -\u003e String {\n        err.to_string()\n    }\n}\n\n//=============================================================================\n// TYPE DEFINITIONS\n//=============================================================================\n\n/// Result of a successful split operation\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SplitResult {\n    /// IDs of the newly created split files in the database\n    pub split_file_ids: Vec\u003ci64\u003e,\n\n    /// Number of tracks that were split\n    pub tracks_split: usize,\n\n    /// Directory where split files were written\n    pub output_dir: PathBuf,\n}\n\n//=============================================================================\n// PUBLIC API (Grown-up Script Pattern)\n//=============================================================================\n\n/// Split a multi-track MIDI file and import each track as a separate file.\n///\n/// This is the main entry point for track splitting operations. It:\n/// 1. Queries the database for the original file's info\n/// 2. Reads the original MIDI file from disk\n/// 3. Calls the track_splitter Trusty Module to split tracks\n/// 4. Creates output directory\n/// 5. For each split track:\n///    - Generates filename based on track metadata\n///    - Writes MIDI bytes to disk\n///    - Imports to database with full metadata\n///    - Creates relationship in track_splits table\n/// 6. Returns list of created file IDs\n///\n/// # Arguments\n///\n/// * `file_id` - Database ID of the parent file to split\n/// * `output_dir` - Directory where split files will be written\n/// * `pool` - Database connection pool\n///\n/// # Returns\n///\n/// `SplitResult` containing IDs of created files and statistics\n///\n/// # Errors\n///\n/// Returns error if:\n/// - File not found in database\n/// - File not found on disk\n/// - Failed to read/parse MIDI file\n/// - Failed to split tracks (e.g., only tempo track)\n/// - Failed to create output directory\n/// - Database transaction fails\n///\n/// # Examples\n///\n/// ```no_run\n/// use pipeline::commands::split_file::split_and_import;\n/// use std::path::PathBuf;\n///\n/// # async fn example(pool: sqlx::PgPool) -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n/// let result = split_and_import(\n///     42,\n///     PathBuf::from(\"/output/splits\"),\n///     \u0026pool\n/// ).await?;\n///\n/// println!(\"Split {} tracks into {} files\",\n///     result.tracks_split,\n///     result.split_file_ids.len()\n/// );\n/// # Ok(())\n/// # }\n/// ```\npub async fn split_and_import(\n    file_id: i64,\n    output_dir: PathBuf,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003cSplitResult, SplitCommandError\u003e {\n    // 1. Query database for parent file info\n    let parent_file = sqlx::query!(\n        r#\"\n        SELECT id, filename, original_filename, filepath\n        FROM files\n        WHERE id = $1\n        \"#,\n        file_id\n    )\n    .fetch_optional(pool)\n    .await\n    .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?\n    .ok_or(SplitCommandError::FileNotFound(file_id))?;\n\n    // 2. Read original file from disk\n    let file_path = Path::new(\u0026parent_file.filepath);\n    if !file_path.exists() {\n        return Err(SplitCommandError::FileNotFoundOnDisk(\n            parent_file.filepath.clone(),\n        ));\n    }\n\n    let original_bytes = tokio::fs::read(file_path).await?;\n\n    // 3. Call Trusty Module to split tracks (pure logic, no I/O)\n    let split_tracks = split_tracks(\u0026original_bytes)?;\n\n    if split_tracks.is_empty() {\n        return Err(SplitCommandError::SplitError(SplitError::NoTracksToSplit));\n    }\n\n    // 4. Create output directory if it doesn't exist\n    if !output_dir.exists() {\n        tokio::fs::create_dir_all(\u0026output_dir)\n            .await\n            .map_err(|e| SplitCommandError::DirectoryCreationError(e.to_string()))?;\n    }\n\n    // 5. Process each split track\n    let mut split_file_ids = Vec::new();\n    let base_filename = Path::new(\u0026parent_file.original_filename)\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"track\");\n\n    for split_track in \u0026split_tracks {\n        // Generate filename: {base}_track_{num:02}_{instrument}.mid\n        let filename = generate_split_filename(base_filename, split_track);\n\n        // Full path for split file\n        let split_path = output_dir.join(\u0026filename);\n\n        // Write MIDI bytes to disk\n        tokio::fs::write(\u0026split_path, \u0026split_track.midi_bytes).await?;\n\n        // Import split file to database with full metadata\n        let split_file_id = import_split_track(\n            \u0026split_path,\n            \u0026filename,\n            \u0026split_track.midi_bytes,\n            pool,\n        )\n        .await\n        .map_err(|e| SplitCommandError::DatabaseError(e.to_string()))?;\n\n        // Create relationship in track_splits table\n        insert_track_split_relationship(\n            file_id,\n            split_file_id,\n            split_track,\n            pool,\n        )\n        .await\n        .map_err(|e| SplitCommandError::TransactionError(e.to_string()))?;\n\n        split_file_ids.push(split_file_id);\n    }\n\n    Ok(SplitResult {\n        split_file_ids,\n        tracks_split: split_tracks.len(),\n        output_dir,\n    })\n}\n\n//=============================================================================\n// HELPER FUNCTIONS (Grown-up Script - I/O Operations)\n//=============================================================================\n\n/// Import a split track file to the database with full metadata.\n///\n/// Performs a complete import operation including:\n/// - Hash calculation for deduplication\n/// - MIDI parsing for metadata extraction\n/// - BPM and key detection\n/// - Transaction-safe insertion to files and musical_metadata tables\n///\n/// # Arguments\n///\n/// * `filepath` - Path to the split MIDI file on disk\n/// * `filename` - Filename to store in database\n/// * `file_data` - MIDI file bytes (already in memory)\n/// * `pool` - Database connection pool\n///\n/// # Returns\n///\n/// Database ID of the newly inserted file\n///\n/// # Errors\n///\n/// Returns error if database insertion fails or file already exists (duplicate hash)\nasync fn import_split_track(\n    filepath: \u0026Path,\n    filename: \u0026str,\n    file_data: \u0026[u8],\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003ci64, Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    // Calculate hash for deduplication (BLAKE3)\n    let hash_bytes = calculate_file_hash(filepath)?;\n    let content_hash: Vec\u003cu8\u003e = hash_bytes.to_vec();\n\n    // Parse MIDI for metadata\n    let midi_data = parse_midi_file(file_data)?;\n\n    // Detect BPM\n    let bpm_result = detect_bpm(\u0026midi_data);\n    let bpm = if bpm_result.confidence \u003e 0.5 {\n        Some(bpm_result.bpm)\n    } else {\n        None\n    };\n\n    // Detect key signature\n    let key_result = detect_key(\u0026midi_data);\n    let key_signature = if key_result.confidence \u003e 0.5 {\n        Some(key_result.key.clone())\n    } else {\n        None\n    };\n\n    // Get file size\n    let file_size_bytes = file_data.len() as i64;\n    let filepath_str = filepath.to_str().ok_or(\"Invalid file path\")?;\n\n    // Begin transaction\n    let mut tx = pool.begin().await?;\n\n    // Insert file record\n    let file_id = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, 1, NOW())\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#,\n    )\n    .bind(filename)\n    .bind(filename) // Original filename is same as filename for splits\n    .bind(filepath_str)\n    .bind(\u0026content_hash)\n    .bind(file_size_bytes)\n    .fetch_optional(\u0026mut *tx)\n    .await?\n    .ok_or(\"File already exists (duplicate hash)\")?;\n\n    // Insert musical metadata if available\n    if bpm.is_some() || key_signature.is_some() {\n        sqlx::query(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                key_signature,\n                time_signature_numerator,\n                time_signature_denominator\n            ) VALUES ($1, $2, $3::musical_key, 4, 4)\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                key_signature = EXCLUDED.key_signature\n            \"#,\n        )\n        .bind(file_id)\n        .bind(bpm)\n        .bind(key_signature.as_deref())\n        .execute(\u0026mut *tx)\n        .await?;\n    }\n\n    // Commit transaction\n    tx.commit().await?;\n\n    Ok(file_id)\n}\n\n/// Insert relationship between parent file and split track into track_splits table.\n///\n/// Creates a record linking the parent multi-track file to the split single-track file\n/// with metadata about the track (number, name, instrument, note count).\n///\n/// # Arguments\n///\n/// * `parent_file_id` - Database ID of the parent file\n/// * `split_file_id` - Database ID of the split file\n/// * `split_track` - Metadata about the split track\n/// * `pool` - Database connection pool\n///\n/// # Errors\n///\n/// Returns error if insertion fails or relationship already exists\nasync fn insert_track_split_relationship(\n    parent_file_id: i64,\n    split_file_id: i64,\n    split_track: \u0026SplitTrack,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003c(), Box\u003cdyn std::error::Error + Send + Sync\u003e\u003e {\n    sqlx::query!(\n        r#\"\n        INSERT INTO track_splits (\n            parent_file_id,\n            split_file_id,\n            track_number,\n            track_name,\n            instrument,\n            note_count,\n            created_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, NOW())\n        \"#,\n        parent_file_id,\n        split_file_id,\n        split_track.track_number as i32,\n        split_track.track_name.as_deref(),\n        split_track.instrument.as_deref(),\n        split_track.note_count as i32,\n    )\n    .execute(pool)\n    .await?;\n\n    Ok(())\n}\n\n//=============================================================================\n// UTILITY FUNCTIONS (Pure - Could be Trusty Module)\n//=============================================================================\n\n/// Generate a filename for a split track based on metadata.\n///\n/// Format: `{base}_track_{num:02}_{instrument}.mid`\n///\n/// If instrument is not available, uses track name. If neither available,\n/// uses just track number.\n///\n/// Sanitizes all components to ensure valid filenames.\n///\n/// # Arguments\n///\n/// * `base_filename` - Base filename from the parent file (without extension)\n/// * `split_track` - Metadata about the split track\n///\n/// # Returns\n///\n/// Sanitized filename with .mid extension\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::commands::split_file::generate_split_filename;\n/// use pipeline::core::splitting::track_splitter::SplitTrack;\n///\n/// let track = SplitTrack {\n///     track_number: 1,\n///     track_name: Some(\"Piano\".to_string()),\n///     channel: Some(0),\n///     instrument: Some(\"Acoustic Grand Piano\".to_string()),\n///     note_count: 100,\n///     midi_bytes: vec![],\n/// };\n///\n/// let filename = generate_split_filename(\"my_song\", \u0026track);\n/// assert_eq!(filename, \"my_song_track_01_Acoustic_Grand_Piano.mid\");\n/// ```\npub fn generate_split_filename(base_filename: \u0026str, split_track: \u0026SplitTrack) -\u003e String {\n    let base = sanitize_filename(base_filename);\n    let track_num = format!(\"{:02}\", split_track.track_number);\n\n    // Build suffix: prefer instrument, fall back to track name, then just number\n    let suffix = if let Some(ref instrument) = split_track.instrument {\n        sanitize_filename(instrument)\n    } else if let Some(ref track_name) = split_track.track_name {\n        sanitize_filename(track_name)\n    } else {\n        String::new()\n    };\n\n    if suffix.is_empty() {\n        format!(\"{}_track_{}.mid\", base, track_num)\n    } else {\n        format!(\"{}_track_{}_{}.mid\", base, track_num, suffix)\n    }\n}\n\n/// Sanitize a string to be used as a filename component.\n///\n/// Removes or replaces problematic characters:\n/// - Replaces spaces with underscores\n/// - Removes: / \\ : * ? \" \u003c \u003e | (filesystem-unsafe characters)\n/// - Removes: control characters, non-ASCII if problematic\n/// - Collapses multiple underscores to single underscore\n/// - Trims underscores from start and end\n///\n/// # Arguments\n///\n/// * `name` - String to sanitize\n///\n/// # Returns\n///\n/// Sanitized string safe for use in filenames\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::commands::split_file::sanitize_filename;\n///\n/// assert_eq!(sanitize_filename(\"Piano Track\"), \"Piano_Track\");\n/// assert_eq!(sanitize_filename(\"Track: 1 (Lead)\"), \"Track_1_Lead\");\n/// assert_eq!(sanitize_filename(\"Bass/Guitar\"), \"BassGuitar\");\n/// assert_eq!(sanitize_filename(\"  Piano  \"), \"Piano\");\n/// ```\npub fn sanitize_filename(name: \u0026str) -\u003e String {\n    name.chars()\n        .map(|c| match c {\n            // Replace spaces with underscores\n            ' ' =\u003e '_',\n            // Remove problematic characters\n            '/' | '\\\\' | ':' | '*' | '?' | '\"' | '\u003c' | '\u003e' | '|' =\u003e '_',\n            // Keep alphanumeric, underscore, hyphen, period, parentheses\n            c if c.is_alphanumeric() || c == '_' || c == '-' || c == '.' || c == '(' || c == ')' =\u003e c,\n            // Replace everything else with underscore\n            _ =\u003e '_',\n        })\n        .collect::\u003cString\u003e()\n        // Collapse multiple underscores\n        .split('_')\n        .filter(|s| !s.is_empty())\n        .collect::\u003cVec\u003c_\u003e\u003e()\n        .join(\"_\")\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_sanitize_filename_spaces() {\n        assert_eq!(sanitize_filename(\"Piano Track\"), \"Piano_Track\");\n        assert_eq!(sanitize_filename(\"My Song Name\"), \"My_Song_Name\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_special_chars() {\n        assert_eq!(sanitize_filename(\"Track: 1\"), \"Track_1\");\n        assert_eq!(sanitize_filename(\"Bass/Guitar\"), \"Bass_Guitar\");\n        assert_eq!(sanitize_filename(\"Lead (Synth)\"), \"Lead_(Synth)\");\n        assert_eq!(sanitize_filename(\"File*Name?\"), \"File_Name\");\n        assert_eq!(sanitize_filename(\"Path\\\\To\\\\File\"), \"Path_To_File\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_multiple_underscores() {\n        assert_eq!(sanitize_filename(\"Track___1\"), \"Track_1\");\n        assert_eq!(sanitize_filename(\"__Piano__\"), \"Piano\");\n        assert_eq!(sanitize_filename(\"A___B___C\"), \"A_B_C\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_edge_cases() {\n        assert_eq!(sanitize_filename(\"\"), \"\");\n        assert_eq!(sanitize_filename(\"   \"), \"\");\n        assert_eq!(sanitize_filename(\"___\"), \"\");\n        assert_eq!(sanitize_filename(\"ValidName123\"), \"ValidName123\");\n    }\n\n    #[test]\n    fn test_sanitize_filename_unicode() {\n        // Keep alphanumeric Unicode (includes accented characters)\n        assert_eq!(sanitize_filename(\"Caf\"), \"Caf\");\n        assert_eq!(sanitize_filename(\"Track1\"), \"Track_1\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_with_instrument() {\n        let track = SplitTrack {\n            track_number: 1,\n            track_name: Some(\"Piano Part\".to_string()),\n            channel: Some(0),\n            instrument: Some(\"Acoustic Grand Piano\".to_string()),\n            note_count: 100,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"my_song\", \u0026track);\n        assert_eq!(filename, \"my_song_track_01_Acoustic_Grand_Piano.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_with_track_name_only() {\n        let track = SplitTrack {\n            track_number: 2,\n            track_name: Some(\"Bass Line\".to_string()),\n            channel: Some(1),\n            instrument: None,\n            note_count: 50,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"song\", \u0026track);\n        assert_eq!(filename, \"song_track_02_Bass_Line.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_no_metadata() {\n        let track = SplitTrack {\n            track_number: 0,\n            track_name: None,\n            channel: None,\n            instrument: None,\n            note_count: 10,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"minimal\", \u0026track);\n        assert_eq!(filename, \"minimal_track_00.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_sanitizes_base() {\n        let track = SplitTrack {\n            track_number: 5,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Guitar\".to_string()),\n            note_count: 75,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"My/Bad\\\\Filename:1\", \u0026track);\n        assert_eq!(filename, \"My_Bad_Filename_1_track_05_Guitar.mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_sanitizes_instrument() {\n        let track = SplitTrack {\n            track_number: 3,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Electric Piano (DX7)\".to_string()),\n            note_count: 80,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"track\", \u0026track);\n        assert_eq!(filename, \"track_track_03_Electric_Piano_(DX7).mid\");\n    }\n\n    #[test]\n    fn test_generate_split_filename_high_track_numbers() {\n        let track = SplitTrack {\n            track_number: 99,\n            track_name: None,\n            channel: None,\n            instrument: Some(\"Drums\".to_string()),\n            note_count: 200,\n            midi_bytes: vec![],\n        };\n\n        let filename = generate_split_filename(\"orchestra\", \u0026track);\n        assert_eq!(filename, \"orchestra_track_99_Drums.mid\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","stats.rs"],"content":"//! Statistics command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: Database statistics and metrics\n//! ARCHETYPE: Grown-up Script (I/O operations)\n//!\n//!  CAN: Perform database I/O\n//!  CAN: Have side effects (complex queries)\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic (delegate to Trusty Modules)\n\nuse crate::AppState;\nuse tauri::State;\nuse std::collections::HashMap;\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get file count breakdown by category\n///\n/// Returns a map of category names to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_category_stats');\n/// // { \"bass\": 150, \"drums\": 200, \"melody\": 100 }\n/// ```\n#[tauri::command]\npub async fn get_category_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT fc.primary_category::text as category, COUNT(*) as count\n        FROM files f\n        LEFT JOIN file_categories fc ON f.id = fc.file_id\n        GROUP BY fc.primary_category\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get category stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (category, count) in results {\n        let category_name = category.unwrap_or_else(|| \"Uncategorized\".to_string());\n        stats.insert(category_name, count);\n    }\n\n    Ok(stats)\n}\n\n/// Get file count breakdown by manufacturer\n///\n/// Returns a map of manufacturer names to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_manufacturer_stats');\n/// ```\n#[tauri::command]\npub async fn get_manufacturer_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT mm.manufacturer::text as manufacturer, COUNT(*) as count\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        WHERE mm.manufacturer IS NOT NULL\n        GROUP BY mm.manufacturer\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get manufacturer stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (manufacturer, count) in results {\n        if let Some(mfr) = manufacturer {\n            stats.insert(mfr, count);\n        }\n    }\n\n    Ok(stats)\n}\n\n/// Get file count breakdown by key signature\n///\n/// Returns a map of key signatures to file counts.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const stats = await invoke\u003cRecord\u003cstring, number\u003e\u003e('get_key_signature_stats');\n/// ```\n#[tauri::command]\npub async fn get_key_signature_stats(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cHashMap\u003cString, i64\u003e, String\u003e {\n    let results: Vec\u003c(Option\u003cString\u003e, i64)\u003e = sqlx::query_as(\n        r#\"\n        SELECT mm.key_signature::text as key_sig, COUNT(*) as count\n        FROM files f\n        LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n        WHERE mm.key_signature IS NOT NULL\n        GROUP BY mm.key_signature\n        ORDER BY count DESC\n        \"#\n    )\n    .fetch_all(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get key signature stats: {}\", e))?;\n\n    let mut stats = HashMap::new();\n    for (key_sig, count) in results {\n        if let Some(key) = key_sig {\n            stats.insert(key, count);\n        }\n    }\n\n    Ok(stats)\n}\n\n/// Get count of recently added files (last 7 days)\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_recently_added_count');\n/// ```\n#[tauri::command]\npub async fn get_recently_added_count(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM files\n        WHERE created_at \u003e= NOW() - INTERVAL '7 days'\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get recently added count: {}\", e))?;\n\n    Ok(count.0)\n}\n\n/// Get count of duplicate files\n///\n/// Files are considered duplicates if they have the same content hash.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const count = await invoke\u003cnumber\u003e('get_duplicate_count');\n/// ```\n#[tauri::command]\npub async fn get_duplicate_count(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let count: (i64,) = sqlx::query_as(\n        r#\"\n        SELECT COUNT(*)\n        FROM (\n            SELECT content_hash\n            FROM files\n            GROUP BY content_hash\n            HAVING COUNT(*) \u003e 1\n        ) as duplicates\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get duplicate count: {}\", e))?;\n\n    Ok(count.0)\n}\n\n/// Get database size as formatted string\n///\n/// Returns the total size of the database in a human-readable format.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const size = await invoke\u003cstring\u003e('get_database_size');\n/// // \"125.4 MB\"\n/// ```\n#[tauri::command]\npub async fn get_database_size(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    let size: (Option\u003cString\u003e,) = sqlx::query_as(\n        r#\"\n        SELECT pg_size_pretty(pg_database_size(current_database()))\n        \"#\n    )\n    .fetch_one(\u0026state.database.pool().await)\n    .await\n    .map_err(|e| format!(\"Failed to get database size: {}\", e))?;\n\n    Ok(size.0.unwrap_or_else(|| \"Unknown\".to_string()))\n}\n\n/// Check database health status\n///\n/// Returns health status based on connection and basic query tests.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const health = await invoke\u003c'good' | 'warning' | 'error'\u003e('check_database_health');\n/// ```\n#[tauri::command]\npub async fn check_database_health(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cString, String\u003e {\n    // Try a simple query\n    match state.database.test_connection().await {\n        Ok(_) =\u003e {\n            // Check if we can count files\n            match sqlx::query_scalar::\u003c_, i64\u003e(\"SELECT COUNT(*) FROM files\")\n                .fetch_one(\u0026state.database.pool().await)\n                .await\n            {\n                Ok(_) =\u003e Ok(\"good\".to_string()),\n                Err(_) =\u003e Ok(\"warning\".to_string()),\n            }\n        }\n        Err(_) =\u003e Ok(\"error\".to_string()),\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","system.rs"],"content":"//! System command handlers - GROWN-UP SCRIPT ARCHETYPE\n//!\n//! PURPOSE: System-level operations and information\n//! ARCHETYPE: Grown-up Script (I/O operations)\n//!\n//!  CAN: Perform system I/O\n//!  CAN: Have side effects\n//!  SHOULD: Handle errors properly\n//!  NO: Complex business logic\n\nuse serde::Serialize;\nuse tauri::State;\nuse crate::AppState;\n\n// =============================================================================\n// DATA STRUCTURES\n// =============================================================================\n\n/// System information response\n#[derive(Debug, Serialize)]\npub struct SystemInfo {\n    pub version: String,\n    pub platform: String,\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get system information\n///\n/// Returns the application version and platform information.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// const info = await invoke\u003c{version: string, platform: string}\u003e('get_system_info');\n/// // { version: \"0.1.0\", platform: \"linux\" }\n/// ```\n#[tauri::command]\npub async fn get_system_info() -\u003e Result\u003cSystemInfo, String\u003e {\n    Ok(SystemInfo {\n        version: env!(\"CARGO_PKG_VERSION\").to_string(),\n        platform: std::env::consts::OS.to_string(),\n    })\n}\n\n/// Initialize database connection on first use\n///\n/// This allows Tauri to start up without blocking, then connects\n/// to database on first command. If already connected, returns ok.\n///\n/// # Frontend Usage\n///\n/// ```typescript\n/// await invoke('initialize_database');\n/// // Now all database commands will work\n/// ```\n#[tauri::command]\npub async fn initialize_database(state: State\u003c'_, AppState\u003e) -\u003e Result\u003c(), String\u003e {\n    // Database is eagerly initialized in main.rs, so this is a no-op\n    // This command exists for completeness if we switch to lazy initialization\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","commands","tags.rs"],"content":"//! Tag Commands - Tauri commands for tag operations\n//!\n//! This module provides frontend-facing commands for:\n//! - Retrieving tags for files\n//! - Getting popular tags (for tag cloud)\n//! - Searching tags (for autocomplete)\n//! - Updating file tags\n\nuse crate::AppState;\nuse crate::db::repositories::tag_repository::{DbTag, TagRepository, TagWithCount};\nuse serde::{Deserialize, Serialize};\nuse tauri::State;\n\n// =============================================================================\n// TYPE DEFINITIONS\n// =============================================================================\n\n/// Tag for JSON serialization (frontend-friendly)\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TagResponse {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\nimpl From\u003cDbTag\u003e for TagResponse {\n    fn from(db_tag: DbTag) -\u003e Self {\n        Self {\n            id: db_tag.id,\n            name: db_tag.name,\n            category: db_tag.category,\n            usage_count: db_tag.usage_count,\n        }\n    }\n}\n\nimpl From\u003cTagWithCount\u003e for TagResponse {\n    fn from(tag: TagWithCount) -\u003e Self {\n        Self {\n            id: tag.id,\n            name: tag.name,\n            category: tag.category,\n            usage_count: tag.usage_count,\n        }\n    }\n}\n\n// =============================================================================\n// TAURI COMMANDS\n// =============================================================================\n\n/// Get all tags for a specific file\n#[tauri::command]\npub async fn get_file_tags(\n    file_id: i64,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let tags = repo\n        .get_file_tags(file_id)\n        .await\n        .map_err(|e| format!(\"Failed to get file tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Get popular tags with usage counts (for tag cloud)\n///\n/// # Arguments\n/// * `limit` - Maximum number of tags to return (default: 50)\n#[tauri::command]\npub async fn get_popular_tags(\n    limit: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let limit = limit.unwrap_or(50);\n\n    let tags = repo\n        .get_popular_tags(limit)\n        .await\n        .map_err(|e| format!(\"Failed to get popular tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Search tags by name prefix (for autocomplete)\n///\n/// # Arguments\n/// * `query` - Search query (prefix match)\n/// * `limit` - Maximum number of results (default: 10)\n#[tauri::command]\npub async fn search_tags(\n    query: String,\n    limit: Option\u003ci32\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let limit = limit.unwrap_or(10);\n\n    let tags = repo\n        .search_tags(\u0026query, limit)\n        .await\n        .map_err(|e| format!(\"Failed to search tags: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Get all unique tag categories\n#[tauri::command]\npub async fn get_tag_categories(\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cString\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let categories = repo\n        .get_tag_categories()\n        .await\n        .map_err(|e| format!(\"Failed to get tag categories: {}\", e))?;\n\n    Ok(categories)\n}\n\n/// Get tags by category\n#[tauri::command]\npub async fn get_tags_by_category(\n    category: String,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003cTagResponse\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let tags = repo\n        .get_tags_by_category(\u0026category)\n        .await\n        .map_err(|e| format!(\"Failed to get tags by category: {}\", e))?;\n\n    Ok(tags.into_iter().map(TagResponse::from).collect())\n}\n\n/// Update tags for a file (replace all existing tags)\n///\n/// # Arguments\n/// * `file_id` - File ID\n/// * `tag_names` - Array of tag names to set\n#[tauri::command]\npub async fn update_file_tags(\n    file_id: i64,\n    tag_names: Vec\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    // Get or create tags and get their IDs\n    let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = tag_names\n        .into_iter()\n        .map(|name| (name, None)) // No category for user-added tags\n        .collect();\n\n    let tag_ids = repo\n        .get_or_create_tags_batch(\u0026tag_data)\n        .await\n        .map_err(|e| format!(\"Failed to create tags: {}\", e))?;\n\n    // Update file tags\n    repo.update_file_tags(file_id, \u0026tag_ids)\n        .await\n        .map_err(|e| format!(\"Failed to update file tags: {}\", e))?;\n\n    Ok(())\n}\n\n/// Add tags to a file (without removing existing tags)\n#[tauri::command]\npub async fn add_tags_to_file(\n    file_id: i64,\n    tag_names: Vec\u003cString\u003e,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    // Get or create tags and get their IDs\n    let tag_data: Vec\u003c(String, Option\u003cString\u003e)\u003e = tag_names\n        .into_iter()\n        .map(|name| (name, None))\n        .collect();\n\n    let tag_ids = repo\n        .get_or_create_tags_batch(\u0026tag_data)\n        .await\n        .map_err(|e| format!(\"Failed to create tags: {}\", e))?;\n\n    // Add tags to file\n    repo.add_tags_to_file(file_id, \u0026tag_ids)\n        .await\n        .map_err(|e| format!(\"Failed to add tags to file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Remove a specific tag from a file\n#[tauri::command]\npub async fn remove_tag_from_file(\n    file_id: i64,\n    tag_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003c(), String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    repo.remove_tag_from_file(file_id, tag_id)\n        .await\n        .map_err(|e| format!(\"Failed to remove tag from file: {}\", e))?;\n\n    Ok(())\n}\n\n/// Get files by tags (for filtering)\n///\n/// # Arguments\n/// * `tag_names` - Array of tag names to filter by\n/// * `match_all` - If true, file must have ALL tags (AND logic). If false, file must have at least one tag (OR logic)\n#[tauri::command]\npub async fn get_files_by_tags(\n    tag_names: Vec\u003cString\u003e,\n    match_all: bool,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003cVec\u003ci64\u003e, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let file_ids = repo\n        .get_files_by_tags(\u0026tag_names, match_all)\n        .await\n        .map_err(|e| format!(\"Failed to get files by tags: {}\", e))?;\n\n    Ok(file_ids)\n}\n\n/// Get usage statistics for a tag\n#[tauri::command]\npub async fn get_tag_stats(\n    tag_id: i32,\n    state: State\u003c'_, AppState\u003e,\n) -\u003e Result\u003ci64, String\u003e {\n    let pool = state.database.pool().await;\n    let repo = TagRepository::new(pool);\n\n    let count = repo\n        .get_tag_file_count(tag_id)\n        .await\n        .map_err(|e| format!(\"Failed to get tag stats: {}\", e))?;\n\n    Ok(count)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","auto_tagger.rs"],"content":"//! Auto-Tagging System for MIDI Files\n//!\n//! This module provides intelligent tag extraction from:\n//! - File names (splitting on _, -, space, camelCase)\n//! - Folder paths (manufacturer, genre, category)\n//! - MIDI content (instrument names, track names)\n//!\n//! Tags are categorized as:\n//! - genre:house, genre:techno, etc.\n//! - instrument:kick, instrument:bass, etc.\n//! - brand:vengeance, brand:splice, etc.\n//! - Style tags: deep, dark, melodic, etc.\n\nuse regex::Regex;\nuse std::collections::HashSet;\n\n/// Main auto-tagging engine\npub struct AutoTagger {\n    genre_keywords: HashSet\u003cString\u003e,\n    instrument_keywords: HashSet\u003cString\u003e,\n    manufacturer_keywords: HashSet\u003cString\u003e,\n    style_keywords: HashSet\u003cString\u003e,\n    common_words: HashSet\u003cString\u003e,\n    split_pattern: Regex,\n}\n\n/// Tag with optional category prefix\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\npub struct Tag {\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n}\n\nimpl Tag {\n    pub fn new(name: impl Into\u003cString\u003e, category: Option\u003cimpl Into\u003cString\u003e\u003e) -\u003e Self {\n        Self {\n            name: name.into(),\n            category: category.map(|c| c.into()),\n        }\n    }\n\n    /// Get the full tag string (e.g., \"genre:house\" or just \"deep\")\n    pub fn full_name(\u0026self) -\u003e String {\n        match \u0026self.category {\n            Some(cat) =\u003e format!(\"{}:{}\", cat, self.name),\n            None =\u003e self.name.clone(),\n        }\n    }\n}\n\nimpl AutoTagger {\n    /// Create a new auto-tagger with default keyword dictionaries\n    ///\n    /// # Errors\n    /// Returns error if internal regex pattern compilation fails (should never happen with valid pattern)\n    pub fn new() -\u003e Result\u003cSelf, regex::Error\u003e {\n        Ok(Self {\n            genre_keywords: Self::load_genre_keywords(),\n            instrument_keywords: Self::load_instrument_keywords(),\n            manufacturer_keywords: Self::load_manufacturer_keywords(),\n            style_keywords: Self::load_style_keywords(),\n            common_words: Self::load_common_words(),\n            // Split on underscores, hyphens, spaces, and dots\n            // Note: camelCase splitting requires lookahead/lookbehind which isn't supported in Rust regex\n            split_pattern: Regex::new(r\"[_\\-\\s.]+\")?,\n        })\n    }\n\n    /// Extract tags from file path, name, and MIDI content\n    ///\n    /// # Arguments\n    /// * `file_path` - Full file path (e.g., \"/Vengeance/DeepHouse/Kicks/VEC_Kick_128.mid\")\n    /// * `file_name` - File name only (e.g., \"VEC_Kick_128.mid\")\n    /// * `midi_instruments` - Instrument names from MIDI file (e.g., [\"Acoustic Bass Drum\"])\n    /// * `bpm` - Detected BPM (optional, added as tag if present)\n    /// * `key_signature` - Detected key (optional, added as tag if present)\n    ///\n    /// # Returns\n    /// Vector of unique tags with categories\n    pub fn extract_tags(\n        \u0026self,\n        file_path: \u0026str,\n        file_name: \u0026str,\n        midi_instruments: \u0026[String],\n        bpm: Option\u003cf64\u003e,\n        key_signature: Option\u003c\u0026str\u003e,\n    ) -\u003e Vec\u003cTag\u003e {\n        let mut tags = HashSet::new();\n\n        // 1. Extract from file name\n        tags.extend(self.extract_from_filename(file_name));\n\n        // 2. Extract from folder path\n        tags.extend(self.extract_from_path(file_path));\n\n        // 3. Extract from MIDI instruments\n        tags.extend(self.extract_from_instruments(midi_instruments));\n\n        // 4. Add BPM tag if available\n        if let Some(bpm_val) = bpm {\n            let bpm_rounded = bpm_val.round() as i32;\n            tags.insert(Tag::new(bpm_rounded.to_string(), Some(\"bpm\")));\n        }\n\n        // 5. Add key signature tag if available\n        if let Some(key) = key_signature {\n            let key_normalized = key.to_lowercase();\n            if key_normalized != \"unknown\" {\n                tags.insert(Tag::new(key_normalized, Some(\"key\")));\n            }\n        }\n\n        tags.into_iter().collect()\n    }\n\n    /// Extract tags from filename by splitting on common separators\n    fn extract_from_filename(\u0026self, filename: \u0026str) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        // Remove extension\n        let name = filename\n            .trim_end_matches(\".mid\")\n            .trim_end_matches(\".MID\")\n            .trim_end_matches(\".midi\")\n            .trim_end_matches(\".MIDI\");\n\n        // Split on separators: _, -, space, and camelCase\n        let words: Vec\u003c\u0026str\u003e = self.split_pattern.split(name).collect();\n\n        for word in words {\n            let word_lower = word.to_lowercase();\n\n            // Skip common/meaningless words\n            if word.len() \u003c 2 || self.common_words.contains(\u0026word_lower) {\n                continue;\n            }\n\n            // Check against known dictionaries with fuzzy matching\n            if let Some(matched_genre) = self.fuzzy_match(\u0026word_lower, \u0026self.genre_keywords) {\n                tags.push(Tag::new(matched_genre, Some(\"genre\")));\n            } else if let Some(matched_instrument) =\n                self.fuzzy_match(\u0026word_lower, \u0026self.instrument_keywords)\n            {\n                tags.push(Tag::new(matched_instrument, Some(\"instrument\")));\n            } else if let Some(matched_brand) =\n                self.fuzzy_match(\u0026word_lower, \u0026self.manufacturer_keywords)\n            {\n                tags.push(Tag::new(matched_brand, Some(\"brand\")));\n            } else if let Some(matched_style) = self.fuzzy_match(\u0026word_lower, \u0026self.style_keywords)\n            {\n                tags.push(Tag::new(matched_style, None::\u003cString\u003e)); // Style tags have no category prefix\n            } else if word.len() \u003e 3 \u0026\u0026 word.chars().all(|c| c.is_alphanumeric()) {\n                // Add as generic tag if it's meaningful (\u003e3 chars, alphanumeric)\n                tags.push(Tag::new(word_lower, None::\u003cString\u003e));\n            }\n        }\n\n        tags\n    }\n\n    /// Extract tags from folder path\n    fn extract_from_path(\u0026self, path: \u0026str) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        // Split path into components\n        let parts: Vec\u003c\u0026str\u003e = path.split('/').filter(|s| !s.is_empty()).collect();\n\n        for part in parts {\n            let part_lower = part.to_lowercase();\n\n            // Check against dictionaries\n            if let Some(matched_genre) = self.fuzzy_match(\u0026part_lower, \u0026self.genre_keywords) {\n                tags.push(Tag::new(matched_genre, Some(\"genre\")));\n            } else if let Some(matched_instrument) =\n                self.fuzzy_match(\u0026part_lower, \u0026self.instrument_keywords)\n            {\n                tags.push(Tag::new(matched_instrument, Some(\"category\")));\n            } else if let Some(matched_brand) =\n                self.fuzzy_match(\u0026part_lower, \u0026self.manufacturer_keywords)\n            {\n                tags.push(Tag::new(matched_brand, Some(\"brand\")));\n            }\n        }\n\n        tags\n    }\n\n    /// Extract tags from MIDI instrument names\n    fn extract_from_instruments(\u0026self, instruments: \u0026[String]) -\u003e Vec\u003cTag\u003e {\n        let mut tags = Vec::new();\n\n        for instrument in instruments {\n            let inst_lower = instrument.to_lowercase();\n\n            // Map MIDI GM instrument names to our keywords\n            if let Some(matched) = self.fuzzy_match(\u0026inst_lower, \u0026self.instrument_keywords) {\n                tags.push(Tag::new(matched, Some(\"instrument\")));\n            }\n        }\n\n        tags\n    }\n\n    /// Fuzzy match a word against a dictionary using Levenshtein distance\n    /// Returns the matched keyword if distance \u003c= 2\n    fn fuzzy_match(\u0026self, input: \u0026str, dictionary: \u0026HashSet\u003cString\u003e) -\u003e Option\u003cString\u003e {\n        // First try exact match\n        if dictionary.contains(input) {\n            return Some(input.to_string());\n        }\n\n        // Try fuzzy matching with threshold of 2 edits\n        let threshold = 2;\n\n        dictionary\n            .iter()\n            .filter(|keyword| {\n                // Only fuzzy match if input is reasonably long\n                if input.len() \u003c 4 {\n                    return false;\n                }\n                strsim::levenshtein(input, keyword) \u003c= threshold\n            })\n            .min_by_key(|keyword| strsim::levenshtein(input, keyword))\n            .cloned()\n    }\n\n    // ==========================================================================\n    // KEYWORD DICTIONARIES\n    // ==========================================================================\n\n    fn load_genre_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"house\",\n            \"deephouse\",\n            \"deep_house\",\n            \"techhouse\",\n            \"tech_house\",\n            \"techno\",\n            \"trance\",\n            \"dubstep\",\n            \"dnb\",\n            \"drum_and_bass\",\n            \"drumnbass\",\n            \"edm\",\n            \"electro\",\n            \"progressive\",\n            \"minimal\",\n            \"acid\",\n            \"ambient\",\n            \"breakbeat\",\n            \"garage\",\n            \"trap\",\n            \"hip_hop\",\n            \"hiphop\",\n            \"lofi\",\n            \"chillout\",\n            \"downtempo\",\n            \"industrial\",\n            \"hardstyle\",\n            \"hardcore\",\n            \"jungle\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_instrument_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            // Drums\n            \"kick\",\n            \"bass_drum\",\n            \"bassdrum\",\n            \"snare\",\n            \"hihat\",\n            \"hat\",\n            \"clap\",\n            \"tom\",\n            \"cymbal\",\n            \"percussion\",\n            \"perc\",\n            \"drum\",\n            \"drums\",\n            // Bass\n            \"bass\",\n            \"sub\",\n            \"subbass\",\n            \"reese\",\n            // Synths\n            \"pluck\",\n            \"lead\",\n            \"synth\",\n            \"pad\",\n            \"chord\",\n            \"stab\",\n            \"arp\",\n            \"arpeggiated\",\n            \"melody\",\n            \"melodic\",\n            // Keys\n            \"piano\",\n            \"keys\",\n            \"organ\",\n            \"rhodes\",\n            \"wurlitzer\",\n            // Orchestral\n            \"strings\",\n            \"string\",\n            \"brass\",\n            \"woodwind\",\n            \"orchestra\",\n            // Vocals\n            \"vocal\",\n            \"vox\",\n            \"voice\",\n            // FX\n            \"fx\",\n            \"effect\",\n            \"riser\",\n            \"impact\",\n            \"sweep\",\n            \"transition\",\n            // Loops\n            \"loop\",\n            \"pattern\",\n            \"sequence\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_manufacturer_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"vengeance\",\n            \"splice\",\n            \"loopmasters\",\n            \"sample_magic\",\n            \"samplemagic\",\n            \"black_octopus\",\n            \"blackoctopus\",\n            \"cymatics\",\n            \"production_master\",\n            \"productionmaster\",\n            \"roland\",\n            \"korg\",\n            \"moog\",\n            \"arturia\",\n            \"native_instruments\",\n            \"native\",\n            \"serum\",\n            \"massive\",\n            \"sylenth\",\n            \"spire\",\n            \"abletonlive\",\n            \"ableton\",\n            \"flstudio\",\n            \"logic\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_style_keywords() -\u003e HashSet\u003cString\u003e {\n        [\n            \"dark\",\n            \"melodic\",\n            \"aggressive\",\n            \"soft\",\n            \"hard\",\n            \"heavy\",\n            \"rolling\",\n            \"bouncy\",\n            \"groovy\",\n            \"punchy\",\n            \"warm\",\n            \"cold\",\n            \"analog\",\n            \"digital\",\n            \"vintage\",\n            \"modern\",\n            \"classic\",\n            \"dirty\",\n            \"clean\",\n            \"distorted\",\n            \"atmospheric\",\n            \"uplifting\",\n            \"euphoric\",\n            \"deep\",\n            \"driving\",\n            \"energetic\",\n            \"chill\",\n            \"relaxed\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n\n    fn load_common_words() -\u003e HashSet\u003cString\u003e {\n        [\n            \"the\", \"and\", \"for\", \"with\", \"track\", \"midi\", \"file\", \"new\", \"ver\", \"vol\", \"v\", \"pt\",\n            \"part\", \"demo\", \"edit\", \"mix\", \"original\", \"version\",\n        ]\n        .iter()\n        .map(|s| s.to_string())\n        .collect()\n    }\n}\n\n// Note: Default trait removed since AutoTagger::new() now returns Result.\n// Users should call AutoTagger::new()? instead of using Default.\n\n// =============================================================================\n// TESTS\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_extract_from_filename() {\n        let tagger = AutoTagger::new().unwrap();\n\n        // Test 1: Vengeance style naming\n        let tags = tagger.extract_from_filename(\"VEC_Deep_House_Kick_128_C.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"genre:house\".to_string()));\n        assert!(tag_names.contains(\u0026\"deep\".to_string()));\n        assert!(tag_names.contains(\u0026\"instrument:kick\".to_string()));\n\n        // Test 2: CamelCase naming\n        let tags = tagger.extract_from_filename(\"TechnoLeadSynth.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"genre:techno\".to_string()));\n        assert!(tag_names.contains(\u0026\"instrument:lead\".to_string()));\n    }\n\n    #[test]\n    fn test_extract_from_path() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_from_path(\"/Vengeance/DeepHouse/Drums/Kicks/file.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        assert!(tag_names.contains(\u0026\"brand:vengeance\".to_string()));\n        assert!(tag_names.contains(\u0026\"category:drums\".to_string()));\n    }\n\n    #[test]\n    fn test_fuzzy_matching() {\n        let tagger = AutoTagger::new().unwrap();\n\n        // \"vengance\" should match \"vengeance\" (1 char difference)\n        let result = tagger.fuzzy_match(\"vengance\", \u0026tagger.manufacturer_keywords);\n        assert_eq!(result, Some(\"vengeance\".to_string()));\n\n        // \"teckno\" should match \"techno\" (1 char swap)\n        let result = tagger.fuzzy_match(\"teckno\", \u0026tagger.genre_keywords);\n        assert_eq!(result, Some(\"techno\".to_string()));\n    }\n\n    #[test]\n    fn test_full_tag_extraction() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_tags(\n            \"/Samples/Vengeance/DeepHouse/Drums/VEC_Deep_Kick_128_C.mid\",\n            \"VEC_Deep_Kick_128_C.mid\",\n            \u0026[\"Acoustic Bass Drum\".to_string()],\n            Some(128.0),\n            Some(\"C\"),\n        );\n\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.full_name()).collect();\n\n        // Should have brand\n        assert!(tag_names.iter().any(|t| t.starts_with(\"brand:\")));\n        // Should have genre\n        assert!(tag_names.iter().any(|t| t.starts_with(\"genre:\")));\n        // Should have instrument\n        assert!(tag_names.iter().any(|t| t.starts_with(\"instrument:\")));\n        // Should have BPM\n        assert!(tag_names.contains(\u0026\"bpm:128\".to_string()));\n        // Should have key\n        assert!(tag_names.contains(\u0026\"key:c\".to_string()));\n    }\n\n    #[test]\n    fn test_common_words_filtered() {\n        let tagger = AutoTagger::new().unwrap();\n\n        let tags = tagger.extract_from_filename(\"The_New_Kick_For_Mix.mid\");\n        let tag_names: Vec\u003cString\u003e = tags.iter().map(|t| t.name.clone()).collect();\n\n        // Common words should be filtered out\n        assert!(!tag_names.contains(\u0026\"the\".to_string()));\n        assert!(!tag_names.contains(\u0026\"new\".to_string()));\n        assert!(!tag_names.contains(\u0026\"for\".to_string()));\n        assert!(!tag_names.contains(\u0026\"mix\".to_string()));\n\n        // But \"kick\" should remain\n        assert!(tag_names.contains(\u0026\"kick\".to_string()));\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":3},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","bpm_detector.rs"],"content":"//! BPM Detection Module\n//!\n//! This module provides BPM (Beats Per Minute) detection for MIDI files.\n//! It analyzes tempo change events and provides confidence scores.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse midi_library_shared::core::midi::types::{Event, MidiFile};\n\n/// Default BPM when no tempo events are found\nconst DEFAULT_BPM: f64 = 120.0;\n\n/// Minimum valid BPM\nconst MIN_BPM: f64 = 20.0;\n\n/// Maximum valid BPM\nconst MAX_BPM: f64 = 300.0;\n\n/// Result of BPM detection\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmDetectionResult {\n    /// Detected BPM (beats per minute)\n    pub bpm: f64,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Detection method used\n    pub method: BpmDetectionMethod,\n\n    /// Additional metadata\n    pub metadata: BpmMetadata,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum BpmDetectionMethod {\n    /// Single tempo event found\n    SingleTempo,\n\n    /// Multiple tempo events, used weighted average\n    WeightedAverage,\n\n    /// No tempo events, used default\n    DefaultTempo,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmMetadata {\n    /// All tempo changes in the file\n    pub tempo_changes: Vec\u003cTempoChange\u003e,\n\n    /// Whether tempo is constant throughout\n    pub is_constant: bool,\n\n    /// Tempo range (min, max) if multiple tempos\n    pub tempo_range: Option\u003c(f64, f64)\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct TempoChange {\n    pub tick: u32,\n    pub bpm: f64,\n}\n\n/// Detects BPM from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `BpmDetectionResult` - Detection result with confidence and metadata\n///\n/// # Examples\n/// ```no_run\n/// use pipeline::core::analysis::bpm_detector::detect_bpm;\n/// use pipeline::core::midi::types::MidiFile;\n///\n/// # fn example() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n/// # let midi_file = MidiFile {\n/// #     header: pipeline::core::midi::types::Header {\n/// #         format: 1,\n/// #         num_tracks: 1,\n/// #         ticks_per_quarter_note: 480,\n/// #     },\n/// #     tracks: vec![],\n/// # };\n/// let result = detect_bpm(\u0026midi_file);\n/// println!(\"Detected BPM: {:.2}\", result.bpm);\n/// # Ok(())\n/// # }\n/// ```\npub fn detect_bpm(midi_file: \u0026MidiFile) -\u003e BpmDetectionResult {\n    // Extract all tempo events from all tracks\n    let tempo_events = extract_tempo_events(midi_file);\n\n    if tempo_events.is_empty() {\n        return BpmDetectionResult {\n            bpm: DEFAULT_BPM,\n            confidence: 0.3, // Low confidence for default tempo\n            method: BpmDetectionMethod::DefaultTempo,\n            metadata: BpmMetadata {\n                tempo_changes: vec![],\n                is_constant: true,\n                tempo_range: None,\n            },\n        };\n    }\n\n    // Convert tempo changes to BPM values\n    let tempo_changes: Vec\u003cTempoChange\u003e = tempo_events\n        .into_iter()\n        .map(|(tick, microseconds_per_quarter)| TempoChange {\n            tick,\n            bpm: microseconds_to_bpm(microseconds_per_quarter),\n        })\n        .collect();\n\n    // Calculate statistics\n    let is_constant = tempo_changes.len() == 1;\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let total_ticks = calculate_total_ticks(midi_file);\n    let avg_bpm = calculate_weighted_average(\u0026tempo_changes, total_ticks);\n\n    let tempo_range = if tempo_changes.len() \u003e 1 {\n        let min = bpms.iter().cloned().fold(f64::INFINITY, f64::min);\n        let max = bpms.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n        Some((min, max))\n    } else {\n        None\n    };\n\n    // Determine confidence based on consistency\n    let confidence = calculate_confidence(\u0026tempo_changes);\n\n    let method = if tempo_changes.len() == 1 {\n        BpmDetectionMethod::SingleTempo\n    } else {\n        BpmDetectionMethod::WeightedAverage\n    };\n\n    BpmDetectionResult {\n        bpm: avg_bpm,\n        confidence,\n        method,\n        metadata: BpmMetadata {\n            tempo_changes,\n            is_constant,\n            tempo_range,\n        },\n    }\n}\n\n/// Extracts tempo events from all tracks in the MIDI file\nfn extract_tempo_events(midi_file: \u0026MidiFile) -\u003e Vec\u003c(u32, u32)\u003e {\n    let mut tempo_events = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            if let Event::TempoChange {\n                microseconds_per_quarter,\n            } = timed_event.event\n            {\n                tempo_events.push((current_tick, microseconds_per_quarter));\n            }\n        }\n    }\n\n    // Sort by tick position\n    tempo_events.sort_by_key(|(tick, _)| *tick);\n    tempo_events\n}\n\n/// Calculates the total number of ticks in the MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e u32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks\n}\n\n/// Converts microseconds per quarter note to BPM\nfn microseconds_to_bpm(microseconds_per_quarter: u32) -\u003e f64 {\n    let bpm = 60_000_000.0 / microseconds_per_quarter as f64;\n\n    // Clamp to valid range\n    bpm.clamp(MIN_BPM, MAX_BPM)\n}\n\n/// Calculates weighted average BPM based on duration each tempo is active\nfn calculate_weighted_average(tempo_changes: \u0026[TempoChange], total_ticks: u32) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return DEFAULT_BPM;\n    }\n\n    if tempo_changes.len() == 1 {\n        return tempo_changes[0].bpm;\n    }\n\n    let mut weighted_sum = 0.0;\n    let mut total_weight = 0.0;\n\n    for (i, tempo_change) in tempo_changes.iter().enumerate() {\n        let duration = if i + 1 \u003c tempo_changes.len() {\n            tempo_changes[i + 1].tick - tempo_change.tick\n        } else {\n            total_ticks.saturating_sub(tempo_change.tick)\n        };\n\n        let weight = duration as f64;\n        weighted_sum += tempo_change.bpm * weight;\n        total_weight += weight;\n    }\n\n    if total_weight \u003e 0.0 {\n        weighted_sum / total_weight\n    } else {\n        tempo_changes[0].bpm\n    }\n}\n\n/// Calculates confidence score based on tempo consistency\nfn calculate_confidence(tempo_changes: \u0026[TempoChange]) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return 0.3; // Low confidence for default\n    }\n\n    if tempo_changes.len() == 1 {\n        return 1.0; // High confidence for single tempo\n    }\n\n    // Calculate variance in BPM values\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let mean = bpms.iter().sum::\u003cf64\u003e() / bpms.len() as f64;\n    let variance = bpms.iter().map(|bpm| (bpm - mean).powi(2)).sum::\u003cf64\u003e() / bpms.len() as f64;\n    let std_dev = variance.sqrt();\n\n    // Lower variance = higher confidence\n    // Scale confidence based on coefficient of variation\n    let cv = std_dev / mean;\n    (1.0 - cv).clamp(0.5, 1.0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_to_bpm() {\n        // 120 BPM = 500,000 microseconds per quarter note\n        assert_eq!(microseconds_to_bpm(500_000), 120.0);\n\n        // 60 BPM = 1,000,000 microseconds\n        assert_eq!(microseconds_to_bpm(1_000_000), 60.0);\n\n        // 140 BPM  428,571 microseconds\n        let bpm = microseconds_to_bpm(428_571);\n        assert!((bpm - 140.0).abs() \u003c 0.1);\n    }\n\n    #[test]\n    fn test_bpm_clamping() {\n        // Test minimum clamping\n        let too_slow = microseconds_to_bpm(5_000_000); // Would be 12 BPM\n        assert_eq!(too_slow, MIN_BPM);\n\n        // Test maximum clamping\n        let too_fast = microseconds_to_bpm(100_000); // Would be 600 BPM\n        assert_eq!(too_fast, MAX_BPM);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","key_detector.rs"],"content":"//! Key Detection Module\n//!\n//! Implements the Krumhansl-Schmuckler key-finding algorithm to detect\n//! the musical key of MIDI files.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse crate::core::analysis::key_profiles::*;\nuse midi_library_shared::core::midi::types::{Event, MidiFile};\n\n/// Musical scale types\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ScaleType {\n    Major,\n    Minor,\n}\n\nimpl std::fmt::Display for ScaleType {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            ScaleType::Major =\u003e write!(f, \"major\"),\n            ScaleType::Minor =\u003e write!(f, \"minor\"),\n        }\n    }\n}\n\n/// Result of key detection\n#[derive(Debug, Clone, PartialEq)]\npub struct KeyDetectionResult {\n    /// Detected key (e.g., \"C\", \"Am\", \"F#\")\n    pub key: String,\n\n    /// Whether the key is major or minor\n    pub scale_type: ScaleType,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Top 3 alternative keys with their correlation scores\n    pub alternatives: Vec\u003cKeyAlternative\u003e,\n\n    /// Pitch class distribution from the MIDI file\n    pub pitch_class_distribution: [f64; 12],\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct KeyAlternative {\n    pub key: String,\n    pub scale_type: ScaleType,\n    pub correlation: f64,\n}\n\n/// Detects the musical key from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `KeyDetectionResult` - Detection result with confidence and alternatives\n///\n/// # Algorithm\n/// Uses Krumhansl-Schmuckler key-finding algorithm:\n/// 1. Extract all notes and build pitch class histogram\n/// 2. Normalize histogram to probability distribution\n/// 3. Correlate with all 24 key profiles (12 major + 12 minor)\n/// 4. Return key with highest correlation\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::midi::types::MidiFile;\n/// use pipeline::core::analysis::key_detector::detect_key;\n///\n/// // Assuming you have a parsed MIDI file\n/// // let midi_file = parse_midi_file(\u0026data)?;\n/// // let result = detect_key(\u0026midi_file);\n/// // println!(\"Detected key: {} ({})\", result.key, result.scale_type);\n/// ```\npub fn detect_key(midi_file: \u0026MidiFile) -\u003e KeyDetectionResult {\n    // Build pitch class histogram\n    let pitch_class_counts = build_pitch_class_histogram(midi_file);\n\n    // Normalize to probability distribution\n    let pitch_class_distribution = normalize_histogram(\u0026pitch_class_counts);\n\n    // Calculate correlations with all 24 key profiles\n    let mut correlations = Vec::new();\n\n    for pitch_class in 0..12 {\n        // Major key\n        let major_correlation = calculate_correlation(\n            \u0026pitch_class_distribution,\n            \u0026rotate_profile(\u0026MAJOR_PROFILE, pitch_class),\n        );\n        correlations.push((pitch_class, ScaleType::Major, major_correlation));\n\n        // Minor key\n        let minor_correlation = calculate_correlation(\n            \u0026pitch_class_distribution,\n            \u0026rotate_profile(\u0026MINOR_PROFILE, pitch_class),\n        );\n        correlations.push((pitch_class, ScaleType::Minor, minor_correlation));\n    }\n\n    // Sort by correlation (descending)\n    // Note: partial_cmp can return None for NaN values, treat them as equal\n    correlations.sort_by(|a, b| b.2.partial_cmp(\u0026a.2).unwrap_or(std::cmp::Ordering::Equal));\n\n    // Get top result\n    let (best_pitch_class, best_scale_type, _best_correlation) = correlations[0];\n\n    let key_name = format_key_name(best_pitch_class, best_scale_type);\n\n    // Calculate confidence from correlation\n    let confidence = calculate_confidence(\u0026correlations);\n\n    // Get top 3 alternatives\n    let alternatives: Vec\u003cKeyAlternative\u003e = correlations[1..4]\n        .iter()\n        .map(|(pc, st, corr)| KeyAlternative {\n            key: format_key_name(*pc, *st),\n            scale_type: *st,\n            correlation: *corr,\n        })\n        .collect();\n\n    KeyDetectionResult {\n        key: key_name,\n        scale_type: best_scale_type,\n        confidence,\n        alternatives,\n        pitch_class_distribution,\n    }\n}\n\n/// Builds a histogram of pitch class occurrences\nfn build_pitch_class_histogram(midi_file: \u0026MidiFile) -\u003e [u32; 12] {\n    let mut histogram = [0u32; 12];\n\n    for track in \u0026midi_file.tracks {\n        for timed_event in \u0026track.events {\n            if let Event::NoteOn { note, velocity, .. } = timed_event.event {\n                if velocity \u003e 0 {\n                    let pitch_class = (note % 12) as usize;\n                    histogram[pitch_class] += 1;\n                }\n            }\n        }\n    }\n\n    histogram\n}\n\n/// Normalizes histogram to probability distribution\nfn normalize_histogram(histogram: \u0026[u32; 12]) -\u003e [f64; 12] {\n    let total: u32 = histogram.iter().sum();\n\n    if total == 0 {\n        return [0.0; 12];\n    }\n\n    let mut normalized = [0.0; 12];\n    for i in 0..12 {\n        normalized[i] = histogram[i] as f64 / total as f64;\n    }\n\n    normalized\n}\n\n/// Rotates a key profile to a different tonic\n///\n/// Takes a profile defined for C (pitch class 0) and rotates it to be\n/// defined for a different pitch class. The rotation shifts the profile\n/// so that the tonic weight appears at the target pitch class.\nfn rotate_profile(profile: \u0026[f64; 12], rotation: usize) -\u003e [f64; 12] {\n    let mut rotated = [0.0; 12];\n\n    for i in 0..12 {\n        rotated[i] = profile[(i + 12 - rotation) % 12];\n    }\n\n    rotated\n}\n\n/// Calculates Pearson correlation coefficient between two distributions\nfn calculate_correlation(distribution: \u0026[f64; 12], profile: \u0026[f64; 12]) -\u003e f64 {\n    // Calculate means\n    let mean_dist = distribution.iter().sum::\u003cf64\u003e() / 12.0;\n    let mean_prof = profile.iter().sum::\u003cf64\u003e() / 12.0;\n\n    // Calculate covariance and standard deviations\n    let mut covariance = 0.0;\n    let mut var_dist = 0.0;\n    let mut var_prof = 0.0;\n\n    for i in 0..12 {\n        let diff_dist = distribution[i] - mean_dist;\n        let diff_prof = profile[i] - mean_prof;\n\n        covariance += diff_dist * diff_prof;\n        var_dist += diff_dist * diff_dist;\n        var_prof += diff_prof * diff_prof;\n    }\n\n    // Calculate correlation\n    let std_dist = var_dist.sqrt();\n    let std_prof = var_prof.sqrt();\n\n    if std_dist == 0.0 || std_prof == 0.0 {\n        return 0.0;\n    }\n\n    covariance / (std_dist * std_prof)\n}\n\n/// Calculates confidence based on separation between best and second-best keys\nfn calculate_confidence(correlations: \u0026[(usize, ScaleType, f64)]) -\u003e f64 {\n    if correlations.len() \u003c 2 {\n        return 0.5;\n    }\n\n    let best = correlations[0].2;\n    let second_best = correlations[1].2;\n\n    // Larger gap = higher confidence\n    let gap = best - second_best;\n\n    // Map gap to confidence score\n    // Gap of 0.0 = 0.5 confidence\n    // Gap of 0.2+ = 1.0 confidence\n    let confidence = 0.5 + (gap * 2.5).min(0.5);\n\n    confidence.clamp(0.5, 1.0)\n}\n\n/// Formats key name based on pitch class and scale type\nfn format_key_name(pitch_class: usize, scale_type: ScaleType) -\u003e String {\n    let base_name = pitch_class_to_key_name(pitch_class);\n\n    match scale_type {\n        ScaleType::Major =\u003e base_name.to_string(),\n        ScaleType::Minor =\u003e format!(\"{}m\", base_name),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_normalize_histogram() {\n        let histogram = [10, 0, 5, 0, 3, 0, 0, 7, 0, 2, 0, 3];\n        let normalized = normalize_histogram(\u0026histogram);\n\n        let total: f64 = normalized.iter().sum();\n        assert!((total - 1.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_normalize_empty_histogram() {\n        let histogram = [0; 12];\n        let normalized = normalize_histogram(\u0026histogram);\n\n        assert_eq!(normalized, [0.0; 12]);\n    }\n\n    #[test]\n    fn test_rotate_profile() {\n        // Test that rotating a profile moves the tonic weight to the correct position\n        let profile = [\n            1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0,\n        ];\n\n        // Rotate to pitch class 3 (D#)\n        let rotated = rotate_profile(\u0026profile, 3);\n\n        // The tonic weight (1.0) should now be at position 3\n        assert_eq!(rotated[3], 1.0);\n        // Position 0 should have the weight that was 3 positions back\n        assert_eq!(rotated[0], 10.0);\n        // Position 4 should have the weight that was at position 1 (the scale degree above tonic)\n        assert_eq!(rotated[4], 2.0);\n    }\n\n    #[test]\n    fn test_correlation_identical() {\n        let dist1 = [\n            0.1, 0.2, 0.1, 0.05, 0.15, 0.1, 0.05, 0.15, 0.03, 0.02, 0.03, 0.02,\n        ];\n        let correlation = calculate_correlation(\u0026dist1, \u0026dist1);\n\n        assert!((correlation - 1.0).abs() \u003c 0.001);\n    }\n\n    #[test]\n    fn test_correlation_zero() {\n        let dist1 = [0.0; 12];\n        let dist2 = [\n            0.1, 0.2, 0.1, 0.05, 0.15, 0.1, 0.05, 0.15, 0.03, 0.02, 0.03, 0.02,\n        ];\n        let correlation = calculate_correlation(\u0026dist1, \u0026dist2);\n\n        assert_eq!(correlation, 0.0);\n    }\n\n    #[test]\n    fn test_format_key_name() {\n        assert_eq!(format_key_name(0, ScaleType::Major), \"C\");\n        assert_eq!(format_key_name(0, ScaleType::Minor), \"Cm\");\n        assert_eq!(format_key_name(9, ScaleType::Minor), \"Am\");\n        assert_eq!(format_key_name(7, ScaleType::Major), \"G\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","key_profiles.rs"],"content":"//! Krumhansl-Schmuckler Key Profiles\n//!\n//! These profiles represent the expected distribution of pitch classes\n//! in major and minor keys, derived from music theory research.\n\n/// Major key profile (Krumhansl \u0026 Kessler, 1982)\n/// Indexed by pitch class: C, C#, D, D#, E, F, F#, G, G#, A, A#, B\npub const MAJOR_PROFILE: [f64; 12] = [\n    6.35, // C  - Tonic (strongest)\n    2.23, // C# - Minor 2nd\n    3.48, // D  - Major 2nd\n    2.33, // D# - Minor 3rd\n    4.38, // E  - Major 3rd\n    4.09, // F  - Perfect 4th\n    2.52, // F# - Tritone\n    5.19, // G  - Perfect 5th\n    2.39, // G# - Minor 6th\n    3.66, // A  - Major 6th\n    2.29, // A# - Minor 7th\n    2.88, // B  - Major 7th\n];\n\n/// Minor key profile (Krumhansl \u0026 Kessler, 1982)\npub const MINOR_PROFILE: [f64; 12] = [\n    6.33, // C  - Tonic (strongest)\n    2.68, // C# - Minor 2nd\n    3.52, // D  - Major 2nd\n    5.38, // D# - Minor 3rd (characteristic of minor)\n    2.60, // E  - Major 3rd\n    3.53, // F  - Perfect 4th\n    2.54, // F# - Tritone\n    4.75, // G  - Perfect 5th\n    3.98, // G# - Minor 6th (characteristic of minor)\n    2.69, // A  - Major 6th\n    3.34, // A# - Minor 7th\n    3.17, // B  - Major 7th\n];\n\n/// All possible key names in circle of fifths order\npub const KEY_NAMES: [\u0026str; 12] = [\n    \"C\", \"G\", \"D\", \"A\", \"E\", \"B\", \"F#\", \"C#\", \"G#\", \"D#\", \"A#\", \"F\",\n];\n\n/// Maps pitch class to key name\npub fn pitch_class_to_key_name(pitch_class: usize) -\u003e \u0026'static str {\n    match pitch_class {\n        0 =\u003e \"C\",\n        1 =\u003e \"C#\",\n        2 =\u003e \"D\",\n        3 =\u003e \"D#\",\n        4 =\u003e \"E\",\n        5 =\u003e \"F\",\n        6 =\u003e \"F#\",\n        7 =\u003e \"G\",\n        8 =\u003e \"G#\",\n        9 =\u003e \"A\",\n        10 =\u003e \"A#\",\n        11 =\u003e \"B\",\n        _ =\u003e \"UNKNOWN\",\n    }\n}\n\n/// Returns the minor key name for a given pitch class\npub fn pitch_class_to_minor_key_name(pitch_class: usize) -\u003e String {\n    format!(\"{}m\", pitch_class_to_key_name(pitch_class))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","analysis","mod.rs"],"content":"//! Analysis modules for MIDI file processing\n\npub mod auto_tagger;\npub mod bpm_detector;\npub mod key_detector;\npub mod key_profiles;\n\n// Re-export main types\npub use auto_tagger::{AutoTagger, Tag};\npub use bpm_detector::{detect_bpm, BpmDetectionMethod, BpmDetectionResult, BpmMetadata};\npub use key_detector::{detect_key, KeyDetectionResult, ScaleType};\n\n// Tests will be added during Phase 1 of test coverage initiative\n// #[cfg(test)]\n// mod tests;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","hash","blake3.rs"],"content":"//! BLAKE3 hashing module for file content deduplication and integrity verification.\n//!\n//! This is a **Trusty Module** with pure hashing logic.\n//!\n//! # Architecture Pattern\n//!\n//! Core functions are pure (no I/O):\n//! - `calculate_content_hash()` - Pure hash calculation\n//! - `hash_to_hex()` - Pure conversion\n//!\n//! Convenience wrapper (does I/O):\n//! - `calculate_file_hash()` - Reads file and calculates hash\n//!\n//! # Performance\n//!\n//! BLAKE3 provides significant performance improvements over SHA-256:\n//! - **Single-threaded**: ~3,000 MB/s (vs SHA-256 ~400 MB/s)\n//! - **Multi-threaded**: ~10,000 MB/s with parallel tree hashing\n//! - **7x faster** than SHA-256 for typical file sizes\n//!\n//! # Examples\n//!\n//! ```rust\n//! use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n//!\n//! let data = b\"Hello, MIDI Library System!\";\n//! let hash = calculate_content_hash(data);\n//! let hex_string = hash_to_hex(\u0026hash);\n//! println!(\"Hash: {}\", hex_string);\n//! ```\n\nuse std::fs::File;\nuse std::io::{self, Read};\nuse std::path::Path;\nuse thiserror::Error;\n\n/// Hash calculation errors\n#[derive(Error, Debug)]\npub enum HashError {\n    /// File could not be opened or read\n    #[error(\"Failed to read file: {0}\")]\n    IoError(#[from] io::Error),\n\n    /// File path is invalid\n    #[error(\"Invalid file path: {0}\")]\n    InvalidPath(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, HashError\u003e;\n\n/// Calculate BLAKE3 hash of byte content.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `data` - Byte slice to hash\n///\n/// # Returns\n///\n/// 32-byte BLAKE3 hash\n///\n/// # Performance\n///\n/// - Single-threaded: ~3,000 MB/s\n/// - For data larger than 128 KB, BLAKE3 automatically uses parallel tree hashing\n/// - Significantly faster than SHA-256 (~400 MB/s)\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::calculate_content_hash;\n///\n/// let data = b\"MIDI file content\";\n/// let hash = calculate_content_hash(data);\n/// assert_eq!(hash.len(), 32);\n/// ```\npub fn calculate_content_hash(data: \u0026[u8]) -\u003e [u8; 32] {\n    // BLAKE3 uses parallel tree hashing automatically for large inputs\n    // This provides multi-threaded performance without explicit parallelism\n    blake3::hash(data).into()\n}\n\n/// Calculate BLAKE3 hash of a file.\n///\n/// This is a **convenience wrapper** that performs file I/O.\n/// For pure hashing logic, use `calculate_content_hash()`.\n///\n/// # Arguments\n///\n/// * `path` - Path to file to hash\n///\n/// # Returns\n///\n/// 32-byte BLAKE3 hash or error if file cannot be read\n///\n/// # Errors\n///\n/// - `HashError::IoError` - File cannot be opened or read\n/// - `HashError::InvalidPath` - Path is invalid or does not exist\n///\n/// # Performance\n///\n/// For large files (\u003e10 MB), consider using memory-mapped files for better performance.\n/// This implementation reads the file into memory, which is optimal for files \u003c100 MB.\n///\n/// # Examples\n///\n/// ```rust,no_run\n/// use std::path::Path;\n/// use pipeline::core::hash::blake3::calculate_file_hash;\n///\n/// let path = Path::new(\"test.mid\");\n/// let hash = calculate_file_hash(path)?;\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn calculate_file_hash(path: \u0026Path) -\u003e Result\u003c[u8; 32]\u003e {\n    // Validate path\n    if !path.exists() {\n        return Err(HashError::InvalidPath(\n            format!(\"File does not exist: {}\", path.display())\n        ));\n    }\n\n    if !path.is_file() {\n        return Err(HashError::InvalidPath(\n            format!(\"Path is not a file: {}\", path.display())\n        ));\n    }\n\n    // Open file\n    let mut file = File::open(path)?;\n\n    // For small to medium files (\u003c100 MB), read entire file into memory\n    // This is fastest approach for most MIDI files which are typically \u003c10 MB\n    let mut buffer = Vec::new();\n    file.read_to_end(\u0026mut buffer)?;\n\n    // Use pure hash function\n    Ok(calculate_content_hash(\u0026buffer))\n}\n\n/// Convert 32-byte hash to hexadecimal string.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `hash` - 32-byte hash to convert\n///\n/// # Returns\n///\n/// 64-character lowercase hexadecimal string\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n///\n/// let data = b\"test\";\n/// let hash = calculate_content_hash(data);\n/// let hex = hash_to_hex(\u0026hash);\n///\n/// assert_eq!(hex.len(), 64); // 32 bytes = 64 hex characters\n/// assert!(hex.chars().all(|c| c.is_ascii_hexdigit()));\n/// ```\npub fn hash_to_hex(hash: \u0026[u8; 32]) -\u003e String {\n    // Use blake3's built-in hex encoding for efficiency\n    blake3::Hash::from(*hash).to_hex().to_string()\n}\n\n/// Convert hexadecimal string back to 32-byte hash.\n///\n/// This is a **pure function** with no side effects (TRUSTY MODULE pattern).\n///\n/// # Arguments\n///\n/// * `hex` - 64-character hexadecimal string\n///\n/// # Returns\n///\n/// 32-byte hash or error if hex string is invalid\n///\n/// # Errors\n///\n/// Returns error if:\n/// - String is not exactly 64 characters\n/// - String contains non-hexadecimal characters\n///\n/// # Examples\n///\n/// ```rust\n/// use pipeline::core::hash::blake3::{hash_to_hex, hex_to_hash};\n///\n/// let original = [0u8; 32];\n/// let hex = hash_to_hex(\u0026original);\n/// let decoded = hex_to_hash(\u0026hex)?;\n/// assert_eq!(original, decoded);\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn hex_to_hash(hex: \u0026str) -\u003e Result\u003c[u8; 32]\u003e {\n    if hex.len() != 64 {\n        return Err(HashError::InvalidPath(\n            format!(\"Hex string must be exactly 64 characters, got {}\", hex.len())\n        ));\n    }\n\n    let mut hash = [0u8; 32];\n    for i in 0..32 {\n        let byte_str = \u0026hex[i * 2..i * 2 + 2];\n        hash[i] = u8::from_str_radix(byte_str, 16)\n            .map_err(|_| HashError::InvalidPath(\n                format!(\"Invalid hex character in string: {}\", byte_str)\n            ))?;\n    }\n\n    Ok(hash)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n\n    #[test]\n    fn test_calculate_content_hash_empty() {\n        let data = b\"\";\n        let hash = calculate_content_hash(data);\n\n        // BLAKE3 hash of empty string (known value)\n        let expected = hex_to_hash(\"af1349b9f5f9a1a6a0404dea36dcc9499bcb25c9adc112b7cc9a93cae41f3262\").unwrap();\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_hello_world() {\n        let data = b\"Hello, World!\";\n        let hash = calculate_content_hash(data);\n\n        // BLAKE3 hash of \"Hello, World!\" (verified with blake3 crate)\n        let expected = hex_to_hash(\"288a86a79f20a3d6dccdca7713beaed178798296bdfa7913fa2a62d9727bf8f8\").unwrap();\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_consistency() {\n        let data = b\"Consistent hashing test\";\n\n        let hash1 = calculate_content_hash(data);\n        let hash2 = calculate_content_hash(data);\n        let hash3 = calculate_content_hash(data);\n\n        // Same input must always produce same hash\n        assert_eq!(hash1, hash2);\n        assert_eq!(hash2, hash3);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_different_inputs() {\n        let data1 = b\"First input\";\n        let data2 = b\"Second input\";\n\n        let hash1 = calculate_content_hash(data1);\n        let hash2 = calculate_content_hash(data2);\n\n        // Different inputs must produce different hashes\n        assert_ne!(hash1, hash2);\n    }\n\n    #[test]\n    fn test_calculate_content_hash_large_data() {\n        // Test with 1 MB of data (triggers parallel tree hashing)\n        let data = vec![0xAB; 1_000_000];\n        let hash = calculate_content_hash(\u0026data);\n\n        // Just verify we get a valid hash\n        assert_eq!(hash.len(), 32);\n\n        // Verify consistency\n        let hash2 = calculate_content_hash(\u0026data);\n        assert_eq!(hash, hash2);\n    }\n\n    #[test]\n    fn test_hash_to_hex() {\n        let hash = [0u8; 32]; // All zeros\n        let hex = hash_to_hex(\u0026hash);\n\n        assert_eq!(hex.len(), 64);\n        assert_eq!(hex, \"0\".repeat(64));\n    }\n\n    #[test]\n    fn test_hash_to_hex_mixed_values() {\n        let hash = [\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n        ];\n        let hex = hash_to_hex(\u0026hash);\n\n        assert_eq!(hex.len(), 64);\n        assert_eq!(\n            hex,\n            \"0123456789abcdeffedcba9876543210\\\n             0123456789abcdeffedcba9876543210\"\n        );\n    }\n\n    #[test]\n    fn test_hex_to_hash_valid() {\n        let hex = \"0123456789abcdef\\\n                   fedcba9876543210\\\n                   0123456789abcdef\\\n                   fedcba9876543210\";\n        let hash = hex_to_hash(hex).unwrap();\n\n        let expected = [\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n            0x01, 0x23, 0x45, 0x67, 0x89, 0xAB, 0xCD, 0xEF,\n            0xFE, 0xDC, 0xBA, 0x98, 0x76, 0x54, 0x32, 0x10,\n        ];\n        assert_eq!(hash, expected);\n    }\n\n    #[test]\n    fn test_hex_to_hash_roundtrip() {\n        let original = [0xAB; 32];\n        let hex = hash_to_hex(\u0026original);\n        let decoded = hex_to_hash(\u0026hex).unwrap();\n\n        assert_eq!(original, decoded);\n    }\n\n    #[test]\n    fn test_hex_to_hash_invalid_length() {\n        let hex = \"too_short\";\n        let result = hex_to_hash(hex);\n\n        assert!(result.is_err());\n        assert!(result.unwrap_err().to_string().contains(\"64 characters\"));\n    }\n\n    #[test]\n    fn test_hex_to_hash_invalid_characters() {\n        let hex = \"0123456789abcdefg123456789abcdef0123456789abcdef0123456789abcdef\"; // 'g' is invalid\n        let result = hex_to_hash(hex);\n\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_calculate_file_hash_nonexistent() {\n        let path = Path::new(\"/nonexistent/file.mid\");\n        let result = calculate_file_hash(path);\n\n        assert!(result.is_err());\n        let error = result.unwrap_err();\n        assert!(matches!(error, HashError::InvalidPath(_)));\n    }\n\n    #[test]\n    fn test_calculate_file_hash_directory() {\n        // Try to hash a directory (should fail)\n        let path = Path::new(\"/tmp\");\n        let result = calculate_file_hash(path);\n\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_calculate_file_hash_real_file() {\n        // Create temporary test file\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"blake3_test.txt\");\n\n        // Write test data\n        let test_data = b\"Test MIDI file content for hashing\";\n        fs::write(\u0026test_file, test_data).unwrap();\n\n        // Calculate hash from file\n        let file_hash = calculate_file_hash(\u0026test_file).unwrap();\n\n        // Calculate hash from data directly\n        let content_hash = calculate_content_hash(test_data);\n\n        // Should match\n        assert_eq!(file_hash, content_hash);\n\n        // Cleanup\n        fs::remove_file(\u0026test_file).unwrap();\n    }\n\n    #[test]\n    fn test_calculate_file_hash_consistency() {\n        // Create temporary test file\n        let temp_dir = std::env::temp_dir();\n        let test_file = temp_dir.join(\"blake3_consistency_test.txt\");\n\n        // Write test data\n        let test_data = b\"Consistency test for file hashing\";\n        fs::write(\u0026test_file, test_data).unwrap();\n\n        // Calculate hash multiple times\n        let hash1 = calculate_file_hash(\u0026test_file).unwrap();\n        let hash2 = calculate_file_hash(\u0026test_file).unwrap();\n        let hash3 = calculate_file_hash(\u0026test_file).unwrap();\n\n        // All hashes must match\n        assert_eq!(hash1, hash2);\n        assert_eq!(hash2, hash3);\n\n        // Cleanup\n        fs::remove_file(\u0026test_file).unwrap();\n    }\n\n    #[test]\n    fn test_integration_full_workflow() {\n        // Test the complete workflow: data -\u003e hash -\u003e hex -\u003e hash -\u003e verify\n        let original_data = b\"Complete integration test for BLAKE3 hashing\";\n\n        // Step 1: Calculate hash\n        let hash = calculate_content_hash(original_data);\n        assert_eq!(hash.len(), 32);\n\n        // Step 2: Convert to hex\n        let hex = hash_to_hex(\u0026hash);\n        assert_eq!(hex.len(), 64);\n\n        // Step 3: Convert back to hash\n        let decoded_hash = hex_to_hash(\u0026hex).unwrap();\n        assert_eq!(hash, decoded_hash);\n\n        // Step 4: Verify hash matches content\n        let verification_hash = calculate_content_hash(original_data);\n        assert_eq!(hash, verification_hash);\n    }\n\n    #[test]\n    fn test_hash_collision_resistance() {\n        // Test that very similar inputs produce different hashes\n        let data1 = b\"test1\";\n        let data2 = b\"test2\";\n\n        let hash1 = calculate_content_hash(data1);\n        let hash2 = calculate_content_hash(data2);\n\n        // Even single bit difference should produce completely different hash\n        assert_ne!(hash1, hash2);\n\n        // Count number of different bytes (should be high due to avalanche effect)\n        let differences = hash1.iter()\n            .zip(hash2.iter())\n            .filter(|(a, b)| a != b)\n            .count();\n\n        // Expect at least 50% of bytes to be different (avalanche effect)\n        assert!(differences \u003e 16, \"Only {} bytes different\", differences);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","hash","mod.rs"],"content":"//! Hash calculation module for file content deduplication.\n//!\n//! This module provides BLAKE3 hashing functionality for calculating\n//! file content hashes to detect and prevent duplicate files in the\n//! MIDI library system.\n//!\n//! # Architecture Pattern: Trusty Module\n//!\n//! This module follows the **Trusty Module** pattern:\n//! - Pure, stateless hash calculation functions\n//! - Comprehensive test coverage\n//! - No side effects (except convenience file I/O wrapper)\n//! - Single responsibility: hash calculation\n//!\n//! # Performance\n//!\n//! BLAKE3 provides 7x performance improvement over SHA-256:\n//! - Single-threaded: ~3,000 MB/s (vs SHA-256 ~400 MB/s)\n//! - Multi-threaded: ~10,000 MB/s (automatic tree hashing)\n//!\n//! # Usage\n//!\n//! ```rust\n//! use pipeline::core::hash::blake3::{calculate_content_hash, hash_to_hex};\n//!\n//! let data = b\"MIDI file content\";\n//! let hash = calculate_content_hash(data);\n//! let hex_string = hash_to_hex(\u0026hash);\n//! ```\n\npub mod blake3;\n\n// Re-export commonly used items\npub use self::blake3::{\n    calculate_content_hash,\n    calculate_file_hash,\n    hash_to_hex,\n    hex_to_hash,\n    HashError,\n    Result,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","mod.rs"],"content":"pub mod analysis;\npub mod hash;\n// pub mod midi; // Moved to shared library (midi-library-shared)\npub mod naming;\npub mod normalization;\npub mod performance;\npub mod splitting;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","generator.rs"],"content":"//! Filename Generator\n//!\n//! Generates intelligent filenames from MIDI file metadata.\n\nuse crate::core::analysis::{BpmDetectionResult, KeyDetectionResult};\nuse crate::core::naming::{sanitizer, templates};\n\n/// Configuration for filename generation\n#[derive(Debug, Clone)]\npub struct NamingConfig {\n    pub template: templates::NamingTemplate,\n    pub include_description: bool,\n    pub max_description_length: usize,\n}\n\nimpl Default for NamingConfig {\n    fn default() -\u003e Self {\n        Self {\n            template: templates::NamingTemplate::Standard,\n            include_description: true,\n            max_description_length: 50,\n        }\n    }\n}\n\n/// Input metadata for filename generation\n#[derive(Debug, Clone)]\npub struct FileMetadata {\n    pub category: String,\n    pub bpm: f64,\n    pub key: String,\n    pub description: Option\u003cString\u003e,\n    pub file_id: String,\n}\n\n/// Generates a new filename from metadata\n///\n/// # Arguments\n/// * `metadata` - File metadata\n/// * `config` - Naming configuration\n///\n/// # Returns\n/// * Generated filename with .mid extension\n///\n/// # Examples\n/// ```\n/// use pipeline::core::naming::generator::*;\n///\n/// let metadata = FileMetadata {\n///     category: \"BASS\".to_string(),\n///     bpm: 140.0,\n///     key: \"Cm\".to_string(),\n///     description: Some(\"Deep Rolling\".to_string()),\n///     file_id: \"001\".to_string(),\n/// };\n///\n/// let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n/// // Result: \"BASS_Cm_140BPM_Deep_Rolling_001.mid\"\n/// ```\npub fn generate_filename(metadata: \u0026FileMetadata, config: \u0026NamingConfig) -\u003e String {\n    // Sanitize category\n    let category = sanitizer::sanitize_filename(\u0026metadata.category.to_uppercase());\n\n    // Sanitize key\n    let key = sanitizer::sanitize_filename(\u0026metadata.key);\n\n    // Process description\n    let description = if config.include_description {\n        process_description(\u0026metadata.description, config.max_description_length)\n    } else {\n        String::new()\n    };\n\n    // Apply template\n    let filename_base = templates::apply_template(\n        \u0026config.template,\n        \u0026category,\n        \u0026key,\n        metadata.bpm,\n        \u0026description,\n        \u0026metadata.file_id,\n    );\n\n    // Final sanitization\n    let sanitized = sanitizer::sanitize_filename(\u0026filename_base);\n\n    // Ensure .mid extension\n    sanitizer::ensure_mid_extension(\u0026sanitized)\n}\n\n/// Processes description text\nfn process_description(description: \u0026Option\u003cString\u003e, max_length: usize) -\u003e String {\n    match description {\n        None =\u003e String::new(),\n        Some(desc) =\u003e {\n            // First sanitize to convert spaces to underscores\n            let sanitized = sanitizer::sanitize_filename(desc);\n\n            // Then clean filler words\n            let cleaned = sanitizer::clean_description(\u0026sanitized);\n\n            // Truncate if needed\n            if cleaned.len() \u003e max_length {\n                cleaned[..max_length].to_string()\n            } else {\n                cleaned\n            }\n        }\n    }\n}\n\n/// Generates filename from analysis results (convenience function)\n///\n/// # Arguments\n/// * `category` - File category (BASS, KICK, etc.)\n/// * `bpm_result` - BPM detection result\n/// * `key_result` - Key detection result\n/// * `original_filename` - Original filename to extract description from\n/// * `file_id` - Unique file identifier\n/// * `config` - Naming configuration\n///\n/// # Returns\n/// * Generated filename with .mid extension\npub fn generate_from_analysis(\n    category: \u0026str,\n    bpm_result: \u0026BpmDetectionResult,\n    key_result: \u0026KeyDetectionResult,\n    original_filename: \u0026str,\n    file_id: \u0026str,\n    config: \u0026NamingConfig,\n) -\u003e String {\n    // Extract description from original filename if useful\n    let description = extract_useful_description(original_filename);\n\n    let metadata = FileMetadata {\n        category: category.to_string(),\n        bpm: bpm_result.bpm,\n        key: key_result.key.clone(),\n        description,\n        file_id: file_id.to_string(),\n    };\n\n    generate_filename(\u0026metadata, config)\n}\n\n/// Extracts useful parts from original filename\nfn extract_useful_description(original_filename: \u0026str) -\u003e Option\u003cString\u003e {\n    // Remove extension\n    let without_ext = original_filename\n        .trim_end_matches(\".mid\")\n        .trim_end_matches(\".MID\");\n\n    // Remove common prefixes\n    let prefixes = [\"MIDI_\", \"Track_\", \"File_\", \"Song_\"];\n    let mut cleaned = without_ext.to_string();\n\n    for prefix in \u0026prefixes {\n        if cleaned.starts_with(prefix) {\n            cleaned = cleaned[prefix.len()..].to_string();\n        }\n    }\n\n    // If cleaned version is meaningful, use it\n    if !cleaned.is_empty() \u0026\u0026 cleaned.len() \u003e 3 {\n        Some(cleaned)\n    } else {\n        None\n    }\n}\n\n/// Handles naming conflicts by appending counter\n///\n/// # Arguments\n/// * `base_filename` - The desired filename\n/// * `existing_files` - List of existing filenames to check against\n///\n/// # Returns\n/// * Unique filename that doesn't conflict with existing files\npub fn resolve_naming_conflict(base_filename: \u0026str, existing_files: \u0026[String]) -\u003e String {\n    let without_ext = base_filename.trim_end_matches(\".mid\");\n\n    if !existing_files.contains(\u0026base_filename.to_string()) {\n        return base_filename.to_string();\n    }\n\n    // Try incrementing counter\n    for i in 1..1000 {\n        let candidate = format!(\"{}_v{}.mid\", without_ext, i);\n        if !existing_files.contains(\u0026candidate) {\n            return candidate;\n        }\n    }\n\n    // Fallback with timestamp\n    // Note: SystemTime before Unix epoch is impossible on modern systems,\n    // but we handle it gracefully per architecture requirements\n    let timestamp = std::time::SystemTime::now()\n        .duration_since(std::time::UNIX_EPOCH)\n        .unwrap_or_else(|_| std::time::Duration::from_secs(0))\n        .as_secs();\n\n    format!(\"{}_{}.mid\", without_ext, timestamp)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_generate_filename_standard() {\n        let metadata = FileMetadata {\n            category: \"BASS\".to_string(),\n            bpm: 140.5,\n            key: \"Cm\".to_string(),\n            description: Some(\"Deep Rolling\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        assert!(filename.starts_with(\"BASS_Cm_140BPM\"));\n        assert!(filename.ends_with(\".mid\"));\n    }\n\n    #[test]\n    fn test_generate_filename_no_description() {\n        let metadata = FileMetadata {\n            category: \"KICK\".to_string(),\n            bpm: 128.0,\n            key: \"C\".to_string(),\n            description: None,\n            file_id: \"042\".to_string(),\n        };\n\n        let config = NamingConfig {\n            include_description: false,\n            ..Default::default()\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026config);\n\n        // Sanitizer removes double underscores, so result is clean\n        assert_eq!(filename, \"KICK_C_128BPM_042.mid\");\n    }\n\n    #[test]\n    fn test_extract_useful_description() {\n        assert_eq!(\n            extract_useful_description(\"MIDI_Cool_Bass.mid\"),\n            Some(\"Cool_Bass\".to_string())\n        );\n\n        assert_eq!(\n            extract_useful_description(\"Track_1.mid\"),\n            None // Too short\n        );\n    }\n\n    #[test]\n    fn test_extract_no_prefix() {\n        assert_eq!(\n            extract_useful_description(\"Amazing_Lead.mid\"),\n            Some(\"Amazing_Lead\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_resolve_naming_conflict() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![base.to_string()];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_ne!(resolved, base);\n        assert!(resolved.ends_with(\".mid\"));\n        assert!(resolved.contains(\"_v1\"));\n    }\n\n    #[test]\n    fn test_resolve_no_conflict() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_eq!(resolved, base);\n    }\n\n    #[test]\n    fn test_category_uppercase() {\n        let metadata = FileMetadata {\n            category: \"bass\".to_string(), // lowercase\n            bpm: 140.0,\n            key: \"Cm\".to_string(),\n            description: None,\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        assert!(filename.starts_with(\"BASS\")); // Should be uppercase\n    }\n\n    #[test]\n    fn test_process_description_truncation() {\n        let long_desc = Some(\"A\".repeat(100));\n\n        let result = process_description(\u0026long_desc, 20);\n\n        assert!(result.len() \u003c= 20);\n    }\n\n    #[test]\n    fn test_process_description_none() {\n        let result = process_description(\u0026None, 50);\n        assert_eq!(result, \"\");\n    }\n\n    #[test]\n    fn test_compact_template() {\n        let metadata = FileMetadata {\n            category: \"KICK\".to_string(),\n            bpm: 128.0,\n            key: \"C\".to_string(),\n            description: Some(\"Heavy\".to_string()),\n            file_id: \"042\".to_string(),\n        };\n\n        let config = NamingConfig {\n            template: templates::NamingTemplate::Compact,\n            include_description: true,\n            max_description_length: 50,\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026config);\n\n        // Compact template doesn't include description in the template\n        assert_eq!(filename, \"KICK_C_128BPM_042.mid\");\n    }\n\n    #[test]\n    fn test_invalid_characters_in_metadata() {\n        let metadata = FileMetadata {\n            category: \"BA\u003cSS\u003e\".to_string(),\n            bpm: 140.0,\n            key: \"C:m\".to_string(),\n            description: Some(\"Deep/Rolling*\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        // Should sanitize all invalid characters\n        assert!(!filename.contains('\u003c'));\n        assert!(!filename.contains('\u003e'));\n        assert!(!filename.contains(':'));\n        assert!(!filename.contains('/'));\n        assert!(!filename.contains('*'));\n    }\n\n    #[test]\n    fn test_description_with_filler_words() {\n        let metadata = FileMetadata {\n            category: \"BASS\".to_string(),\n            bpm: 140.0,\n            key: \"Cm\".to_string(),\n            description: Some(\"the new bass and track file\".to_string()),\n            file_id: \"001\".to_string(),\n        };\n\n        let filename = generate_filename(\u0026metadata, \u0026NamingConfig::default());\n\n        println!(\"Generated filename: {}\", filename);\n\n        // Filler words should be removed (the, new, and, track, file)\n        // Result should have \"bass\" but not the filler words\n        assert!(filename.contains(\"bass\"));\n    }\n\n    #[test]\n    fn test_multiple_conflicts() {\n        let base = \"BASS_Cm_140BPM_Deep_001.mid\";\n        let existing = vec![\n            base.to_string(),\n            \"BASS_Cm_140BPM_Deep_001_v1.mid\".to_string(),\n            \"BASS_Cm_140BPM_Deep_001_v2.mid\".to_string(),\n        ];\n\n        let resolved = resolve_naming_conflict(base, \u0026existing);\n\n        assert_eq!(resolved, \"BASS_Cm_140BPM_Deep_001_v3.mid\");\n    }\n\n    #[test]\n    fn test_extract_empty_filename() {\n        assert_eq!(extract_useful_description(\"\"), None);\n        assert_eq!(extract_useful_description(\".mid\"), None);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","mod.rs"],"content":"//! Intelligent filename generation\n\npub mod generator;\npub mod sanitizer;\npub mod templates;\n\n// Re-export main types\npub use generator::{\n    generate_filename, generate_from_analysis, resolve_naming_conflict, FileMetadata, NamingConfig,\n};\npub use templates::NamingTemplate;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","sanitizer.rs"],"content":"//! Filename Sanitization\n//!\n//! Ensures filenames are valid across all operating systems.\n\n/// Sanitizes a string for use in filenames\n///\n/// # Rules\n/// - Removes/replaces invalid characters\n/// - Limits length to 255 characters\n/// - Removes leading/trailing spaces\n/// - Converts to ASCII where possible\n///\n/// # Arguments\n/// * `input` - String to sanitize\n///\n/// # Returns\n/// * Sanitized string safe for filenames\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::naming::sanitizer::sanitize_filename;\n///\n/// let sanitized = sanitize_filename(\"my file\u003cname\u003e\");\n/// assert_eq!(sanitized, \"my_file_name_\");\n/// ```\npub fn sanitize_filename(input: \u0026str) -\u003e String {\n    let mut sanitized = input.to_string();\n\n    // Remove/replace invalid characters\n    sanitized = sanitized\n        .chars()\n        .map(|c| match c {\n            // Windows reserved characters\n            '\u003c' | '\u003e' | ':' | '\"' | '/' | '\\\\' | '|' | '?' | '*' =\u003e '_',\n            // Control characters\n            c if c.is_control() =\u003e '_',\n            // Keep valid characters\n            c =\u003e c,\n        })\n        .collect();\n\n    // Remove leading/trailing whitespace\n    sanitized = sanitized.trim().to_string();\n\n    // Replace multiple spaces with single space\n    while sanitized.contains(\"  \") {\n        sanitized = sanitized.replace(\"  \", \" \");\n    }\n\n    // Replace spaces with underscores for consistency\n    sanitized = sanitized.replace(' ', \"_\");\n\n    // Remove multiple underscores\n    while sanitized.contains(\"__\") {\n        sanitized = sanitized.replace(\"__\", \"_\");\n    }\n\n    // Limit length (leave room for extension)\n    if sanitized.len() \u003e 250 {\n        sanitized.truncate(250);\n    }\n\n    // Remove leading/trailing underscores\n    sanitized = sanitized.trim_matches('_').to_string();\n\n    // If empty after sanitization, use default\n    if sanitized.is_empty() {\n        sanitized = \"untitled\".to_string();\n    }\n\n    sanitized\n}\n\n/// Removes common filler words from descriptions\n///\n/// # Arguments\n/// * `description` - Description text to clean\n///\n/// # Returns\n/// * Description with filler words removed\npub fn clean_description(description: \u0026str) -\u003e String {\n    let filler_words = [\n        \"untitled\", \"new\", \"midi\", \"file\", \"song\", \"track\", \"the\", \"a\", \"an\", \"and\", \"or\", \"but\",\n    ];\n\n    let words: Vec\u003c\u0026str\u003e = description\n        .split('_')\n        .filter(|word| {\n            let lower = word.to_lowercase();\n            !filler_words.contains(\u0026lower.as_str()) \u0026\u0026 !lower.is_empty()\n        })\n        .collect();\n\n    words.join(\"_\")\n}\n\n/// Ensures filename has .mid extension\n///\n/// # Arguments\n/// * `filename` - Filename to check\n///\n/// # Returns\n/// * Filename with .mid extension\npub fn ensure_mid_extension(filename: \u0026str) -\u003e String {\n    if filename.to_lowercase().ends_with(\".mid\") {\n        filename.to_string()\n    } else {\n        format!(\"{}.mid\", filename)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_remove_invalid_characters() {\n        let input = \"test\u003cfile\u003ename:with|invalid*chars\";\n        let output = sanitize_filename(input);\n\n        assert!(!output.contains('\u003c'));\n        assert!(!output.contains('\u003e'));\n        assert!(!output.contains(':'));\n        assert!(!output.contains('|'));\n        assert!(!output.contains('*'));\n    }\n\n    #[test]\n    fn test_replace_spaces() {\n        let input = \"test file name\";\n        let output = sanitize_filename(input);\n\n        assert_eq!(output, \"test_file_name\");\n    }\n\n    #[test]\n    fn test_remove_multiple_underscores() {\n        let input = \"test___file___name\";\n        let output = sanitize_filename(input);\n\n        assert_eq!(output, \"test_file_name\");\n    }\n\n    #[test]\n    fn test_length_limit() {\n        let input = \"a\".repeat(300);\n        let output = sanitize_filename(\u0026input);\n\n        assert!(output.len() \u003c= 250);\n    }\n\n    #[test]\n    fn test_empty_input() {\n        let output = sanitize_filename(\"\");\n        assert_eq!(output, \"untitled\");\n    }\n\n    #[test]\n    fn test_clean_description() {\n        let input = \"the_new_bass_and_lead_file\";\n        let output = clean_description(input);\n\n        // Should remove filler words\n        assert_eq!(output, \"bass_lead\");\n    }\n\n    #[test]\n    fn test_ensure_extension() {\n        assert_eq!(ensure_mid_extension(\"test\"), \"test.mid\");\n        assert_eq!(ensure_mid_extension(\"test.mid\"), \"test.mid\");\n        assert_eq!(ensure_mid_extension(\"test.MID\"), \"test.MID\");\n    }\n\n    #[test]\n    fn test_trim_leading_trailing_underscores() {\n        let input = \"___test___\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"test\");\n    }\n\n    #[test]\n    fn test_control_characters() {\n        let input = \"test\\n\\r\\tfile\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"test_file\");\n    }\n\n    #[test]\n    fn test_only_invalid_characters() {\n        let input = \"\u003c\u003e?*|\";\n        let output = sanitize_filename(input);\n        assert_eq!(output, \"untitled\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","naming","templates.rs"],"content":"//! Naming Templates\n//!\n//! Provides different template formats for filename generation.\n\n/// Naming template format\n#[derive(Debug, Clone, PartialEq, Default)]\npub enum NamingTemplate {\n    /// {CATEGORY}_{KEY}_{BPM}BPM_{DESCRIPTION}_{ID}\n    #[default]\n    Standard,\n\n    /// {CATEGORY}_{KEY}_{BPM}BPM_{ID}\n    Compact,\n\n    /// {BPM}BPM_{KEY}_{CATEGORY}_{DESCRIPTION}\n    BpmFirst,\n\n    /// Custom template with placeholders\n    Custom(String),\n}\n\n/// Applies template to metadata\n///\n/// # Arguments\n/// * `template` - The naming template to use\n/// * `category` - File category (e.g., BASS, KICK, CHORD)\n/// * `key` - Musical key (e.g., C, Am, F#)\n/// * `bpm` - Beats per minute\n/// * `description` - Optional description text\n/// * `id` - File identifier\n///\n/// # Returns\n/// * Formatted filename string (without extension)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::naming::templates::{NamingTemplate, apply_template};\n///\n/// let result = apply_template(\n///     \u0026NamingTemplate::Standard,\n///     \"BASS\",\n///     \"Cm\",\n///     140.0,\n///     \"Deep_Rolling\",\n///     \"001\"\n/// );\n/// assert_eq!(result, \"BASS_Cm_140BPM_Deep_Rolling_001\");\n/// ```\npub fn apply_template(\n    template: \u0026NamingTemplate,\n    category: \u0026str,\n    key: \u0026str,\n    bpm: f64,\n    description: \u0026str,\n    id: \u0026str,\n) -\u003e String {\n    match template {\n        NamingTemplate::Standard =\u003e {\n            format!(\"{}_{}_{:.0}BPM_{}_{}\", category, key, bpm, description, id)\n        }\n\n        NamingTemplate::Compact =\u003e {\n            format!(\"{}_{}_{:.0}BPM_{}\", category, key, bpm, id)\n        }\n\n        NamingTemplate::BpmFirst =\u003e {\n            format!(\"{:.0}BPM_{}_{}_{}\", bpm, key, category, description)\n        }\n\n        NamingTemplate::Custom(template_str) =\u003e template_str\n            .replace(\"{CATEGORY}\", category)\n            .replace(\"{KEY}\", key)\n            .replace(\"{BPM}\", \u0026format!(\"{:.0}\", bpm))\n            .replace(\"{DESCRIPTION}\", description)\n            .replace(\"{ID}\", id),\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_standard_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::Standard,\n            \"BASS\",\n            \"Cm\",\n            140.0,\n            \"Deep_Rolling\",\n            \"001\",\n        );\n\n        assert_eq!(result, \"BASS_Cm_140BPM_Deep_Rolling_001\");\n    }\n\n    #[test]\n    fn test_compact_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::Compact,\n            \"KICK\",\n            \"C\",\n            128.0,\n            \"\", // Description ignored in compact\n            \"042\",\n        );\n\n        assert_eq!(result, \"KICK_C_128BPM_042\");\n    }\n\n    #[test]\n    fn test_bpm_first_template() {\n        let result = apply_template(\n            \u0026NamingTemplate::BpmFirst,\n            \"LEAD\",\n            \"Am\",\n            150.0,\n            \"Energetic\",\n            \"123\",\n        );\n\n        assert_eq!(result, \"150BPM_Am_LEAD_Energetic\");\n    }\n\n    #[test]\n    fn test_custom_template() {\n        let custom = NamingTemplate::Custom(\"{BPM}bpm_{KEY}_{CATEGORY}\".to_string());\n\n        let result = apply_template(\n            \u0026custom, \"LEAD\", \"Am\", 150.0, \"\", // Not used in this template\n            \"\", // Not used in this template\n        );\n\n        assert_eq!(result, \"150bpm_Am_LEAD\");\n    }\n\n    #[test]\n    fn test_custom_template_with_all_placeholders() {\n        let custom =\n            NamingTemplate::Custom(\"{ID}_{CATEGORY}_{KEY}_{BPM}_{DESCRIPTION}\".to_string());\n\n        let result = apply_template(\u0026custom, \"BASS\", \"Dm\", 120.0, \"Groovy\", \"999\");\n\n        assert_eq!(result, \"999_BASS_Dm_120_Groovy\");\n    }\n\n    #[test]\n    fn test_default_template() {\n        let default = NamingTemplate::default();\n        assert_eq!(default, NamingTemplate::Standard);\n    }\n\n    #[test]\n    fn test_bpm_rounding() {\n        let result = apply_template(\u0026NamingTemplate::Standard, \"KICK\", \"C\", 127.8, \"desc\", \"001\");\n\n        assert!(result.contains(\"128BPM\"));\n    }\n\n    #[test]\n    fn test_empty_description() {\n        let result = apply_template(\u0026NamingTemplate::Standard, \"BASS\", \"C\", 120.0, \"\", \"001\");\n\n        assert_eq!(result, \"BASS_C_120BPM__001\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","normalization","filename.rs"],"content":"//! Filename normalization utilities for MIDI files.\n//!\n//! This module provides pure functions for normalizing MIDI filenames,\n//! specifically converting `.midi` extensions to `.mid` and replacing\n//! spaces with underscores.\n//!\n//! # Archetype: Trusty Module\n//!\n//! This is a pure logic module with NO side effects:\n//! -  NO file I/O\n//! -  NO database access\n//! -  NO printing/logging\n//! -  Pure functions only\n//! -  Comprehensive tests\n//!\n//! # Examples\n//!\n//! ```\n//! use pipeline::core::normalization::filename::normalize_midi_filename;\n//!\n//! // Extension normalization\n//! let normalized = normalize_midi_filename(\"song.midi\");\n//! assert_eq!(normalized, \"song.mid\");\n//!\n//! // Space replacement\n//! let normalized = normalize_midi_filename(\"my song.mid\");\n//! assert_eq!(normalized, \"my_song.mid\");\n//!\n//! // Both transformations\n//! let normalized = normalize_midi_filename(\"Cool Track.midi\");\n//! assert_eq!(normalized, \"Cool_Track.mid\");\n//! ```\n\n/// Normalize a MIDI filename by converting `.midi` extension to `.mid`\n/// and replacing all spaces with underscores.\n///\n/// This function performs two normalizations:\n/// 1. Converts `.midi` extension to `.mid` (case-insensitive)\n/// 2. Replaces all spaces ` ` with underscores `_`\n///\n/// # Arguments\n///\n/// * `filename` - The filename to normalize (without path, just the filename)\n///\n/// # Returns\n///\n/// A new `String` with the normalized filename.\n///\n/// # Examples\n///\n/// ```\n/// # use pipeline::core::normalization::filename::normalize_midi_filename;\n/// // Convert .midi to .mid\n/// assert_eq!(normalize_midi_filename(\"song.midi\"), \"song.mid\");\n///\n/// // Replace spaces with underscores\n/// assert_eq!(normalize_midi_filename(\"my song.mid\"), \"my_song.mid\");\n///\n/// // Both transformations\n/// assert_eq!(normalize_midi_filename(\"Cool Track.midi\"), \"Cool_Track.mid\");\n///\n/// // Case insensitive extension\n/// assert_eq!(normalize_midi_filename(\"song.MIDI\"), \"song.mid\");\n///\n/// // Multiple spaces become multiple underscores\n/// assert_eq!(normalize_midi_filename(\"jazz  blues.midi\"), \"jazz__blues.mid\");\n///\n/// // Already normalized - unchanged\n/// assert_eq!(normalize_midi_filename(\"song.mid\"), \"song.mid\");\n///\n/// // Preserve other special characters\n/// assert_eq!(normalize_midi_filename(\"my-song_123.midi\"), \"my-song_123.mid\");\n/// ```\npub fn normalize_midi_filename(filename: \u0026str) -\u003e String {\n    // Step 1: Normalize extension (.midi -\u003e .mid)\n    let extension_normalized = if let Some(name_without_ext) = strip_midi_extension(filename) {\n        format!(\"{}.mid\", name_without_ext)\n    } else {\n        filename.to_string()\n    };\n\n    // Step 2: Replace all spaces with underscores\n    extension_normalized.replace(' ', \"_\")\n}\n\n/// Check if a filename needs normalization.\n///\n/// Returns `true` if the filename:\n/// - Has a `.midi` extension (case-insensitive) that should be converted to `.mid`, OR\n/// - Contains spaces that should be replaced with underscores\n///\n/// # Arguments\n///\n/// * `filename` - The filename to check\n///\n/// # Returns\n///\n/// `true` if the filename needs normalization, `false` otherwise.\n///\n/// # Examples\n///\n/// ```\n/// # use pipeline::core::normalization::filename::needs_normalization;\n/// // Has .midi extension\n/// assert!(needs_normalization(\"song.midi\"));\n/// assert!(needs_normalization(\"song.MIDI\"));\n///\n/// // Has spaces\n/// assert!(needs_normalization(\"my song.mid\"));\n/// assert!(needs_normalization(\"Cool Track.mp3\"));\n///\n/// // Has both\n/// assert!(needs_normalization(\"my song.midi\"));\n///\n/// // Already normalized\n/// assert!(!needs_normalization(\"song.mid\"));\n/// assert!(!needs_normalization(\"my_song.mid\"));\n/// ```\npub fn needs_normalization(filename: \u0026str) -\u003e bool {\n    // Check if has .midi extension OR contains spaces\n    strip_midi_extension(filename).is_some() || filename.contains(' ')\n}\n\n/// Strip `.midi` extension from filename if present (case-insensitive).\n///\n/// This is an internal helper function that checks if a filename ends with\n/// `.midi` (in any case combination) and returns the filename without the\n/// extension if found.\n///\n/// # Arguments\n///\n/// * `filename` - The filename to process\n///\n/// # Returns\n///\n/// `Some(\u0026str)` containing the filename without `.midi` extension if found,\n/// `None` otherwise.\nfn strip_midi_extension(filename: \u0026str) -\u003e Option\u003c\u0026str\u003e {\n    // Check for .midi extension (case-insensitive)\n    // We need to check the last 5 characters (.midi)\n    if filename.len() \u003e 5 {\n        let extension_start = filename.len() - 5;\n        let potential_ext = \u0026filename[extension_start..];\n\n        if potential_ext.eq_ignore_ascii_case(\".midi\") {\n            return Some(\u0026filename[..extension_start]);\n        }\n    } else if filename.len() == 5 {\n        // Special case: filename is exactly \".midi\"\n        if filename.eq_ignore_ascii_case(\".midi\") {\n            return Some(\"\");\n        }\n    }\n\n    None\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    // Basic functionality tests\n    #[test]\n    fn test_normalize_midi_to_mid() {\n        assert_eq!(normalize_midi_filename(\"song.midi\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_already_mid_unchanged() {\n        assert_eq!(normalize_midi_filename(\"song.mid\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_uppercase_midi() {\n        assert_eq!(normalize_midi_filename(\"song.MIDI\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_mixed_case_midi() {\n        assert_eq!(normalize_midi_filename(\"song.MiDi\"), \"song.mid\");\n        assert_eq!(normalize_midi_filename(\"song.mIdI\"), \"song.mid\");\n        assert_eq!(normalize_midi_filename(\"song.Midi\"), \"song.mid\");\n    }\n\n    #[test]\n    fn test_uppercase_mid_unchanged() {\n        // .MID is already the correct length, just different case\n        // We should preserve it as-is since it's not .midi\n        assert_eq!(normalize_midi_filename(\"song.MID\"), \"song.MID\");\n    }\n\n    // Space replacement tests\n    #[test]\n    fn test_space_replacement() {\n        assert_eq!(\n            normalize_midi_filename(\"my song.mid\"),\n            \"my_song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_multiple_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my  song.midi\"),\n            \"my__song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_space_and_midi_extension() {\n        assert_eq!(\n            normalize_midi_filename(\"Cool Track.midi\"),\n            \"Cool_Track.mid\"\n        );\n    }\n\n    #[test]\n    fn test_no_spaces_no_change() {\n        assert_eq!(\n            normalize_midi_filename(\"song.mid\"),\n            \"song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_spaces_in_complex_filename() {\n        assert_eq!(\n            normalize_midi_filename(\"120bpm Cmaj Scale.midi\"),\n            \"120bpm_Cmaj_Scale.mid\"\n        );\n    }\n\n    #[test]\n    fn test_needs_normalization_with_spaces() {\n        assert!(needs_normalization(\"my song.mid\"));\n        assert!(needs_normalization(\"song.midi\"));\n        assert!(needs_normalization(\"my song.midi\"));\n        assert!(!needs_normalization(\"song.mid\"));\n        assert!(!needs_normalization(\"my_song.mid\"));\n    }\n\n    // Special characters and spaces\n    #[test]\n    fn test_filename_with_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my song name.midi\"),\n            \"my_song_name.mid\"\n        );\n    }\n\n    #[test]\n    fn test_filename_with_special_chars() {\n        assert_eq!(\n            normalize_midi_filename(\"song-123_test@example.midi\"),\n            \"song-123_test@example.mid\"\n        );\n    }\n\n    #[test]\n    fn test_filename_with_unicode() {\n        assert_eq!(\n            normalize_midi_filename(\".midi\"),\n            \".mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"caf-song.midi\"),\n            \"caf-song.mid\"\n        );\n    }\n\n    #[test]\n    fn test_spaces_with_unicode() {\n        assert_eq!(\n            normalize_midi_filename(\"caf song.midi\"),\n            \"caf_song.mid\"\n        );\n    }\n\n    // Multiple dots\n    #[test]\n    fn test_multiple_dots_in_filename() {\n        assert_eq!(\n            normalize_midi_filename(\"my.song.title.midi\"),\n            \"my.song.title.mid\"\n        );\n    }\n\n    #[test]\n    fn test_dots_preserved() {\n        assert_eq!(\n            normalize_midi_filename(\"song.v2.final.midi\"),\n            \"song.v2.final.mid\"\n        );\n    }\n\n    #[test]\n    fn test_dots_and_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"my.song v2.midi\"),\n            \"my.song_v2.mid\"\n        );\n    }\n\n    // Edge cases\n    #[test]\n    fn test_no_extension() {\n        assert_eq!(normalize_midi_filename(\"song\"), \"song\");\n    }\n\n    #[test]\n    fn test_no_extension_with_spaces() {\n        assert_eq!(normalize_midi_filename(\"my song\"), \"my_song\");\n    }\n\n    #[test]\n    fn test_wrong_extension() {\n        assert_eq!(normalize_midi_filename(\"song.mp3\"), \"song.mp3\");\n        assert_eq!(normalize_midi_filename(\"song.wav\"), \"song.wav\");\n        assert_eq!(normalize_midi_filename(\"song.txt\"), \"song.txt\");\n    }\n\n    #[test]\n    fn test_wrong_extension_with_spaces() {\n        assert_eq!(normalize_midi_filename(\"my song.mp3\"), \"my_song.mp3\");\n    }\n\n    #[test]\n    fn test_midi_not_at_end() {\n        // .midi in the middle of filename shouldn't be changed\n        assert_eq!(\n            normalize_midi_filename(\"song.midi.backup\"),\n            \"song.midi.backup\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"midi.txt\"),\n            \"midi.txt\"\n        );\n    }\n\n    #[test]\n    fn test_just_extension() {\n        // Edge case: filename is just \".midi\"\n        assert_eq!(normalize_midi_filename(\".midi\"), \".mid\");\n    }\n\n    #[test]\n    fn test_empty_string() {\n        assert_eq!(normalize_midi_filename(\"\"), \"\");\n    }\n\n    #[test]\n    fn test_very_short_filename() {\n        assert_eq!(normalize_midi_filename(\"a.midi\"), \"a.mid\");\n        assert_eq!(normalize_midi_filename(\"ab.midi\"), \"ab.mid\");\n    }\n\n    #[test]\n    fn test_very_short_filename_with_space() {\n        assert_eq!(normalize_midi_filename(\"a b.midi\"), \"a_b.mid\");\n    }\n\n    #[test]\n    fn test_only_spaces() {\n        assert_eq!(normalize_midi_filename(\"   .midi\"), \"___.mid\");\n        assert_eq!(normalize_midi_filename(\" \"), \"_\");\n    }\n\n    #[test]\n    fn test_leading_trailing_spaces() {\n        assert_eq!(normalize_midi_filename(\" song.midi\"), \"_song.mid\");\n        assert_eq!(normalize_midi_filename(\"song .midi\"), \"song_.mid\");\n        assert_eq!(normalize_midi_filename(\" song .midi\"), \"_song_.mid\");\n    }\n\n    // needs_normalization tests\n    #[test]\n    fn test_needs_normalization_true() {\n        // Has .midi extension\n        assert!(needs_normalization(\"song.midi\"));\n        assert!(needs_normalization(\"song.MIDI\"));\n        assert!(needs_normalization(\"song.MiDi\"));\n        assert!(needs_normalization(\"my.song.midi\"));\n\n        // Has spaces\n        assert!(needs_normalization(\"my song.mid\"));\n        assert!(needs_normalization(\"Cool Track.mp3\"));\n\n        // Has both\n        assert!(needs_normalization(\"my song.midi\"));\n        assert!(needs_normalization(\"Cool Track.MIDI\"));\n    }\n\n    #[test]\n    fn test_needs_normalization_false() {\n        assert!(!needs_normalization(\"song.mid\"));\n        assert!(!needs_normalization(\"song.MID\"));\n        assert!(!needs_normalization(\"song.mp3\"));\n        assert!(!needs_normalization(\"song\"));\n        assert!(!needs_normalization(\"\"));\n        assert!(!needs_normalization(\"song.midi.backup\"));\n        assert!(!needs_normalization(\"my_song.mid\"));\n        assert!(!needs_normalization(\"my-song.mid\"));\n    }\n\n    // strip_midi_extension tests\n    #[test]\n    fn test_strip_midi_extension() {\n        assert_eq!(strip_midi_extension(\"song.midi\"), Some(\"song\"));\n        assert_eq!(strip_midi_extension(\"song.MIDI\"), Some(\"song\"));\n        assert_eq!(strip_midi_extension(\"my.song.midi\"), Some(\"my.song\"));\n        assert_eq!(strip_midi_extension(\".midi\"), Some(\"\"));\n        assert_eq!(strip_midi_extension(\"my song.midi\"), Some(\"my song\"));\n    }\n\n    #[test]\n    fn test_strip_midi_extension_none() {\n        assert_eq!(strip_midi_extension(\"song.mid\"), None);\n        assert_eq!(strip_midi_extension(\"song\"), None);\n        assert_eq!(strip_midi_extension(\"\"), None);\n        assert_eq!(strip_midi_extension(\"song.mp3\"), None);\n        assert_eq!(strip_midi_extension(\"my song.mid\"), None);\n    }\n\n    // Property-based style tests\n    #[test]\n    fn test_normalization_idempotent() {\n        // Normalizing twice should give same result\n        let filename = \"my song.midi\";\n        let normalized_once = normalize_midi_filename(filename);\n        let normalized_twice = normalize_midi_filename(\u0026normalized_once);\n        assert_eq!(normalized_once, normalized_twice);\n        assert_eq!(normalized_once, \"my_song.mid\");\n    }\n\n    #[test]\n    fn test_normalized_files_dont_need_normalization() {\n        // After normalization, needs_normalization should return false\n        let filename = \"my song.midi\";\n        let normalized = normalize_midi_filename(filename);\n        assert!(!needs_normalization(\u0026normalized));\n        assert_eq!(normalized, \"my_song.mid\");\n    }\n\n    #[test]\n    fn test_long_filename() {\n        let long_name = \"a\".repeat(200) + \".midi\";\n        let normalized = normalize_midi_filename(\u0026long_name);\n        assert_eq!(normalized, \"a\".repeat(200) + \".mid\");\n    }\n\n    #[test]\n    fn test_long_filename_with_spaces() {\n        let long_name = \"a b \".repeat(50) + \"c.midi\";\n        let normalized = normalize_midi_filename(\u0026long_name);\n        assert!(normalized.contains('_'));\n        assert!(!normalized.contains(' '));\n        assert!(normalized.ends_with(\".mid\"));\n    }\n\n    #[test]\n    fn test_real_world_examples() {\n        // Common real-world filename patterns\n        assert_eq!(\n            normalize_midi_filename(\"Drum Loop 120 BPM.midi\"),\n            \"Drum_Loop_120_BPM.mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Bass Line - C Minor.MIDI\"),\n            \"Bass_Line_-_C_Minor.mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Synth Pad (Ambient).midi\"),\n            \"Synth_Pad_(Ambient).mid\"\n        );\n        assert_eq!(\n            normalize_midi_filename(\"Track 01 Intro.midi\"),\n            \"Track_01_Intro.mid\"\n        );\n    }\n\n    #[test]\n    fn test_consecutive_spaces() {\n        assert_eq!(\n            normalize_midi_filename(\"song     name.midi\"),\n            \"song_____name.mid\"\n        );\n    }\n\n    #[test]\n    fn test_space_preservation_in_count() {\n        // Each space becomes exactly one underscore\n        let input = \"a b c d.midi\";\n        let output = normalize_midi_filename(input);\n        assert_eq!(output, \"a_b_c_d.mid\");\n        assert_eq!(output.matches('_').count(), 3);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","normalization","mod.rs"],"content":"//! Filename and path normalization utilities.\n//!\n//! This module provides utilities for normalizing MIDI filenames and paths,\n//! ensuring consistency across the system.\n\npub mod filename;\n\n// Re-export commonly used functions for convenience\npub use filename::{normalize_midi_filename, needs_normalization};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","performance","concurrency.rs"],"content":"//! Dynamic Concurrency Tuning Module\n//!\n//! This module provides automatic detection and calculation of optimal concurrency\n//! settings based on system resources (CPU cores, RAM, disk type).\n//!\n//! # Architecture\n//!\n//! This is a **Trusty Module** - pure logic with comprehensive tests.\n//! - NO I/O operations (system detection is read-only introspection)\n//! - All functions are pure calculations\n//! - Highly testable with different configurations\n//!\n//! # Usage\n//!\n//! ```rust\n//! use pipeline::core::performance::concurrency::{\n//!     detect_system_resources,\n//!     calculate_optimal_concurrency\n//! };\n//!\n//! // Auto-detect system resources\n//! let resources = detect_system_resources();\n//!\n//! // Calculate optimal concurrency\n//! let concurrency = calculate_optimal_concurrency(\u0026resources);\n//! println!(\"Using {} concurrent workers\", concurrency);\n//! ```\n//!\n//! # Performance Tuning Strategy\n//!\n//! The optimal concurrency is calculated using a multi-factor formula:\n//!\n//! 1. **CPU-based baseline**: `cpu_cores  2`\n//!    - Accounts for I/O-bound operations (file reading, database writes)\n//!    - Each core can handle ~2 concurrent I/O operations efficiently\n//!\n//! 2. **Memory constraints**: Reduce concurrency if RAM \u003c 8GB\n//!    - 4GB RAM: Divide by 4 (risk of swapping)\n//!    - 6GB RAM: Divide by 2 (limited headroom)\n//!    - 8GB+ RAM: No reduction\n//!\n//! 3. **Storage type**: Cap based on disk performance\n//!    - HDD: Cap at 50 (seek times limit parallelism)\n//!    - SSD: Cap at 100 (near-linear scaling)\n//!\n//! 4. **Absolute bounds**: Clamp to [10, 100]\n//!    - Minimum 10: Ensure reasonable throughput on any system\n//!    - Maximum 100: Prevent database connection exhaustion\n\nuse sysinfo::System;\nuse std::thread;\n\n/// System resource information used to calculate optimal concurrency.\n///\n/// This struct captures the relevant system capabilities that affect\n/// file processing performance.\n#[derive(Debug, Clone, PartialEq)]\npub struct SystemResources {\n    /// Number of logical CPU cores (includes hyperthreading)\n    pub cpu_cores: usize,\n\n    /// Available system memory in gigabytes\n    pub available_memory_gb: f64,\n\n    /// Whether the primary storage is an SSD (true) or HDD (false)\n    pub is_ssd: bool,\n}\n\nimpl SystemResources {\n    /// Create a new SystemResources with explicit values.\n    ///\n    /// Useful for testing different configurations.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use pipeline::core::performance::concurrency::SystemResources;\n    ///\n    /// let resources = SystemResources::new(8, 16.0, true);\n    /// assert_eq!(resources.cpu_cores, 8);\n    /// assert_eq!(resources.available_memory_gb, 16.0);\n    /// assert!(resources.is_ssd);\n    /// ```\n    pub fn new(cpu_cores: usize, available_memory_gb: f64, is_ssd: bool) -\u003e Self {\n        Self {\n            cpu_cores,\n            available_memory_gb,\n            is_ssd,\n        }\n    }\n}\n\n/// Automatically detect system resources.\n///\n/// This function queries the operating system to determine:\n/// - CPU core count (logical cores including hyperthreading)\n/// - Available system memory\n/// - Primary disk type (SSD vs HDD)\n///\n/// # Returns\n///\n/// A `SystemResources` struct with detected values.\n///\n/// # Fallback Behavior\n///\n/// If detection fails:\n/// - CPU cores: Falls back to 4\n/// - Memory: Falls back to 8.0 GB\n/// - SSD: Assumes true (conservative for performance)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::detect_system_resources;\n///\n/// let resources = detect_system_resources();\n/// println!(\"Detected {} CPU cores\", resources.cpu_cores);\n/// println!(\"Available memory: {:.2} GB\", resources.available_memory_gb);\n/// println!(\"SSD: {}\", resources.is_ssd);\n/// ```\npub fn detect_system_resources() -\u003e SystemResources {\n    // Detect CPU cores\n    let cpu_cores = thread::available_parallelism()\n        .map(|n| n.get())\n        .unwrap_or(4); // Fallback to 4 cores if detection fails\n\n    // Initialize system info\n    let sys = System::new_all();\n\n    // Detect available memory (convert bytes to GB)\n    // sysinfo 0.30 returns memory in bytes\n    let total_memory_bytes = sys.total_memory();\n    let available_memory_gb = (total_memory_bytes as f64) / (1024.0 * 1024.0 * 1024.0);\n\n    // Detect if primary disk is SSD\n    // Strategy: In sysinfo 0.30, we don't have direct SSD detection\n    // Default to true (SSD) as a conservative assumption for modern systems\n    // In production, this could be enhanced with platform-specific detection\n    let is_ssd = true; // Conservative default: assume SSD for better performance\n\n    SystemResources {\n        cpu_cores,\n        available_memory_gb,\n        is_ssd,\n    }\n}\n\n/// Calculate the optimal concurrency limit based on system resources.\n///\n/// This function implements a multi-factor formula to determine the ideal\n/// number of concurrent file processing workers.\n///\n/// # Algorithm\n///\n/// 1. Start with CPU-based baseline: `cpu_cores  2`\n/// 2. Apply memory constraints:\n///    - If RAM \u003c 4GB: divide by 4\n///    - If RAM \u003c 6GB: divide by 2\n///    - If RAM \u003e= 8GB: no reduction\n/// 3. Apply storage type cap:\n///    - HDD: cap at 50\n///    - SSD: cap at 100\n/// 4. Clamp to absolute bounds [10, 100]\n///\n/// # Arguments\n///\n/// * `resources` - System resource information\n///\n/// # Returns\n///\n/// Optimal concurrency limit (10-100)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::{SystemResources, calculate_optimal_concurrency};\n///\n/// // High-end system: 16 cores, 32GB RAM, SSD\n/// let resources = SystemResources::new(16, 32.0, true);\n/// let concurrency = calculate_optimal_concurrency(\u0026resources);\n/// assert_eq!(concurrency, 32); // 16  2, no constraints\n///\n/// // Low-end system: 4 cores, 4GB RAM, HDD\n/// let resources = SystemResources::new(4, 4.0, false);\n/// let concurrency = calculate_optimal_concurrency(\u0026resources);\n/// assert_eq!(concurrency, 10); // Limited by memory and minimum bound\n/// ```\npub fn calculate_optimal_concurrency(resources: \u0026SystemResources) -\u003e usize {\n    // Step 1: CPU-based baseline (2 cores for I/O-bound operations)\n    let mut concurrency = resources.cpu_cores * 2;\n\n    // Step 2: Apply memory constraints\n    if resources.available_memory_gb \u003c 4.0 {\n        // Very limited memory: reduce significantly to avoid swapping\n        concurrency /= 4;\n    } else if resources.available_memory_gb \u003c 6.0 {\n        // Limited memory: reduce moderately\n        concurrency /= 2;\n    }\n    // 8GB+ RAM: no memory-based reduction\n\n    // Step 3: Apply storage type cap\n    let storage_cap = if resources.is_ssd {\n        100 // SSDs scale well with parallelism\n    } else {\n        50 // HDDs are limited by seek times\n    };\n\n    concurrency = concurrency.min(storage_cap);\n\n    // Step 4: Apply absolute bounds\n    // - Minimum 10: ensure reasonable throughput\n    // - Maximum 100: prevent resource exhaustion\n    concurrency.clamp(10, 100)\n}\n\n/// Calculate the optimal database connection pool size.\n///\n/// The pool size should support concurrent operations plus some overhead\n/// for connection management and potential contention.\n///\n/// # Formula\n///\n/// `pool_size = (concurrency  1.5).clamp(20, 200)`\n///\n/// - 1.5 multiplier: Provides headroom for connection recycling\n/// - Minimum 20: Ensures adequate connections even on small systems\n/// - Maximum 200: Prevents PostgreSQL connection exhaustion\n///\n/// # Arguments\n///\n/// * `concurrency` - Target concurrency limit\n///\n/// # Returns\n///\n/// Optimal database connection pool size (20-200)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_database_pool_size;\n///\n/// let pool_size = calculate_database_pool_size(50);\n/// assert_eq!(pool_size, 75); // 50  1.5\n///\n/// let pool_size = calculate_database_pool_size(10);\n/// assert_eq!(pool_size, 20); // Clamped to minimum\n///\n/// let pool_size = calculate_database_pool_size(150);\n/// assert_eq!(pool_size, 200); // Clamped to maximum\n/// ```\npub fn calculate_database_pool_size(concurrency: usize) -\u003e usize {\n    // 1.5 concurrency to provide connection headroom\n    let pool_size = (concurrency as f64 * 1.5) as usize;\n\n    // Clamp to PostgreSQL-friendly bounds\n    pool_size.clamp(20, 200)\n}\n\n/// Calculate the optimal batch size for database operations.\n///\n/// Larger batches reduce transaction overhead but increase memory usage\n/// and potential lock contention. The optimal size balances these factors.\n///\n/// # Formula\n///\n/// `batch_size = (concurrency  100).clamp(500, 10000)`\n///\n/// - 100 multiplier: Each worker can handle ~100 records per batch\n/// - Minimum 500: Ensures meaningful batch performance improvement\n/// - Maximum 10,000: Prevents excessive memory usage and lock duration\n///\n/// # Arguments\n///\n/// * `concurrency` - Target concurrency limit\n///\n/// # Returns\n///\n/// Optimal batch size for database inserts (500-10,000)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_batch_size;\n///\n/// let batch_size = calculate_batch_size(50);\n/// assert_eq!(batch_size, 5000); // 50  100\n///\n/// let batch_size = calculate_batch_size(10);\n/// assert_eq!(batch_size, 1000); // 10  100\n///\n/// let batch_size = calculate_batch_size(150);\n/// assert_eq!(batch_size, 10000); // Clamped to maximum\n/// ```\npub fn calculate_batch_size(concurrency: usize) -\u003e usize {\n    // Each concurrent worker can process ~100 records efficiently\n    let batch_size = concurrency * 100;\n\n    // Clamp to reasonable bounds\n    batch_size.clamp(500, 10_000)\n}\n\n/// Calculate all performance settings in one call.\n///\n/// This is a convenience function that calculates optimal concurrency,\n/// database pool size, and batch size based on detected system resources.\n///\n/// # Returns\n///\n/// Tuple of (concurrency, pool_size, batch_size)\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::performance::concurrency::calculate_all_settings;\n///\n/// let (concurrency, pool_size, batch_size) = calculate_all_settings();\n/// println!(\"Concurrency: {}\", concurrency);\n/// println!(\"DB Pool: {}\", pool_size);\n/// println!(\"Batch Size: {}\", batch_size);\n/// ```\npub fn calculate_all_settings() -\u003e (usize, usize, usize) {\n    let resources = detect_system_resources();\n    let concurrency = calculate_optimal_concurrency(\u0026resources);\n    let pool_size = calculate_database_pool_size(concurrency);\n    let batch_size = calculate_batch_size(concurrency);\n\n    (concurrency, pool_size, batch_size)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_system_resources_new() {\n        let resources = SystemResources::new(8, 16.0, true);\n        assert_eq!(resources.cpu_cores, 8);\n        assert_eq!(resources.available_memory_gb, 16.0);\n        assert!(resources.is_ssd);\n    }\n\n    #[test]\n    fn test_detect_system_resources() {\n        let resources = detect_system_resources();\n\n        // Should detect at least 1 core\n        assert!(resources.cpu_cores \u003e= 1);\n\n        // Should detect some memory\n        assert!(resources.available_memory_gb \u003e 0.0);\n\n        // is_ssd is boolean\n        assert!(resources.is_ssd || !resources.is_ssd);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_high_end_system() {\n        // 16 cores, 32GB RAM, SSD\n        let resources = SystemResources::new(16, 32.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be 16  2 = 32 (no constraints)\n        assert_eq!(concurrency, 32);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_mid_range_system() {\n        // 8 cores, 16GB RAM, SSD\n        let resources = SystemResources::new(8, 16.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be 8  2 = 16 (no constraints)\n        assert_eq!(concurrency, 16);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_low_end_system() {\n        // 4 cores, 4GB RAM, HDD\n        let resources = SystemResources::new(4, 4.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be limited by memory: 4  2 = 8, then / 4 = 2, clamped to 10\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_memory_constrained() {\n        // 8 cores, 5GB RAM, SSD\n        let resources = SystemResources::new(8, 5.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be: 8  2 = 16, then / 2 = 8, clamped to 10 (minimum)\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_hdd_cap() {\n        // 32 cores, 64GB RAM, HDD\n        let resources = SystemResources::new(32, 64.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be capped at 50 for HDD\n        assert_eq!(concurrency, 50);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_ssd_cap() {\n        // 64 cores, 128GB RAM, SSD\n        let resources = SystemResources::new(64, 128.0, true);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be capped at 100 (absolute maximum)\n        assert_eq!(concurrency, 100);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_minimum_bound() {\n        // 2 cores, 2GB RAM, HDD\n        let resources = SystemResources::new(2, 2.0, false);\n        let concurrency = calculate_optimal_concurrency(\u0026resources);\n\n        // Should be clamped to minimum of 10\n        assert_eq!(concurrency, 10);\n    }\n\n    #[test]\n    fn test_optimal_concurrency_various_cpu_counts() {\n        let test_cases = vec![\n            (4, 16.0, true, 10),   // 4 cores: 42=8, clamped to 10\n            (6, 16.0, true, 12),   // 6 cores: 62=12\n            (8, 16.0, true, 16),   // 8 cores: 82=16\n            (12, 16.0, true, 24),  // 12 cores: 122=24\n            (16, 16.0, true, 32),  // 16 cores: 162=32\n            (24, 16.0, true, 48),  // 24 cores: 242=48\n            (32, 16.0, true, 64),  // 32 cores: 322=64\n        ];\n\n        for (cores, ram, ssd, expected) in test_cases {\n            let resources = SystemResources::new(cores, ram, ssd);\n            let concurrency = calculate_optimal_concurrency(\u0026resources);\n            assert_eq!(\n                concurrency, expected,\n                \"Failed for {} cores: expected {}, got {}\",\n                cores, expected, concurrency\n            );\n        }\n    }\n\n    #[test]\n    fn test_database_pool_size() {\n        // Test various concurrency levels\n        assert_eq!(calculate_database_pool_size(10), 20);   // Clamped to minimum\n        assert_eq!(calculate_database_pool_size(20), 30);   // 20  1.5 = 30\n        assert_eq!(calculate_database_pool_size(50), 75);   // 50  1.5 = 75\n        assert_eq!(calculate_database_pool_size(100), 150); // 100  1.5 = 150\n        assert_eq!(calculate_database_pool_size(150), 200); // Clamped to maximum\n    }\n\n    #[test]\n    fn test_database_pool_size_minimum_bound() {\n        // Very low concurrency should still get minimum pool\n        assert_eq!(calculate_database_pool_size(1), 20);\n        assert_eq!(calculate_database_pool_size(5), 20);\n        assert_eq!(calculate_database_pool_size(10), 20);\n    }\n\n    #[test]\n    fn test_database_pool_size_maximum_bound() {\n        // Very high concurrency should be capped\n        assert_eq!(calculate_database_pool_size(200), 200);\n        assert_eq!(calculate_database_pool_size(500), 200);\n    }\n\n    #[test]\n    fn test_batch_size() {\n        // Test various concurrency levels\n        assert_eq!(calculate_batch_size(10), 1000);   // 10  100 = 1000\n        assert_eq!(calculate_batch_size(20), 2000);   // 20  100 = 2000\n        assert_eq!(calculate_batch_size(50), 5000);   // 50  100 = 5000\n        assert_eq!(calculate_batch_size(100), 10000); // 100  100 = 10000 (clamped)\n        assert_eq!(calculate_batch_size(150), 10000); // Clamped to maximum\n    }\n\n    #[test]\n    fn test_batch_size_minimum_bound() {\n        // Very low concurrency should get minimum batch\n        assert_eq!(calculate_batch_size(1), 500);\n        assert_eq!(calculate_batch_size(3), 500);\n        assert_eq!(calculate_batch_size(5), 500);\n    }\n\n    #[test]\n    fn test_batch_size_maximum_bound() {\n        // Very high concurrency should be capped\n        assert_eq!(calculate_batch_size(150), 10000);\n        assert_eq!(calculate_batch_size(500), 10000);\n    }\n\n    #[test]\n    fn test_calculate_all_settings() {\n        let (concurrency, pool_size, batch_size) = calculate_all_settings();\n\n        // Verify all values are in expected ranges\n        assert!(concurrency \u003e= 10 \u0026\u0026 concurrency \u003c= 100);\n        assert!(pool_size \u003e= 20 \u0026\u0026 pool_size \u003c= 200);\n        assert!(batch_size \u003e= 500 \u0026\u0026 batch_size \u003c= 10000);\n\n        // Verify relationships\n        assert!(pool_size \u003e= concurrency, \"Pool should be \u003e= concurrency\");\n        assert!(batch_size \u003e= concurrency * 50, \"Batch should be \u003e= concurrency  50\");\n    }\n\n    #[test]\n    fn test_realistic_scenarios() {\n        // Scenario 1: Development laptop (MacBook Pro)\n        let dev_laptop = SystemResources::new(8, 16.0, true);\n        let conc = calculate_optimal_concurrency(\u0026dev_laptop);\n        assert_eq!(conc, 16);\n        assert_eq!(calculate_database_pool_size(conc), 24);\n        assert_eq!(calculate_batch_size(conc), 1600);\n\n        // Scenario 2: Entry-level desktop\n        let entry_desktop = SystemResources::new(4, 8.0, false);\n        let conc = calculate_optimal_concurrency(\u0026entry_desktop);\n        assert_eq!(conc, 10); // 42=8, clamped to 10\n        assert_eq!(calculate_database_pool_size(conc), 20);\n        assert_eq!(calculate_batch_size(conc), 1000);\n\n        // Scenario 3: High-end workstation\n        let workstation = SystemResources::new(32, 64.0, true);\n        let conc = calculate_optimal_concurrency(\u0026workstation);\n        assert_eq!(conc, 64);\n        assert_eq!(calculate_database_pool_size(conc), 96);\n        assert_eq!(calculate_batch_size(conc), 6400);\n\n        // Scenario 4: Cloud server (16 vCPUs, SSD)\n        let cloud_server = SystemResources::new(16, 32.0, true);\n        let conc = calculate_optimal_concurrency(\u0026cloud_server);\n        assert_eq!(conc, 32);\n        assert_eq!(calculate_database_pool_size(conc), 48);\n        assert_eq!(calculate_batch_size(conc), 3200);\n    }\n\n    #[test]\n    fn test_memory_threshold_boundaries() {\n        // Test exact boundary conditions\n\n        // Just below 4GB\n        let resources = SystemResources::new(8, 3.9, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 824=4, clamped to 10\n\n        // Just at 4GB\n        let resources = SystemResources::new(8, 4.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 824=4, clamped to 10\n\n        // Just above 4GB\n        let resources = SystemResources::new(8, 4.1, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 822=8, clamped to 10\n\n        // Just below 6GB\n        let resources = SystemResources::new(8, 5.9, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 10); // 822=8, clamped to 10\n\n        // Just at 6GB (boundary - no reduction)\n        let resources = SystemResources::new(8, 6.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n\n        // Just above 6GB (no reduction)\n        let resources = SystemResources::new(8, 6.1, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n\n        // At 8GB (no reduction)\n        let resources = SystemResources::new(8, 8.0, true);\n        assert_eq!(calculate_optimal_concurrency(\u0026resources), 16); // 82=16, no reduction\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","performance","mod.rs"],"content":"//! Performance optimization modules\n//!\n//! This module contains pure logic for optimizing file processing performance\n//! based on system resources and workload characteristics.\n//!\n//! # Architecture\n//!\n//! All modules in this package are **Trusty Modules** - pure logic with no I/O.\n//!\n//! # Modules\n//!\n//! - `concurrency`: Dynamic concurrency tuning based on system resources\n\npub mod concurrency;\n\n// Re-export commonly used items\npub use concurrency::{\n    SystemResources,\n    detect_system_resources,\n    calculate_optimal_concurrency,\n    calculate_database_pool_size,\n    calculate_batch_size,\n    calculate_all_settings,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","splitting","mod.rs"],"content":"//! Splitting Module\n//!\n//! Pure logic for splitting multi-track MIDI files into individual tracks.\n//!\n//! # Archetype: TRUSTY MODULE\n//!\n//! This module contains pure functions for:\n//! - Parsing multi-track MIDI files\n//! - Splitting into separate Format 0 (single-track) files\n//! - Extracting track metadata\n//!\n//! All functions operate on byte arrays with no I/O operations.\n\npub mod track_splitter;\n\n// Re-export main types and functions\npub use track_splitter::{\n    count_notes, create_single_track_midi, extract_instrument, extract_primary_channel,\n    extract_track_name, get_instrument_name, is_tempo_track, split_tracks, SplitError, SplitTrack,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","core","splitting","track_splitter.rs"],"content":"//! Track Splitter - TRUSTY MODULE\n//!\n//! Pure logic for splitting multi-track MIDI files into individual single-track files.\n//!\n//! This module operates on byte arrays (no I/O) and provides functions to:\n//! - Parse multi-track MIDI files (Format 1)\n//! - Split into separate Format 0 (single-track) MIDI files\n//! - Extract metadata (track name, channel, instrument, note count)\n//! - Handle tempo tracks and edge cases\n//!\n//! # Archetype: TRUSTY MODULE\n//! -  Pure functions, no side effects\n//! -  No I/O operations\n//! -  Operates on byte slices\n//! -  Comprehensive error handling\n//! -  Well-tested\n\nuse midly::{Format, Header, MetaMessage, Smf, Track, TrackEvent, TrackEventKind};\nuse thiserror::Error;\n\n/// Error types for track splitting operations\n#[derive(Error, Debug, Clone, PartialEq)]\npub enum SplitError {\n    /// Failed to parse MIDI data\n    #[error(\"Failed to parse MIDI data: {0}\")]\n    ParseError(String),\n\n    /// Failed to write MIDI data\n    #[error(\"Failed to write MIDI data: {0}\")]\n    WriteError(String),\n\n    /// No tracks to split (empty or single tempo track)\n    #[error(\"No tracks to split - file contains only tempo track or is empty\")]\n    NoTracksToSplit,\n}\n\n/// Information about a split track\n#[derive(Debug, Clone, PartialEq)]\npub struct SplitTrack {\n    /// Original track number (0-indexed)\n    pub track_number: usize,\n\n    /// Track name from meta events (if present)\n    pub track_name: Option\u003cString\u003e,\n\n    /// Primary MIDI channel used by this track (0-15)\n    pub channel: Option\u003cu8\u003e,\n\n    /// General MIDI instrument name\n    pub instrument: Option\u003cString\u003e,\n\n    /// Number of note-on events in this track\n    pub note_count: usize,\n\n    /// Complete Format 0 MIDI file as bytes\n    pub midi_bytes: Vec\u003cu8\u003e,\n}\n\n/// Split multi-track MIDI file into individual single-track files.\n///\n/// Parses a MIDI file and creates separate Format 0 (single-track) MIDI files\n/// for each music track. Skips tempo-only tracks (Track 0 in Format 1 files).\n/// Preserves tempo, time signature, and key signature from the original file.\n///\n/// # Arguments\n///\n/// * `original_midi_bytes` - Complete MIDI file as byte slice\n///\n/// # Returns\n///\n/// Vector of `SplitTrack` structs, one for each music track found.\n/// Returns error if parsing fails or no music tracks exist.\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::splitting::track_splitter::split_tracks;\n///\n/// // Parse multi-track MIDI\n/// let midi_bytes = include_bytes!(\"test_data/multitrack.mid\");\n/// let tracks = split_tracks(midi_bytes)?;\n///\n/// for track in tracks {\n///     println!(\"Track {}: {} notes\", track.track_number, track.note_count);\n///     if let Some(name) = track.track_name {\n///         println!(\"  Name: {}\", name);\n///     }\n/// }\n/// # Ok::\u003c(), pipeline::core::splitting::track_splitter::SplitError\u003e(())\n/// ```\npub fn split_tracks(original_midi_bytes: \u0026[u8]) -\u003e Result\u003cVec\u003cSplitTrack\u003e, SplitError\u003e {\n    // Parse the original MIDI file\n    let smf = Smf::parse(original_midi_bytes)\n        .map_err(|e| SplitError::ParseError(format!(\"midly parse error: {}\", e)))?;\n\n    // Check format - if already Format 0, return as-is\n    if smf.header.format == Format::SingleTrack {\n        let track = \u0026smf.tracks[0];\n        let note_count = count_notes(track);\n\n        // Only return if it has notes\n        if note_count == 0 {\n            return Err(SplitError::NoTracksToSplit);\n        }\n\n        return Ok(vec![SplitTrack {\n            track_number: 0,\n            track_name: extract_track_name(track),\n            channel: extract_primary_channel(track),\n            instrument: extract_instrument(track),\n            note_count,\n            midi_bytes: original_midi_bytes.to_vec(),\n        }]);\n    }\n\n    // Process Format 1 (parallel tracks) or Format 2 (sequential)\n    let mut split_tracks = Vec::new();\n\n    for (idx, track) in smf.tracks.iter().enumerate() {\n        // Skip tempo-only tracks (usually Track 0)\n        if is_tempo_track(track) {\n            continue;\n        }\n\n        let note_count = count_notes(track);\n\n        // Skip tracks with no notes\n        if note_count == 0 {\n            continue;\n        }\n\n        // Create Format 0 MIDI file for this track\n        let midi_bytes = create_single_track_midi(\u0026smf, track, idx)?;\n\n        split_tracks.push(SplitTrack {\n            track_number: idx,\n            track_name: extract_track_name(track),\n            channel: extract_primary_channel(track),\n            instrument: extract_instrument(track),\n            note_count,\n            midi_bytes,\n        });\n    }\n\n    if split_tracks.is_empty() {\n        return Err(SplitError::NoTracksToSplit);\n    }\n\n    Ok(split_tracks)\n}\n\n/// Check if a track is a tempo-only track.\n///\n/// Tempo tracks contain only meta events (tempo, time signature, key signature)\n/// and no note events. Common in Format 1 MIDI files as Track 0.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// `true` if track contains only meta events, `false` otherwise\npub fn is_tempo_track(track: \u0026Track) -\u003e bool {\n    let mut has_meta_events = false;\n    let mut has_note_events = false;\n\n    for event in track.iter() {\n        match event.kind {\n            TrackEventKind::Meta(_) =\u003e has_meta_events = true,\n            TrackEventKind::Midi { message, .. } =\u003e {\n                // Check for note-on or note-off\n                use midly::MidiMessage;\n                match message {\n                    MidiMessage::NoteOn { .. } | MidiMessage::NoteOff { .. } =\u003e {\n                        has_note_events = true;\n                        break;\n                    }\n                    _ =\u003e {}\n                }\n            }\n            _ =\u003e {}\n        }\n    }\n\n    has_meta_events \u0026\u0026 !has_note_events\n}\n\n/// Create a Format 0 (single-track) MIDI file from a single track.\n///\n/// Merges tempo/time signature/key signature events from Track 0 (if Format 1)\n/// with the music events from the specified track. Creates a valid Format 0 MIDI file.\n///\n/// # Arguments\n///\n/// * `original` - Original parsed MIDI file\n/// * `track` - Track to extract\n/// * `track_idx` - Index of the track (for reference)\n///\n/// # Returns\n///\n/// Complete Format 0 MIDI file as bytes\npub fn create_single_track_midi(\n    original: \u0026Smf,\n    track: \u0026Track,\n    track_idx: usize,\n) -\u003e Result\u003cVec\u003cu8\u003e, SplitError\u003e {\n    // Create new Format 0 header with same timing\n    let new_header = Header {\n        format: Format::SingleTrack,\n        timing: original.header.timing,\n    };\n\n    // Build new track by merging tempo events from Track 0 (if exists) with this track\n    let mut new_track_events = Vec::new();\n\n    // If Format 1 and this isn't Track 0, copy tempo/meta events from Track 0\n    if original.header.format == Format::Parallel \u0026\u0026 track_idx \u003e 0 \u0026\u0026 !original.tracks.is_empty() {\n        let track_0 = \u0026original.tracks[0];\n        for event in track_0.iter() {\n            match event.kind {\n                TrackEventKind::Meta(MetaMessage::Tempo(_))\n                | TrackEventKind::Meta(MetaMessage::TimeSignature(..))\n                | TrackEventKind::Meta(MetaMessage::KeySignature(..)) =\u003e {\n                    new_track_events.push(event.clone());\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n\n    // Add all events from the target track\n    new_track_events.extend(track.iter().cloned());\n\n    // Ensure track ends with End of Track\n    let has_end_of_track = new_track_events.iter().any(|e| {\n        matches!(e.kind, TrackEventKind::Meta(MetaMessage::EndOfTrack))\n    });\n\n    if !has_end_of_track {\n        new_track_events.push(TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::EndOfTrack),\n        });\n    }\n\n    // Create new SMF with single track\n    let new_smf = Smf {\n        header: new_header,\n        tracks: vec![new_track_events],\n    };\n\n    // Write to bytes\n    let mut bytes = Vec::new();\n    new_smf\n        .write_std(\u0026mut bytes)\n        .map_err(|e| SplitError::WriteError(format!(\"midly write error: {}\", e)))?;\n\n    Ok(bytes)\n}\n\n/// Extract track name from meta events.\n///\n/// Searches for TrackName or InstrumentName meta events.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Track name if found, `None` otherwise\npub fn extract_track_name(track: \u0026Track) -\u003e Option\u003cString\u003e {\n    for event in track.iter() {\n        if let TrackEventKind::Meta(meta) = \u0026event.kind {\n            match meta {\n                MetaMessage::TrackName(name) | MetaMessage::InstrumentName(name) =\u003e {\n                    // Convert bytes to string\n                    if let Ok(name_str) = String::from_utf8(name.to_vec()) {\n                        let trimmed = name_str.trim();\n                        if !trimmed.is_empty() {\n                            return Some(trimmed.to_string());\n                        }\n                    }\n                }\n                _ =\u003e {}\n            }\n        }\n    }\n    None\n}\n\n/// Extract the primary MIDI channel used by this track.\n///\n/// Analyzes all MIDI messages and returns the most frequently used channel.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Most frequently used channel (0-15), or `None` if no MIDI messages found\npub fn extract_primary_channel(track: \u0026Track) -\u003e Option\u003cu8\u003e {\n    let mut channel_counts = [0u32; 16];\n\n    for event in track.iter() {\n        if let TrackEventKind::Midi { channel, .. } = event.kind {\n            channel_counts[channel.as_int() as usize] += 1;\n        }\n    }\n\n    // Find channel with highest count\n    let max_channel = channel_counts\n        .iter()\n        .enumerate()\n        .max_by_key(|(_, \u0026count)| count)?;\n\n    if max_channel.1 \u003e \u00260 {\n        Some(max_channel.0 as u8)\n    } else {\n        None\n    }\n}\n\n/// Extract instrument name from Program Change events.\n///\n/// Searches for the first Program Change event and maps to General MIDI instrument name.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// General MIDI instrument name, or `None` if no Program Change found\npub fn extract_instrument(track: \u0026Track) -\u003e Option\u003cString\u003e {\n    for event in track.iter() {\n        if let TrackEventKind::Midi { message, .. } = \u0026event.kind {\n            use midly::MidiMessage;\n            if let MidiMessage::ProgramChange { program } = message {\n                return Some(get_instrument_name(program.as_int()));\n            }\n        }\n    }\n    None\n}\n\n/// Count note-on events in a track.\n///\n/// # Arguments\n///\n/// * `track` - MIDI track to analyze\n///\n/// # Returns\n///\n/// Number of note-on events with velocity \u003e 0\npub fn count_notes(track: \u0026Track) -\u003e usize {\n    let mut count = 0;\n\n    for event in track.iter() {\n        if let TrackEventKind::Midi { message, .. } = \u0026event.kind {\n            use midly::MidiMessage;\n            if let MidiMessage::NoteOn { vel, .. } = message {\n                if vel.as_int() \u003e 0 {\n                    count += 1;\n                }\n            }\n        }\n    }\n\n    count\n}\n\n/// Get General MIDI instrument name from program number.\n///\n/// Maps GM program numbers (0-127) to standard instrument names.\n///\n/// # Arguments\n///\n/// * `program` - GM program number (0-127)\n///\n/// # Returns\n///\n/// General MIDI instrument name\n///\n/// # Examples\n///\n/// ```\n/// use pipeline::core::splitting::track_splitter::get_instrument_name;\n///\n/// assert_eq!(get_instrument_name(0), \"Acoustic Grand Piano\");\n/// assert_eq!(get_instrument_name(25), \"Acoustic Guitar (nylon)\");\n/// assert_eq!(get_instrument_name(127), \"Gunshot\");\n/// ```\npub fn get_instrument_name(program: u8) -\u003e String {\n    match program {\n        // Piano (0-7)\n        0 =\u003e \"Acoustic Grand Piano\",\n        1 =\u003e \"Bright Acoustic Piano\",\n        2 =\u003e \"Electric Grand Piano\",\n        3 =\u003e \"Honky-tonk Piano\",\n        4 =\u003e \"Electric Piano 1\",\n        5 =\u003e \"Electric Piano 2\",\n        6 =\u003e \"Harpsichord\",\n        7 =\u003e \"Clavinet\",\n\n        // Chromatic Percussion (8-15)\n        8 =\u003e \"Celesta\",\n        9 =\u003e \"Glockenspiel\",\n        10 =\u003e \"Music Box\",\n        11 =\u003e \"Vibraphone\",\n        12 =\u003e \"Marimba\",\n        13 =\u003e \"Xylophone\",\n        14 =\u003e \"Tubular Bells\",\n        15 =\u003e \"Dulcimer\",\n\n        // Organ (16-23)\n        16 =\u003e \"Drawbar Organ\",\n        17 =\u003e \"Percussive Organ\",\n        18 =\u003e \"Rock Organ\",\n        19 =\u003e \"Church Organ\",\n        20 =\u003e \"Reed Organ\",\n        21 =\u003e \"Accordion\",\n        22 =\u003e \"Harmonica\",\n        23 =\u003e \"Tango Accordion\",\n\n        // Guitar (24-31)\n        24 =\u003e \"Acoustic Guitar (nylon)\",\n        25 =\u003e \"Acoustic Guitar (steel)\",\n        26 =\u003e \"Electric Guitar (jazz)\",\n        27 =\u003e \"Electric Guitar (clean)\",\n        28 =\u003e \"Electric Guitar (muted)\",\n        29 =\u003e \"Overdriven Guitar\",\n        30 =\u003e \"Distortion Guitar\",\n        31 =\u003e \"Guitar Harmonics\",\n\n        // Bass (32-39)\n        32 =\u003e \"Acoustic Bass\",\n        33 =\u003e \"Electric Bass (finger)\",\n        34 =\u003e \"Electric Bass (pick)\",\n        35 =\u003e \"Fretless Bass\",\n        36 =\u003e \"Slap Bass 1\",\n        37 =\u003e \"Slap Bass 2\",\n        38 =\u003e \"Synth Bass 1\",\n        39 =\u003e \"Synth Bass 2\",\n\n        // Strings (40-47)\n        40 =\u003e \"Violin\",\n        41 =\u003e \"Viola\",\n        42 =\u003e \"Cello\",\n        43 =\u003e \"Contrabass\",\n        44 =\u003e \"Tremolo Strings\",\n        45 =\u003e \"Pizzicato Strings\",\n        46 =\u003e \"Orchestral Harp\",\n        47 =\u003e \"Timpani\",\n\n        // Ensemble (48-55)\n        48 =\u003e \"String Ensemble 1\",\n        49 =\u003e \"String Ensemble 2\",\n        50 =\u003e \"Synth Strings 1\",\n        51 =\u003e \"Synth Strings 2\",\n        52 =\u003e \"Choir Aahs\",\n        53 =\u003e \"Voice Oohs\",\n        54 =\u003e \"Synth Voice\",\n        55 =\u003e \"Orchestra Hit\",\n\n        // Brass (56-63)\n        56 =\u003e \"Trumpet\",\n        57 =\u003e \"Trombone\",\n        58 =\u003e \"Tuba\",\n        59 =\u003e \"Muted Trumpet\",\n        60 =\u003e \"French Horn\",\n        61 =\u003e \"Brass Section\",\n        62 =\u003e \"Synth Brass 1\",\n        63 =\u003e \"Synth Brass 2\",\n\n        // Reed (64-71)\n        64 =\u003e \"Soprano Sax\",\n        65 =\u003e \"Alto Sax\",\n        66 =\u003e \"Tenor Sax\",\n        67 =\u003e \"Baritone Sax\",\n        68 =\u003e \"Oboe\",\n        69 =\u003e \"English Horn\",\n        70 =\u003e \"Bassoon\",\n        71 =\u003e \"Clarinet\",\n\n        // Pipe (72-79)\n        72 =\u003e \"Piccolo\",\n        73 =\u003e \"Flute\",\n        74 =\u003e \"Recorder\",\n        75 =\u003e \"Pan Flute\",\n        76 =\u003e \"Blown Bottle\",\n        77 =\u003e \"Shakuhachi\",\n        78 =\u003e \"Whistle\",\n        79 =\u003e \"Ocarina\",\n\n        // Synth Lead (80-87)\n        80 =\u003e \"Lead 1 (square)\",\n        81 =\u003e \"Lead 2 (sawtooth)\",\n        82 =\u003e \"Lead 3 (calliope)\",\n        83 =\u003e \"Lead 4 (chiff)\",\n        84 =\u003e \"Lead 5 (charang)\",\n        85 =\u003e \"Lead 6 (voice)\",\n        86 =\u003e \"Lead 7 (fifths)\",\n        87 =\u003e \"Lead 8 (bass + lead)\",\n\n        // Synth Pad (88-95)\n        88 =\u003e \"Pad 1 (new age)\",\n        89 =\u003e \"Pad 2 (warm)\",\n        90 =\u003e \"Pad 3 (polysynth)\",\n        91 =\u003e \"Pad 4 (choir)\",\n        92 =\u003e \"Pad 5 (bowed)\",\n        93 =\u003e \"Pad 6 (metallic)\",\n        94 =\u003e \"Pad 7 (halo)\",\n        95 =\u003e \"Pad 8 (sweep)\",\n\n        // Synth Effects (96-103)\n        96 =\u003e \"FX 1 (rain)\",\n        97 =\u003e \"FX 2 (soundtrack)\",\n        98 =\u003e \"FX 3 (crystal)\",\n        99 =\u003e \"FX 4 (atmosphere)\",\n        100 =\u003e \"FX 5 (brightness)\",\n        101 =\u003e \"FX 6 (goblins)\",\n        102 =\u003e \"FX 7 (echoes)\",\n        103 =\u003e \"FX 8 (sci-fi)\",\n\n        // Ethnic (104-111)\n        104 =\u003e \"Sitar\",\n        105 =\u003e \"Banjo\",\n        106 =\u003e \"Shamisen\",\n        107 =\u003e \"Koto\",\n        108 =\u003e \"Kalimba\",\n        109 =\u003e \"Bag pipe\",\n        110 =\u003e \"Fiddle\",\n        111 =\u003e \"Shanai\",\n\n        // Percussive (112-119)\n        112 =\u003e \"Tinkle Bell\",\n        113 =\u003e \"Agogo\",\n        114 =\u003e \"Steel Drums\",\n        115 =\u003e \"Woodblock\",\n        116 =\u003e \"Taiko Drum\",\n        117 =\u003e \"Melodic Tom\",\n        118 =\u003e \"Synth Drum\",\n        119 =\u003e \"Reverse Cymbal\",\n\n        // Sound Effects (120-127)\n        120 =\u003e \"Guitar Fret Noise\",\n        121 =\u003e \"Breath Noise\",\n        122 =\u003e \"Seashore\",\n        123 =\u003e \"Bird Tweet\",\n        124 =\u003e \"Telephone Ring\",\n        125 =\u003e \"Helicopter\",\n        126 =\u003e \"Applause\",\n        127 =\u003e \"Gunshot\",\n\n        // Fallback (should never happen with u8)\n        _ =\u003e \"Unknown Instrument\",\n    }\n    .to_string()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use midly::{MetaMessage, MidiMessage, TrackEvent, TrackEventKind};\n\n    // Helper: Create test track with events\n    fn create_test_track(events: Vec\u003cTrackEvent\u003e) -\u003e Track {\n        events\n    }\n\n    #[test]\n    fn test_get_instrument_name_piano() {\n        assert_eq!(get_instrument_name(0), \"Acoustic Grand Piano\");\n        assert_eq!(get_instrument_name(1), \"Bright Acoustic Piano\");\n        assert_eq!(get_instrument_name(7), \"Clavinet\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_guitar() {\n        assert_eq!(get_instrument_name(24), \"Acoustic Guitar (nylon)\");\n        assert_eq!(get_instrument_name(25), \"Acoustic Guitar (steel)\");\n        assert_eq!(get_instrument_name(30), \"Distortion Guitar\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_strings() {\n        assert_eq!(get_instrument_name(40), \"Violin\");\n        assert_eq!(get_instrument_name(42), \"Cello\");\n        assert_eq!(get_instrument_name(46), \"Orchestral Harp\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_brass() {\n        assert_eq!(get_instrument_name(56), \"Trumpet\");\n        assert_eq!(get_instrument_name(57), \"Trombone\");\n        assert_eq!(get_instrument_name(60), \"French Horn\");\n    }\n\n    #[test]\n    fn test_get_instrument_name_effects() {\n        assert_eq!(get_instrument_name(120), \"Guitar Fret Noise\");\n        assert_eq!(get_instrument_name(122), \"Seashore\");\n        assert_eq!(get_instrument_name(127), \"Gunshot\");\n    }\n\n    #[test]\n    fn test_count_notes_empty_track() {\n        let track = create_test_track(vec![]);\n        assert_eq!(count_notes(\u0026track), 0);\n    }\n\n    #[test]\n    fn test_count_notes_with_notes() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 80.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOff {\n                        key: 60.into(),\n                        vel: 0.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(count_notes(\u0026track), 2);\n    }\n\n    #[test]\n    fn test_count_notes_ignores_zero_velocity() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 0.into(), // Zero velocity = note off\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(count_notes(\u0026track), 1);\n    }\n\n    #[test]\n    fn test_is_tempo_track_true() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::TimeSignature(4, 2, 24, 8)),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::EndOfTrack),\n            },\n        ]);\n\n        assert!(is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_is_tempo_track_false_with_notes() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n            },\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert!(!is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_is_tempo_track_false_empty() {\n        let track = create_test_track(vec![]);\n        assert!(!is_tempo_track(\u0026track));\n    }\n\n    #[test]\n    fn test_extract_track_name_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::TrackName(b\"Piano Track\")),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), Some(\"Piano Track\".to_string()));\n    }\n\n    #[test]\n    fn test_extract_track_name_instrument_name() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::InstrumentName(b\"Grand Piano\")),\n        }]);\n\n        assert_eq!(\n            extract_track_name(\u0026track),\n            Some(\"Grand Piano\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_extract_track_name_not_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_track_name_empty_string() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::TrackName(b\"   \")),\n        }]);\n\n        assert_eq!(extract_track_name(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_primary_channel_single_channel() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 5.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 5.into(),\n                    message: MidiMessage::NoteOff {\n                        key: 60.into(),\n                        vel: 0.into(),\n                    },\n                },\n            },\n        ]);\n\n        assert_eq!(extract_primary_channel(\u0026track), Some(5));\n    }\n\n    #[test]\n    fn test_extract_primary_channel_multiple_channels() {\n        let track = create_test_track(vec![\n            TrackEvent {\n                delta: 0.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 0.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 60.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 1.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 64.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n            TrackEvent {\n                delta: 10.into(),\n                kind: TrackEventKind::Midi {\n                    channel: 1.into(),\n                    message: MidiMessage::NoteOn {\n                        key: 67.into(),\n                        vel: 64.into(),\n                    },\n                },\n            },\n        ]);\n\n        // Channel 1 has more events\n        assert_eq!(extract_primary_channel(\u0026track), Some(1));\n    }\n\n    #[test]\n    fn test_extract_primary_channel_no_midi() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Meta(MetaMessage::Tempo(500000.into())),\n        }]);\n\n        assert_eq!(extract_primary_channel(\u0026track), None);\n    }\n\n    #[test]\n    fn test_extract_instrument_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Midi {\n                channel: 0.into(),\n                message: MidiMessage::ProgramChange { program: 0.into() },\n            },\n        }]);\n\n        assert_eq!(\n            extract_instrument(\u0026track),\n            Some(\"Acoustic Grand Piano\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_extract_instrument_not_found() {\n        let track = create_test_track(vec![TrackEvent {\n            delta: 0.into(),\n            kind: TrackEventKind::Midi {\n                channel: 0.into(),\n                message: MidiMessage::NoteOn {\n                    key: 60.into(),\n                    vel: 64.into(),\n                },\n            },\n        }]);\n\n        assert_eq!(extract_instrument(\u0026track), None);\n    }\n\n    #[test]\n    fn test_split_error_display() {\n        let err = SplitError::ParseError(\"test error\".to_string());\n        assert_eq!(err.to_string(), \"Failed to parse MIDI data: test error\");\n\n        let err = SplitError::NoTracksToSplit;\n        assert_eq!(\n            err.to_string(),\n            \"No tracks to split - file contains only tempo track or is empty\"\n        );\n    }\n\n    #[test]\n    fn test_split_track_struct() {\n        let track = SplitTrack {\n            track_number: 1,\n            track_name: Some(\"Piano\".to_string()),\n            channel: Some(0),\n            instrument: Some(\"Acoustic Grand Piano\".to_string()),\n            note_count: 42,\n            midi_bytes: vec![0x4d, 0x54, 0x68, 0x64],\n        };\n\n        assert_eq!(track.track_number, 1);\n        assert_eq!(track.track_name, Some(\"Piano\".to_string()));\n        assert_eq!(track.channel, Some(0));\n        assert_eq!(track.note_count, 42);\n        assert_eq!(track.midi_bytes.len(), 4);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","database","batch_insert.rs"],"content":"//! Batch Database Insert Operations\n//!\n//! Architecture: Grown-up Script (service layer with database access)\n//! Purpose: High-performance batch insertion of MIDI file records and metadata\n//!\n//! This module provides batched database operations for importing large numbers\n//! of MIDI files. It uses chunked transactions to achieve 10-50x speedup over\n//! individual INSERT statements.\n//!\n//! # Performance\n//!\n//! - Individual INSERT: ~200 rows/sec\n//! - Batched INSERT: ~10,000-50,000 rows/sec\n//!\n//! # Examples\n//!\n//! ```rust\n//! use batch_insert::BatchInserter;\n//!\n//! let inserter = BatchInserter::new(pool, 1000);\n//! let file_ids = inserter.insert_files_batch(file_records).await?;\n//! inserter.insert_metadata_batch(metadata_records).await?;\n//! ```\n\nuse crate::core::performance::concurrency::calculate_all_settings;\nuse sqlx::{PgPool, Postgres, Transaction};\nuse thiserror::Error;\nuse serde::{Deserialize, Serialize};\n\n//=============================================================================\n// ERROR TYPES\n//=============================================================================\n\n#[derive(Error, Debug)]\npub enum BatchInsertError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n\n    #[error(\"Transaction failed: {0}\")]\n    Transaction(String),\n\n    #[error(\"Empty batch provided\")]\n    EmptyBatch,\n\n    #[error(\"Batch size mismatch: expected {expected}, got {actual}\")]\n    BatchSizeMismatch { expected: usize, actual: usize },\n\n    #[error(\"Invalid data: {0}\")]\n    InvalidData(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, BatchInsertError\u003e;\n\n//=============================================================================\n// DATA STRUCTURES\n//=============================================================================\n\n/// File record for batch insertion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FileRecord {\n    pub filename: String,\n    pub new_filename: String,\n    pub filepath: String,\n    pub parent_folder: Option\u003cString\u003e,\n    pub hash: String,\n    pub file_size: i64,\n    pub category: Option\u003cString\u003e,\n}\n\nimpl FileRecord {\n    pub fn new(\n        filename: String,\n        new_filename: String,\n        filepath: String,\n        parent_folder: Option\u003cString\u003e,\n        hash: String,\n        file_size: i64,\n        category: Option\u003cString\u003e,\n    ) -\u003e Self {\n        Self {\n            filename,\n            new_filename,\n            filepath,\n            parent_folder,\n            hash,\n            file_size,\n            category,\n        }\n    }\n\n    /// Validate record data\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        if self.filename.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"filename cannot be empty\".to_string()));\n        }\n        if self.filepath.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"filepath cannot be empty\".to_string()));\n        }\n        if self.hash.is_empty() {\n            return Err(BatchInsertError::InvalidData(\"hash cannot be empty\".to_string()));\n        }\n        if self.file_size \u003c= 0 {\n            return Err(BatchInsertError::InvalidData(\"file_size must be positive\".to_string()));\n        }\n        Ok(())\n    }\n}\n\n/// Musical metadata for batch insertion\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MusicalMetadata {\n    pub file_id: i64,\n    pub bpm: Option\u003ci32\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub time_signature: Option\u003cString\u003e,\n    pub num_tracks: Option\u003ci32\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n}\n\nimpl MusicalMetadata {\n    pub fn new(file_id: i64) -\u003e Self {\n        Self {\n            file_id,\n            bpm: None,\n            key_signature: None,\n            time_signature: Some(\"4/4\".to_string()),\n            num_tracks: None,\n            duration_seconds: None,\n        }\n    }\n\n    pub fn with_bpm(mut self, bpm: i32) -\u003e Self {\n        self.bpm = Some(bpm);\n        self\n    }\n\n    pub fn with_key(mut self, key: String) -\u003e Self {\n        self.key_signature = Some(key);\n        self\n    }\n\n    pub fn with_time_signature(mut self, time_sig: String) -\u003e Self {\n        self.time_signature = Some(time_sig);\n        self\n    }\n\n    pub fn with_tracks(mut self, tracks: i32) -\u003e Self {\n        self.num_tracks = Some(tracks);\n        self\n    }\n\n    pub fn with_duration(mut self, duration: f64) -\u003e Self {\n        self.duration_seconds = Some(duration);\n        self\n    }\n\n    /// Validate metadata\n    pub fn validate(\u0026self) -\u003e Result\u003c()\u003e {\n        if self.file_id \u003c= 0 {\n            return Err(BatchInsertError::InvalidData(\"file_id must be positive\".to_string()));\n        }\n        if let Some(bpm) = self.bpm {\n            if bpm \u003c 20 || bpm \u003e 300 {\n                return Err(BatchInsertError::InvalidData(\n                    format!(\"BPM {} out of range (20-300)\", bpm)\n                ));\n            }\n        }\n        if let Some(duration) = self.duration_seconds {\n            if duration \u003c 0.0 {\n                return Err(BatchInsertError::InvalidData(\"duration cannot be negative\".to_string()));\n            }\n        }\n        Ok(())\n    }\n}\n\n//=============================================================================\n// BATCH INSERTER\n//=============================================================================\n\n/// High-performance batch inserter for MIDI file records\n///\n/// This struct provides methods for inserting large numbers of records\n/// efficiently using chunked transactions. It automatically handles\n/// batching, transaction management, and error recovery.\n///\n/// # Performance Characteristics\n///\n/// - Batch size affects memory usage vs speed tradeoff\n/// - Larger batches = fewer transactions = faster (but more memory)\n/// - Default batch size of 1000 is optimal for most cases\n/// - Can achieve 10,000-50,000 inserts/second\n///\n/// # Transaction Safety\n///\n/// All operations use transactions with automatic rollback on error.\n/// If any record in a batch fails, the entire batch is rolled back.\npub struct BatchInserter {\n    pool: PgPool,\n    batch_size: usize,\n}\n\nimpl BatchInserter {\n    /// Create a new batch inserter with specified batch size\n    ///\n    /// # Arguments\n    ///\n    /// * `pool` - PostgreSQL connection pool\n    /// * `batch_size` - Number of records per transaction (recommended: 500-2000)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let inserter = BatchInserter::new(pool, 1000);\n    /// ```\n    pub fn new(pool: PgPool, batch_size: usize) -\u003e Self {\n        Self { pool, batch_size }\n    }\n\n    /// Create with default batch size (1000)\n    ///\n    /// # Deprecated\n    ///\n    /// Consider using `with_optimal_batch_size()` instead for dynamic tuning.\n    pub fn with_defaults(pool: PgPool) -\u003e Self {\n        Self::new(pool, 1000)\n    }\n\n    /// Create with dynamically calculated optimal batch size\n    ///\n    /// Automatically determines the best batch size based on system resources\n    /// (CPU cores, RAM, storage type). This is the recommended constructor.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let inserter = BatchInserter::with_optimal_batch_size(pool);\n    /// ```\n    pub fn with_optimal_batch_size(pool: PgPool) -\u003e Self {\n        let (_, _, batch_size) = calculate_all_settings();\n        println!(\" BatchInserter: Using optimal batch size of {} records\", batch_size);\n        Self::new(pool, batch_size)\n    }\n\n    /// Insert multiple file records in batches\n    ///\n    /// This method chunks the input into batches and inserts each batch\n    /// within a single transaction. Returns the database IDs of all\n    /// inserted records in the same order as input.\n    ///\n    /// # Arguments\n    ///\n    /// * `files` - Vector of file records to insert\n    ///\n    /// # Returns\n    ///\n    /// Vector of database IDs for the inserted records\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Input is empty\n    /// - Any record is invalid\n    /// - Database constraint violation (e.g., duplicate hash)\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let files = vec![\n    ///     FileRecord::new(...),\n    ///     FileRecord::new(...),\n    /// ];\n    /// let ids = inserter.insert_files_batch(files).await?;\n    /// ```\n    pub async fn insert_files_batch(\u0026self, files: Vec\u003cFileRecord\u003e) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        if files.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        // Validate all records first\n        for file in \u0026files {\n            file.validate()?;\n        }\n\n        let mut all_ids = Vec::with_capacity(files.len());\n\n        // Process in chunks\n        for chunk in files.chunks(self.batch_size) {\n            let chunk_ids = self.insert_files_chunk(chunk).await?;\n            all_ids.extend(chunk_ids);\n        }\n\n        Ok(all_ids)\n    }\n\n    /// Insert multiple metadata records in batches\n    ///\n    /// This method efficiently inserts musical metadata for previously\n    /// inserted files. It uses chunked transactions for high performance.\n    ///\n    /// # Arguments\n    ///\n    /// * `metadata` - Vector of metadata records to insert\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Input is empty\n    /// - Any metadata is invalid\n    /// - Referenced file_id doesn't exist\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let metadata = vec![\n    ///     MusicalMetadata::new(1).with_bpm(120).with_key(\"C\".to_string()),\n    ///     MusicalMetadata::new(2).with_bpm(140).with_key(\"Am\".to_string()),\n    /// ];\n    /// inserter.insert_metadata_batch(metadata).await?;\n    /// ```\n    pub async fn insert_metadata_batch(\u0026self, metadata: Vec\u003cMusicalMetadata\u003e) -\u003e Result\u003c()\u003e {\n        if metadata.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        // Validate all records first\n        for meta in \u0026metadata {\n            meta.validate()?;\n        }\n\n        // Process in chunks\n        for chunk in metadata.chunks(self.batch_size) {\n            self.insert_metadata_chunk(chunk).await?;\n        }\n\n        Ok(())\n    }\n\n    /// Insert files and metadata in a single atomic transaction\n    ///\n    /// This method ensures that files and their associated metadata are\n    /// inserted together atomically. If either operation fails, both are\n    /// rolled back.\n    ///\n    /// # Arguments\n    ///\n    /// * `files` - Vector of file records\n    /// * `metadata` - Vector of metadata records (must match file count)\n    ///\n    /// # Returns\n    ///\n    /// Vector of database IDs for the inserted files\n    ///\n    /// # Errors\n    ///\n    /// Returns error if:\n    /// - Inputs are empty\n    /// - File and metadata counts don't match\n    /// - Any validation fails\n    /// - Transaction fails\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// let files = vec![FileRecord::new(...)];\n    /// let metadata = vec![MusicalMetadata::new(0).with_bpm(120)];\n    /// let ids = inserter.insert_with_transaction(files, metadata).await?;\n    /// ```\n    pub async fn insert_with_transaction(\n        \u0026self,\n        files: Vec\u003cFileRecord\u003e,\n        metadata: Vec\u003cMusicalMetadata\u003e,\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        if files.is_empty() {\n            return Err(BatchInsertError::EmptyBatch);\n        }\n\n        if files.len() != metadata.len() {\n            return Err(BatchInsertError::BatchSizeMismatch {\n                expected: files.len(),\n                actual: metadata.len(),\n            });\n        }\n\n        // Validate all records\n        for file in \u0026files {\n            file.validate()?;\n        }\n\n        let mut all_ids = Vec::with_capacity(files.len());\n\n        // Process in chunks, maintaining file-metadata relationship\n        for (file_chunk, meta_chunk) in files.chunks(self.batch_size).zip(metadata.chunks(self.batch_size)) {\n            let mut tx = self.pool.begin().await?;\n\n            // Insert files and get IDs\n            let chunk_ids = self.insert_files_in_transaction(\u0026mut tx, file_chunk).await?;\n\n            // Update metadata with actual file IDs\n            let mut updated_metadata = Vec::new();\n            for (meta, \u0026file_id) in meta_chunk.iter().zip(chunk_ids.iter()) {\n                let mut updated = meta.clone();\n                updated.file_id = file_id;\n                updated.validate()?;\n                updated_metadata.push(updated);\n            }\n\n            // Insert metadata\n            self.insert_metadata_in_transaction(\u0026mut tx, \u0026updated_metadata).await?;\n\n            // Commit transaction\n            tx.commit().await.map_err(|e| {\n                BatchInsertError::Transaction(format!(\"Failed to commit transaction: {}\", e))\n            })?;\n\n            all_ids.extend(chunk_ids);\n        }\n\n        Ok(all_ids)\n    }\n\n    //=========================================================================\n    // PRIVATE HELPER METHODS\n    //=========================================================================\n\n    /// Insert a single chunk of files (internal method)\n    async fn insert_files_chunk(\u0026self, files: \u0026[FileRecord]) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let mut tx = self.pool.begin().await?;\n        let ids = self.insert_files_in_transaction(\u0026mut tx, files).await?;\n        tx.commit().await?;\n        Ok(ids)\n    }\n\n    /// Insert files within an existing transaction\n    async fn insert_files_in_transaction(\n        \u0026self,\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        files: \u0026[FileRecord],\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let mut ids = Vec::with_capacity(files.len());\n\n        for file in files {\n            let id = sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                INSERT INTO files (\n                    filename, original_filename, filepath, parent_folder, content_hash,\n                    file_size_bytes, imported_at\n                )\n                VALUES ($1, $2, $3, $4, decode($5, 'hex'), $6, NOW())\n                ON CONFLICT (content_hash) DO NOTHING\n                RETURNING id\n                \"#,\n            )\n            .bind(\u0026file.filename)\n            .bind(\u0026file.new_filename)\n            .bind(\u0026file.filepath)\n            .bind(\u0026file.parent_folder)\n            .bind(\u0026file.hash)\n            .bind(file.file_size)\n            .fetch_optional(\u0026mut **tx)\n            .await?;\n\n            // If conflict (duplicate), skip this record\n            if let Some(id) = id {\n                ids.push(id);\n            }\n        }\n\n        Ok(ids)\n    }\n\n    /// Insert a single chunk of metadata (internal method)\n    async fn insert_metadata_chunk(\u0026self, metadata: \u0026[MusicalMetadata]) -\u003e Result\u003c()\u003e {\n        let mut tx = self.pool.begin().await?;\n        self.insert_metadata_in_transaction(\u0026mut tx, metadata).await?;\n        tx.commit().await?;\n        Ok(())\n    }\n\n    /// Insert metadata within an existing transaction\n    async fn insert_metadata_in_transaction(\n        \u0026self,\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        metadata: \u0026[MusicalMetadata],\n    ) -\u003e Result\u003c()\u003e {\n        for meta in metadata {\n            sqlx::query(\n                r#\"\n                INSERT INTO musical_metadata (\n                    file_id, bpm, key_signature, time_signature,\n                    num_tracks, duration_seconds\n                )\n                VALUES ($1, $2, $3, $4, $5, $6)\n                ON CONFLICT (file_id) DO UPDATE SET\n                    bpm = EXCLUDED.bpm,\n                    key_signature = EXCLUDED.key_signature,\n                    time_signature = EXCLUDED.time_signature,\n                    num_tracks = EXCLUDED.num_tracks,\n                    duration_seconds = EXCLUDED.duration_seconds\n                \"#,\n            )\n            .bind(meta.file_id)\n            .bind(meta.bpm)\n            .bind(\u0026meta.key_signature)\n            .bind(\u0026meta.time_signature)\n            .bind(meta.num_tracks)\n            .bind(meta.duration_seconds)\n            .execute(\u0026mut **tx)\n            .await?;\n        }\n\n        Ok(())\n    }\n}\n\n//=============================================================================\n// UTILITY FUNCTIONS\n//=============================================================================\n\n/// Calculate optimal batch size based on system memory\n///\n/// This function provides a dynamically calculated batch size based on\n/// detected system resources (CPU cores, RAM, storage type).\n///\n/// # Returns\n///\n/// Recommended batch size (between 500 and 10,000)\n///\n/// # Examples\n///\n/// ```rust\n/// let batch_size = calculate_optimal_batch_size();\n/// let inserter = BatchInserter::new(pool, batch_size);\n/// ```\npub fn calculate_optimal_batch_size() -\u003e usize {\n    // Use the dynamic concurrency module to calculate optimal batch size\n    let (_, _, batch_size) = calculate_all_settings();\n    batch_size\n}\n\n//=============================================================================\n// TESTS\n//=============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_file_record_validation() {\n        let valid = FileRecord::new(\n            \"test.mid\".to_string(),\n            \"new_test.mid\".to_string(),\n            \"/path/to/test.mid\".to_string(),\n            Some(\"drums\".to_string()),\n            \"abc123\".to_string(),\n            1024,\n            Some(\"drums\".to_string()),\n        );\n        assert!(valid.validate().is_ok());\n\n        let empty_filename = FileRecord::new(\n            \"\".to_string(),\n            \"new.mid\".to_string(),\n            \"/path\".to_string(),\n            None,\n            \"hash\".to_string(),\n            1024,\n            None,\n        );\n        assert!(empty_filename.validate().is_err());\n\n        let negative_size = FileRecord::new(\n            \"test.mid\".to_string(),\n            \"new.mid\".to_string(),\n            \"/path\".to_string(),\n            None,\n            \"hash\".to_string(),\n            -100,\n            None,\n        );\n        assert!(negative_size.validate().is_err());\n    }\n\n    #[test]\n    fn test_musical_metadata_validation() {\n        let valid = MusicalMetadata::new(1)\n            .with_bpm(120)\n            .with_key(\"C\".to_string())\n            .with_duration(180.5);\n        assert!(valid.validate().is_ok());\n\n        let invalid_bpm = MusicalMetadata::new(1).with_bpm(500);\n        assert!(invalid_bpm.validate().is_err());\n\n        let negative_duration = MusicalMetadata::new(1).with_duration(-10.0);\n        assert!(negative_duration.validate().is_err());\n\n        let invalid_file_id = MusicalMetadata::new(0);\n        assert!(invalid_file_id.validate().is_err());\n    }\n\n    #[test]\n    fn test_musical_metadata_builder() {\n        let meta = MusicalMetadata::new(1)\n            .with_bpm(140)\n            .with_key(\"Am\".to_string())\n            .with_time_signature(\"3/4\".to_string())\n            .with_tracks(8)\n            .with_duration(240.0);\n\n        assert_eq!(meta.file_id, 1);\n        assert_eq!(meta.bpm, Some(140));\n        assert_eq!(meta.key_signature, Some(\"Am\".to_string()));\n        assert_eq!(meta.time_signature, Some(\"3/4\".to_string()));\n        assert_eq!(meta.num_tracks, Some(8));\n        assert_eq!(meta.duration_seconds, Some(240.0));\n    }\n\n    #[test]\n    fn test_calculate_optimal_batch_size() {\n        let size = calculate_optimal_batch_size();\n        assert!(size \u003e= 100 \u0026\u0026 size \u003c= 5000);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","database","mod.rs"],"content":"// Database Connection Module - MANAGER ARCHETYPE (OPTIMIZED)\n//\n// PURPOSE: Manage PostgreSQL connection pool and provide database access with performance optimizations\n// ARCHETYPE: Manager (I/O operations with side effects)\n// LOCATION: pipeline/src-tauri/src/database/mod.rs\n//\n//  CAN: Perform I/O operations (database connections)\n//  CAN: Have side effects (connection pooling)\n//  SHOULD: Handle errors properly with retry logic\n//  SHOULD: Monitor performance metrics\n//  NO: Business logic\n//  NO: UI concerns\n//\n// OPTIMIZATIONS APPLIED:\n// 1. Connection pool tuning for high-performance workloads\n// 2. Prepared statement caching enabled\n// 3. Query timeout handling\n// 4. Retry logic with exponential backoff for transient failures\n// 5. Performance monitoring and health checks\n// 6. Slow query logging\n// 7. Connection health validation\n\n// Batch insert module for high-performance bulk operations\npub mod batch_insert;\n\nuse crate::core::performance::concurrency::calculate_all_settings;\nuse sqlx::postgres::{PgPool, PgPoolOptions, PgConnectOptions};\nuse std::time::{Duration, Instant};\nuse std::future::Future;\nuse std::str::FromStr;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n/// Database connection pool wrapper with performance optimizations\n///\n/// ## Connection Pool Settings (OPTIMIZED):\n/// - Max connections: 50 (increased from 20 for better concurrency)\n/// - Min connections: 10 (increased from 5 to reduce cold starts)\n/// - Acquire timeout: 10 seconds (reduced from 30s for faster failure detection)\n/// - Idle timeout: 300 seconds (5 minutes, reduced from 10min for better recycling)\n/// - Max lifetime: 1800 seconds (30 minutes)\n/// - Statement cache size: 100 (NEW - prepared statement caching)\n/// - Test before acquire: true (validates connection health)\n///\n/// ## Performance Features:\n/// - Automatic retry with exponential backoff for transient errors\n/// - Connection health monitoring\n/// - Slow query detection (queries \u003e 1s)\n/// - Pool statistics tracking\n/// - Comprehensive health checks\n///\n/// # Example\n///\n/// ```rust\n/// use database::Database;\n///\n/// #[tokio::main]\n/// async fn main() -\u003e Result\u003c(), sqlx::Error\u003e {\n///     let db = Database::new(\"postgresql://midiuser:145278963@localhost:5433/midi_library\").await?;\n///\n///     // Test connection with health check\n///     let health = db.health_check().await;\n///     println!(\"Database health: {:?}\", health);\n///\n///     // Execute query with automatic retry\n///     let result = db.execute_with_retry(3, || async {\n///         sqlx::query(\"SELECT * FROM files LIMIT 10\")\n///             .fetch_all(db.pool())\n///             .await\n///     }).await?;\n///\n///     Ok(())\n/// }\n/// ```\npub struct Database {\n    pool: Arc\u003cRwLock\u003cPgPool\u003e\u003e,\n    database_url: String,\n    reconnect_attempts: Arc\u003cRwLock\u003cu32\u003e\u003e,\n}\n\nimpl Database {\n    /// Create new database connection pool with optimized settings\n    ///\n    /// Establishes connection to PostgreSQL database with production-grade pool settings\n    /// optimized for handling MIDI library operations at scale (millions of files).\n    ///\n    /// ## Connection Pool Optimizations:\n    /// - **50 max connections**: Supports high concurrency for batch imports\n    /// - **10 min connections**: Reduces latency by keeping connections warm\n    /// - **Prepared statement cache**: Speeds up repeated queries by 2-5x\n    /// - **Connection validation**: Tests connections before use to prevent stale connections\n    /// - **Aggressive timeouts**: Fast failure detection for better user experience\n    ///\n    /// ## Performance Characteristics:\n    /// - Connection acquisition: \u003c 5ms (warm pool)\n    /// - Query execution: 1-100ms (depending on complexity)\n    /// - Handles 100-500 concurrent operations\n    /// - Memory overhead: ~50MB for connection pool\n    ///\n    /// # Arguments\n    ///\n    /// * `database_url` - PostgreSQL connection string (e.g., \"postgresql://user:pass@localhost:5433/dbname\")\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cSelf, sqlx::Error\u003e` - Database instance or connection error\n    ///\n    /// # Errors\n    ///\n    /// - Connection refused: Database not running\n    /// - Authentication failed: Invalid credentials\n    /// - Timeout: Database unreachable\n    /// - Invalid URL: Malformed connection string\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let db = Database::new(\"postgresql://midiuser:145278963@localhost:5433/midi_library\").await?;\n    /// ```\n    pub async fn new(database_url: \u0026str) -\u003e Result\u003cSelf, sqlx::Error\u003e {\n        println!(\" Connecting to database: {}\", database_url);\n        println!(\" Applying performance optimizations...\");\n\n        // Calculate optimal pool size dynamically based on system resources\n        let (concurrency, pool_size, batch_size) = calculate_all_settings();\n        println!(\" Dynamic pool sizing detected:\");\n        println!(\"   Concurrency:  {} workers\", concurrency);\n        println!(\"   Pool Size:    {} connections (auto-tuned)\", pool_size);\n        println!(\"   Batch Size:   {} records\", batch_size);\n\n        // Parse connection options for advanced configuration\n        let mut connect_options = PgConnectOptions::from_str(database_url)?;\n\n        // Enable prepared statement caching (OPTIMIZATION #2)\n        // Caches up to 100 prepared statements per connection\n        // Reduces parsing overhead for repeated queries by 2-5x\n        connect_options = connect_options.statement_cache_capacity(100);\n\n        // Set application name for monitoring\n        connect_options = connect_options.application_name(\"midi-library-pipeline\");\n\n        // Calculate minimum connections (20% of max, but at least 5)\n        let min_connections = (pool_size as f64 * 0.2).max(5.0) as u32;\n\n        // Build optimized connection pool (OPTIMIZATION #1)\n        let pool = PgPoolOptions::new()\n            // Dynamic max connections - auto-tuned based on CPU cores and RAM\n            // Formula: (concurrency  1.5).clamp(20, 200)\n            .max_connections(pool_size as u32)\n\n            // Dynamic min connections - scales with pool size (20% of max, min 5)\n            // Keeps connections warm for better performance\n            .min_connections(min_connections)\n\n            // 10s acquire timeout - fail fast for better UX\n            // Reduced from 30s to detect issues earlier\n            .acquire_timeout(Duration::from_secs(10))\n\n            // 30min max lifetime - prevents connection leaks\n            // Balances connection reuse with freshness\n            .max_lifetime(Duration::from_secs(1800))\n\n            // 5min idle timeout - recycles idle connections faster\n            // Reduced from 10min for better resource management\n            .idle_timeout(Duration::from_secs(300))\n\n            // Test before acquire - validates connection health\n            // Prevents using stale/broken connections\n            .test_before_acquire(true)\n\n            // Connect with optimized options\n            .connect_with(connect_options)\n            .await?;\n\n        println!(\" Database connected successfully\");\n        println!(\" Pool configuration: {} max, {} min, 10s timeout\",\n                 pool_size, min_connections);\n        println!(\" Prepared statement cache: enabled (100 statements)\");\n        println!(\" Expected performance: ~{} files/sec parallel import\",\n                 concurrency * 25);\n\n        Ok(Self {\n            pool: Arc::new(RwLock::new(pool)),\n            database_url: database_url.to_string(),\n            reconnect_attempts: Arc::new(RwLock::new(0)),\n        })\n    }\n\n    /// Get cloned connection pool for use in queries\n    ///\n    /// Returns a cloned reference to the underlying PgPool.\n    /// PgPool uses Arc internally, so cloning is cheap (just increments ref count).\n    ///\n    /// # Returns\n    ///\n    /// * `PgPool` - Cloned pool reference\n    ///\n    /// # Performance Notes\n    ///\n    /// - Clone operation: \u003c 1s (just Arc clone)\n    /// - Connection acquisition: \u003c 5ms with warm pool\n    /// - Automatic connection health validation\n    /// - Thread-safe for concurrent access\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let pool = db.pool().await;\n    /// sqlx::query(\"SELECT * FROM files\").fetch_all(\u0026pool).await?;\n    /// ```\n    pub async fn pool(\u0026self) -\u003e PgPool {\n        self.pool.read().await.clone()\n    }\n\n    /// Attempt to reconnect to the database with exponential backoff\n    ///\n    /// Implements automatic reconnection with exponential backoff strategy:\n    /// - Initial delay: 1 second\n    /// - Max delay: 30 seconds\n    /// - Max attempts: 5\n    /// - Backoff multiplier: 2x\n    ///\n    /// ## Reconnection Strategy:\n    /// 1. Attempt 1: Wait 1s before retry\n    /// 2. Attempt 2: Wait 2s before retry\n    /// 3. Attempt 3: Wait 4s before retry\n    /// 4. Attempt 4: Wait 8s before retry\n    /// 5. Attempt 5: Wait 16s before retry (capped at 30s)\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003c(), sqlx::Error\u003e` - Ok if reconnection successful\n    ///\n    /// # Errors\n    ///\n    /// Returns error if all reconnection attempts fail\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// if let Err(e) = db.reconnect().await {\n    ///     eprintln!(\"Failed to reconnect: {}\", e);\n    /// }\n    /// ```\n    pub async fn reconnect(\u0026self) -\u003e Result\u003c(), sqlx::Error\u003e {\n        const MAX_ATTEMPTS: u32 = 5;\n        const MAX_DELAY_SECS: u64 = 30;\n\n        let mut attempts = self.reconnect_attempts.write().await;\n        *attempts = 0;\n\n        println!(\" Attempting database reconnection...\");\n\n        for attempt in 1..=MAX_ATTEMPTS {\n            *attempts = attempt;\n\n            // Calculate delay with exponential backoff (1s, 2s, 4s, 8s, 16s)\n            let delay_secs = std::cmp::min(2_u64.pow(attempt - 1), MAX_DELAY_SECS);\n\n            if attempt \u003e 1 {\n                println!(\" Waiting {} seconds before reconnection attempt {}/{}...\",\n                    delay_secs, attempt, MAX_ATTEMPTS);\n                tokio::time::sleep(Duration::from_secs(delay_secs)).await;\n            }\n\n            println!(\" Reconnection attempt {}/{}\", attempt, MAX_ATTEMPTS);\n\n            match Self::create_pool(\u0026self.database_url).await {\n                Ok(new_pool) =\u003e {\n                    // Successfully reconnected - replace pool\n                    let mut pool = self.pool.write().await;\n                    *pool = new_pool;\n                    *attempts = 0;\n\n                    println!(\" Database reconnected successfully on attempt {}\", attempt);\n                    return Ok(());\n                }\n                Err(e) =\u003e {\n                    eprintln!(\" Reconnection attempt {} failed: {}\", attempt, e);\n\n                    if attempt == MAX_ATTEMPTS {\n                        eprintln!(\" All reconnection attempts exhausted\");\n                        return Err(e);\n                    }\n                }\n            }\n        }\n\n        Err(sqlx::Error::PoolTimedOut)\n    }\n\n    /// Internal helper to create a new connection pool\n    ///\n    /// Extracted from `new()` for reuse in reconnection logic.\n    async fn create_pool(database_url: \u0026str) -\u003e Result\u003cPgPool, sqlx::Error\u003e {\n        // Get dynamic pool settings\n        let (_, pool_size, _) = calculate_all_settings();\n        let min_connections = (pool_size as f64 * 0.2).max(5.0) as u32;\n\n        let mut connect_options = PgConnectOptions::from_str(database_url)?;\n        connect_options = connect_options.statement_cache_capacity(100);\n        connect_options = connect_options.application_name(\"midi-library-pipeline\");\n\n        let pool = PgPoolOptions::new()\n            .max_connections(pool_size as u32)\n            .min_connections(min_connections)\n            .acquire_timeout(Duration::from_secs(10))\n            .max_lifetime(Duration::from_secs(1800))\n            .idle_timeout(Duration::from_secs(300))\n            .test_before_acquire(true)\n            .connect_with(connect_options)\n            .await?;\n\n        Ok(pool)\n    }\n\n    /// Execute operation with automatic reconnection on connection loss\n    ///\n    /// Wraps database operations with automatic reconnection logic.\n    /// If operation fails due to connection issues, attempts to reconnect\n    /// and retry the operation once.\n    ///\n    /// ## Recovery Strategy:\n    /// 1. Execute operation\n    /// 2. If connection error detected  reconnect\n    /// 3. Retry operation once after reconnection\n    /// 4. If still fails  return error\n    ///\n    /// # Arguments\n    ///\n    /// * `operation` - Async operation to execute\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cT, sqlx::Error\u003e` - Operation result\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let count = db.execute_with_reconnect(|| async {\n    ///     sqlx::query_scalar::\u003c_, i64\u003e(\"SELECT COUNT(*) FROM files\")\n    ///         .fetch_one(\u0026db.pool().await)\n    ///         .await\n    /// }).await?;\n    /// ```\n    pub async fn execute_with_reconnect\u003cT, F, Fut\u003e(\n        \u0026self,\n        operation: F,\n    ) -\u003e Result\u003cT, sqlx::Error\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: Future\u003cOutput = Result\u003cT, sqlx::Error\u003e\u003e,\n    {\n        // Try operation first\n        match operation().await {\n            Ok(result) =\u003e Ok(result),\n            Err(e) if is_connection_error(\u0026e) =\u003e {\n                eprintln!(\"  Connection error detected: {}. Attempting reconnection...\", e);\n\n                // Try to reconnect\n                if let Err(reconnect_err) = self.reconnect().await {\n                    eprintln!(\" Reconnection failed: {}\", reconnect_err);\n                    return Err(e); // Return original error\n                }\n\n                // Retry operation after successful reconnection\n                println!(\" Retrying operation after reconnection...\");\n                match operation().await {\n                    Ok(result) =\u003e {\n                        println!(\" Operation succeeded after reconnection\");\n                        Ok(result)\n                    }\n                    Err(retry_err) =\u003e {\n                        eprintln!(\" Operation failed even after reconnection: {}\", retry_err);\n                        Err(retry_err)\n                    }\n                }\n            }\n            Err(e) =\u003e Err(e),\n        }\n    }\n\n    /// Convert technical database errors to user-friendly messages\n    ///\n    /// Transforms low-level PostgreSQL/sqlx errors into messages that\n    /// users can understand and potentially act upon.\n    ///\n    /// # Arguments\n    ///\n    /// * `error` - Database error to convert\n    ///\n    /// # Returns\n    ///\n    /// * `String` - User-friendly error message with context\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let friendly_msg = db.create_user_friendly_error(\u0026err);\n    /// // Returns: \"Database connection lost. Please check your connection and try again.\"\n    /// ```\n    pub fn create_user_friendly_error(\u0026self, error: \u0026sqlx::Error) -\u003e String {\n        match error {\n            // Connection errors\n            sqlx::Error::PoolTimedOut =\u003e {\n                \"Database is busy. Too many concurrent requests. Please try again in a moment.\".to_string()\n            }\n            sqlx::Error::PoolClosed =\u003e {\n                \"Database connection lost. The application is attempting to reconnect...\".to_string()\n            }\n            sqlx::Error::Io(io_err) =\u003e {\n                format!(\"Network error while connecting to database: {}. Please check your connection.\",\n                    io_err)\n            }\n\n            // Query errors\n            sqlx::Error::RowNotFound =\u003e {\n                \"The requested item was not found in the database.\".to_string()\n            }\n            sqlx::Error::ColumnNotFound(col) =\u003e {\n                format!(\"Database structure error: Column '{}' not found. Please update your database schema.\", col)\n            }\n\n            // Database errors with detailed handling\n            sqlx::Error::Database(db_err) =\u003e {\n                let code = db_err.code().unwrap_or_default();\n\n                match code.as_ref() {\n                    // Unique constraint violation\n                    \"23505\" =\u003e \"This item already exists in the database. Duplicate entries are not allowed.\".to_string(),\n\n                    // Foreign key violation\n                    \"23503\" =\u003e \"Cannot perform this operation because it would violate data relationships.\".to_string(),\n\n                    // Not null violation\n                    \"23502\" =\u003e \"Required field is missing. Please provide all required information.\".to_string(),\n\n                    // Connection errors\n                    \"08000\" | \"08003\" | \"08006\" =\u003e {\n                        \"Database connection error. Please check that the database is running and try again.\".to_string()\n                    }\n\n                    // Syntax errors\n                    \"42601\" | \"42P01\" =\u003e {\n                        format!(\"Database query error: {}. This may indicate a software bug.\", db_err.message())\n                    }\n\n                    // Permission errors\n                    \"42501\" =\u003e \"Database permission denied. Please check your database user permissions.\".to_string(),\n\n                    // Default for other database errors\n                    _ =\u003e format!(\"Database error ({}): {}. Please contact support if this persists.\",\n                        code, db_err.message())\n                }\n            }\n\n            // Timeout\n            sqlx::Error::WorkerCrashed =\u003e {\n                \"Database operation failed unexpectedly. Please try again.\".to_string()\n            }\n\n            // Type conversion errors\n            sqlx::Error::Decode(decode_err) =\u003e {\n                format!(\"Data format error: {}. The database may contain unexpected data.\", decode_err)\n            }\n\n            // Default fallback\n            _ =\u003e {\n                format!(\"An unexpected database error occurred: {}. Please try again or contact support.\", error)\n            }\n        }\n    }\n\n    /// Test database connection\n    ///\n    /// Executes a simple query to verify database connectivity.\n    /// Uses a lightweight query that doesn't require table access.\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cbool, sqlx::Error\u003e` - True if connected, error otherwise\n    ///\n    /// # Performance\n    ///\n    /// - Typical execution: 1-5ms\n    /// - Network latency: 0-2ms (localhost)\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// if db.test_connection().await? {\n    ///     println!(\" Database is reachable\");\n    /// }\n    /// ```\n    pub async fn test_connection(\u0026self) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let pool = self.pool().await;\n        sqlx::query(\"SELECT 1\")\n            .fetch_one(\u0026pool)\n            .await?;\n        Ok(true)\n    }\n\n    /// Execute operation with automatic retry and exponential backoff (OPTIMIZATION #4)\n    ///\n    /// Retries transient database errors (connection timeouts, pool exhaustion, I/O errors)\n    /// with exponential backoff to handle temporary failures gracefully.\n    ///\n    /// ## Retry Strategy:\n    /// - Initial delay: 100ms\n    /// - Backoff multiplier: 2x (exponential)\n    /// - Max retries: configurable (typically 3-5)\n    /// - Only retries transient errors\n    ///\n    /// ## Transient Errors (retried):\n    /// - `PoolTimedOut`: Pool exhausted, retry after delay\n    /// - `PoolClosed`: Connection pool closing\n    /// - `Io`: Network I/O errors\n    ///\n    /// ## Non-Transient Errors (fail immediately):\n    /// - Query syntax errors\n    /// - Permission denied\n    /// - Table/column not found\n    /// - Constraint violations\n    ///\n    /// # Arguments\n    ///\n    /// * `max_retries` - Maximum retry attempts (typically 3-5)\n    /// * `operation` - Async operation to execute\n    ///\n    /// # Returns\n    ///\n    /// * `Result\u003cT, sqlx::Error\u003e` - Operation result or final error\n    ///\n    /// # Performance Impact\n    ///\n    /// - Success case: no overhead\n    /// - Retry case: adds 100ms, 200ms, 400ms delays (exponential)\n    /// - Total retry time for 3 retries: ~700ms\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// // Retry up to 3 times for transient failures\n    /// let files = db.execute_with_retry(3, || async {\n    ///     sqlx::query_as::\u003c_, MidiFile\u003e(\"SELECT * FROM files WHERE bpm \u003e $1\")\n    ///         .bind(120)\n    ///         .fetch_all(db.pool())\n    ///         .await\n    /// }).await?;\n    /// ```\n    pub async fn execute_with_retry\u003cT, F, Fut\u003e(\n        \u0026self,\n        max_retries: u32,\n        operation: F,\n    ) -\u003e Result\u003cT, sqlx::Error\u003e\n    where\n        F: Fn() -\u003e Fut,\n        Fut: Future\u003cOutput = Result\u003cT, sqlx::Error\u003e\u003e,\n    {\n        let mut retries = 0;\n        let mut delay = Duration::from_millis(100); // Start with 100ms\n\n        loop {\n            match operation().await {\n                Ok(result) =\u003e return Ok(result),\n                Err(e) if retries \u003c max_retries \u0026\u0026 is_transient_error(\u0026e) =\u003e {\n                    retries += 1;\n                    eprintln!(\n                        \"  Database operation failed (attempt {}/{}): {}. Retrying in {:?}...\",\n                        retries, max_retries, e, delay\n                    );\n                    tokio::time::sleep(delay).await;\n                    delay = delay * 2; // Exponential backoff\n                }\n                Err(e) =\u003e {\n                    if retries \u003e 0 {\n                        eprintln!(\" Database operation failed after {} retries: {}\", retries, e);\n                    }\n                    return Err(e);\n                }\n            }\n        }\n    }\n\n    /// Get connection pool statistics (OPTIMIZATION #5)\n    ///\n    /// Returns current pool statistics for monitoring and debugging.\n    /// Useful for capacity planning and performance troubleshooting.\n    ///\n    /// ## Metrics Provided:\n    /// - Total connections: Current pool size\n    /// - Idle connections: Available for immediate use\n    /// - Active connections: Currently executing queries\n    ///\n    /// ## Healthy Pool Indicators:\n    /// - Idle \u003e 0: Connections available\n    /// - Active \u003c max: Not at capacity\n    /// - Size \u003e= min: Pool properly initialized\n    ///\n    /// # Returns\n    ///\n    /// * `PoolStats` - Current pool statistics\n    ///\n    /// # Performance\n    ///\n    /// - Execution time: \u003c 1s (no I/O, just reads atomic counters)\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let stats = db.get_pool_stats();\n    /// println!(\"Pool utilization: {}/{} ({} idle)\",\n    ///     stats.active, stats.size, stats.idle);\n    ///\n    /// if stats.idle == 0 {\n    ///     println!(\"  Warning: Connection pool exhausted!\");\n    /// }\n    /// ```\n    pub async fn get_pool_stats(\u0026self) -\u003e PoolStats {\n        let pool = self.pool.read().await;\n        let size = pool.size();\n        let idle = pool.num_idle();\n        let active = size as usize - idle;\n\n        PoolStats {\n            size,\n            idle,\n            active,\n        }\n    }\n\n    /// Comprehensive health check (OPTIMIZATION #5)\n    ///\n    /// Performs multiple health checks to verify database is fully operational.\n    /// More thorough than `test_connection()`, includes pool health and timing.\n    ///\n    /// ## Health Checks Performed:\n    /// 1. Connection pool statistics (capacity check)\n    /// 2. Simple query execution (connectivity check)\n    /// 3. Response time measurement (performance check)\n    ///\n    /// ## Health Status:\n    /// - **Healthy**: All checks pass, response \u003c 100ms\n    /// - **Degraded**: Checks pass but slow (100-1000ms)\n    /// - **Unhealthy**: Checks fail or response \u003e 1000ms\n    ///\n    /// # Returns\n    ///\n    /// * `HealthStatus` - Comprehensive health information\n    ///\n    /// # Performance\n    ///\n    /// - Typical execution: 1-10ms\n    /// - Degraded: 100-1000ms\n    /// - Failed: \u003e 1000ms or error\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// let health = db.health_check().await;\n    /// if health.is_healthy {\n    ///     println!(\" Database healthy ({} ms)\", health.response_time_ms);\n    /// } else {\n    ///     println!(\" Database unhealthy: pool={:?}, connection={}\",\n    ///         health.pool_stats, health.connection_test);\n    /// }\n    /// ```\n    pub async fn health_check(\u0026self) -\u003e HealthStatus {\n        let start = Instant::now();\n\n        // Check 1: Pool statistics\n        let pool_stats = self.get_pool_stats().await;\n\n        // Check 2: Connection test\n        let connection_test = self.test_connection().await.is_ok();\n\n        // Measure response time\n        let response_time_ms = start.elapsed().as_millis() as u64;\n\n        // Determine overall health\n        let is_healthy = connection_test\n            \u0026\u0026 pool_stats.size \u003e 0\n            \u0026\u0026 response_time_ms \u003c 1000; // Consider unhealthy if \u003e 1s response\n\n        // Log slow health checks (OPTIMIZATION #6 - slow query logging)\n        if response_time_ms \u003e 100 {\n            eprintln!(\"  Slow health check: {} ms (threshold: 100ms)\", response_time_ms);\n        }\n\n        HealthStatus {\n            is_healthy,\n            pool_stats,\n            connection_test,\n            response_time_ms,\n        }\n    }\n\n    /// Close all connections gracefully\n    ///\n    /// Gracefully closes all connections in the pool.\n    /// Should be called during application shutdown to clean up resources.\n    ///\n    /// ## Shutdown Process:\n    /// 1. Stop accepting new connections\n    /// 2. Wait for active queries to complete (with timeout)\n    /// 3. Close idle connections\n    /// 4. Close remaining connections\n    ///\n    /// # Performance\n    ///\n    /// - Typical shutdown: 100-500ms\n    /// - Waits for active queries to complete\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// // During application shutdown\n    /// db.close().await;\n    /// ```\n    pub async fn close(\u0026self) {\n        println!(\" Closing database connections...\");\n        let pool = self.pool.read().await;\n        pool.close().await;\n        println!(\" All connections closed\");\n    }\n}\n\n/// Connection pool statistics\n///\n/// Provides monitoring information about the connection pool state.\n/// Used for capacity planning, performance monitoring, and debugging.\n#[derive(Debug, Clone)]\npub struct PoolStats {\n    /// Total number of connections in the pool\n    pub size: u32,\n    /// Number of idle connections available for immediate use\n    pub idle: usize,\n    /// Number of active connections currently executing queries\n    pub active: usize,\n}\n\nimpl std::fmt::Display for PoolStats {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(\n            f,\n            \"Pool: {} total, {} idle, {} active\",\n            self.size, self.idle, self.active\n        )\n    }\n}\n\n/// Comprehensive health status information\n///\n/// Contains detailed health check results for monitoring and diagnostics.\n#[derive(Debug, Clone)]\npub struct HealthStatus {\n    /// Overall health status (true = healthy, false = unhealthy)\n    pub is_healthy: bool,\n    /// Current connection pool statistics\n    pub pool_stats: PoolStats,\n    /// Connection test result (true = connected, false = failed)\n    pub connection_test: bool,\n    /// Response time for health check in milliseconds\n    pub response_time_ms: u64,\n}\n\nimpl std::fmt::Display for HealthStatus {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        let status = if self.is_healthy { \"HEALTHY \" } else { \"UNHEALTHY \" };\n        write!(\n            f,\n            \"{} - Response: {}ms, {}, Connection: {}\",\n            status,\n            self.response_time_ms,\n            self.pool_stats,\n            if self.connection_test { \"OK\" } else { \"FAILED\" }\n        )\n    }\n}\n\n/// Check if error is transient and can be retried\n///\n/// Transient errors are temporary failures that may succeed on retry.\n/// Non-transient errors are permanent failures that won't change on retry.\n///\n/// # Arguments\n///\n/// * `error` - Database error to check\n///\n/// # Returns\n///\n/// * `bool` - True if error is transient and should be retried\nfn is_transient_error(error: \u0026sqlx::Error) -\u003e bool {\n    match error {\n        // Pool exhaustion - may recover as connections are released\n        sqlx::Error::PoolTimedOut =\u003e true,\n\n        // Pool closing - may be temporary during reconnection\n        sqlx::Error::PoolClosed =\u003e true,\n\n        // Network I/O errors - may be temporary network issues\n        sqlx::Error::Io(_) =\u003e true,\n\n        // All other errors are non-transient\n        _ =\u003e false,\n    }\n}\n\n/// Check if error is a connection error that requires reconnection\n///\n/// Connection errors indicate the database connection is broken and\n/// needs to be re-established before operations can continue.\n///\n/// # Arguments\n///\n/// * `error` - Database error to check\n///\n/// # Returns\n///\n/// * `bool` - True if error indicates connection loss\nfn is_connection_error(error: \u0026sqlx::Error) -\u003e bool {\n    match error {\n        // Connection pool closed - requires reconnection\n        sqlx::Error::PoolClosed =\u003e true,\n\n        // Network I/O errors - likely connection loss\n        sqlx::Error::Io(_) =\u003e true,\n\n        // Check for specific database connection errors\n        sqlx::Error::Database(db_err) =\u003e {\n            let code = db_err.code().unwrap_or_default();\n            matches!(code.as_ref(), \"08000\" | \"08003\" | \"08006\" | \"57P01\" | \"57P02\" | \"57P03\")\n        }\n\n        // All other errors are not connection errors\n        _ =\u003e false,\n    }\n}\n\n// ============================================================================\n// TESTS\n// ============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    const TEST_DATABASE_URL: \u0026str = \"postgresql://midiuser:145278963@localhost:5433/midi_library\";\n\n    /// Test database connection with optimized settings\n    #[tokio::test]\n    async fn test_database_connection() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let is_connected = db\n            .test_connection()\n            .await\n            .expect(\"Connection test failed\");\n\n        assert!(is_connected);\n    }\n\n    /// Test pool statistics with optimized pool\n    #[tokio::test]\n    async fn test_pool_stats() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let stats = db.get_pool_stats().await;\n\n        // Should have at least min_connections (10) in optimized pool\n        assert!(stats.size \u003e= 10, \"Pool size should be \u003e= 10, got {}\", stats.size);\n        assert_eq!(stats.idle + stats.active, stats.size as usize);\n        println!(\" {}\", stats);\n    }\n\n    /// Test health check functionality\n    #[tokio::test]\n    async fn test_health_check() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let health = db.health_check().await;\n\n        assert!(health.is_healthy, \"Database should be healthy\");\n        assert!(health.connection_test, \"Connection test should pass\");\n        assert!(health.response_time_ms \u003c 1000, \"Response time should be \u003c 1s\");\n        assert!(health.pool_stats.size \u003e 0, \"Pool should have connections\");\n\n        println!(\" {}\", health);\n    }\n\n    /// Test retry logic with successful operation\n    #[tokio::test]\n    async fn test_retry_success() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let result = db.execute_with_retry(3, || async {\n            let pool = db.pool().await;\n            sqlx::query_as::\u003c_, (i32,)\u003e(\"SELECT 1\")\n                .fetch_one(\u0026pool)\n                .await\n        }).await;\n\n        assert!(result.is_ok(), \"Retry should succeed on first attempt\");\n        assert_eq!(result.unwrap().0, 1);\n    }\n\n    /// Test pool reference access with optimized pool\n    #[tokio::test]\n    async fn test_pool_reference() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let pool = db.pool().await;\n\n        // Execute query using pool reference\n        let result: (i32,) = sqlx::query_as(\"SELECT 1\")\n            .fetch_one(\u0026pool)\n            .await\n            .expect(\"Query failed\");\n\n        assert_eq!(result.0, 1);\n    }\n\n    /// Test graceful shutdown\n    #[tokio::test]\n    async fn test_close_connections() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        // Verify pool is active\n        let pool = db.pool().await;\n        assert!(pool.size() \u003e 0, \"Pool should be initialized\");\n\n        // Close connections\n        db.close().await;\n\n        // Pool should be closed (size = 0)\n        let pool_after = db.pool().await;\n        assert_eq!(pool_after.size(), 0, \"Pool should be closed\");\n    }\n\n    /// Test prepared statement cache is enabled\n    #[tokio::test]\n    async fn test_prepared_statement_cache() {\n        let db = Database::new(TEST_DATABASE_URL)\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let pool = db.pool().await;\n\n        // Execute same query multiple times - should benefit from cache\n        for _ in 0..10 {\n            let _: (i32,) = sqlx::query_as(\"SELECT 1\")\n                .fetch_one(\u0026pool)\n                .await\n                .expect(\"Query failed\");\n        }\n\n        // If cache is working, these queries should be fast\n        // No direct way to verify cache hits, but performance should improve\n        println!(\" Prepared statement cache test completed\");\n    }\n}\n","traces":[{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":29},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","mod.rs"],"content":"//! Database module\n\npub mod models;\npub mod repositories;\n\npub use repositories::{FileRepository, MetadataRepository, SearchQuery, SearchRepository};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","models.rs"],"content":"//! Database models aligned with actual schema\n//!\n//! These models match the database schema from 001_initial_schema.sql\n//! Database: midi_library on port 5433\n\nuse chrono::{DateTime, Utc};\nuse serde::Deserialize;\nuse sqlx::types::BigDecimal;\nuse sqlx::FromRow;\nuse uuid::Uuid;\n\n// =============================================================================\n// FILES TABLE\n// =============================================================================\n\n/// File record from database (aligned with schema)\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone, FromRow)]\npub struct File {\n    pub id: i64,\n\n    // File identification\n    pub filename: String,\n    pub filepath: String,\n    pub original_filename: String,\n    pub content_hash: Vec\u003cu8\u003e,\n    pub file_size_bytes: i64,\n\n    // MIDI format\n    pub format: Option\u003ci16\u003e,\n    pub num_tracks: i16,\n    pub ticks_per_quarter_note: Option\u003ci32\u003e,\n\n    // Duration\n    pub duration_seconds: Option\u003cBigDecimal\u003e,\n    pub duration_ticks: Option\u003ci64\u003e,\n\n    // Multi-track handling\n    pub is_multi_track: Option\u003cbool\u003e,\n    pub parent_file_id: Option\u003ci64\u003e,\n    pub track_number: Option\u003ci16\u003e,\n    pub total_tracks: Option\u003ci16\u003e,\n\n    // Extracted context\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    pub folder_tags: Option\u003cVec\u003cString\u003e\u003e,\n\n    // Timestamps\n    pub created_at: DateTime\u003cUtc\u003e,\n    pub updated_at: DateTime\u003cUtc\u003e,\n    pub analyzed_at: Option\u003cDateTime\u003cUtc\u003e\u003e,\n\n    // Processing\n    pub import_batch_id: Option\u003cUuid\u003e,\n}\n\n/// New file for insertion\n#[derive(Debug, Clone)]\npub struct NewFile {\n    pub filename: String,\n    pub filepath: String,\n    pub original_filename: String,\n    pub content_hash: Vec\u003cu8\u003e,\n    pub file_size_bytes: i64,\n    pub format: Option\u003ci16\u003e,\n    pub num_tracks: i16,\n    pub ticks_per_quarter_note: Option\u003ci32\u003e,\n    pub duration_seconds: Option\u003cBigDecimal\u003e,\n    pub duration_ticks: Option\u003ci64\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection_name: Option\u003cString\u003e,\n    pub folder_tags: Option\u003cVec\u003cString\u003e\u003e,\n    pub import_batch_id: Option\u003cUuid\u003e,\n}\n\n// =============================================================================\n// MUSICAL_METADATA TABLE\n// =============================================================================\n\n/// Musical metadata from database (aligned with schema)\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone, FromRow)]\npub struct MusicalMetadata {\n    pub file_id: i64,\n\n    // Tempo\n    pub bpm: Option\u003cBigDecimal\u003e,\n    pub bpm_confidence: Option\u003cf32\u003e,\n    pub has_tempo_changes: Option\u003cbool\u003e,\n    pub tempo_changes: Option\u003cserde_json::Value\u003e,\n\n    // Key signature (enum type in database)\n    pub key_signature: Option\u003cString\u003e,  // We'll handle the enum as String\n    pub key_confidence: Option\u003cf32\u003e,\n    pub has_key_changes: Option\u003cbool\u003e,\n    pub key_changes: Option\u003cserde_json::Value\u003e,\n\n    // Time signature\n    pub time_signature_numerator: Option\u003ci16\u003e,\n    pub time_signature_denominator: Option\u003ci16\u003e,\n    pub has_time_signature_changes: Option\u003cbool\u003e,\n    pub time_signature_changes: Option\u003cserde_json::Value\u003e,\n\n    // Note statistics\n    pub total_notes: i32,\n    pub unique_pitches: Option\u003ci32\u003e,\n    pub pitch_range_min: Option\u003ci16\u003e,\n    pub pitch_range_max: Option\u003ci16\u003e,\n    pub avg_velocity: Option\u003cBigDecimal\u003e,\n\n    // Density metrics\n    pub note_density: Option\u003cBigDecimal\u003e,\n    pub polyphony_max: Option\u003ci16\u003e,\n    pub polyphony_avg: Option\u003cBigDecimal\u003e,\n\n    // Musical characteristics\n    pub is_monophonic: Option\u003cbool\u003e,\n    pub is_polyphonic: Option\u003cbool\u003e,\n    pub is_percussive: Option\u003cbool\u003e,\n\n    // Chord analysis\n    pub has_chords: Option\u003cbool\u003e,\n    pub chord_complexity: Option\u003cf32\u003e,\n\n    // Melody analysis\n    pub has_melody: Option\u003cbool\u003e,\n    pub melodic_range: Option\u003ci16\u003e,\n\n    pub created_at: DateTime\u003cUtc\u003e,\n}\n\n/// New musical metadata for insertion\n#[derive(Debug, Clone)]\npub struct NewMusicalMetadata {\n    pub file_id: i64,\n    pub bpm: Option\u003cBigDecimal\u003e,\n    pub bpm_confidence: Option\u003cf32\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub key_confidence: Option\u003cf32\u003e,\n    pub time_signature_numerator: Option\u003ci16\u003e,\n    pub time_signature_denominator: Option\u003ci16\u003e,\n    pub total_notes: i32,\n    pub unique_pitches: Option\u003ci32\u003e,\n    pub pitch_range_min: Option\u003ci16\u003e,\n    pub pitch_range_max: Option\u003ci16\u003e,\n    pub avg_velocity: Option\u003cBigDecimal\u003e,\n    pub note_density: Option\u003cBigDecimal\u003e,\n    pub polyphony_max: Option\u003ci16\u003e,\n    pub polyphony_avg: Option\u003cBigDecimal\u003e,\n    pub is_percussive: Option\u003cbool\u003e,\n}\n\n// =============================================================================\n// SEARCH \u0026 QUERY MODELS\n// =============================================================================\n\n/// Search filters from frontend\n#[derive(Debug, Clone, Deserialize)]\npub struct SearchFilters {\n    pub category: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key_signatures: Option\u003cVec\u003cString\u003e\u003e,\n    pub min_duration: Option\u003cf64\u003e,\n    pub max_duration: Option\u003cf64\u003e,\n}\n\n/// Search result combining file and metadata\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct FileSearchResult {\n    pub id: i64,\n    pub filename: String,\n    pub filepath: String,\n    pub bpm: Option\u003cf64\u003e,\n    pub key_signature: Option\u003cString\u003e,\n    pub duration_seconds: Option\u003cf64\u003e,\n    pub total_notes: i32,\n    pub category: Option\u003cString\u003e,\n}\n\n/// Paginated search results\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct SearchResults {\n    pub files: Vec\u003cFileSearchResult\u003e,\n    pub total_count: i64,\n    pub page: i32,\n    pub page_size: i32,\n    pub total_pages: i32,\n}\n\n/// Detailed file view with metadata\n// TODO: Fix BigDecimal serde support - temporarily disabled\n#[derive(Debug, Clone)]\npub struct FileWithMetadata {\n    pub file: File,\n    pub metadata: Option\u003cMusicalMetadata\u003e,\n}\n\n// =============================================================================\n// TYPE CONVERSION HELPERS\n// =============================================================================\n\nuse num_traits::ToPrimitive;\n\n/// Convert BigDecimal to f64\npub fn bigdecimal_to_f64(bd: Option\u003cBigDecimal\u003e) -\u003e Option\u003cf64\u003e {\n    bd.and_then(|b| b.to_f64())\n}\n\n/// Convert f64 to BigDecimal\npub fn f64_to_bigdecimal(val: Option\u003cf64\u003e) -\u003e Option\u003cBigDecimal\u003e {\n    use num_traits::FromPrimitive;\n    val.and_then(|v| BigDecimal::from_f64(v))\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","file_repository.rs"],"content":"//! File repository - CRUD operations for files table\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::{File, NewFile};\nuse sqlx::PgPool;\n\npub struct FileRepository;\n\nimpl FileRepository {\n    /// Inserts a new file and returns its ID\n    pub async fn insert(pool: \u0026PgPool, new_file: NewFile) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let file_id = sqlx::query_scalar!(\n            r#\"\n            INSERT INTO files (\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                import_batch_id\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\n            RETURNING id\n            \"#,\n            new_file.filename,\n            new_file.filepath,\n            new_file.original_filename,\n            \u0026new_file.content_hash[..],\n            new_file.file_size_bytes,\n            new_file.format,\n            new_file.num_tracks,\n            new_file.ticks_per_quarter_note,\n            new_file.duration_seconds,\n            new_file.duration_ticks,\n            new_file.manufacturer,\n            new_file.collection_name,\n            new_file.folder_tags.as_deref(),\n            new_file.import_batch_id,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(file_id)\n    }\n\n    /// Finds file by ID\n    pub async fn find_by_id(pool: \u0026PgPool, id: i64) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE id = $1\n            \"#,\n            id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Checks if file with hash already exists\n    pub async fn check_duplicate(pool: \u0026PgPool, content_hash: \u0026[u8]) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files\n            WHERE content_hash = $1\n            \"#,\n            content_hash\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count \u003e 0)\n    }\n\n    /// Finds file by hash\n    pub async fn find_by_hash(\n        pool: \u0026PgPool,\n        content_hash: \u0026[u8],\n    ) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE content_hash = $1 LIMIT 1\n            \"#,\n            content_hash\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Finds file by filepath\n    pub async fn find_by_path(pool: \u0026PgPool, filepath: \u0026str) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let file = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files WHERE filepath = $1\n            \"#,\n            filepath\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(file)\n    }\n\n    /// Updates file's analyzed_at timestamp\n    pub async fn mark_analyzed(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE files\n            SET analyzed_at = NOW(), updated_at = NOW()\n            WHERE id = $1\n            \"#,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates file metadata fields\n    pub async fn update_metadata_fields(\n        pool: \u0026PgPool,\n        file_id: i64,\n        format: Option\u003ci16\u003e,\n        num_tracks: i16,\n        ticks_per_quarter_note: Option\u003ci32\u003e,\n        duration_seconds: Option\u003csqlx::types::BigDecimal\u003e,\n        duration_ticks: Option\u003ci64\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE files\n            SET\n                format = $2,\n                num_tracks = $3,\n                ticks_per_quarter_note = $4,\n                duration_seconds = $5,\n                duration_ticks = $6,\n                updated_at = NOW()\n            WHERE id = $1\n            \"#,\n            file_id,\n            format,\n            num_tracks,\n            ticks_per_quarter_note,\n            duration_seconds,\n            duration_ticks\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Deletes file by ID\n    pub async fn delete(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\"DELETE FROM files WHERE id = $1\", file_id)\n            .execute(pool)\n            .await?;\n\n        Ok(())\n    }\n\n    /// Gets file count\n    pub async fn count(pool: \u0026PgPool) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(r#\"SELECT COUNT(*) as \"count!\" FROM files\"#)\n            .fetch_one(pool)\n            .await?;\n\n        Ok(count)\n    }\n\n    /// Lists files with pagination\n    pub async fn list(pool: \u0026PgPool, limit: i64, offset: i64) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            ORDER BY created_at DESC\n            LIMIT $1 OFFSET $2\n            \"#,\n            limit,\n            offset\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Lists files by manufacturer\n    pub async fn list_by_manufacturer(\n        pool: \u0026PgPool,\n        manufacturer: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE manufacturer = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            manufacturer,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Lists files by collection\n    pub async fn list_by_collection(\n        pool: \u0026PgPool,\n        collection_name: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE collection_name = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            collection_name,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_insert_and_find() {\n        let pool = setup_test_pool().await;\n\n        let new_file = NewFile {\n            filename: \"test_file.mid\".to_string(),\n            filepath: \"/test/test_file.mid\".to_string(),\n            original_filename: \"test_file.mid\".to_string(),\n            content_hash: vec![1, 2, 3, 4, 5, 6, 7, 8],\n            file_size_bytes: 1024,\n            format: Some(1),\n            num_tracks: 1,\n            ticks_per_quarter_note: Some(480),\n            duration_seconds: None,\n            duration_ticks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: None,\n            import_batch_id: None,\n        };\n\n        let file_id = FileRepository::insert(\u0026pool, new_file).await.unwrap();\n        assert!(file_id \u003e 0);\n\n        let found = FileRepository::find_by_id(\u0026pool, file_id).await.unwrap();\n        assert!(found.is_some());\n\n        let file = found.unwrap();\n        assert_eq!(file.id, file_id);\n        assert_eq!(file.filename, \"test_file.mid\");\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_check_duplicate() {\n        let pool = setup_test_pool().await;\n\n        let hash = vec![9, 9, 9, 9, 9, 9, 9, 9];\n\n        // Should not exist initially\n        let exists = FileRepository::check_duplicate(\u0026pool, \u0026hash).await.unwrap();\n        assert!(!exists);\n\n        // Insert file\n        let new_file = NewFile {\n            filename: \"dup_test.mid\".to_string(),\n            filepath: \"/test/dup_test.mid\".to_string(),\n            original_filename: \"dup_test.mid\".to_string(),\n            content_hash: hash.clone(),\n            file_size_bytes: 512,\n            format: Some(1),\n            num_tracks: 1,\n            ticks_per_quarter_note: Some(480),\n            duration_seconds: None,\n            duration_ticks: None,\n            manufacturer: None,\n            collection_name: None,\n            folder_tags: None,\n            import_batch_id: None,\n        };\n\n        FileRepository::insert(\u0026pool, new_file).await.unwrap();\n\n        // Should exist now\n        let exists = FileRepository::check_duplicate(\u0026pool, \u0026hash).await.unwrap();\n        assert!(exists);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","file_repository_fixed.rs"],"content":"//! Fixed file repository - avoids custom types\n\nuse crate::db::models::{File, NewFile};\nuse sqlx::PgPool;\n\npub struct FileRepository;\n\nimpl FileRepository {\n    /// Inserts a new file and returns its ID\n    pub async fn insert(pool: \u0026PgPool, new_file: NewFile) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let file_id = sqlx::query_scalar!(\n            r#\"\n            INSERT INTO files (\n                original_path,\n                current_path,\n                original_filename,\n                new_filename,\n                content_hash,\n                file_size,\n                file_modified,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                import_batch_id\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n            RETURNING id\n            \"#,\n            new_file.original_path,\n            new_file.current_path,\n            new_file.original_filename,\n            new_file.new_filename,\n            \u0026new_file.content_hash[..],\n            new_file.file_size,\n            new_file.file_modified,\n            new_file.manufacturer,\n            new_file.collection_name,\n            new_file.folder_tags.as_deref(),\n            new_file.import_batch_id,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(file_id)\n    }\n\n    /// Finds file by ID using manual mapping\n    pub async fn find_by_id(pool: \u0026PgPool, id: i64) -\u003e Result\u003cOption\u003cFile\u003e, sqlx::Error\u003e {\n        let row = sqlx::query!(\n            r#\"\n            SELECT \n                id,\n                original_path,\n                current_path,\n                original_filename,\n                new_filename,\n                content_hash,\n                file_size as file_size_bytes,\n                file_modified,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                category::text,\n                subcategory,\n                auto_tags,\n                user_tags,\n                analyzed_at,\n                import_batch_id,\n                created_at,\n                updated_at\n            FROM files WHERE id = $1\n            \"#,\n            id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(row.map(|r| File {\n            id: r.id,\n            original_path: r.original_path,\n            current_path: r.current_path,\n            original_filename: r.original_filename,\n            new_filename: r.new_filename,\n            content_hash: r.content_hash,\n            file_size_bytes: r.file_size_bytes,\n            file_modified: r.file_modified,\n            is_multi_track: r.is_multi_track,\n            parent_file_id: r.parent_file_id,\n            track_number: r.track_number,\n            total_tracks: r.total_tracks,\n            manufacturer: r.manufacturer,\n            collection_name: r.collection_name,\n            folder_tags: r.folder_tags,\n            category: r.category,\n            subcategory: r.subcategory,\n            auto_tags: r.auto_tags,\n            user_tags: r.user_tags,\n            analyzed_at: r.analyzed_at,\n            import_batch_id: r.import_batch_id,\n            created_at: r.created_at,\n            updated_at: r.updated_at,\n        }))\n    }\n\n    /// Checks if file with hash already exists\n    pub async fn check_duplicate(pool: \u0026PgPool, content_hash: \u0026[u8]) -\u003e Result\u003cbool, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files\n            WHERE content_hash = $1\n            \"#,\n            content_hash\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count \u003e 0)\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","metadata_repository.rs"],"content":"//! Musical metadata repository\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::{MusicalMetadata, NewMusicalMetadata};\nuse sqlx::PgPool;\n\npub struct MetadataRepository;\n\nimpl MetadataRepository {\n    /// Inserts musical metadata\n    pub async fn insert(pool: \u0026PgPool, metadata: NewMusicalMetadata) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            INSERT INTO musical_metadata (\n                file_id,\n                bpm,\n                bpm_confidence,\n                key_signature,\n                key_confidence,\n                time_signature_numerator,\n                time_signature_denominator,\n                total_notes,\n                unique_pitches,\n                pitch_range_min,\n                pitch_range_max,\n                avg_velocity,\n                note_density,\n                polyphony_max,\n                polyphony_avg,\n                is_percussive\n            ) VALUES (\n                $1, $2, $3, $4::text::musical_key, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16\n            )\n            ON CONFLICT (file_id) DO UPDATE SET\n                bpm = EXCLUDED.bpm,\n                bpm_confidence = EXCLUDED.bpm_confidence,\n                key_signature = EXCLUDED.key_signature,\n                key_confidence = EXCLUDED.key_confidence,\n                time_signature_numerator = EXCLUDED.time_signature_numerator,\n                time_signature_denominator = EXCLUDED.time_signature_denominator,\n                total_notes = EXCLUDED.total_notes,\n                unique_pitches = EXCLUDED.unique_pitches,\n                pitch_range_min = EXCLUDED.pitch_range_min,\n                pitch_range_max = EXCLUDED.pitch_range_max,\n                avg_velocity = EXCLUDED.avg_velocity,\n                note_density = EXCLUDED.note_density,\n                polyphony_max = EXCLUDED.polyphony_max,\n                polyphony_avg = EXCLUDED.polyphony_avg,\n                is_percussive = EXCLUDED.is_percussive\n            \"#,\n            metadata.file_id,\n            metadata.bpm,\n            metadata.bpm_confidence,\n            metadata.key_signature,\n            metadata.key_confidence,\n            metadata.time_signature_numerator,\n            metadata.time_signature_denominator,\n            metadata.total_notes,\n            metadata.unique_pitches,\n            metadata.pitch_range_min,\n            metadata.pitch_range_max,\n            metadata.avg_velocity,\n            metadata.note_density,\n            metadata.polyphony_max,\n            metadata.polyphony_avg,\n            metadata.is_percussive,\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Finds metadata by file ID\n    pub async fn find_by_file_id(\n        pool: \u0026PgPool,\n        file_id: i64,\n    ) -\u003e Result\u003cOption\u003cMusicalMetadata\u003e, sqlx::Error\u003e {\n        let metadata = sqlx::query_as!(\n            MusicalMetadata,\n            r#\"\n            SELECT\n                file_id,\n                bpm,\n                bpm_confidence,\n                has_tempo_changes,\n                tempo_changes,\n                key_signature::text as key_signature,\n                key_confidence,\n                has_key_changes,\n                key_changes,\n                time_signature_numerator,\n                time_signature_denominator,\n                has_time_signature_changes,\n                time_signature_changes,\n                total_notes,\n                unique_pitches,\n                pitch_range_min,\n                pitch_range_max,\n                avg_velocity,\n                note_density,\n                polyphony_max,\n                polyphony_avg,\n                is_monophonic,\n                is_polyphonic,\n                is_percussive,\n                has_chords,\n                chord_complexity,\n                has_melody,\n                melodic_range,\n                created_at as \"created_at!\"\n            FROM musical_metadata WHERE file_id = $1\n            \"#,\n            file_id\n        )\n        .fetch_optional(pool)\n        .await?;\n\n        Ok(metadata)\n    }\n\n    /// Updates BPM and confidence\n    pub async fn update_bpm(\n        pool: \u0026PgPool,\n        file_id: i64,\n        bpm: sqlx::types::BigDecimal,\n        confidence: Option\u003cf32\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET bpm = $1,\n                bpm_confidence = $2\n            WHERE file_id = $3\n            \"#,\n            bpm,\n            confidence,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates key and confidence\n    pub async fn update_key(\n        pool: \u0026PgPool,\n        file_id: i64,\n        key: \u0026str,\n        confidence: Option\u003cf32\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET key_signature = $1::text::musical_key,\n                key_confidence = $2\n            WHERE file_id = $3\n            \"#,\n            key,\n            confidence,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Updates note statistics\n    pub async fn update_note_stats(\n        pool: \u0026PgPool,\n        file_id: i64,\n        total_notes: i32,\n        unique_pitches: Option\u003ci32\u003e,\n        pitch_range_min: Option\u003ci16\u003e,\n        pitch_range_max: Option\u003ci16\u003e,\n        avg_velocity: Option\u003csqlx::types::BigDecimal\u003e,\n    ) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\n            r#\"\n            UPDATE musical_metadata\n            SET total_notes = $1,\n                unique_pitches = $2,\n                pitch_range_min = $3,\n                pitch_range_max = $4,\n                avg_velocity = $5\n            WHERE file_id = $6\n            \"#,\n            total_notes,\n            unique_pitches,\n            pitch_range_min,\n            pitch_range_max,\n            avg_velocity,\n            file_id\n        )\n        .execute(pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Deletes metadata by file ID\n    pub async fn delete(pool: \u0026PgPool, file_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e {\n        sqlx::query!(\"DELETE FROM musical_metadata WHERE file_id = $1\", file_id)\n            .execute(pool)\n            .await?;\n\n        Ok(())\n    }\n\n    /// Gets metadata count\n    pub async fn count(pool: \u0026PgPool) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"SELECT COUNT(*) as \"count!\" FROM musical_metadata\"#\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n    use num_traits::FromPrimitive;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_insert_and_find() {\n        let pool = setup_test_pool().await;\n\n        let metadata = NewMusicalMetadata {\n            file_id: 1,\n            bpm: sqlx::types::BigDecimal::from_f64(120.0),\n            bpm_confidence: Some(0.95),\n            key_signature: Some(\"C\".to_string()),\n            key_confidence: Some(0.9),\n            time_signature_numerator: Some(4),\n            time_signature_denominator: Some(4),\n            total_notes: 1000,\n            unique_pitches: Some(12),\n            pitch_range_min: Some(60),\n            pitch_range_max: Some(84),\n            avg_velocity: sqlx::types::BigDecimal::from_f64(100.0),\n            note_density: sqlx::types::BigDecimal::from_f64(5.5),\n            polyphony_max: Some(4),\n            polyphony_avg: sqlx::types::BigDecimal::from_f64(2.5),\n            is_percussive: Some(false),\n        };\n\n        MetadataRepository::insert(\u0026pool, metadata).await.unwrap();\n\n        let found = MetadataRepository::find_by_file_id(\u0026pool, 1).await.unwrap();\n        assert!(found.is_some());\n\n        let meta = found.unwrap();\n        assert_eq!(meta.file_id, 1);\n        assert_eq!(meta.total_notes, 1000);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","mod.rs"],"content":"//! Database repositories\n\npub mod file_repository;\npub mod metadata_repository;\npub mod search_repository;\npub mod tag_repository;\n\npub use file_repository::FileRepository;\npub use metadata_repository::MetadataRepository;\npub use search_repository::{SearchQuery, SearchRepository};\npub use tag_repository::{TagRepository, DbTag, TagWithCount};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","search_repository.rs"],"content":"//! Search operations repository\n//! Aligned with actual schema from 001_initial_schema.sql\n\nuse crate::db::models::File;\nuse sqlx::PgPool;\n\npub struct SearchRepository;\n\n#[derive(Debug, Clone)]\npub struct SearchQuery {\n    pub text: Option\u003cString\u003e,\n    pub min_bpm: Option\u003cf64\u003e,\n    pub max_bpm: Option\u003cf64\u003e,\n    pub key: Option\u003cString\u003e,\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection: Option\u003cString\u003e,\n}\n\nimpl SearchRepository {\n    /// Full-text search with filters\n    pub async fn search(\n        pool: \u0026PgPool,\n        query: SearchQuery,\n        limit: i64,\n        offset: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                f.id,\n                f.filename,\n                f.filepath,\n                f.original_filename,\n                f.content_hash,\n                f.file_size_bytes,\n                f.format,\n                f.num_tracks,\n                f.ticks_per_quarter_note,\n                f.duration_seconds,\n                f.duration_ticks,\n                f.is_multi_track,\n                f.parent_file_id,\n                f.track_number,\n                f.total_tracks,\n                f.manufacturer,\n                f.collection_name,\n                f.folder_tags,\n                f.created_at as \"created_at!\",\n                f.updated_at as \"updated_at!\",\n                f.analyzed_at,\n                f.import_batch_id\n            FROM files f\n            LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n            WHERE\n                ($1::text IS NULL OR f.search_vector @@ plainto_tsquery('english', $1))\n                AND ($2::float8 IS NULL OR mm.bpm::float8 \u003e= $2)\n                AND ($3::float8 IS NULL OR mm.bpm::float8 \u003c= $3)\n                AND ($4::text IS NULL OR mm.key_signature::text = $4)\n                AND ($5::text IS NULL OR f.manufacturer = $5)\n                AND ($6::text IS NULL OR f.collection_name = $6)\n            ORDER BY\n                CASE WHEN $1::text IS NOT NULL\n                    THEN ts_rank(f.search_vector, plainto_tsquery('english', $1))\n                    ELSE 0\n                END DESC,\n                f.created_at DESC\n            LIMIT $7 OFFSET $8\n            \"#,\n            query.text,\n            query.min_bpm,\n            query.max_bpm,\n            query.key,\n            query.manufacturer,\n            query.collection,\n            limit,\n            offset\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Count search results\n    pub async fn count_search_results(\n        pool: \u0026PgPool,\n        query: SearchQuery,\n    ) -\u003e Result\u003ci64, sqlx::Error\u003e {\n        let count = sqlx::query_scalar!(\n            r#\"\n            SELECT COUNT(*) as \"count!\"\n            FROM files f\n            LEFT JOIN musical_metadata mm ON f.id = mm.file_id\n            WHERE\n                ($1::text IS NULL OR f.search_vector @@ plainto_tsquery('english', $1))\n                AND ($2::float8 IS NULL OR mm.bpm::float8 \u003e= $2)\n                AND ($3::float8 IS NULL OR mm.bpm::float8 \u003c= $3)\n                AND ($4::text IS NULL OR mm.key_signature::text = $4)\n                AND ($5::text IS NULL OR f.manufacturer = $5)\n                AND ($6::text IS NULL OR f.collection_name = $6)\n            \"#,\n            query.text,\n            query.min_bpm,\n            query.max_bpm,\n            query.key,\n            query.manufacturer,\n            query.collection,\n        )\n        .fetch_one(pool)\n        .await?;\n\n        Ok(count)\n    }\n\n    /// Search by manufacturer\n    pub async fn search_by_manufacturer(\n        pool: \u0026PgPool,\n        manufacturer: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE manufacturer = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            manufacturer,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n\n    /// Search by collection\n    pub async fn search_by_collection(\n        pool: \u0026PgPool,\n        collection: \u0026str,\n        limit: i64,\n    ) -\u003e Result\u003cVec\u003cFile\u003e, sqlx::Error\u003e {\n        let files = sqlx::query_as!(\n            File,\n            r#\"\n            SELECT\n                id,\n                filename,\n                filepath,\n                original_filename,\n                content_hash,\n                file_size_bytes,\n                format,\n                num_tracks,\n                ticks_per_quarter_note,\n                duration_seconds,\n                duration_ticks,\n                is_multi_track,\n                parent_file_id,\n                track_number,\n                total_tracks,\n                manufacturer,\n                collection_name,\n                folder_tags,\n                created_at as \"created_at!\",\n                updated_at as \"updated_at!\",\n                analyzed_at,\n                import_batch_id\n            FROM files\n            WHERE collection_name = $1\n            ORDER BY created_at DESC\n            LIMIT $2\n            \"#,\n            collection,\n            limit\n        )\n        .fetch_all(pool)\n        .await?;\n\n        Ok(files)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use sqlx::postgres::PgPoolOptions;\n\n    async fn setup_test_pool() -\u003e PgPool {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .unwrap_or_else(|_| {\n                \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string()\n            });\n\n        PgPoolOptions::new()\n            .max_connections(5)\n            .connect(\u0026database_url)\n            .await\n            .expect(\"Failed to connect to test database\")\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_search_empty() {\n        let pool = setup_test_pool().await;\n\n        let query = SearchQuery {\n            text: None,\n            min_bpm: None,\n            max_bpm: None,\n            key: None,\n            manufacturer: None,\n            collection: None,\n        };\n\n        let results = SearchRepository::search(\u0026pool, query, 10, 0).await.unwrap();\n        assert!(results.len() \u003c= 10);\n    }\n\n    #[tokio::test]\n    #[ignore] // Only run when database is available\n    async fn test_count_search() {\n        let pool = setup_test_pool().await;\n\n        let query = SearchQuery {\n            text: None,\n            min_bpm: None,\n            max_bpm: None,\n            key: None,\n            manufacturer: None,\n            collection: None,\n        };\n\n        let count = SearchRepository::count_search_results(\u0026pool, query).await.unwrap();\n        assert!(count \u003e= 0);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","db","repositories","tag_repository.rs"],"content":"//! Tag Repository - Database operations for tags\n//!\n//! This module handles all database operations related to tags:\n//! - Creating/retrieving tags\n//! - Associating tags with files\n//! - Searching and filtering tags\n//! - Tag usage statistics\n\nuse sqlx::{PgPool, Postgres, Transaction};\nuse thiserror::Error;\n\n/// Tag database model\n#[derive(Debug, Clone, sqlx::FromRow)]\npub struct DbTag {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\n/// Tag with usage count for tag cloud\n#[derive(Debug, Clone, sqlx::FromRow)]\npub struct TagWithCount {\n    pub id: i32,\n    pub name: String,\n    pub category: Option\u003cString\u003e,\n    pub usage_count: i32,\n}\n\n#[derive(Debug, Error)]\npub enum TagRepositoryError {\n    #[error(\"Database error: {0}\")]\n    DatabaseError(#[from] sqlx::Error),\n\n    #[error(\"Tag not found: {0}\")]\n    TagNotFound(String),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, TagRepositoryError\u003e;\n\n/// Tag repository for database operations\npub struct TagRepository {\n    pool: PgPool,\n}\n\nimpl TagRepository {\n    pub fn new(pool: PgPool) -\u003e Self {\n        Self { pool }\n    }\n\n    /// Get or create a tag by name and category\n    ///\n    /// Returns the tag ID. If the tag exists, returns existing ID.\n    /// If not, creates a new tag and returns the new ID.\n    pub async fn get_or_create_tag(\n        \u0026self,\n        name: \u0026str,\n        category: Option\u003c\u0026str\u003e,\n    ) -\u003e Result\u003ci32\u003e {\n        let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n            r#\"\n            INSERT INTO tags (name, category, usage_count, created_at)\n            VALUES ($1, $2, 0, NOW())\n            ON CONFLICT (name) DO UPDATE\n            SET name = EXCLUDED.name\n            RETURNING id\n            \"#,\n        )\n        .bind(name)\n        .bind(category)\n        .fetch_one(\u0026self.pool)\n        .await?;\n\n        Ok(tag_id)\n    }\n\n    /// Get or create multiple tags in a single transaction\n    ///\n    /// More efficient for bulk operations like file imports\n    pub async fn get_or_create_tags_batch(\n        \u0026self,\n        tags: \u0026[(String, Option\u003cString\u003e)], // (name, category)\n    ) -\u003e Result\u003cVec\u003ci32\u003e\u003e {\n        let mut tag_ids = Vec::with_capacity(tags.len());\n\n        // Use a transaction for atomicity\n        let mut tx = self.pool.begin().await?;\n\n        for (name, category) in tags {\n            let tag_id = sqlx::query_scalar::\u003c_, i32\u003e(\n                r#\"\n                INSERT INTO tags (name, category, usage_count, created_at)\n                VALUES ($1, $2, 0, NOW())\n                ON CONFLICT (name) DO UPDATE\n                SET name = EXCLUDED.name\n                RETURNING id\n                \"#,\n            )\n            .bind(name)\n            .bind(category.as_deref())\n            .fetch_one(\u0026mut *tx)\n            .await?;\n\n            tag_ids.push(tag_id);\n        }\n\n        tx.commit().await?;\n\n        Ok(tag_ids)\n    }\n\n    /// Add tags to a file\n    ///\n    /// Uses ON CONFLICT DO NOTHING to avoid duplicate errors\n    pub async fn add_tags_to_file(\u0026self, file_id: i64, tag_ids: \u0026[i32]) -\u003e Result\u003c()\u003e {\n        // Batch insert using unnest\n        sqlx::query(\n            r#\"\n            INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n            SELECT $1, unnest($2::int[]), NOW(), 'system'\n            ON CONFLICT (file_id, tag_id) DO NOTHING\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_ids)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Add tags to a file within a transaction\n    pub async fn add_tags_to_file_tx(\n        tx: \u0026mut Transaction\u003c'_, Postgres\u003e,\n        file_id: i64,\n        tag_ids: \u0026[i32],\n    ) -\u003e Result\u003c()\u003e {\n        sqlx::query(\n            r#\"\n            INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n            SELECT $1, unnest($2::int[]), NOW(), 'system'\n            ON CONFLICT (file_id, tag_id) DO NOTHING\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_ids)\n        .execute(\u0026mut **tx)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Get all tags for a specific file\n    pub async fn get_file_tags(\u0026self, file_id: i64) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT t.id, t.name, t.category, t.usage_count\n            FROM tags t\n            JOIN file_tags ft ON t.id = ft.tag_id\n            WHERE ft.file_id = $1\n            ORDER BY t.category, t.name\n            \"#,\n        )\n        .bind(file_id)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get popular tags with usage counts (for tag cloud)\n    pub async fn get_popular_tags(\u0026self, limit: i32) -\u003e Result\u003cVec\u003cTagWithCount\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, TagWithCount\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE usage_count \u003e 0\n            ORDER BY usage_count DESC, name ASC\n            LIMIT $1\n            \"#,\n        )\n        .bind(limit)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Search tags by name prefix (for autocomplete)\n    pub async fn search_tags(\u0026self, query: \u0026str, limit: i32) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let search_pattern = format!(\"{}%\", query.to_lowercase());\n\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE LOWER(name) LIKE $1\n            ORDER BY usage_count DESC, name ASC\n            LIMIT $2\n            \"#,\n        )\n        .bind(\u0026search_pattern)\n        .bind(limit)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get tags by category\n    pub async fn get_tags_by_category(\u0026self, category: \u0026str) -\u003e Result\u003cVec\u003cDbTag\u003e\u003e {\n        let tags = sqlx::query_as::\u003c_, DbTag\u003e(\n            r#\"\n            SELECT id, name, category, usage_count\n            FROM tags\n            WHERE category = $1\n            ORDER BY usage_count DESC, name ASC\n            \"#,\n        )\n        .bind(category)\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(tags)\n    }\n\n    /// Get all unique tag categories\n    pub async fn get_tag_categories(\u0026self) -\u003e Result\u003cVec\u003cString\u003e\u003e {\n        let categories = sqlx::query_scalar::\u003c_, String\u003e(\n            r#\"\n            SELECT DISTINCT category\n            FROM tags\n            WHERE category IS NOT NULL\n            ORDER BY category\n            \"#,\n        )\n        .fetch_all(\u0026self.pool)\n        .await?;\n\n        Ok(categories)\n    }\n\n    /// Remove a tag from a file\n    pub async fn remove_tag_from_file(\u0026self, file_id: i64, tag_id: i32) -\u003e Result\u003c()\u003e {\n        sqlx::query(\n            r#\"\n            DELETE FROM file_tags\n            WHERE file_id = $1 AND tag_id = $2\n            \"#,\n        )\n        .bind(file_id)\n        .bind(tag_id)\n        .execute(\u0026self.pool)\n        .await?;\n\n        Ok(())\n    }\n\n    /// Update file tags (replace all tags)\n    pub async fn update_file_tags(\u0026self, file_id: i64, tag_ids: \u0026[i32]) -\u003e Result\u003c()\u003e {\n        let mut tx = self.pool.begin().await?;\n\n        // Remove all existing tags\n        sqlx::query(\n            r#\"\n            DELETE FROM file_tags\n            WHERE file_id = $1\n            \"#,\n        )\n        .bind(file_id)\n        .execute(\u0026mut *tx)\n        .await?;\n\n        // Add new tags\n        if !tag_ids.is_empty() {\n            sqlx::query(\n                r#\"\n                INSERT INTO file_tags (file_id, tag_id, added_at, added_by)\n                SELECT $1, unnest($2::int[]), NOW(), 'user'\n                \"#,\n            )\n            .bind(file_id)\n            .bind(tag_ids)\n            .execute(\u0026mut *tx)\n            .await?;\n        }\n\n        tx.commit().await?;\n\n        Ok(())\n    }\n\n    /// Get file count for a tag\n    pub async fn get_tag_file_count(\u0026self, tag_id: i32) -\u003e Result\u003ci64\u003e {\n        let count = sqlx::query_scalar::\u003c_, i64\u003e(\n            r#\"\n            SELECT COUNT(*)\n            FROM file_tags\n            WHERE tag_id = $1\n            \"#,\n        )\n        .bind(tag_id)\n        .fetch_one(\u0026self.pool)\n        .await?;\n\n        Ok(count)\n    }\n\n    /// Get files by tag (for filtering)\n    pub async fn get_files_by_tags(\n        \u0026self,\n        tag_names: \u0026[String],\n        match_all: bool, // true for AND, false for OR\n    ) -\u003e Result\u003cVec\u003ci64\u003e\u003e {\n        let file_ids = if match_all {\n            // AND logic: file must have all tags\n            sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                SELECT ft.file_id\n                FROM file_tags ft\n                JOIN tags t ON ft.tag_id = t.id\n                WHERE t.name = ANY($1)\n                GROUP BY ft.file_id\n                HAVING COUNT(DISTINCT t.id) = $2\n                \"#,\n            )\n            .bind(tag_names)\n            .bind(tag_names.len() as i64)\n            .fetch_all(\u0026self.pool)\n            .await?\n        } else {\n            // OR logic: file must have at least one tag\n            sqlx::query_scalar::\u003c_, i64\u003e(\n                r#\"\n                SELECT DISTINCT ft.file_id\n                FROM file_tags ft\n                JOIN tags t ON ft.tag_id = t.id\n                WHERE t.name = ANY($1)\n                \"#,\n            )\n            .bind(tag_names)\n            .fetch_all(\u0026self.pool)\n            .await?\n        };\n\n        Ok(file_ids)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    // Note: These tests require a running PostgreSQL database\n    // They are integration tests, not unit tests\n\n    #[tokio::test]\n    #[ignore] // Run with: cargo test -- --ignored\n    async fn test_get_or_create_tag() {\n        let pool = PgPool::connect(\"postgresql://localhost:5433/midi_library\")\n            .await\n            .expect(\"Failed to connect to database\");\n\n        let repo = TagRepository::new(pool);\n\n        let tag_id = repo\n            .get_or_create_tag(\"test_tag\", Some(\"test\"))\n            .await\n            .expect(\"Failed to create tag\");\n\n        assert!(tag_id \u003e 0);\n\n        // Try to create again, should return same ID\n        let tag_id2 = repo\n            .get_or_create_tag(\"test_tag\", Some(\"test\"))\n            .await\n            .expect(\"Failed to get existing tag\");\n\n        assert_eq!(tag_id, tag_id2);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","error.rs"],"content":"//! Error Handling Module - PURE FUNCTION ARCHETYPE\n//!\n//! PURPOSE: Transform and convert error types for Tauri commands\n//! ARCHETYPE: Pure Function (deterministic transformations, no I/O)\n//! LOCATION: pipeline/src-tauri/src/error.rs\n//!\n//!  CAN: Transform errors (sqlx::Error  AppError)\n//!  CAN: Convert types (AppError  String)\n//!  SHOULD: Be deterministic\n//!  NO: I/O operations\n//!  NO: Side effects\n//!  NO: State\n\nuse std::fmt;\n\n/// Application error types\n///\n/// Centralized error handling for all Tauri commands.\n/// All variants can be converted to String for frontend consumption.\n///\n/// # Examples\n///\n/// ```rust\n/// use error::AppError;\n///\n/// // From database error\n/// let db_err = AppError::DatabaseError(sqlx_error);\n///\n/// // From validation\n/// let val_err = AppError::ValidationError(\"Invalid BPM range\".to_string());\n///\n/// // Convert to String for Tauri\n/// let error_msg: String = app_err.into();\n/// ```\n#[derive(Debug)]\npub enum AppError {\n    /// Database operation failed\n    DatabaseError(sqlx::Error),\n\n    /// Requested resource not found\n    NotFound(String),\n\n    /// Input validation failed\n    ValidationError(String),\n\n    /// File I/O operation failed\n    IOError(std::io::Error),\n\n    /// MIDI parsing or analysis error\n    MidiError(String),\n\n    /// Generic application error\n    GeneralError(String),\n}\n\n// =============================================================================\n// DISPLAY TRAIT - Pure transformation to string representation\n// =============================================================================\n\nimpl fmt::Display for AppError {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        match self {\n            AppError::DatabaseError(e) =\u003e write!(f, \"Database error: {}\", e),\n            AppError::NotFound(msg) =\u003e write!(f, \"Not found: {}\", msg),\n            AppError::ValidationError(msg) =\u003e write!(f, \"Validation error: {}\", msg),\n            AppError::IOError(e) =\u003e write!(f, \"I/O error: {}\", e),\n            AppError::MidiError(msg) =\u003e write!(f, \"MIDI error: {}\", msg),\n            AppError::GeneralError(msg) =\u003e write!(f, \"Error: {}\", msg),\n        }\n    }\n}\n\n// =============================================================================\n// ERROR TRAIT - Standard error interface\n// =============================================================================\n\nimpl std::error::Error for AppError {\n    fn source(\u0026self) -\u003e Option\u003c\u0026(dyn std::error::Error + 'static)\u003e {\n        match self {\n            AppError::DatabaseError(e) =\u003e Some(e),\n            AppError::IOError(e) =\u003e Some(e),\n            _ =\u003e None,\n        }\n    }\n}\n\n// =============================================================================\n// FROM TRAIT IMPLEMENTATIONS - Pure type conversions\n// =============================================================================\n\n/// Convert from sqlx::Error to AppError (pure transformation)\nimpl From\u003csqlx::Error\u003e for AppError {\n    fn from(error: sqlx::Error) -\u003e Self {\n        AppError::DatabaseError(error)\n    }\n}\n\n/// Convert from std::io::Error to AppError (pure transformation)\nimpl From\u003cstd::io::Error\u003e for AppError {\n    fn from(error: std::io::Error) -\u003e Self {\n        AppError::IOError(error)\n    }\n}\n\n/// Convert from String to AppError (pure transformation)\nimpl From\u003cString\u003e for AppError {\n    fn from(error: String) -\u003e Self {\n        AppError::GeneralError(error)\n    }\n}\n\n/// Convert from \u0026str to AppError (pure transformation)\nimpl From\u003c\u0026str\u003e for AppError {\n    fn from(error: \u0026str) -\u003e Self {\n        AppError::GeneralError(error.to_string())\n    }\n}\n\n// =============================================================================\n// TAURI CONVERSION - Pure transformation to String for frontend\n// =============================================================================\n\n/// Convert AppError to String for Tauri command return types\n///\n/// This is a pure transformation with no side effects.\n/// Tauri requires errors to be String for IPC serialization.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn my_command() -\u003e Result\u003cData, String\u003e {\n///     let result = database_operation()\n///         .await\n///         .map_err(|e| AppError::from(e).into())?;\n///     Ok(result)\n/// }\n/// ```\nimpl From\u003cAppError\u003e for String {\n    fn from(error: AppError) -\u003e Self {\n        error.to_string()\n    }\n}\n\n// =============================================================================\n// HELPER FUNCTIONS - Pure error creation utilities\n// =============================================================================\n\nimpl AppError {\n    /// Create a NotFound error (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::not_found(\"File with ID 123\"));\n    /// ```\n    pub fn not_found(resource: \u0026str) -\u003e Self {\n        AppError::NotFound(format!(\"{} not found\", resource))\n    }\n\n    /// Create a ValidationError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::validation(\"BPM must be between 20 and 300\"));\n    /// ```\n    pub fn validation(message: \u0026str) -\u003e Self {\n        AppError::ValidationError(message.to_string())\n    }\n\n    /// Create a MidiError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::midi(\"Invalid MIDI header\"));\n    /// ```\n    pub fn midi(message: \u0026str) -\u003e Self {\n        AppError::MidiError(message.to_string())\n    }\n\n    /// Create a GeneralError (pure function)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// return Err(AppError::general(\"Something went wrong\"));\n    /// ```\n    pub fn general(message: \u0026str) -\u003e Self {\n        AppError::GeneralError(message.to_string())\n    }\n}\n\n// =============================================================================\n// RESULT TYPE ALIAS - Convenience type for commands\n// =============================================================================\n\n/// Standard Result type for Tauri commands\n///\n/// Uses String as error type for Tauri IPC compatibility.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn get_file(id: i64) -\u003e AppResult\u003cFile\u003e {\n///     let file = database.get_file(id)\n///         .await\n///         .map_err(AppError::from)?;\n///\n///     file.ok_or_else(|| AppError::not_found(\u0026format!(\"File {}\", id)))\n/// }\n/// ```\npub type AppResult\u003cT\u003e = Result\u003cT, AppError\u003e;\n\n/// Tauri-compatible Result type (with String error)\n///\n/// For use in Tauri command return types.\n///\n/// # Examples\n///\n/// ```rust\n/// #[tauri::command]\n/// pub async fn search_files() -\u003e TauriResult\u003cVec\u003cFile\u003e\u003e {\n///     let files = database.search()\n///         .await\n///         .map_err(|e| AppError::from(e).into())?;\n///     Ok(files)\n/// }\n/// ```\npub type TauriResult\u003cT\u003e = Result\u003cT, String\u003e;\n\n// =============================================================================\n// TESTS - Pure function testing\n// =============================================================================\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_display_database_error() {\n        let err = AppError::DatabaseError(\n            sqlx::Error::RowNotFound\n        );\n        assert!(err.to_string().contains(\"Database error\"));\n    }\n\n    #[test]\n    fn test_display_not_found() {\n        let err = AppError::NotFound(\"File 123\".to_string());\n        assert_eq!(err.to_string(), \"Not found: File 123\");\n    }\n\n    #[test]\n    fn test_display_validation() {\n        let err = AppError::ValidationError(\"Invalid input\".to_string());\n        assert_eq!(err.to_string(), \"Validation error: Invalid input\");\n    }\n\n    #[test]\n    fn test_display_midi_error() {\n        let err = AppError::MidiError(\"Bad header\".to_string());\n        assert_eq!(err.to_string(), \"MIDI error: Bad header\");\n    }\n\n    #[test]\n    fn test_from_string() {\n        let err = AppError::from(\"Test error\");\n        match err {\n            AppError::GeneralError(msg) =\u003e assert_eq!(msg, \"Test error\"),\n            _ =\u003e panic!(\"Wrong variant\"),\n        }\n    }\n\n    #[test]\n    fn test_from_sqlx_error() {\n        let sqlx_err = sqlx::Error::RowNotFound;\n        let app_err = AppError::from(sqlx_err);\n        match app_err {\n            AppError::DatabaseError(_) =\u003e (),\n            _ =\u003e panic!(\"Wrong variant\"),\n        }\n    }\n\n    #[test]\n    fn test_to_string_conversion() {\n        let err = AppError::NotFound(\"Resource\".to_string());\n        let string_err: String = err.into();\n        assert_eq!(string_err, \"Not found: Resource\");\n    }\n\n    #[test]\n    fn test_not_found_helper() {\n        let err = AppError::not_found(\"File 123\");\n        assert_eq!(err.to_string(), \"Not found: File 123 not found\");\n    }\n\n    #[test]\n    fn test_validation_helper() {\n        let err = AppError::validation(\"BPM out of range\");\n        assert_eq!(err.to_string(), \"Validation error: BPM out of range\");\n    }\n\n    #[test]\n    fn test_midi_helper() {\n        let err = AppError::midi(\"Invalid format\");\n        assert_eq!(err.to_string(), \"MIDI error: Invalid format\");\n    }\n\n    #[test]\n    fn test_general_helper() {\n        let err = AppError::general(\"Something wrong\");\n        assert_eq!(err.to_string(), \"Error: Something wrong\");\n    }\n\n    #[test]\n    fn test_deterministic_conversion() {\n        // Pure function - same input always produces same output\n        let err1 = AppError::validation(\"Test\");\n        let err2 = AppError::validation(\"Test\");\n        assert_eq!(err1.to_string(), err2.to_string());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","extractor.rs"],"content":"//! Archive Extraction Logic\n//!\n//! # Archetype: Grown-up Script\n//! - Performs I/O operations (file extraction)\n//! - Separates I/O logic from business logic\n//! - Both runnable AND importable\n//! - Returns Result types for error handling\n\nuse std::fs::{self, File};\nuse std::io;\nuse std::path::{Path, PathBuf};\nuse zip::ZipArchive;\n\nuse crate::io::decompressor::{formats, temp_manager};\nuse crate::io::{IoError, Result};\n\n/// Configuration for extraction\n#[derive(Debug, Clone)]\npub struct ExtractionConfig {\n    /// Maximum recursion depth for nested archives\n    pub max_depth: usize,\n\n    /// Whether to extract nested archives\n    pub recursive: bool,\n\n    /// Extensions to extract (e.g., [\"mid\", \"midi\"])\n    pub target_extensions: Vec\u003cString\u003e,\n}\n\nimpl Default for ExtractionConfig {\n    fn default() -\u003e Self {\n        Self {\n            max_depth: 10, // Increased to handle deeply nested archives (up to 8 layers observed)\n            recursive: true,\n            target_extensions: vec![\"mid\".to_string(), \"midi\".to_string()],\n        }\n    }\n}\n\n/// Result of extraction operation\n#[derive(Debug)]\npub struct ExtractionResult {\n    /// Paths to extracted MIDI files\n    pub midi_files: Vec\u003cPathBuf\u003e,\n\n    /// Number of archives processed\n    pub archives_processed: usize,\n\n    /// Errors encountered\n    pub errors: Vec\u003cString\u003e,\n}\n\n/// Extracts MIDI files from an archive\n///\n/// # Arguments\n/// * `archive_path` - Path to archive file\n/// * `output_dir` - Where to extract files\n/// * `config` - Extraction configuration\n///\n/// # Returns\n/// * `ExtractionResult` - List of extracted MIDI files\n///\n/// # Examples\n/// ```no_run\n/// use std::path::Path;\n/// use pipeline::io::decompressor::extractor::*;\n///\n/// let config = ExtractionConfig::default();\n/// let result = extract_archive(\n///     Path::new(\"samples.zip\"),\n///     Path::new(\"/output\"),\n///     \u0026config\n/// ).unwrap();\n///\n/// println!(\"Extracted {} MIDI files\", result.midi_files.len());\n/// ```\npub fn extract_archive(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n) -\u003e Result\u003cExtractionResult\u003e {\n    let format = formats::detect_format(archive_path)\n        .ok_or_else(|| IoError::UnsupportedFormat {\n            path: archive_path.to_path_buf(),\n        })?;\n\n    let mut result = ExtractionResult {\n        midi_files: Vec::new(),\n        archives_processed: 0,\n        errors: Vec::new(),\n    };\n\n    extract_recursive(archive_path, output_dir, config, 0, \u0026mut result, format)?;\n\n    Ok(result)\n}\n\n/// Internal recursive extraction function\nfn extract_recursive(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n    current_depth: usize,\n    result: \u0026mut ExtractionResult,\n    format: formats::ArchiveFormat,\n) -\u003e Result\u003c()\u003e {\n    if current_depth \u003e= config.max_depth {\n        result\n            .errors\n            .push(format!(\"Max depth reached at: {}\", archive_path.display()));\n        return Ok(());\n    }\n\n    result.archives_processed += 1;\n\n    match format {\n        formats::ArchiveFormat::Zip =\u003e {\n            extract_zip(archive_path, output_dir, config, current_depth, result)?;\n        }\n        _ =\u003e {\n            result\n                .errors\n                .push(format!(\"Format {:?} not yet implemented\", format));\n        }\n    }\n\n    Ok(())\n}\n\n/// Extracts ZIP archive\nfn extract_zip(\n    archive_path: \u0026Path,\n    output_dir: \u0026Path,\n    config: \u0026ExtractionConfig,\n    current_depth: usize,\n    result: \u0026mut ExtractionResult,\n) -\u003e Result\u003c()\u003e {\n    let file = File::open(archive_path)?;\n    let mut archive = ZipArchive::new(file)?;\n\n    fs::create_dir_all(output_dir)?;\n\n    for i in 0..archive.len() {\n        let mut file = archive.by_index(i)?;\n        let outpath = match file.enclosed_name() {\n            Some(path) =\u003e output_dir.join(path),\n            None =\u003e continue,\n        };\n\n        if file.name().ends_with('/') {\n            // Directory\n            fs::create_dir_all(\u0026outpath)?;\n        } else {\n            // File\n            if let Some(parent) = outpath.parent() {\n                fs::create_dir_all(parent)?;\n            }\n\n            let mut outfile = File::create(\u0026outpath)?;\n            io::copy(\u0026mut file, \u0026mut outfile)?;\n\n            // Check if it's a MIDI file\n            if is_target_file(\u0026outpath, \u0026config.target_extensions) {\n                result.midi_files.push(outpath.clone());\n            }\n\n            // Check if it's a nested archive\n            if config.recursive \u0026\u0026 formats::is_archive(\u0026outpath) {\n                if let Some(nested_format) = formats::detect_format(\u0026outpath) {\n                    let _ = extract_recursive(\n                        \u0026outpath,\n                        output_dir,\n                        config,\n                        current_depth + 1,\n                        result,\n                        nested_format,\n                    );\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n\n/// Checks if file has target extension\nfn is_target_file(path: \u0026Path, target_extensions: \u0026[String]) -\u003e bool {\n    path.extension()\n        .and_then(|ext| ext.to_str())\n        .map(|ext_str| {\n            let ext_lower = ext_str.to_lowercase();\n            target_extensions.iter().any(|target| target == \u0026ext_lower)\n        })\n        .unwrap_or(false)\n}\n\n/// Convenience function for extracting to temporary directory\n///\n/// # Arguments\n/// * `archive_path` - Path to archive file\n/// * `config` - Extraction configuration\n///\n/// # Returns\n/// * `(ExtractionResult, PathBuf)` - Extraction result and temp directory path\npub fn extract_to_temp(\n    archive_path: \u0026Path,\n    config: \u0026ExtractionConfig,\n) -\u003e Result\u003c(ExtractionResult, PathBuf)\u003e {\n    let mut temp_mgr = temp_manager::TempManager::new()?;\n    let temp_dir = temp_mgr.create_temp_dir()?;\n\n    let result = extract_archive(archive_path, \u0026temp_dir, config)?;\n\n    // Note: temp_mgr will be dropped but we return temp_dir\n    // Caller is responsible for cleanup\n    std::mem::forget(temp_mgr);\n\n    Ok((result, temp_dir))\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::path::PathBuf;\n\n    #[test]\n    fn test_is_target_file() {\n        let path = PathBuf::from(\"test.mid\");\n        let extensions = vec![\"mid\".to_string(), \"midi\".to_string()];\n\n        assert!(is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_is_target_file_case_insensitive() {\n        let path = PathBuf::from(\"test.MID\");\n        let extensions = vec![\"mid\".to_string()];\n\n        assert!(is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_not_target_file() {\n        let path = PathBuf::from(\"test.txt\");\n        let extensions = vec![\"mid\".to_string()];\n\n        assert!(!is_target_file(\u0026path, \u0026extensions));\n    }\n\n    #[test]\n    fn test_default_config() {\n        let config = ExtractionConfig::default();\n\n        assert_eq!(config.max_depth, 5);\n        assert!(config.recursive);\n        assert_eq!(config.target_extensions, vec![\"mid\", \"midi\"]);\n    }\n\n    #[test]\n    fn test_extraction_result() {\n        let result = ExtractionResult {\n            midi_files: vec![PathBuf::from(\"test.mid\")],\n            archives_processed: 1,\n            errors: vec![],\n        };\n\n        assert_eq!(result.midi_files.len(), 1);\n        assert_eq!(result.archives_processed, 1);\n        assert!(result.errors.is_empty());\n    }\n\n    #[test]\n    fn test_unsupported_format() {\n        let path = PathBuf::from(\"test.txt\");\n        let output = PathBuf::from(\"/tmp/output\");\n        let config = ExtractionConfig::default();\n\n        let result = extract_archive(\u0026path, \u0026output, \u0026config);\n\n        assert!(result.is_err());\n        assert!(result\n            .unwrap_err()\n            .to_string()\n            .contains(\"Unsupported archive format\"));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","formats.rs"],"content":"//! Archive Format Detection\n\nuse std::path::Path;\n\n/// Supported archive formats\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum ArchiveFormat {\n    Zip,\n    Rar,\n    SevenZip,\n    TarGz,\n    Tar,\n}\n\nimpl ArchiveFormat {\n    /// Returns file extension for format\n    pub fn extension(\u0026self) -\u003e \u0026'static str {\n        match self {\n            ArchiveFormat::Zip =\u003e \"zip\",\n            ArchiveFormat::Rar =\u003e \"rar\",\n            ArchiveFormat::SevenZip =\u003e \"7z\",\n            ArchiveFormat::TarGz =\u003e \"tar.gz\",\n            ArchiveFormat::Tar =\u003e \"tar\",\n        }\n    }\n}\n\n/// Detects archive format from file extension\n///\n/// # Arguments\n/// * `path` - Path to check\n///\n/// # Returns\n/// * `Some(ArchiveFormat)` if recognized, `None` otherwise\npub fn detect_format(path: \u0026Path) -\u003e Option\u003cArchiveFormat\u003e {\n    let filename = path.file_name()?.to_str()?.to_lowercase();\n\n    if filename.ends_with(\".zip\") {\n        Some(ArchiveFormat::Zip)\n    } else if filename.ends_with(\".rar\") {\n        Some(ArchiveFormat::Rar)\n    } else if filename.ends_with(\".7z\") {\n        Some(ArchiveFormat::SevenZip)\n    } else if filename.ends_with(\".tar.gz\") || filename.ends_with(\".tgz\") {\n        Some(ArchiveFormat::TarGz)\n    } else if filename.ends_with(\".tar\") {\n        Some(ArchiveFormat::Tar)\n    } else {\n        None\n    }\n}\n\n/// Checks if file is a supported archive\n///\n/// # Arguments\n/// * `path` - Path to check\n///\n/// # Returns\n/// * `true` if file is a recognized archive format\npub fn is_archive(path: \u0026Path) -\u003e bool {\n    detect_format(path).is_some()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::path::PathBuf;\n\n    #[test]\n    fn test_detect_zip() {\n        let path = PathBuf::from(\"test.zip\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Zip));\n    }\n\n    #[test]\n    fn test_detect_rar() {\n        let path = PathBuf::from(\"archive.rar\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Rar));\n    }\n\n    #[test]\n    fn test_detect_7z() {\n        let path = PathBuf::from(\"package.7z\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::SevenZip));\n    }\n\n    #[test]\n    fn test_detect_tar_gz() {\n        let path = PathBuf::from(\"archive.tar.gz\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::TarGz));\n    }\n\n    #[test]\n    fn test_detect_tgz() {\n        let path = PathBuf::from(\"archive.tgz\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::TarGz));\n    }\n\n    #[test]\n    fn test_detect_tar() {\n        let path = PathBuf::from(\"archive.tar\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Tar));\n    }\n\n    #[test]\n    fn test_not_archive() {\n        let path = PathBuf::from(\"file.mid\");\n        assert_eq!(detect_format(\u0026path), None);\n    }\n\n    #[test]\n    fn test_is_archive() {\n        assert!(is_archive(\u0026PathBuf::from(\"test.zip\")));\n        assert!(!is_archive(\u0026PathBuf::from(\"test.mid\")));\n    }\n\n    #[test]\n    fn test_extension() {\n        assert_eq!(ArchiveFormat::Zip.extension(), \"zip\");\n        assert_eq!(ArchiveFormat::Rar.extension(), \"rar\");\n        assert_eq!(ArchiveFormat::SevenZip.extension(), \"7z\");\n        assert_eq!(ArchiveFormat::TarGz.extension(), \"tar.gz\");\n        assert_eq!(ArchiveFormat::Tar.extension(), \"tar\");\n    }\n\n    #[test]\n    fn test_case_insensitive() {\n        let path = PathBuf::from(\"TEST.ZIP\");\n        assert_eq!(detect_format(\u0026path), Some(ArchiveFormat::Zip));\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","mod.rs"],"content":"//! Archive decompression module\n//!\n//! # Archetype: Grown-up Script\n//! - Performs I/O operations\n//! - Can be run standalone OR imported\n//! - Separates I/O from business logic\n\npub mod extractor;\npub mod formats;\npub mod temp_manager;\n\n// Re-export main types\npub use extractor::{extract_archive, extract_to_temp, ExtractionConfig, ExtractionResult};\npub use formats::{detect_format, is_archive, ArchiveFormat};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","decompressor","temp_manager.rs"],"content":"//! Temporary File Management\n\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse uuid::Uuid;\n\nuse crate::io::Result;\n\n/// Manages temporary extraction directories\npub struct TempManager {\n    base_dir: PathBuf,\n    active_dirs: Vec\u003cPathBuf\u003e,\n}\n\nimpl TempManager {\n    /// Creates new temp manager\n    ///\n    /// # Returns\n    /// * `Result\u003cTempManager\u003e` - New temp manager or I/O error\n    pub fn new() -\u003e Result\u003cSelf\u003e {\n        let base_dir = std::env::temp_dir().join(\"midi_extraction\");\n        fs::create_dir_all(\u0026base_dir)?;\n\n        Ok(Self {\n            base_dir,\n            active_dirs: Vec::new(),\n        })\n    }\n\n    /// Creates a new temporary directory\n    ///\n    /// # Returns\n    /// * `Result\u003cPathBuf\u003e` - Path to created temp directory or I/O error\n    pub fn create_temp_dir(\u0026mut self) -\u003e Result\u003cPathBuf\u003e {\n        let dir_name = Uuid::new_v4().to_string();\n        let temp_dir = self.base_dir.join(dir_name);\n\n        fs::create_dir_all(\u0026temp_dir)?;\n        self.active_dirs.push(temp_dir.clone());\n\n        Ok(temp_dir)\n    }\n\n    /// Cleans up all temporary directories\n    ///\n    /// # Returns\n    /// * `Result\u003c()\u003e` - Success or I/O error\n    pub fn cleanup(\u0026mut self) -\u003e Result\u003c()\u003e {\n        for dir in \u0026self.active_dirs {\n            if dir.exists() {\n                fs::remove_dir_all(dir)?;\n            }\n        }\n        self.active_dirs.clear();\n        Ok(())\n    }\n\n    /// Returns the base directory for temp files\n    pub fn base_dir(\u0026self) -\u003e \u0026Path {\n        \u0026self.base_dir\n    }\n\n    /// Returns count of active temporary directories\n    pub fn active_count(\u0026self) -\u003e usize {\n        self.active_dirs.len()\n    }\n}\n\nimpl Drop for TempManager {\n    fn drop(\u0026mut self) {\n        let _ = self.cleanup();\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_create_temp_dir() {\n        let mut manager = TempManager::new().unwrap();\n        let temp_dir = manager.create_temp_dir().unwrap();\n\n        assert!(temp_dir.exists());\n        assert_eq!(manager.active_count(), 1);\n\n        manager.cleanup().unwrap();\n        assert!(!temp_dir.exists());\n        assert_eq!(manager.active_count(), 0);\n    }\n\n    #[test]\n    fn test_multiple_temp_dirs() {\n        let mut manager = TempManager::new().unwrap();\n\n        let dir1 = manager.create_temp_dir().unwrap();\n        let dir2 = manager.create_temp_dir().unwrap();\n\n        assert!(dir1.exists());\n        assert!(dir2.exists());\n        assert_ne!(dir1, dir2);\n        assert_eq!(manager.active_count(), 2);\n\n        manager.cleanup().unwrap();\n        assert!(!dir1.exists());\n        assert!(!dir2.exists());\n    }\n\n    #[test]\n    fn test_base_dir() {\n        let manager = TempManager::new().unwrap();\n        let base = manager.base_dir();\n\n        assert!(base.exists());\n        // Use to_string_lossy() to avoid unwrap - it's safe for testing\n        assert!(base.to_string_lossy().contains(\"midi_extraction\"));\n    }\n\n    #[test]\n    fn test_cleanup_nonexistent_dir() {\n        let mut manager = TempManager::new().unwrap();\n        let temp_dir = manager.create_temp_dir().unwrap();\n\n        // Manually remove the directory\n        fs::remove_dir_all(\u0026temp_dir).unwrap();\n\n        // Cleanup should not fail even if dir doesn't exist\n        assert!(manager.cleanup().is_ok());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","error.rs"],"content":"//! I/O Error Types\n//!\n//! Defines error types for the I/O layer using thiserror.\n//! These errors cover file operations, archive extraction, and temporary file management.\n\nuse std::path::PathBuf;\nuse thiserror::Error;\n\n/// Errors that can occur during I/O operations\n#[derive(Error, Debug)]\npub enum IoError {\n    /// Standard I/O error\n    #[error(\"I/O error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    /// ZIP archive error\n    #[error(\"ZIP archive error: {0}\")]\n    Zip(#[from] zip::result::ZipError),\n\n    /// Invalid file path (contains non-UTF8 characters)\n    #[error(\"Invalid path (non-UTF8): {path:?}\")]\n    InvalidPath { path: PathBuf },\n\n    /// Unsupported archive format\n    #[error(\"Unsupported archive format: {path:?}\")]\n    UnsupportedFormat { path: PathBuf },\n\n    /// Maximum extraction depth exceeded\n    #[error(\"Maximum extraction depth ({max_depth}) exceeded at: {path:?}\")]\n    MaxDepthExceeded { max_depth: usize, path: PathBuf },\n\n    /// Archive format not implemented yet\n    #[error(\"Archive format {format:?} not yet implemented\")]\n    FormatNotImplemented { format: String },\n\n    /// Lock poisoning error (from RwLock or Mutex)\n    #[error(\"Lock poisoned\")]\n    LockPoisoned,\n\n    /// Temporary directory creation failed\n    #[error(\"Failed to create temporary directory\")]\n    TempDirCreation,\n\n    /// Generic boxed error for compatibility\n    #[error(\"Error: {0}\")]\n    Other(#[from] Box\u003cdyn std::error::Error + Send + Sync\u003e),\n}\n\n/// Result type for I/O operations\npub type Result\u003cT\u003e = std::result::Result\u003cT, IoError\u003e;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","io","mod.rs"],"content":"//! I/O operations module\n//!\n//! Contains Grown-up Scripts that perform file I/O operations\n\npub mod decompressor;\npub mod error;\n\n// Re-export error types\npub use error::{IoError, Result};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","lib.rs"],"content":"//! MIDI Library Pipeline Processor\n//!\n//! Core library for MIDI file processing, analysis, and management.\n\npub mod commands;\npub mod core;\npub mod db;\npub mod io;\n\n// Database connection module\npub mod database;\n\n// Error handling module\npub mod error;\n\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Re-export commonly used types\npub use database::Database;\npub use error::{AppError, AppResult, TauriResult};\npub use db::models::{File, MusicalMetadata, SearchFilters};\n\n/// Application state shared across all Tauri commands\npub struct AppState {\n    pub database: Database,\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","pipeline","src-tauri","src","main.rs"],"content":"// pipeline/src-tauri/src/main.rs\n// Task-O-Matic: Main entry point for Pipeline application\n// Purpose: Initialize app, register commands, manage state\n\n#![cfg_attr(\n    all(not(debug_assertions), target_os = \"windows\"),\n    windows_subsystem = \"windows\"\n)]\n\nuse tracing::{info};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\n\n// Import from lib\nuse midi_pipeline::{AppState, Database};\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    // Load .env file\n    dotenv::dotenv().ok();\n\n    // Initialize tracing/logging\n    init_logging();\n\n    info!(\"Starting MIDI Pipeline application\");\n\n    // Get database URL from environment\n    let database_url = std::env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    // Initialize database connection\n    let database = match Database::new(\u0026database_url).await {\n        Ok(db) =\u003e {\n            info!(\"Database connection established\");\n            db\n        }\n        Err(e) =\u003e {\n            info!(\"Database initialization deferred (will retry on first command): {}\", e);\n            // Retry once\n            Database::new(\u0026database_url).await.map_err(|retry_err| {\n                format!(\"Failed to create database instance after retry: {}\", retry_err)\n            })?\n        }\n    };\n\n    // Create application state\n    let state = AppState {\n        database,\n    };\n\n    // Build and run Tauri application\n    tauri::Builder::default()\n        .manage(state)\n        .invoke_handler(tauri::generate_handler![\n            // File commands\n            midi_pipeline::commands::files::test_db_connection,\n            midi_pipeline::commands::files::get_file_count,\n            midi_pipeline::commands::files::get_file_details,\n            midi_pipeline::commands::files::get_file,\n            midi_pipeline::commands::files::list_files,\n            midi_pipeline::commands::files::get_files_by_category,\n            midi_pipeline::commands::files::get_recent_files,\n            midi_pipeline::commands::files::delete_file,\n\n            // Import commands\n            midi_pipeline::commands::file_import::import_single_file,\n            midi_pipeline::commands::file_import::import_directory,\n            midi_pipeline::commands::archive_import::import_archive_collection,\n\n            // Search commands\n            midi_pipeline::commands::search::search_files,\n            midi_pipeline::commands::search::get_all_tags,\n            midi_pipeline::commands::search::get_files_by_tag,\n            midi_pipeline::commands::search::get_bpm_range,\n            midi_pipeline::commands::search::get_all_keys,\n\n            // Analysis commands\n            midi_pipeline::commands::analyze::start_analysis,\n\n            // Statistics commands\n            midi_pipeline::commands::stats::get_category_stats,\n            midi_pipeline::commands::stats::get_manufacturer_stats,\n            midi_pipeline::commands::stats::get_key_signature_stats,\n            midi_pipeline::commands::stats::get_recently_added_count,\n            midi_pipeline::commands::stats::get_duplicate_count,\n            midi_pipeline::commands::stats::get_database_size,\n            midi_pipeline::commands::stats::check_database_health,\n\n            // Tag commands\n            midi_pipeline::commands::tags::get_file_tags,\n            midi_pipeline::commands::tags::get_popular_tags,\n            midi_pipeline::commands::tags::search_tags,\n            midi_pipeline::commands::tags::get_tag_categories,\n            midi_pipeline::commands::tags::get_tags_by_category,\n            midi_pipeline::commands::tags::update_file_tags,\n            midi_pipeline::commands::tags::add_tags_to_file,\n            midi_pipeline::commands::tags::remove_tag_from_file,\n            midi_pipeline::commands::tags::get_files_by_tags,\n            midi_pipeline::commands::tags::get_tag_stats,\n\n            // Progress tracking commands\n            midi_pipeline::commands::progress::start_progress_tracking,\n            midi_pipeline::commands::progress::update_progress,\n            midi_pipeline::commands::progress::increment_error_count,\n            midi_pipeline::commands::progress::increment_duplicate_count,\n            midi_pipeline::commands::progress::complete_progress,\n            midi_pipeline::commands::progress::get_current_progress,\n            midi_pipeline::commands::progress::reset_progress,\n\n            // System commands\n            midi_pipeline::commands::system::get_system_info,\n        ])\n        .setup(|_app| {\n            info!(\"Application setup complete\");\n            Ok(())\n        })\n        .run(tauri::generate_context!())?;\n\n    Ok(())\n}\n\n/// Initialize logging/tracing system\nfn init_logging() {\n    let log_dir = std::env::var(\"LOG_DIR\").unwrap_or_else(|_| \"./logs\".to_string());\n    std::fs::create_dir_all(\u0026log_dir).ok();\n\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"pipeline.log\");\n    let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);\n\n    tracing_subscriber::registry()\n        .with(\n            tracing_subscriber::EnvFilter::try_from_default_env()\n                .unwrap_or_else(|_| \"info,midi_pipeline=debug\".into()),\n        )\n        .with(tracing_subscriber::fmt::layer().with_writer(std::io::stdout))\n        .with(tracing_subscriber::fmt::layer().with_writer(non_blocking))\n        .init();\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_logging_init() {\n        // Test that logging initialization doesn't panic\n        init_logging();\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","analyze-tool","src","analyzer.rs"],"content":"//! MIDI Analyzer - Trusty Module\n//!\n//! Extracts complete musical metadata from MIDI files\n\nuse midly::{Smf, Timing, MetaMessage, TrackEventKind, MidiMessage};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone)]\npub struct MidiAnalysis {\n    pub bpm: Option\u003cf64\u003e,\n    pub bpm_confidence: f32,\n    pub has_tempo_changes: bool,\n\n    pub key_signature: Option\u003cString\u003e,\n    pub key_confidence: f32,\n\n    pub time_sig_num: i16,\n    pub time_sig_den: i16,\n\n    pub duration_seconds: f64,\n    pub duration_ticks: i64,\n\n    pub total_notes: i32,\n    pub unique_pitches: i32,\n    pub pitch_range_min: i16,\n    pub pitch_range_max: i16,\n\n    pub avg_velocity: f64,\n    pub polyphony_max: i16,\n    pub polyphony_avg: f64,\n\n    pub is_monophonic: bool,\n    pub is_polyphonic: bool,\n    pub is_percussive: bool,\n    pub has_chords: bool,\n\n    pub note_density: f64,\n    pub instruments: Vec\u003cString\u003e,\n}\n\nimpl Default for MidiAnalysis {\n    fn default() -\u003e Self {\n        Self {\n            bpm: None,\n            bpm_confidence: 0.0,\n            has_tempo_changes: false,\n            key_signature: None,\n            key_confidence: 0.0,\n            time_sig_num: 4,\n            time_sig_den: 4,\n            duration_seconds: 0.0,\n            duration_ticks: 0,\n            total_notes: 0,\n            unique_pitches: 0,\n            pitch_range_min: 127,\n            pitch_range_max: 0,\n            avg_velocity: 0.0,\n            polyphony_max: 0,\n            polyphony_avg: 0.0,\n            is_monophonic: false,\n            is_polyphonic: false,\n            is_percussive: false,\n            has_chords: false,\n            note_density: 0.0,\n            instruments: Vec::new(),\n        }\n    }\n}\n\npub fn analyze_midi(data: \u0026[u8]) -\u003e Result\u003cMidiAnalysis, String\u003e {\n    let smf = Smf::parse(data).map_err(|e| format!(\"Parse error: {}\", e))?;\n\n    let mut analysis = MidiAnalysis::default();\n\n    // Get PPQ\n    let ppq = match smf.header.timing {\n        Timing::Metrical(tpb) =\u003e tpb.as_int() as i64,\n        Timing::Timecode(_, _) =\u003e 480,\n    };\n\n    // Extract tempo\n    let tempo_us = extract_tempo(\u0026smf);\n    if tempo_us \u003e 0 {\n        analysis.bpm = Some(60_000_000.0 / tempo_us as f64);\n        analysis.bpm_confidence = 1.0;\n    }\n\n    // Extract time signature\n    let (num, den) = extract_time_signature(\u0026smf);\n    analysis.time_sig_num = num;\n    analysis.time_sig_den = den;\n\n    // Collect all notes\n    let notes = collect_notes(\u0026smf);\n    analysis.total_notes = notes.len() as i32;\n\n    if !notes.is_empty() {\n        // Pitch analysis\n        let unique_pitches: std::collections::HashSet\u003cu8\u003e =\n            notes.iter().map(|(_, pitch, _)| *pitch).collect();\n        analysis.unique_pitches = unique_pitches.len() as i32;\n\n        analysis.pitch_range_min = notes.iter().map(|(_, p, _)| *p).min().unwrap_or(127) as i16;\n        analysis.pitch_range_max = notes.iter().map(|(_, p, _)| *p).max().unwrap_or(0) as i16;\n\n        // Velocity analysis\n        let total_vel: u32 = notes.iter().map(|(_, _, v)| *v as u32).sum();\n        analysis.avg_velocity = total_vel as f64 / notes.len() as f64;\n\n        // Polyphony analysis\n        analysis.polyphony_max = calculate_max_polyphony(\u0026notes);\n        analysis.polyphony_avg = calculate_avg_polyphony(\u0026notes);\n\n        analysis.is_monophonic = analysis.polyphony_max \u003c= 1;\n        analysis.is_polyphonic = analysis.polyphony_max \u003e= 3;\n        analysis.has_chords = analysis.polyphony_max \u003e= 3;\n\n        // Check for percussion (channel 10 or low pitch range)\n        analysis.is_percussive = notes.iter().any(|(_, pitch, _)| *pitch \u003c 36);\n\n        // Duration\n        let max_tick = notes.iter().map(|(tick, _, _)| *tick).max().unwrap_or(0);\n        analysis.duration_ticks = max_tick as i64;\n\n        if let Some(bpm) = analysis.bpm {\n            if bpm \u003e 0.0 {\n                analysis.duration_seconds = (max_tick as f64 / ppq as f64) * (60.0 / bpm);\n            }\n        }\n\n        // Note density\n        if analysis.duration_seconds \u003e 0.0 {\n            analysis.note_density = analysis.total_notes as f64 / analysis.duration_seconds;\n        }\n\n        // Key detection\n        if let Some((key, confidence)) = detect_key(\u0026notes) {\n            analysis.key_signature = Some(key);\n            analysis.key_confidence = confidence;\n        }\n\n        // Instruments\n        analysis.instruments = extract_instruments(\u0026smf);\n    }\n\n    Ok(analysis)\n}\n\nfn extract_tempo(smf: \u0026Smf) -\u003e u32 {\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Meta(MetaMessage::Tempo(tempo)) = event.kind {\n                return tempo.as_int();\n            }\n        }\n    }\n    500_000 // Default 120 BPM\n}\n\nfn extract_time_signature(smf: \u0026Smf) -\u003e (i16, i16) {\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Meta(MetaMessage::TimeSignature(num, den, _, _)) = event.kind {\n                return (num as i16, 2_i16.pow(den as u32));\n            }\n        }\n    }\n    (4, 4)\n}\n\nfn collect_notes(smf: \u0026Smf) -\u003e Vec\u003c(u32, u8, u8)\u003e {\n    let mut notes = Vec::new();\n\n    for track in \u0026smf.tracks {\n        let mut tick = 0u32;\n        for event in track {\n            tick += event.delta.as_int();\n\n            if let TrackEventKind::Midi { message, .. } = event.kind {\n                if let MidiMessage::NoteOn { key, vel } = message {\n                    if vel.as_int() \u003e 0 {\n                        notes.push((tick, key.as_int(), vel.as_int()));\n                    }\n                }\n            }\n        }\n    }\n\n    notes\n}\n\nfn calculate_max_polyphony(notes: \u0026[(u32, u8, u8)]) -\u003e i16 {\n    let mut note_states: HashMap\u003cu32, Vec\u003cu8\u003e\u003e = HashMap::new();\n\n    for (tick, pitch, _) in notes {\n        note_states.entry(*tick).or_insert_with(Vec::new).push(*pitch);\n    }\n\n    note_states.values()\n        .map(|pitches| {\n            pitches.iter().collect::\u003cstd::collections::HashSet\u003c_\u003e\u003e().len() as i16\n        })\n        .max()\n        .unwrap_or(0)\n}\n\nfn calculate_avg_polyphony(notes: \u0026[(u32, u8, u8)]) -\u003e f64 {\n    if notes.is_empty() {\n        return 0.0;\n    }\n\n    let max = calculate_max_polyphony(notes);\n    max as f64 * 0.6 // Rough estimate\n}\n\nfn detect_key(notes: \u0026[(u32, u8, u8)]) -\u003e Option\u003c(String, f32)\u003e {\n    if notes.is_empty() {\n        return None;\n    }\n\n    // Krumhansl-Schmuckler algorithm\n    const MAJOR_PROFILE: [f32; 12] = [\n        6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n        2.52, 5.19, 2.39, 3.66, 2.29, 2.88\n    ];\n\n    const MINOR_PROFILE: [f32; 12] = [\n        6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n        2.54, 4.75, 3.98, 2.69, 3.34, 3.17\n    ];\n\n    const NOTE_NAMES: [\u0026str; 12] = [\n        \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\",\n        \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"\n    ];\n\n    // Count pitch class occurrences\n    let mut pitch_class_counts = [0u32; 12];\n    for (_, pitch, _) in notes {\n        pitch_class_counts[(pitch % 12) as usize] += 1;\n    }\n\n    // Normalize\n    let total: u32 = pitch_class_counts.iter().sum();\n    if total == 0 {\n        return None;\n    }\n\n    let distribution: Vec\u003cf32\u003e = pitch_class_counts\n        .iter()\n        .map(|\u0026c| c as f32 / total as f32)\n        .collect();\n\n    // Find best correlation\n    let mut best_key = String::new();\n    let mut best_corr = -1.0f32;\n\n    for tonic in 0..12 {\n        // Test major\n        let major_corr = correlate(\u0026distribution, \u0026rotate_profile(\u0026MAJOR_PROFILE, tonic));\n        if major_corr \u003e best_corr {\n            best_corr = major_corr;\n            best_key = NOTE_NAMES[tonic].to_string();\n        }\n\n        // Test minor\n        let minor_corr = correlate(\u0026distribution, \u0026rotate_profile(\u0026MINOR_PROFILE, tonic));\n        if minor_corr \u003e best_corr {\n            best_corr = minor_corr;\n            best_key = format!(\"{}m\", NOTE_NAMES[tonic]);\n        }\n    }\n\n    Some((best_key, best_corr.max(0.0).min(1.0)))\n}\n\nfn correlate(a: \u0026[f32], b: \u0026[f32]) -\u003e f32 {\n    let mean_a: f32 = a.iter().sum::\u003cf32\u003e() / a.len() as f32;\n    let mean_b: f32 = b.iter().sum::\u003cf32\u003e() / b.len() as f32;\n\n    let mut numerator = 0.0f32;\n    let mut denom_a = 0.0f32;\n    let mut denom_b = 0.0f32;\n\n    for i in 0..a.len() {\n        let da = a[i] - mean_a;\n        let db = b[i] - mean_b;\n        numerator += da * db;\n        denom_a += da * da;\n        denom_b += db * db;\n    }\n\n    if denom_a == 0.0 || denom_b == 0.0 {\n        return 0.0;\n    }\n\n    numerator / (denom_a * denom_b).sqrt()\n}\n\nfn rotate_profile(profile: \u0026[f32; 12], steps: usize) -\u003e [f32; 12] {\n    let mut rotated = [0.0f32; 12];\n    for i in 0..12 {\n        rotated[i] = profile[(i + steps) % 12];\n    }\n    rotated\n}\n\nfn extract_instruments(smf: \u0026Smf) -\u003e Vec\u003cString\u003e {\n    let mut instruments = Vec::new();\n\n    for track in \u0026smf.tracks {\n        for event in track {\n            if let TrackEventKind::Midi { message, .. } = event.kind {\n                if let MidiMessage::ProgramChange { program } = message {\n                    let instrument = get_instrument_name(program.as_int());\n                    if !instruments.contains(\u0026instrument) {\n                        instruments.push(instrument);\n                    }\n                }\n            }\n        }\n    }\n\n    instruments\n}\n\nfn get_instrument_name(program: u8) -\u003e String {\n    match program {\n        0..=7 =\u003e \"Piano\".to_string(),\n        8..=15 =\u003e \"Chromatic Percussion\".to_string(),\n        16..=23 =\u003e \"Organ\".to_string(),\n        24..=31 =\u003e \"Guitar\".to_string(),\n        32..=39 =\u003e \"Bass\".to_string(),\n        40..=47 =\u003e \"Strings\".to_string(),\n        48..=55 =\u003e \"Ensemble\".to_string(),\n        56..=63 =\u003e \"Brass\".to_string(),\n        64..=71 =\u003e \"Reed\".to_string(),\n        72..=79 =\u003e \"Pipe\".to_string(),\n        80..=87 =\u003e \"Synth Lead\".to_string(),\n        88..=95 =\u003e \"Synth Pad\".to_string(),\n        96..=103 =\u003e \"Synth Effects\".to_string(),\n        104..=111 =\u003e \"Ethnic\".to_string(),\n        112..=119 =\u003e \"Percussive\".to_string(),\n        120..=127 =\u003e \"Sound Effects\".to_string(),\n        _ =\u003e \"Unknown\".to_string(),\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","analyze-tool","src","tag_extractor.rs"],"content":"///! Tag Extractor - Trusty Module\n//!\n//! Extracts tags from file paths and folder names\n\nuse std::path::Path;\n\n#[derive(Debug, Clone)]\npub struct ExtractedTags {\n    pub manufacturer: Option\u003cString\u003e,\n    pub collection: Option\u003cString\u003e,\n    pub genres: Vec\u003cString\u003e,\n    pub category: Option\u003cString\u003e,\n    pub bpm_hint: Option\u003ci16\u003e,\n    pub descriptors: Vec\u003cString\u003e,\n}\n\npub fn extract_tags_from_path(filepath: \u0026str) -\u003e ExtractedTags {\n    let path = Path::new(filepath);\n    let components: Vec\u003c\u0026str\u003e = path\n        .components()\n        .filter_map(|c| c.as_os_str().to_str())\n        .collect();\n\n    let mut tags = ExtractedTags {\n        manufacturer: None,\n        collection: None,\n        genres: Vec::new(),\n        category: None,\n        bpm_hint: None,\n        descriptors: Vec::new(),\n    };\n\n    // Extract manufacturer\n    tags.manufacturer = detect_manufacturer(\u0026components);\n\n    // Extract genres\n    tags.genres = extract_genres(\u0026components);\n\n    // Extract category\n    tags.category = detect_category(\u0026components);\n\n    // Extract BPM hint\n    tags.bpm_hint = extract_bpm_hint(filepath);\n\n    // Extract descriptors\n    tags.descriptors = extract_descriptors(\u0026components);\n\n    tags\n}\n\nfn detect_manufacturer(components: \u0026[\u0026str]) -\u003e Option\u003cString\u003e {\n    let manufacturers = [\n        \"DMS\", \"Loopmasters\", \"Vengeance\", \"Sample Magic\", \"Singomakers\",\n        \"Hy2rogen\", \"Production Master\", \"Function Loops\", \"Audentity\",\n        \"Chill Samples\", \"Class A Samples\", \"Diginoiz\", \"Prime Loops\",\n        \"Producer Loops\", \"Sonic Academy\", \"Black Octopus\", \"MIDI Focus\",\n        \"Zenhiser\"\n    ];\n\n    for component in components {\n        for mfr in \u0026manufacturers {\n            if component.contains(mfr) {\n                return Some(mfr.to_string());\n            }\n        }\n    }\n\n    None\n}\n\nfn extract_genres(components: \u0026[\u0026str]) -\u003e Vec\u003cString\u003e {\n    let genres = [\n        \"Trance\", \"House\", \"Techno\", \"Drum and Bass\", \"DnB\", \"Dubstep\",\n        \"Hardcore\", \"Progressive\", \"Electro\", \"Tech House\", \"Deep House\",\n        \"Psytrance\", \"Minimal\", \"Ambient\", \"Chill\", \"Lo-Fi\", \"Trap\",\n        \"Future Bass\", \"Liquid\"\n    ];\n\n    let mut found = Vec::new();\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for genre in \u0026genres {\n        if path_str.contains(\u0026genre.to_lowercase()) {\n            found.push(genre.to_string());\n        }\n    }\n\n    found\n}\n\nfn detect_category(components: \u0026[\u0026str]) -\u003e Option\u003cString\u003e {\n    let categories = [\n        (\"Bass\", vec![\"bass\", \"sub\", \"reese\"]),\n        (\"Melody\", vec![\"melody\", \"lead\", \"melodic\"]),\n        (\"Pad\", vec![\"pad\", \"atmosphere\", \"ambient\"]),\n        (\"Chord\", vec![\"chord\", \"progression\"]),\n        (\"Arp\", vec![\"arp\", \"arpegg\"]),\n        (\"Drum\", vec![\"drum\", \"kick\", \"snare\", \"hat\", \"perc\"]),\n        (\"FX\", vec![\"fx\", \"effect\", \"riser\", \"sweep\"]),\n    ];\n\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for (category, keywords) in \u0026categories {\n        for keyword in keywords {\n            if path_str.contains(keyword) {\n                return Some(category.to_string());\n            }\n        }\n    }\n\n    None\n}\n\nfn extract_bpm_hint(filepath: \u0026str) -\u003e Option\u003ci16\u003e {\n    // Look for patterns like \"140 BPM\", \"140BPM\", \"140bpm\"\n    let re = regex::Regex::new(r\"(\\d{2,3})\\s*[Bb][Pp][Mm]\").ok()?;\n\n    if let Some(cap) = re.captures(filepath) {\n        return cap[1].parse().ok();\n    }\n\n    // Also check for folder names like \"140 BPM\"\n    let re2 = regex::Regex::new(r\"/(\\d{2,3})\\s*[Bb][Pp][Mm]/\").ok()?;\n    if let Some(cap) = re2.captures(filepath) {\n        return cap[1].parse().ok();\n    }\n\n    None\n}\n\nfn extract_descriptors(components: \u0026[\u0026str]) -\u003e Vec\u003cString\u003e {\n    let descriptors = [\n        \"Hard\", \"Soft\", \"Deep\", \"Bright\", \"Dark\", \"Warm\", \"Cold\",\n        \"Fat\", \"Thin\", \"Punchy\", \"Smooth\", \"Rough\", \"Clean\", \"Dirty\",\n        \"Melodic\", \"Atmospheric\", \"Epic\", \"Minimal\", \"Complex\",\n        \"Liquid\", \"Uplifting\", \"Driving\", \"Bouncy\", \"Rolling\",\n        \"Variation\", \"Straight\", \"Shuffle\", \"Triplet\", \"Syncopation\"\n    ];\n\n    let mut found = Vec::new();\n    let path_str = components.join(\"/\").to_lowercase();\n\n    for desc in \u0026descriptors {\n        if path_str.contains(\u0026desc.to_lowercase()) \u0026\u0026 !found.contains(\u0026desc.to_string()) {\n            found.push(desc.to_string());\n        }\n    }\n\n    found\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","scripts","import-tool","src","main.rs"],"content":"//! Simple High-Performance MIDI Importer\n//!\n//! Usage: ./import_midi ~/midi_extraction\n//!\n//! This script:\n//! - Scans recursively for .mid/.midi files\n//! - Calculates SHA-256 hash for deduplication\n//! - Inserts into database with parallel processing\n//! - Shows real-time progress\n\nuse chrono::Utc;\nuse sha2::{Digest, Sha256};\nuse std::path::PathBuf;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::sync::Arc;\nuse tokio::sync::Semaphore;\n\n#[tokio::main]\nasync fn main() -\u003e Result\u003c(), Box\u003cdyn std::error::Error\u003e\u003e {\n    let args: Vec\u003cString\u003e = std::env::args().collect();\n\n    if args.len() \u003c 2 {\n        eprintln!(\"Usage: {} \u003cdirectory\u003e\", args[0]);\n        eprintln!(\"Example: {} ~/midi_extraction\", args[0]);\n        std::process::exit(1);\n    }\n\n    let directory = \u0026args[1];\n\n    println!(\" MIDI Library Importer\");\n    println!(\"\");\n    println!();\n\n    // Connect to database\n    let db_url = std::env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://midiuser:145278963@localhost:5433/midi_library\".to_string());\n\n    println!(\" Connecting to database...\");\n    let pool = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(32)\n        .connect(\u0026db_url)\n        .await?;\n    println!(\" Connected\\n\");\n\n    // Collect MIDI files\n    println!(\" Scanning: {}\", directory);\n    let files: Vec\u003cPathBuf\u003e = walkdir::WalkDir::new(directory)\n        .into_iter()\n        .filter_map(|e| e.ok())\n        .filter(|e| {\n            e.path()\n                .extension()\n                .and_then(|s| s.to_str())\n                .map(|s| s.eq_ignore_ascii_case(\"mid\") || s.eq_ignore_ascii_case(\"midi\"))\n                .unwrap_or(false)\n        })\n        .map(|e| e.path().to_path_buf())\n        .collect();\n\n    let total = files.len();\n    println!(\" Found {} MIDI files\\n\", total);\n\n    if total == 0 {\n        println!(\"  No MIDI files found!\");\n        return Ok(());\n    }\n\n    println!(\" Starting import with 32 workers...\\n\");\n\n    // Counters\n    let imported = Arc::new(AtomicUsize::new(0));\n    let skipped = Arc::new(AtomicUsize::new(0));\n    let errors = Arc::new(AtomicUsize::new(0));\n\n    let semaphore = Arc::new(Semaphore::new(32));\n    let start_time = std::time::Instant::now();\n\n    // Process files\n    let mut tasks = vec![];\n\n    for (idx, file_path) in files.into_iter().enumerate() {\n        let sem = Arc::clone(\u0026semaphore);\n        let pool_clone = pool.clone();\n        let imported = Arc::clone(\u0026imported);\n        let skipped = Arc::clone(\u0026skipped);\n        let errors = Arc::clone(\u0026errors);\n\n        let task = tokio::spawn(async move {\n            let _permit = match sem.acquire().await {\n                Ok(permit) =\u003e permit,\n                Err(_) =\u003e {\n                    eprintln!(\"Warning: Semaphore closed during import\");\n                    return;\n                }\n            };\n\n            match process_file(\u0026file_path, \u0026pool_clone).await {\n                Ok(true) =\u003e {\n                    imported.fetch_add(1, Ordering::SeqCst);\n                }\n                Ok(false) =\u003e {\n                    skipped.fetch_add(1, Ordering::SeqCst);\n                }\n                Err(_) =\u003e {\n                    errors.fetch_add(1, Ordering::SeqCst);\n                }\n            }\n\n            // Print progress every 100 files\n            if idx % 100 == 0 {\n                let elapsed = start_time.elapsed().as_secs_f64();\n                let processed = idx + 1;\n                let rate = processed as f64 / elapsed;\n                println!(\"Progress: {}/{} ({:.1}%) - {:.0} files/sec\",\n                    processed, total,\n                    (processed as f64 / total as f64) * 100.0,\n                    rate\n                );\n            }\n        });\n\n        tasks.push(task);\n    }\n\n    // Wait for all tasks\n    for task in tasks {\n        task.await?;\n    }\n\n    let elapsed = start_time.elapsed();\n    let imported_count = imported.load(Ordering::SeqCst);\n    let skipped_count = skipped.load(Ordering::SeqCst);\n    let error_count = errors.load(Ordering::SeqCst);\n\n    // Final report\n    println!();\n    println!(\"\");\n    println!(\" Import Complete!\");\n    println!(\"\");\n    println!(\"Total:     {}\", total);\n    println!(\"Imported:  {} \", imported_count);\n    println!(\"Skipped:   {} (duplicates)\", skipped_count);\n    println!(\"Errors:    {}\", error_count);\n    println!();\n    println!(\"  Time:  {:.2}s\", elapsed.as_secs_f64());\n    println!(\" Rate:  {:.0} files/sec\", total as f64 / elapsed.as_secs_f64());\n    println!();\n\n    Ok(())\n}\n\nasync fn process_file(\n    file_path: \u0026std::path::Path,\n    pool: \u0026sqlx::PgPool,\n) -\u003e Result\u003cbool, Box\u003cdyn std::error::Error\u003e\u003e {\n    // Read file\n    let file_data = tokio::fs::read(file_path).await?;\n\n    // Calculate hash\n    let mut hasher = Sha256::new();\n    hasher.update(\u0026file_data);\n    let content_hash = hasher.finalize().to_vec();\n\n    // Parse basic MIDI info\n    let (num_tracks, tpqn) = parse_midi_basic(\u0026file_data);\n\n    // Get parent folder name\n    let parent_folder = file_path\n        .parent()\n        .and_then(|p| p.file_name())\n        .and_then(|n| n.to_str())\n        .map(|s| s.to_string());\n\n    // Get filename (normalize .midi -\u003e .mid)\n    let original_filename = file_path\n        .file_name()\n        .and_then(|n| n.to_str())\n        .unwrap_or(\"unknown.mid\")\n        .to_string();\n\n    let filename = if original_filename.to_lowercase().ends_with(\".midi\") {\n        original_filename[..original_filename.len()-1].to_string() // .midi -\u003e .mid\n    } else {\n        original_filename.clone()\n    };\n\n    let filepath = file_path.to_str().unwrap_or(\"\").to_string();\n\n    // Insert into database\n    let result = sqlx::query_scalar::\u003c_, i64\u003e(\n        r#\"\n        INSERT INTO files (\n            filename,\n            original_filename,\n            filepath,\n            parent_folder,\n            content_hash,\n            file_size_bytes,\n            num_tracks,\n            ticks_per_quarter_note,\n            created_at,\n            updated_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\n        ON CONFLICT (content_hash) DO NOTHING\n        RETURNING id\n        \"#,\n    )\n    .bind(\u0026filename)\n    .bind(\u0026original_filename)\n    .bind(\u0026filepath)\n    .bind(parent_folder)\n    .bind(\u0026content_hash)\n    .bind(file_data.len() as i64)\n    .bind(num_tracks)\n    .bind(tpqn)\n    .bind(Utc::now())\n    .bind(Utc::now())\n    .fetch_optional(pool)\n    .await?;\n\n    Ok(result.is_some())\n}\n\n/// Parse basic MIDI info (tracks and TPPQ)\nfn parse_midi_basic(data: \u0026[u8]) -\u003e (i16, i32) {\n    if data.len() \u003c 14 || \u0026data[0..4] != b\"MThd\" {\n        return (1, 480);\n    }\n\n    let num_tracks = i16::from_be_bytes([data[10], data[11]]);\n    let ticks = u16::from_be_bytes([data[12], data[13]]);\n\n    (num_tracks, ticks as i32)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","auto_tagger.rs"],"content":"//! Auto-tagging functionality\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub fn generate_tags(_midi_file: \u0026crate::core::midi::MidiFile) -\u003e Vec\u003cString\u003e {\n    unimplemented!(\"Will be implemented in Phase 5\")\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","bpm_detector.rs"],"content":"//! BPM Detection Module\n//!\n//! This module provides BPM (Beats Per Minute) detection for MIDI files.\n//! It analyzes tempo change events and provides confidence scores.\n//!\n//! # Archetype: Trusty Module\n//! - Pure functions with no side effects\n//! - No I/O operations\n//! - Highly testable\n//! - Reusable across the application\n\nuse crate::core::midi::types::{Event, MidiFile};\n\n/// Default BPM when no tempo events are found\nconst DEFAULT_BPM: f64 = 120.0;\n\n/// Minimum valid BPM\nconst MIN_BPM: f64 = 20.0;\n\n/// Maximum valid BPM\nconst MAX_BPM: f64 = 300.0;\n\n/// Result of BPM detection\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmDetectionResult {\n    /// Detected BPM (beats per minute)\n    pub bpm: f64,\n\n    /// Confidence score (0.0 to 1.0)\n    pub confidence: f64,\n\n    /// Detection method used\n    pub method: BpmDetectionMethod,\n\n    /// Additional metadata\n    pub metadata: BpmMetadata,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum BpmDetectionMethod {\n    /// Single tempo event found\n    SingleTempo,\n\n    /// Multiple tempo events, used weighted average\n    WeightedAverage,\n\n    /// No tempo events, used default\n    DefaultTempo,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct BpmMetadata {\n    /// All tempo changes in the file\n    pub tempo_changes: Vec\u003cTempoChange\u003e,\n\n    /// Whether tempo is constant throughout\n    pub is_constant: bool,\n\n    /// Tempo range (min, max) if multiple tempos\n    pub tempo_range: Option\u003c(f64, f64)\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct TempoChange {\n    pub tick: u32,\n    pub bpm: f64,\n}\n\n/// Detects BPM from a parsed MIDI file\n///\n/// # Arguments\n/// * `midi_file` - Parsed MIDI file structure\n///\n/// # Returns\n/// * `BpmDetectionResult` - Detection result with confidence and metadata\n///\n/// # Examples\n/// ```ignore\n/// use midi_library_shared::core::analysis::bpm_detector::detect_bpm;\n/// use midi_library_shared::core::midi::types::MidiFile;\n///\n/// let result = detect_bpm(\u0026midi_file);\n/// println!(\"Detected BPM: {:.2}\", result.bpm);\n/// ```\npub fn detect_bpm(midi_file: \u0026MidiFile) -\u003e BpmDetectionResult {\n    // Extract all tempo events from all tracks\n    let tempo_events = extract_tempo_events(midi_file);\n\n    if tempo_events.is_empty() {\n        return BpmDetectionResult {\n            bpm: DEFAULT_BPM,\n            confidence: 0.3, // Low confidence for default tempo\n            method: BpmDetectionMethod::DefaultTempo,\n            metadata: BpmMetadata {\n                tempo_changes: vec![],\n                is_constant: true,\n                tempo_range: None,\n            },\n        };\n    }\n\n    // Convert tempo changes to BPM values\n    let tempo_changes: Vec\u003cTempoChange\u003e = tempo_events\n        .into_iter()\n        .map(|(tick, microseconds_per_quarter)| TempoChange {\n            tick,\n            bpm: microseconds_to_bpm(microseconds_per_quarter),\n        })\n        .collect();\n\n    // Calculate statistics\n    let is_constant = tempo_changes.len() == 1;\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let total_ticks = calculate_total_ticks(midi_file);\n    let avg_bpm = calculate_weighted_average(\u0026tempo_changes, total_ticks);\n\n    let tempo_range = if tempo_changes.len() \u003e 1 {\n        let min = bpms.iter().cloned().fold(f64::INFINITY, f64::min);\n        let max = bpms.iter().cloned().fold(f64::NEG_INFINITY, f64::max);\n        Some((min, max))\n    } else {\n        None\n    };\n\n    // Determine confidence based on consistency\n    let confidence = calculate_confidence(\u0026tempo_changes);\n\n    let method = if tempo_changes.len() == 1 {\n        BpmDetectionMethod::SingleTempo\n    } else {\n        BpmDetectionMethod::WeightedAverage\n    };\n\n    BpmDetectionResult {\n        bpm: avg_bpm,\n        confidence,\n        method,\n        metadata: BpmMetadata {\n            tempo_changes,\n            is_constant,\n            tempo_range,\n        },\n    }\n}\n\n/// Extracts tempo events from all tracks in the MIDI file\nfn extract_tempo_events(midi_file: \u0026MidiFile) -\u003e Vec\u003c(u32, u32)\u003e {\n    let mut tempo_events = Vec::new();\n\n    for track in \u0026midi_file.tracks {\n        let mut current_tick = 0u32;\n\n        for timed_event in \u0026track.events {\n            current_tick += timed_event.delta_ticks;\n\n            if let Event::TempoChange {\n                microseconds_per_quarter,\n            } = timed_event.event\n            {\n                tempo_events.push((current_tick, microseconds_per_quarter));\n            }\n        }\n    }\n\n    // Sort by tick position\n    tempo_events.sort_by_key(|(tick, _)| *tick);\n    tempo_events\n}\n\n/// Calculates the total number of ticks in the MIDI file\nfn calculate_total_ticks(midi_file: \u0026MidiFile) -\u003e u32 {\n    let mut max_ticks = 0u32;\n\n    for track in \u0026midi_file.tracks {\n        let mut track_ticks = 0u32;\n        for timed_event in \u0026track.events {\n            track_ticks += timed_event.delta_ticks;\n        }\n        max_ticks = max_ticks.max(track_ticks);\n    }\n\n    max_ticks\n}\n\n/// Converts microseconds per quarter note to BPM\nfn microseconds_to_bpm(microseconds_per_quarter: u32) -\u003e f64 {\n    let bpm = 60_000_000.0 / microseconds_per_quarter as f64;\n\n    // Clamp to valid range\n    bpm.clamp(MIN_BPM, MAX_BPM)\n}\n\n/// Calculates weighted average BPM based on duration each tempo is active\nfn calculate_weighted_average(tempo_changes: \u0026[TempoChange], total_ticks: u32) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return DEFAULT_BPM;\n    }\n\n    if tempo_changes.len() == 1 {\n        return tempo_changes[0].bpm;\n    }\n\n    let mut weighted_sum = 0.0;\n    let mut total_weight = 0.0;\n\n    for (i, tempo_change) in tempo_changes.iter().enumerate() {\n        let duration = if i + 1 \u003c tempo_changes.len() {\n            tempo_changes[i + 1].tick - tempo_change.tick\n        } else {\n            total_ticks.saturating_sub(tempo_change.tick)\n        };\n\n        let weight = duration as f64;\n        weighted_sum += tempo_change.bpm * weight;\n        total_weight += weight;\n    }\n\n    if total_weight \u003e 0.0 {\n        weighted_sum / total_weight\n    } else {\n        tempo_changes[0].bpm\n    }\n}\n\n/// Calculates confidence score based on tempo consistency\nfn calculate_confidence(tempo_changes: \u0026[TempoChange]) -\u003e f64 {\n    if tempo_changes.is_empty() {\n        return 0.3; // Low confidence for default\n    }\n\n    if tempo_changes.len() == 1 {\n        return 1.0; // High confidence for single tempo\n    }\n\n    // Calculate variance in BPM values\n    let bpms: Vec\u003cf64\u003e = tempo_changes.iter().map(|tc| tc.bpm).collect();\n    let mean = bpms.iter().sum::\u003cf64\u003e() / bpms.len() as f64;\n    let variance = bpms.iter().map(|bpm| (bpm - mean).powi(2)).sum::\u003cf64\u003e() / bpms.len() as f64;\n    let std_dev = variance.sqrt();\n\n    // Lower variance = higher confidence\n    // Scale confidence based on coefficient of variation\n    let cv = std_dev / mean;\n    (1.0 - cv).clamp(0.5, 1.0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_microseconds_to_bpm() {\n        // 120 BPM = 500,000 microseconds per quarter note\n        assert_eq!(microseconds_to_bpm(500_000), 120.0);\n\n        // 60 BPM = 1,000,000 microseconds\n        assert_eq!(microseconds_to_bpm(1_000_000), 60.0);\n\n        // 140 BPM  428,571 microseconds\n        let bpm = microseconds_to_bpm(428_571);\n        assert!((bpm - 140.0).abs() \u003c 0.1);\n    }\n\n    #[test]\n    fn test_bpm_clamping() {\n        // Test minimum clamping\n        let too_slow = microseconds_to_bpm(5_000_000); // Would be 12 BPM\n        assert_eq!(too_slow, MIN_BPM);\n\n        // Test maximum clamping\n        let too_fast = microseconds_to_bpm(100_000); // Would be 600 BPM\n        assert_eq!(too_fast, MAX_BPM);\n    }\n}\n","traces":[{"line":187,"address":[764656],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":1},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","key_detector.rs"],"content":"//! Key detection\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub fn detect_key(_midi_file: \u0026crate::core::midi::MidiFile) -\u003e Option\u003cString\u003e {\n    unimplemented!(\"Will be implemented in Phase 5\")\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","key_profiles.rs"],"content":"//! Key profile data\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","analysis","mod.rs"],"content":"//! Musical analysis modules\n//!\n//! This module provides:\n//! - BPM detection\n//! - Key detection\n//! - Auto-tagging\n//! - Key profile data\n\npub mod bpm_detector;\npub mod key_detector;\npub mod key_profiles;\npub mod auto_tagger;\n\n// Re-export main functions\npub use bpm_detector::detect_bpm;\npub use key_detector::detect_key;\npub use auto_tagger::generate_tags;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","error.rs"],"content":"use thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum MidiParseError {\n    #[error(\"Invalid MIDI header: {0}\")]\n    InvalidHeader(String),\n\n    #[error(\"Invalid track data at byte {position}: {reason}\")]\n    InvalidTrack { position: usize, reason: String },\n\n    #[error(\"Unsupported MIDI format: {0}\")]\n    UnsupportedFormat(u16),\n\n    #[error(\"Invalid event at byte {position}: {reason}\")]\n    InvalidEvent { position: usize, reason: String },\n\n    #[error(\"Incomplete data: expected {expected} bytes, got {actual}\")]\n    IncompleteData { expected: usize, actual: usize },\n\n    #[error(\"Invalid variable-length quantity at byte {0}\")]\n    InvalidVarLen(usize),\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"UTF-8 decode error: {0}\")]\n    Utf8(#[from] std::string::FromUtf8Error),\n}\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, MidiParseError\u003e;\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::io;\n\n    // ============================================================================\n    // Error Construction Tests\n    // ============================================================================\n\n    #[test]\n    fn test_invalid_header_construction() {\n        let error = MidiParseError::InvalidHeader(\"bad magic number\".to_string());\n        assert!(matches!(error, MidiParseError::InvalidHeader(_)));\n    }\n\n    #[test]\n    fn test_invalid_track_construction() {\n        let error = MidiParseError::InvalidTrack {\n            position: 42,\n            reason: \"unexpected end\".to_string(),\n        };\n        assert!(matches!(error, MidiParseError::InvalidTrack { .. }));\n    }\n\n    #[test]\n    fn test_unsupported_format_construction() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        assert!(matches!(error, MidiParseError::UnsupportedFormat(99)));\n    }\n\n    #[test]\n    fn test_invalid_event_construction() {\n        let error = MidiParseError::InvalidEvent {\n            position: 100,\n            reason: \"invalid status byte\".to_string(),\n        };\n        assert!(matches!(error, MidiParseError::InvalidEvent { .. }));\n    }\n\n    #[test]\n    fn test_incomplete_data_construction() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        assert!(matches!(error, MidiParseError::IncompleteData { .. }));\n    }\n\n    #[test]\n    fn test_invalid_var_len_construction() {\n        let error = MidiParseError::InvalidVarLen(256);\n        assert!(matches!(error, MidiParseError::InvalidVarLen(256)));\n    }\n\n    // ============================================================================\n    // Display Formatting Tests\n    // ============================================================================\n\n    #[test]\n    fn test_invalid_header_message_format() {\n        let error = MidiParseError::InvalidHeader(\"bad magic number\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Invalid MIDI header\"));\n        assert!(msg.contains(\"bad magic number\"));\n    }\n\n    #[test]\n    fn test_invalid_track_message_includes_position() {\n        let error = MidiParseError::InvalidTrack {\n            position: 42,\n            reason: \"unexpected end\".to_string(),\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"42\"));\n        assert!(msg.contains(\"unexpected end\"));\n        assert!(msg.contains(\"Invalid track data\"));\n    }\n\n    #[test]\n    fn test_unsupported_format_message() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        let msg = error.to_string();\n        assert!(msg.contains(\"Unsupported MIDI format\"));\n        assert!(msg.contains(\"99\"));\n    }\n\n    #[test]\n    fn test_invalid_event_message_includes_position() {\n        let error = MidiParseError::InvalidEvent {\n            position: 100,\n            reason: \"invalid status byte\".to_string(),\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"100\"));\n        assert!(msg.contains(\"invalid status byte\"));\n    }\n\n    #[test]\n    fn test_incomplete_data_shows_expected_vs_actual() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        let msg = error.to_string();\n        assert!(msg.contains(\"100\"));\n        assert!(msg.contains(\"50\"));\n        assert!(msg.contains(\"Incomplete data\"));\n    }\n\n    #[test]\n    fn test_invalid_var_len_message() {\n        let error = MidiParseError::InvalidVarLen(256);\n        let msg = error.to_string();\n        assert!(msg.contains(\"256\"));\n        assert!(msg.contains(\"Invalid variable-length quantity\"));\n    }\n\n    #[test]\n    fn test_io_error_message() {\n        let io_error = io::Error::new(io::ErrorKind::NotFound, \"file not found\");\n        let error = MidiParseError::Io(io_error);\n        let msg = error.to_string();\n        assert!(msg.contains(\"IO error\"));\n        assert!(msg.contains(\"file not found\"));\n    }\n\n    #[test]\n    fn test_utf8_error_message() {\n        let invalid_utf8 = vec![0xFF, 0xFE, 0xFD];\n        let utf8_error = String::from_utf8(invalid_utf8).unwrap_err();\n        let error = MidiParseError::Utf8(utf8_error);\n        let msg = error.to_string();\n        assert!(msg.contains(\"UTF-8 decode error\"));\n    }\n\n    // ============================================================================\n    // Error Conversion Tests (From trait)\n    // ============================================================================\n\n    #[test]\n    fn test_io_error_conversion() {\n        let io_error = io::Error::new(io::ErrorKind::NotFound, \"test file\");\n        let midi_error: MidiParseError = io_error.into();\n\n        assert!(matches!(midi_error, MidiParseError::Io(_)));\n        assert!(midi_error.to_string().contains(\"test file\"));\n    }\n\n    #[test]\n    fn test_utf8_error_conversion() {\n        let invalid_utf8 = vec![0xFF, 0xFE, 0xFD];\n        let utf8_error = String::from_utf8(invalid_utf8).unwrap_err();\n        let midi_error: MidiParseError = utf8_error.into();\n\n        assert!(matches!(midi_error, MidiParseError::Utf8(_)));\n    }\n\n    // ============================================================================\n    // Debug Formatting Tests\n    // ============================================================================\n\n    #[test]\n    fn test_error_debug_format() {\n        let error = MidiParseError::UnsupportedFormat(99);\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"UnsupportedFormat\"));\n        assert!(debug.contains(\"99\"));\n    }\n\n    #[test]\n    fn test_error_debug_includes_variant_name() {\n        let error = MidiParseError::InvalidHeader(\"test\".to_string());\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"InvalidHeader\"));\n    }\n\n    #[test]\n    fn test_error_debug_includes_data() {\n        let error = MidiParseError::IncompleteData {\n            expected: 100,\n            actual: 50,\n        };\n        let debug = format!(\"{:?}\", error);\n        assert!(debug.contains(\"100\"));\n        assert!(debug.contains(\"50\"));\n    }\n\n    // ============================================================================\n    // Result Type Alias Tests\n    // ============================================================================\n\n    #[test]\n    fn test_result_type_alias_ok() {\n        let result: Result\u003ci32\u003e = Ok(42);\n        assert_eq!(result.unwrap(), 42);\n    }\n\n    #[test]\n    fn test_result_type_alias_err() {\n        let result: Result\u003ci32\u003e = Err(MidiParseError::InvalidVarLen(0));\n        assert!(result.is_err());\n    }\n\n    // ============================================================================\n    // Edge Case Tests\n    // ============================================================================\n\n    #[test]\n    fn test_empty_error_messages() {\n        let error = MidiParseError::InvalidHeader(String::new());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Invalid MIDI header\"));\n    }\n\n    #[test]\n    fn test_very_long_error_message() {\n        let long_msg = \"x\".repeat(10000);\n        let error = MidiParseError::InvalidHeader(long_msg.clone());\n        let msg = error.to_string();\n        assert!(msg.contains(\u0026long_msg));\n        assert_eq!(msg.len(), \"Invalid MIDI header: \".len() + 10000);\n    }\n\n    #[test]\n    fn test_special_characters_in_error() {\n        let error = MidiParseError::InvalidHeader(\"Line 1\\nLine 2\\tTab\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"Line 1\\nLine 2\\tTab\"));\n    }\n\n    #[test]\n    fn test_unicode_in_error_message() {\n        let error = MidiParseError::InvalidHeader(\"Invalid:  MIDI file\".to_string());\n        let msg = error.to_string();\n        assert!(msg.contains(\"\"));\n    }\n\n    #[test]\n    fn test_position_boundaries() {\n        let error_min = MidiParseError::InvalidTrack {\n            position: 0,\n            reason: \"start of file\".to_string(),\n        };\n        let error_max = MidiParseError::InvalidTrack {\n            position: usize::MAX,\n            reason: \"end of file\".to_string(),\n        };\n\n        assert!(error_min.to_string().contains(\"0\"));\n        assert!(error_max.to_string().contains(\u0026usize::MAX.to_string()));\n    }\n\n    #[test]\n    fn test_all_format_variants() {\n        // Test format values 0-2 (valid) and beyond\n        for format in [0, 1, 2, 3, 99, u16::MAX] {\n            let error = MidiParseError::UnsupportedFormat(format);\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026format.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_expected_actual_boundaries() {\n        let cases = vec![\n            (0, 0),\n            (1, 0),\n            (100, 50),\n            (usize::MAX, 0),\n            (1000, 999),\n        ];\n\n        for (expected, actual) in cases {\n            let error = MidiParseError::IncompleteData { expected, actual };\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026expected.to_string()));\n            assert!(msg.contains(\u0026actual.to_string()));\n        }\n    }\n\n    // ============================================================================\n    // Security Tests\n    // ============================================================================\n\n    #[test]\n    fn test_error_message_no_memory_leak() {\n        // Create large error messages to ensure no memory leak\n        for _ in 0..1000 {\n            let error = MidiParseError::InvalidHeader(\"x\".repeat(1000));\n            let _ = error.to_string();\n        }\n        // If we get here, no memory leak (would OOM otherwise)\n    }\n\n    #[test]\n    fn test_malicious_position_values() {\n        // Test extreme position values don't cause issues\n        let positions = vec![0, 1, usize::MAX - 1, usize::MAX];\n\n        for pos in positions {\n            let error = MidiParseError::InvalidEvent {\n                position: pos,\n                reason: \"test\".to_string(),\n            };\n            let msg = error.to_string();\n            assert!(msg.contains(\u0026pos.to_string()));\n        }\n    }\n\n    #[test]\n    fn test_error_size_is_reasonable() {\n        // Ensure error type doesn't use excessive memory\n        use std::mem;\n        let size = mem::size_of::\u003cMidiParseError\u003e();\n\n        // thiserror errors should be reasonably sized (\u003c 200 bytes typical)\n        assert!(\n            size \u003c 256,\n            \"MidiParseError is too large: {} bytes\",\n            size\n        );\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","mod.rs"],"content":"//! MIDI file parsing and types\n//!\n//! This module provides:\n//! - MIDI file parsing\n//! - MIDI data types\n//! - Error handling\n\npub mod parser;\npub mod types;\npub mod error;\n\n// Re-export commonly used items\npub use parser::parse_midi_file;\npub use types::{MidiFile, Event, Track};\npub use error::{MidiParseError, Result};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","parser.rs"],"content":"use super::error::{MidiParseError, Result};\nuse super::types::*;\n\n/// Parse a MIDI file from raw bytes\n///\n/// This is the main entry point for MIDI parsing. It accepts raw file bytes\n/// and returns a structured MidiFile or an error.\n///\n/// # Examples\n/// ```ignore\n/// use midi_library_shared::core::midi::parse_midi_file;\n///\n/// let data = std::fs::read(\"song.mid\").unwrap();\n/// let midi_file = parse_midi_file(\u0026data)?;\n/// println!(\"Format: {}, Tracks: {}\", midi_file.header.format, midi_file.header.num_tracks);\n/// # Ok::\u003c(), Box\u003cdyn std::error::Error\u003e\u003e(())\n/// ```\npub fn parse_midi_file(data: \u0026[u8]) -\u003e Result\u003cMidiFile\u003e {\n    if data.len() \u003c 14 {\n        return Err(MidiParseError::IncompleteData {\n            expected: 14,\n            actual: data.len(),\n        });\n    }\n\n    // Parse header chunk\n    let header = parse_header(\u0026data[0..14])?;\n\n    // Parse tracks\n    let mut tracks = Vec::with_capacity(header.num_tracks as usize);\n    let mut pos = 14;\n\n    for track_num in 0..header.num_tracks {\n        let (track, bytes_read) = parse_track(\u0026data[pos..]).map_err(|e| match e {\n            MidiParseError::InvalidTrack { position, reason } =\u003e MidiParseError::InvalidTrack {\n                position: pos + position,\n                reason: format!(\"Track {}: {}\", track_num, reason),\n            },\n            e =\u003e e,\n        })?;\n\n        tracks.push(track);\n        pos += bytes_read;\n    }\n\n    Ok(MidiFile { header, tracks })\n}\n\n/// Parse MIDI header chunk (MThd)\nfn parse_header(data: \u0026[u8]) -\u003e Result\u003cHeader\u003e {\n    // Check magic number \"MThd\"\n    if \u0026data[0..4] != b\"MThd\" {\n        return Err(MidiParseError::InvalidHeader(format!(\n            \"Expected 'MThd', got {:?}\",\n            \u0026data[0..4]\n        )));\n    }\n\n    // Check header length (must be 6)\n    let length = u32::from_be_bytes([data[4], data[5], data[6], data[7]]);\n    if length != 6 {\n        return Err(MidiParseError::InvalidHeader(format!(\n            \"Expected header length 6, got {}\",\n            length\n        )));\n    }\n\n    let format = u16::from_be_bytes([data[8], data[9]]);\n    let num_tracks = u16::from_be_bytes([data[10], data[11]]);\n    let ticks_per_quarter_note = u16::from_be_bytes([data[12], data[13]]);\n\n    // Validate format\n    if format \u003e 2 {\n        return Err(MidiParseError::UnsupportedFormat(format));\n    }\n\n    Ok(Header {\n        format,\n        num_tracks,\n        ticks_per_quarter_note,\n    })\n}\n\n/// Parse a single MIDI track (MTrk)\n/// Returns (Track, bytes_consumed)\nfn parse_track(data: \u0026[u8]) -\u003e Result\u003c(Track, usize)\u003e {\n    if data.len() \u003c 8 {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: \"Track too short\".to_string(),\n        });\n    }\n\n    // Check magic number \"MTrk\"\n    if \u0026data[0..4] != b\"MTrk\" {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: format!(\"Expected 'MTrk', got {:?}\", \u0026data[0..4]),\n        });\n    }\n\n    let track_length = u32::from_be_bytes([data[4], data[5], data[6], data[7]]) as usize;\n\n    if data.len() \u003c 8 + track_length {\n        return Err(MidiParseError::InvalidTrack {\n            position: 0,\n            reason: format!(\n                \"Track data incomplete: expected {} bytes, got {}\",\n                track_length,\n                data.len() - 8\n            ),\n        });\n    }\n\n    let track_data = \u0026data[8..8 + track_length];\n    let events = parse_track_events(track_data)?;\n\n    Ok((Track { events }, 8 + track_length))\n}\n\n/// Parse all events within a track\nfn parse_track_events(data: \u0026[u8]) -\u003e Result\u003cVec\u003cTimedEvent\u003e\u003e {\n    let mut events = Vec::new();\n    let mut pos = 0;\n    let mut running_status: Option\u003cu8\u003e = None;\n\n    while pos \u003c data.len() {\n        // Parse delta time (variable-length quantity)\n        let (delta_ticks, delta_bytes) =\n            read_var_len(\u0026data[pos..]).ok_or(MidiParseError::InvalidVarLen(pos))?;\n        pos += delta_bytes;\n\n        // Parse event\n        let (event, event_bytes, new_running_status) = parse_event(\u0026data[pos..], running_status)\n            .map_err(|e| match e {\n                MidiParseError::InvalidEvent { position, reason } =\u003e MidiParseError::InvalidEvent {\n                    position: pos + position,\n                    reason,\n                },\n                e =\u003e e,\n            })?;\n\n        pos += event_bytes;\n        running_status = new_running_status;\n\n        events.push(TimedEvent { delta_ticks, event });\n\n        // End of track?\n        if matches!(\n            events.last(),\n            Some(TimedEvent {\n                event: Event::EndOfTrack,\n                ..\n            })\n        ) {\n            break;\n        }\n    }\n\n    Ok(events)\n}\n\n/// Parse a single MIDI event\n/// Returns (Event, bytes_consumed, new_running_status)\nfn parse_event(data: \u0026[u8], running_status: Option\u003cu8\u003e) -\u003e Result\u003c(Event, usize, Option\u003cu8\u003e)\u003e {\n    if data.is_empty() {\n        return Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: \"No data for event\".to_string(),\n        });\n    }\n\n    let mut status = data[0];\n    let mut pos = 1;\n\n    // Handle running status (reuse previous status byte if data byte encountered)\n    if status \u003c 0x80 {\n        if let Some(rs) = running_status {\n            status = rs;\n            pos = 0; // Don't consume the byte, it's data\n        } else {\n            return Err(MidiParseError::InvalidEvent {\n                position: 0,\n                reason: \"Data byte without running status\".to_string(),\n            });\n        }\n    }\n\n    let event_type = status \u0026 0xF0;\n    let channel = status \u0026 0x0F;\n\n    match event_type {\n        0x80 =\u003e {\n            // Note Off\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::NoteOff {\n                    channel,\n                    note: data[pos],\n                    velocity: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0x90 =\u003e {\n            // Note On\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::NoteOn {\n                    channel,\n                    note: data[pos],\n                    velocity: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xA0 =\u003e {\n            // Polyphonic Aftertouch\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::Aftertouch {\n                    channel,\n                    note: data[pos],\n                    pressure: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xB0 =\u003e {\n            // Control Change\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ControlChange {\n                    channel,\n                    controller: data[pos],\n                    value: data[pos + 1],\n                },\n                pos + 2,\n                Some(status),\n            ))\n        }\n        0xC0 =\u003e {\n            // Program Change\n            if data.len() \u003c pos + 1 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 1,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ProgramChange {\n                    channel,\n                    program: data[pos],\n                },\n                pos + 1,\n                Some(status),\n            ))\n        }\n        0xD0 =\u003e {\n            // Channel Aftertouch\n            if data.len() \u003c pos + 1 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 1,\n                    actual: data.len(),\n                });\n            }\n            Ok((\n                Event::ChannelAftertouch {\n                    channel,\n                    pressure: data[pos],\n                },\n                pos + 1,\n                Some(status),\n            ))\n        }\n        0xE0 =\u003e {\n            // Pitch Bend\n            if data.len() \u003c pos + 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: pos + 2,\n                    actual: data.len(),\n                });\n            }\n            let lsb = data[pos] as i16;\n            let msb = data[pos + 1] as i16;\n            let value = ((msb \u003c\u003c 7) | lsb) - 8192; // Center at 0\n            Ok((Event::PitchBend { channel, value }, pos + 2, Some(status)))\n        }\n        0xF0 =\u003e {\n            // System/Meta events\n            parse_meta_or_sysex(\u0026data[pos - 1..])\n        }\n        _ =\u003e Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: format!(\"Unknown event type: 0x{:02X}\", status),\n        }),\n    }\n}\n\n/// Parse meta events and SysEx\nfn parse_meta_or_sysex(data: \u0026[u8]) -\u003e Result\u003c(Event, usize, Option\u003cu8\u003e)\u003e {\n    let status = data[0];\n\n    match status {\n        0xFF =\u003e {\n            // Meta event\n            if data.len() \u003c 2 {\n                return Err(MidiParseError::IncompleteData {\n                    expected: 2,\n                    actual: data.len(),\n                });\n            }\n\n            let meta_type = data[1];\n            let (length, len_bytes) =\n                read_var_len(\u0026data[2..]).ok_or(MidiParseError::InvalidVarLen(2))?;\n\n            let data_start = 2 + len_bytes;\n            let data_end = data_start + length as usize;\n\n            if data.len() \u003c data_end {\n                return Err(MidiParseError::IncompleteData {\n                    expected: data_end,\n                    actual: data.len(),\n                });\n            }\n\n            let event_data = \u0026data[data_start..data_end];\n\n            let event = match meta_type {\n                0x2F =\u003e Event::EndOfTrack,\n                0x51 =\u003e {\n                    if event_data.len() != 3 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Tempo event must be 3 bytes\".to_string(),\n                        });\n                    }\n                    let microseconds_per_quarter =\n                        u32::from_be_bytes([0, event_data[0], event_data[1], event_data[2]]);\n                    Event::TempoChange {\n                        microseconds_per_quarter,\n                    }\n                }\n                0x58 =\u003e {\n                    if event_data.len() != 4 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Time signature event must be 4 bytes\".to_string(),\n                        });\n                    }\n                    Event::TimeSignature {\n                        numerator: event_data[0],\n                        denominator: event_data[1],\n                        clocks_per_click: event_data[2],\n                        thirty_seconds_per_quarter: event_data[3],\n                    }\n                }\n                0x59 =\u003e {\n                    if event_data.len() != 2 {\n                        return Err(MidiParseError::InvalidEvent {\n                            position: 0,\n                            reason: \"Key signature event must be 2 bytes\".to_string(),\n                        });\n                    }\n                    Event::KeySignature {\n                        sharps_flats: event_data[0] as i8,\n                        is_minor: event_data[1] != 0,\n                    }\n                }\n                0x01..=0x0F =\u003e {\n                    // Text events\n                    let text = String::from_utf8(event_data.to_vec())?;\n                    let text_type = match meta_type {\n                        0x01 =\u003e TextType::Text,\n                        0x02 =\u003e TextType::Copyright,\n                        0x03 =\u003e TextType::TrackName,\n                        0x04 =\u003e TextType::InstrumentName,\n                        0x05 =\u003e TextType::Lyric,\n                        0x06 =\u003e TextType::Marker,\n                        0x07 =\u003e TextType::CuePoint,\n                        _ =\u003e TextType::Text,\n                    };\n                    Event::Text { text_type, text }\n                }\n                _ =\u003e Event::Unknown {\n                    status,\n                    data: event_data.to_vec(),\n                },\n            };\n\n            Ok((event, data_end, None)) // Meta events don't have running status\n        }\n        0xF0 | 0xF7 =\u003e {\n            // SysEx\n            let (length, len_bytes) =\n                read_var_len(\u0026data[1..]).ok_or(MidiParseError::InvalidVarLen(1))?;\n\n            let data_start = 1 + len_bytes;\n            let data_end = data_start + length as usize;\n\n            if data.len() \u003c data_end {\n                return Err(MidiParseError::IncompleteData {\n                    expected: data_end,\n                    actual: data.len(),\n                });\n            }\n\n            Ok((\n                Event::SysEx {\n                    data: data[data_start..data_end].to_vec(),\n                },\n                data_end,\n                None, // SysEx doesn't have running status\n            ))\n        }\n        _ =\u003e Err(MidiParseError::InvalidEvent {\n            position: 0,\n            reason: format!(\"Unknown system event: 0x{:02X}\", status),\n        }),\n    }\n}\n\n/// Read a MIDI variable-length quantity\n/// Returns (value, bytes_consumed) or None if invalid\nfn read_var_len(data: \u0026[u8]) -\u003e Option\u003c(u32, usize)\u003e {\n    let mut value = 0u32;\n    let mut bytes_read = 0;\n\n    for (i, \u0026byte) in data.iter().enumerate() {\n        if i \u003e= 4 {\n            // Variable length can be at most 4 bytes\n            return None;\n        }\n\n        value = (value \u003c\u003c 7) | (byte \u0026 0x7F) as u32;\n        bytes_read += 1;\n\n        // If high bit is clear, we're done\n        if byte \u0026 0x80 == 0 {\n            return Some((value, bytes_read));\n        }\n    }\n\n    None // Ran out of data before finding end\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_read_var_len() {\n        // Single byte\n        assert_eq!(read_var_len(\u0026[0x00]), Some((0, 1)));\n        assert_eq!(read_var_len(\u0026[0x7F]), Some((127, 1)));\n\n        // Two bytes\n        assert_eq!(read_var_len(\u0026[0x81, 0x00]), Some((128, 2)));\n        assert_eq!(read_var_len(\u0026[0xFF, 0x7F]), Some((16383, 2)));\n\n        // Invalid (no terminating byte)\n        assert_eq!(read_var_len(\u0026[0x81, 0x82, 0x83, 0x84]), None);\n    }\n\n    #[test]\n    fn test_parse_header() {\n        let data = [\n            b'M', b'T', b'h', b'd', // Magic\n            0, 0, 0, 6, // Length\n            0, 1, // Format 1\n            0, 3, // 3 tracks\n            0, 96, // 96 ticks per quarter note\n        ];\n\n        let header = parse_header(\u0026data).unwrap();\n        assert_eq!(header.format, 1);\n        assert_eq!(header.num_tracks, 3);\n        assert_eq!(header.ticks_per_quarter_note, 96);\n    }\n\n    #[test]\n    fn test_parse_invalid_header_magic() {\n        let data = [\n            b'M', b'T', b'h', b'X', // Wrong magic\n            0, 0, 0, 6, 0, 1, 0, 3, 0, 96,\n        ];\n\n        assert!(parse_header(\u0026data).is_err());\n    }\n\n    #[test]\n    fn test_parse_note_on() {\n        // Delta time: 0, Note On channel 0, note 60, velocity 100\n        let data = [0x00, 0x90, 0x3C, 0x64, 0x00, 0xFF, 0x2F, 0x00]; // Add End of Track\n\n        let events = parse_track_events(\u0026data).unwrap();\n        assert_eq!(events.len(), 2); // NoteOn + EndOfTrack\n        assert_eq!(events[0].delta_ticks, 0);\n\n        match \u0026events[0].event {\n            Event::NoteOn {\n                channel,\n                note,\n                velocity,\n            } =\u003e {\n                assert_eq!(*channel, 0);\n                assert_eq!(*note, 60);\n                assert_eq!(*velocity, 100);\n            }\n            _ =\u003e panic!(\"Expected NoteOn event\"),\n        }\n    }\n\n    #[test]\n    fn test_parse_minimal_file() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 4, 0x00, 0xFF, 0x2F, 0x00, // End of track\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        assert_eq!(midi.header.format, 0);\n        assert_eq!(midi.header.num_tracks, 1);\n        assert_eq!(midi.tracks.len(), 1);\n    }\n\n    #[test]\n    fn test_total_notes() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 12, // Note On\n            0x00, 0x90, 0x3C, 0x64, // Note On\n            0x00, 0x90, 0x40, 0x64, // End of track\n            0x00, 0xFF, 0x2F, 0x00,\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        assert_eq!(midi.total_notes(), 2);\n    }\n\n    #[test]\n    fn test_channels_used() {\n        let data = vec![\n            // Header\n            b'M', b'T', b'h', b'd', 0, 0, 0, 6, 0, 0, // Format 0\n            0, 1, // 1 track\n            0, 96, // 96 TPPQN\n            // Track\n            b'M', b'T', b'r', b'k', 0, 0, 0, 16, // Note On channel 0\n            0x00, 0x90, 0x3C, 0x64, // Note On channel 1\n            0x00, 0x91, 0x40, 0x64, // Note On channel 9 (drums)\n            0x00, 0x99, 0x24, 0x64, // End of track\n            0x00, 0xFF, 0x2F, 0x00,\n        ];\n\n        let midi = parse_midi_file(\u0026data).unwrap();\n        let channels = midi.channels_used();\n        assert_eq!(channels, vec![0, 1, 9]);\n    }\n}\n","traces":[{"line":18,"address":[634727,633632],"length":1,"stats":{"Line":0}},{"line":19,"address":[633655],"length":1,"stats":{"Line":0}},{"line":20,"address":[633671],"length":1,"stats":{"Line":0}},{"line":27,"address":[634423,633716,633788],"length":1,"stats":{"Line":0}},{"line":31,"address":[633900],"length":1,"stats":{"Line":0}},{"line":33,"address":[634353,633936,633919],"length":1,"stats":{"Line":0}},{"line":34,"address":[634209,633965,634154,633945],"length":1,"stats":{"Line":0}},{"line":35,"address":[707710,707559],"length":1,"stats":{"Line":0}},{"line":36,"address":[707580,707892],"length":1,"stats":{"Line":0}},{"line":37,"address":[707589],"length":1,"stats":{"Line":0}},{"line":39,"address":[707798],"length":1,"stats":{"Line":0}},{"line":43,"address":[634318,634663],"length":1,"stats":{"Line":0}},{"line":46,"address":[634359],"length":1,"stats":{"Line":0}},{"line":50,"address":[634736],"length":1,"stats":{"Line":0}},{"line":52,"address":[634760],"length":1,"stats":{"Line":0}},{"line":55,"address":[634962],"length":1,"stats":{"Line":0}},{"line":60,"address":[634848,634766,635212],"length":1,"stats":{"Line":0}},{"line":61,"address":[634852,634840],"length":1,"stats":{"Line":0}},{"line":68,"address":[634858,635305],"length":1,"stats":{"Line":0}},{"line":69,"address":[634878,635351],"length":1,"stats":{"Line":0}},{"line":70,"address":[635152,634898,635397],"length":1,"stats":{"Line":0}},{"line":73,"address":[634926],"length":1,"stats":{"Line":0}},{"line":74,"address":[634946],"length":1,"stats":{"Line":0}},{"line":77,"address":[635160],"length":1,"stats":{"Line":0}},{"line":86,"address":[635456],"length":1,"stats":{"Line":0}},{"line":87,"address":[635468],"length":1,"stats":{"Line":0}},{"line":88,"address":[635629],"length":1,"stats":{"Line":0}},{"line":95,"address":[635653],"length":1,"stats":{"Line":0}},{"line":98,"address":[635772],"length":1,"stats":{"Line":0}},{"line":102,"address":[635655,635660],"length":1,"stats":{"Line":0}},{"line":104,"address":[635665],"length":1,"stats":{"Line":0}},{"line":105,"address":[635770],"length":1,"stats":{"Line":0}},{"line":110,"address":[635678],"length":1,"stats":{"Line":0}},{"line":116,"address":[635941,635903],"length":1,"stats":{"Line":0}},{"line":118,"address":[635958],"length":1,"stats":{"Line":0}},{"line":122,"address":[637544,636080],"length":1,"stats":{"Line":0}},{"line":127,"address":[636200,636147],"length":1,"stats":{"Line":0}},{"line":129,"address":[636561,636496,636407,637168],"length":1,"stats":{"Line":0}},{"line":131,"address":[637406,636570],"length":1,"stats":{"Line":0}},{"line":134,"address":[636876,636611],"length":1,"stats":{"Line":0}},{"line":135,"address":[650245,650397],"length":1,"stats":{"Line":0}},{"line":136,"address":[650250,650295],"length":1,"stats":{"Line":0}},{"line":137,"address":[708180,708112],"length":1,"stats":{"Line":0}},{"line":138,"address":[650280],"length":1,"stats":{"Line":0}},{"line":140,"address":[650328],"length":1,"stats":{"Line":0}},{"line":143,"address":[637421,636921],"length":1,"stats":{"Line":0}},{"line":146,"address":[636934],"length":1,"stats":{"Line":0}},{"line":149,"address":[637106],"length":1,"stats":{"Line":0}},{"line":150,"address":[637097],"length":1,"stats":{"Line":0}},{"line":160,"address":[637131],"length":1,"stats":{"Line":0}},{"line":165,"address":[637552],"length":1,"stats":{"Line":0}},{"line":166,"address":[637569],"length":1,"stats":{"Line":0}},{"line":167,"address":[637733],"length":1,"stats":{"Line":0}},{"line":173,"address":[637571],"length":1,"stats":{"Line":0}},{"line":177,"address":[637580,638121],"length":1,"stats":{"Line":0}},{"line":178,"address":[637604,637589],"length":1,"stats":{"Line":0}},{"line":179,"address":[637597],"length":1,"stats":{"Line":0}},{"line":182,"address":[637996],"length":1,"stats":{"Line":0}},{"line":189,"address":[637773],"length":1,"stats":{"Line":0}},{"line":192,"address":[637778],"length":1,"stats":{"Line":0}},{"line":195,"address":[637821],"length":1,"stats":{"Line":0}},{"line":201,"address":[637851],"length":1,"stats":{"Line":0}},{"line":204,"address":[637847],"length":1,"stats":{"Line":0}},{"line":205,"address":[638651,637834],"length":1,"stats":{"Line":0}},{"line":213,"address":[638164],"length":1,"stats":{"Line":0}},{"line":219,"address":[638190],"length":1,"stats":{"Line":0}},{"line":222,"address":[638186],"length":1,"stats":{"Line":0}},{"line":223,"address":[638678,638173],"length":1,"stats":{"Line":0}},{"line":231,"address":[638051],"length":1,"stats":{"Line":0}},{"line":237,"address":[638081],"length":1,"stats":{"Line":0}},{"line":240,"address":[638077],"length":1,"stats":{"Line":0}},{"line":241,"address":[638064,638660],"length":1,"stats":{"Line":0}},{"line":249,"address":[638086],"length":1,"stats":{"Line":0}},{"line":255,"address":[638116],"length":1,"stats":{"Line":0}},{"line":258,"address":[638112],"length":1,"stats":{"Line":0}},{"line":259,"address":[638669,638099],"length":1,"stats":{"Line":0}},{"line":267,"address":[638040,638027],"length":1,"stats":{"Line":0}},{"line":273,"address":[638043],"length":1,"stats":{"Line":0}},{"line":276,"address":[638036],"length":1,"stats":{"Line":0}},{"line":284,"address":[638206,638215],"length":1,"stats":{"Line":0}},{"line":290,"address":[638218],"length":1,"stats":{"Line":0}},{"line":293,"address":[638211],"length":1,"stats":{"Line":0}},{"line":301,"address":[638271],"length":1,"stats":{"Line":0}},{"line":307,"address":[638486],"length":1,"stats":{"Line":0}},{"line":308,"address":[638473,638687,638490],"length":1,"stats":{"Line":0}},{"line":309,"address":[638495],"length":1,"stats":{"Line":0}},{"line":310,"address":[638506],"length":1,"stats":{"Line":0}},{"line":314,"address":[638638,638124,638148],"length":1,"stats":{"Line":0}},{"line":316,"address":[638444],"length":1,"stats":{"Line":0}},{"line":324,"address":[638720],"length":1,"stats":{"Line":0}},{"line":325,"address":[640488,638737],"length":1,"stats":{"Line":0}},{"line":327,"address":[638767],"length":1,"stats":{"Line":0}},{"line":330,"address":[638787],"length":1,"stats":{"Line":0}},{"line":331,"address":[638807],"length":1,"stats":{"Line":0}},{"line":337,"address":[639347],"length":1,"stats":{"Line":0}},{"line":338,"address":[639518,639753,639802],"length":1,"stats":{"Line":0}},{"line":341,"address":[640531,639763],"length":1,"stats":{"Line":0}},{"line":342,"address":[639773,640544],"length":1,"stats":{"Line":0}},{"line":344,"address":[639785],"length":1,"stats":{"Line":0}},{"line":345,"address":[639790],"length":1,"stats":{"Line":0}},{"line":353,"address":[639931,639853],"length":1,"stats":{"Line":0}},{"line":356,"address":[639875],"length":1,"stats":{"Line":0}},{"line":357,"address":[640217],"length":1,"stats":{"Line":0}},{"line":359,"address":[640221],"length":1,"stats":{"Line":0}},{"line":362,"address":[639885],"length":1,"stats":{"Line":0}},{"line":369,"address":[640110],"length":1,"stats":{"Line":0}},{"line":370,"address":[640253],"length":1,"stats":{"Line":0}},{"line":372,"address":[640257],"length":1,"stats":{"Line":0}},{"line":376,"address":[640120],"length":1,"stats":{"Line":0}},{"line":377,"address":[640124],"length":1,"stats":{"Line":0}},{"line":378,"address":[640129],"length":1,"stats":{"Line":0}},{"line":379,"address":[640134],"length":1,"stats":{"Line":0}},{"line":383,"address":[639947],"length":1,"stats":{"Line":0}},{"line":384,"address":[640235],"length":1,"stats":{"Line":0}},{"line":386,"address":[640239],"length":1,"stats":{"Line":0}},{"line":390,"address":[639957],"length":1,"stats":{"Line":0}},{"line":391,"address":[639961],"length":1,"stats":{"Line":0}},{"line":394,"address":[639977],"length":1,"stats":{"Line":0}},{"line":396,"address":[640299,639994,640043],"length":1,"stats":{"Line":0}},{"line":397,"address":[640082],"length":1,"stats":{"Line":0}},{"line":411,"address":[640151],"length":1,"stats":{"Line":0}},{"line":415,"address":[639914,640166],"length":1,"stats":{"Line":0}},{"line":419,"address":[639239,639296,639007],"length":1,"stats":{"Line":0}},{"line":422,"address":[639249,640505],"length":1,"stats":{"Line":0}},{"line":423,"address":[639258,640518],"length":1,"stats":{"Line":0}},{"line":425,"address":[639270],"length":1,"stats":{"Line":0}},{"line":426,"address":[639279],"length":1,"stats":{"Line":0}},{"line":432,"address":[639703],"length":1,"stats":{"Line":0}},{"line":434,"address":[639649],"length":1,"stats":{"Line":0}},{"line":440,"address":[639200],"length":1,"stats":{"Line":0}},{"line":449,"address":[640560],"length":1,"stats":{"Line":0}},{"line":453,"address":[662141,662163,661779,661949,661757,661971],"length":1,"stats":{"Line":0}},{"line":454,"address":[636295,640664,636328,639447,638904,638936,640627,639416],"length":1,"stats":{"Line":0}},{"line":459,"address":[638960,640684,639471,636352],"length":1,"stats":{"Line":0}},{"line":460,"address":[639452,640462,640728,640669,636333,638941],"length":1,"stats":{"Line":0}},{"line":463,"address":[636365,638973,639484,640698],"length":1,"stats":{"Line":0}},{"line":464,"address":[638978,639489,636370,640703],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":137},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","midi","types.rs"],"content":"use serde::{Deserialize, Serialize};\n\n/// Represents a complete MIDI file\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MidiFile {\n    pub header: Header,\n    pub tracks: Vec\u003cTrack\u003e,\n}\n\n/// MIDI header chunk\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Header {\n    pub format: u16, // 0, 1, or 2\n    pub num_tracks: u16,\n    pub ticks_per_quarter_note: u16,\n}\n\n/// A single MIDI track\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Track {\n    pub events: Vec\u003cTimedEvent\u003e,\n}\n\n/// Event with delta time\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TimedEvent {\n    pub delta_ticks: u32,\n    pub event: Event,\n}\n\n/// MIDI events\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum Event {\n    // Channel events\n    NoteOn {\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    },\n    NoteOff {\n        channel: u8,\n        note: u8,\n        velocity: u8,\n    },\n    Aftertouch {\n        channel: u8,\n        note: u8,\n        pressure: u8,\n    },\n    ControlChange {\n        channel: u8,\n        controller: u8,\n        value: u8,\n    },\n    ProgramChange {\n        channel: u8,\n        program: u8,\n    },\n    ChannelAftertouch {\n        channel: u8,\n        pressure: u8,\n    },\n    PitchBend {\n        channel: u8,\n        value: i16,\n    },\n\n    // Meta events\n    TempoChange {\n        microseconds_per_quarter: u32,\n    },\n    TimeSignature {\n        numerator: u8,\n        denominator: u8,\n        clocks_per_click: u8,\n        thirty_seconds_per_quarter: u8,\n    },\n    KeySignature {\n        sharps_flats: i8,\n        is_minor: bool,\n    },\n    Text {\n        text_type: TextType,\n        text: String,\n    },\n    EndOfTrack,\n\n    // SysEx\n    SysEx {\n        data: Vec\u003cu8\u003e,\n    },\n\n    // Unknown/unsupported\n    Unknown {\n        status: u8,\n        data: Vec\u003cu8\u003e,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum TextType {\n    Text,\n    Copyright,\n    TrackName,\n    InstrumentName,\n    Lyric,\n    Marker,\n    CuePoint,\n}\n\nimpl MidiFile {\n    /// Calculate total duration in seconds\n    pub fn duration_seconds(\u0026self, _default_tempo_bpm: f64) -\u003e f64 {\n        let mut total_ticks = 0u64;\n        let mut current_tempo_us_per_qn = 500_000u32; // Default: 120 BPM\n\n        for track in \u0026self.tracks {\n            let mut track_ticks = 0u64;\n\n            for timed_event in \u0026track.events {\n                track_ticks += timed_event.delta_ticks as u64;\n\n                // Update tempo if we encounter a tempo change\n                if let Event::TempoChange {\n                    microseconds_per_quarter,\n                } = timed_event.event\n                {\n                    current_tempo_us_per_qn = microseconds_per_quarter;\n                }\n            }\n\n            total_ticks = total_ticks.max(track_ticks);\n        }\n\n        // Convert ticks to seconds\n        let seconds_per_tick = (current_tempo_us_per_qn as f64 / 1_000_000.0)\n            / self.header.ticks_per_quarter_note as f64;\n        total_ticks as f64 * seconds_per_tick\n    }\n\n    /// Count total notes across all tracks\n    pub fn total_notes(\u0026self) -\u003e usize {\n        self.tracks\n            .iter()\n            .flat_map(|track| \u0026track.events)\n            .filter(|event| matches!(event.event, Event::NoteOn { velocity, .. } if velocity \u003e 0))\n            .count()\n    }\n\n    /// Get all unique MIDI channels used\n    pub fn channels_used(\u0026self) -\u003e Vec\u003cu8\u003e {\n        let mut channels = std::collections::HashSet::new();\n\n        for track in \u0026self.tracks {\n            for timed_event in \u0026track.events {\n                if let Some(channel) = timed_event.event.channel() {\n                    channels.insert(channel);\n                }\n            }\n        }\n\n        let mut result: Vec\u003cu8\u003e = channels.into_iter().collect();\n        result.sort();\n        result\n    }\n}\n\nimpl Event {\n    /// Get the MIDI channel for channel events, None for meta/sysex\n    pub fn channel(\u0026self) -\u003e Option\u003cu8\u003e {\n        match self {\n            Event::NoteOn { channel, .. }\n            | Event::NoteOff { channel, .. }\n            | Event::Aftertouch { channel, .. }\n            | Event::ControlChange { channel, .. }\n            | Event::ProgramChange { channel, .. }\n            | Event::ChannelAftertouch { channel, .. }\n            | Event::PitchBend { channel, .. } =\u003e Some(*channel),\n            _ =\u003e None,\n        }\n    }\n\n    /// Check if this is a note event\n    pub fn is_note(\u0026self) -\u003e bool {\n        matches!(self, Event::NoteOn { .. } | Event::NoteOff { .. })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    /// Helper function to create a basic MIDI file for testing\n    fn create_basic_midi() -\u003e MidiFile {\n        MidiFile {\n            header: Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![Track { events: vec![] }],\n        }\n    }\n\n    /// Helper function to create a MIDI file with notes\n    fn create_midi_with_notes() -\u003e MidiFile {\n        MidiFile {\n            header: Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 480,\n            },\n            tracks: vec![Track {\n                events: vec![\n                    TimedEvent {\n                        delta_ticks: 0,\n                        event: Event::NoteOn {\n                            channel: 0,\n                            note: 60,\n                            velocity: 100,\n                        },\n                    },\n                    TimedEvent {\n                        delta_ticks: 480,\n                        event: Event::NoteOff {\n                            channel: 0,\n                            note: 60,\n                            velocity: 0,\n                        },\n                    },\n                    TimedEvent {\n                        delta_ticks: 0,\n                        event: Event::NoteOn {\n                            channel: 1,\n                            note: 64,\n                            velocity: 80,\n                        },\n                    },\n                ],\n            }],\n        }\n    }\n\n    mod midi_file_tests {\n        use super::*;\n\n        #[test]\n        fn test_duration_seconds_empty_file() {\n            let midi = create_basic_midi();\n            let duration = midi.duration_seconds(120.0);\n\n            // Empty file should have 0 duration\n            assert_eq!(duration, 0.0);\n        }\n\n        #[test]\n        fn test_duration_seconds_with_default_tempo() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 1920, // 4 quarters = 1 bar at 480 tpq\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // At 120 BPM (500,000 s/quarter), 1920 ticks = 4 quarters = 2 seconds\n            // seconds_per_tick = 500_000 / 1_000_000 / 480 = 0.00104166...\n            // duration = 1920 * 0.00104166...  2.0 seconds\n            assert!(\n                (duration - 2.0).abs() \u003c 0.01,\n                \"Duration should be ~2.0 seconds, got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_duration_seconds_with_tempo_change() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 600_000, // 100 BPM\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 1920, // 4 quarters at 100 BPM\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // At 100 BPM (600,000 s/quarter), 1920 ticks = 4 quarters = 2.4 seconds\n            // seconds_per_tick = 600_000 / 1_000_000 / 480 = 0.00125\n            // duration = 1920 * 0.00125 = 2.4 seconds\n            assert!(\n                (duration - 2.4).abs() \u003c 0.01,\n                \"Duration should be ~2.4 seconds, got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_duration_seconds_multiple_tracks() {\n            // Duration should be the length of the longest track\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 960, // Short track\n                            event: Event::EndOfTrack,\n                        }],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 1920, // Longer track\n                            event: Event::EndOfTrack,\n                        }],\n                    },\n                ],\n            };\n\n            let duration = midi.duration_seconds(120.0);\n\n            // Should use longest track (1920 ticks)\n            assert!(\n                (duration - 2.0).abs() \u003c 0.01,\n                \"Duration should be ~2.0 seconds (longest track), got {}\",\n                duration\n            );\n        }\n\n        #[test]\n        fn test_total_notes_empty_file() {\n            let midi = create_basic_midi();\n            assert_eq!(midi.total_notes(), 0);\n        }\n\n        #[test]\n        fn test_total_notes_with_notes() {\n            let midi = create_midi_with_notes();\n\n            // Should count 2 NoteOn events (velocity \u003e 0)\n            assert_eq!(midi.total_notes(), 2);\n        }\n\n        #[test]\n        fn test_total_notes_excludes_zero_velocity() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 0, // Zero velocity = note off\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 64,\n                                velocity: 100, // Real note on\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should only count note with velocity \u003e 0\n            assert_eq!(midi.total_notes(), 1);\n        }\n\n        #[test]\n        fn test_total_notes_excludes_note_off() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 480,\n                            event: Event::NoteOff {\n                                channel: 0,\n                                note: 60,\n                                velocity: 64,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should only count NoteOn events\n            assert_eq!(midi.total_notes(), 1);\n        }\n\n        #[test]\n        fn test_total_notes_multiple_tracks() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![\n                            TimedEvent {\n                                delta_ticks: 0,\n                                event: Event::NoteOn {\n                                    channel: 0,\n                                    note: 60,\n                                    velocity: 100,\n                                },\n                            },\n                            TimedEvent {\n                                delta_ticks: 0,\n                                event: Event::NoteOn {\n                                    channel: 0,\n                                    note: 64,\n                                    velocity: 80,\n                                },\n                            },\n                        ],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1,\n                                note: 67,\n                                velocity: 90,\n                            },\n                        }],\n                    },\n                ],\n            };\n\n            // Should count notes across all tracks\n            assert_eq!(midi.total_notes(), 3);\n        }\n\n        #[test]\n        fn test_channels_used_empty_file() {\n            let midi = create_basic_midi();\n            assert_eq!(midi.channels_used(), Vec::\u003cu8\u003e::new());\n        }\n\n        #[test]\n        fn test_channels_used_single_channel() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 5,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 480,\n                            event: Event::NoteOff {\n                                channel: 5,\n                                note: 60,\n                                velocity: 0,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            assert_eq!(midi.channels_used(), vec![5]);\n        }\n\n        #[test]\n        fn test_channels_used_multiple_channels() {\n            let midi = create_midi_with_notes();\n\n            // Should return sorted unique channels\n            assert_eq!(midi.channels_used(), vec![0, 1]);\n        }\n\n        #[test]\n        fn test_channels_used_all_16_channels() {\n            let mut events = Vec::new();\n\n            // Add events on all 16 MIDI channels (0-15)\n            for channel in 0..16 {\n                events.push(TimedEvent {\n                    delta_ticks: 0,\n                    event: Event::NoteOn {\n                        channel,\n                        note: 60,\n                        velocity: 100,\n                    },\n                });\n            }\n\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track { events }],\n            };\n\n            assert_eq!(midi.channels_used(), (0..16).collect::\u003cVec\u003cu8\u003e\u003e());\n        }\n\n        #[test]\n        fn test_channels_used_excludes_meta_events() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 500_000,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::EndOfTrack,\n                        },\n                    ],\n                }],\n            };\n\n            // Should only include channel from NoteOn\n            assert_eq!(midi.channels_used(), vec![0]);\n        }\n\n        #[test]\n        fn test_channels_used_deduplicates() {\n            let midi = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 1,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![Track {\n                    events: vec![\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 3,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1,\n                                note: 64,\n                                velocity: 80,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 3, // Duplicate\n                                note: 67,\n                                velocity: 90,\n                            },\n                        },\n                        TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 1, // Duplicate\n                                note: 70,\n                                velocity: 85,\n                            },\n                        },\n                    ],\n                }],\n            };\n\n            // Should return sorted unique channels\n            assert_eq!(midi.channels_used(), vec![1, 3]);\n        }\n    }\n\n    mod event_tests {\n        use super::*;\n\n        #[test]\n        fn test_channel_note_on() {\n            let event = Event::NoteOn {\n                channel: 5,\n                note: 60,\n                velocity: 100,\n            };\n            assert_eq!(event.channel(), Some(5));\n        }\n\n        #[test]\n        fn test_channel_note_off() {\n            let event = Event::NoteOff {\n                channel: 3,\n                note: 60,\n                velocity: 0,\n            };\n            assert_eq!(event.channel(), Some(3));\n        }\n\n        #[test]\n        fn test_channel_aftertouch() {\n            let event = Event::Aftertouch {\n                channel: 7,\n                note: 60,\n                pressure: 50,\n            };\n            assert_eq!(event.channel(), Some(7));\n        }\n\n        #[test]\n        fn test_channel_control_change() {\n            let event = Event::ControlChange {\n                channel: 10,\n                controller: 7,\n                value: 100,\n            };\n            assert_eq!(event.channel(), Some(10));\n        }\n\n        #[test]\n        fn test_channel_program_change() {\n            let event = Event::ProgramChange {\n                channel: 15,\n                program: 0,\n            };\n            assert_eq!(event.channel(), Some(15));\n        }\n\n        #[test]\n        fn test_channel_channel_aftertouch() {\n            let event = Event::ChannelAftertouch {\n                channel: 2,\n                pressure: 64,\n            };\n            assert_eq!(event.channel(), Some(2));\n        }\n\n        #[test]\n        fn test_channel_pitch_bend() {\n            let event = Event::PitchBend {\n                channel: 8,\n                value: 0,\n            };\n            assert_eq!(event.channel(), Some(8));\n        }\n\n        #[test]\n        fn test_channel_tempo_change_returns_none() {\n            let event = Event::TempoChange {\n                microseconds_per_quarter: 500_000,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_time_signature_returns_none() {\n            let event = Event::TimeSignature {\n                numerator: 4,\n                denominator: 4,\n                clocks_per_click: 24,\n                thirty_seconds_per_quarter: 8,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_key_signature_returns_none() {\n            let event = Event::KeySignature {\n                sharps_flats: 0,\n                is_minor: false,\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_text_returns_none() {\n            let event = Event::Text {\n                text_type: TextType::TrackName,\n                text: \"Piano\".to_string(),\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_end_of_track_returns_none() {\n            let event = Event::EndOfTrack;\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_sysex_returns_none() {\n            let event = Event::SysEx {\n                data: vec![0xF0, 0x7E, 0x7F, 0xF7],\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_channel_unknown_returns_none() {\n            let event = Event::Unknown {\n                status: 0xFF,\n                data: vec![0x01, 0x02],\n            };\n            assert_eq!(event.channel(), None);\n        }\n\n        #[test]\n        fn test_is_note_for_note_on() {\n            let event = Event::NoteOn {\n                channel: 0,\n                note: 60,\n                velocity: 100,\n            };\n            assert!(event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_note_off() {\n            let event = Event::NoteOff {\n                channel: 0,\n                note: 60,\n                velocity: 0,\n            };\n            assert!(event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_control_change() {\n            let event = Event::ControlChange {\n                channel: 0,\n                controller: 7,\n                value: 100,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_program_change() {\n            let event = Event::ProgramChange {\n                channel: 0,\n                program: 5,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_tempo_change() {\n            let event = Event::TempoChange {\n                microseconds_per_quarter: 500_000,\n            };\n            assert!(!event.is_note());\n        }\n\n        #[test]\n        fn test_is_note_for_aftertouch() {\n            let event = Event::Aftertouch {\n                channel: 0,\n                note: 60,\n                pressure: 50,\n            };\n            assert!(!event.is_note());\n        }\n    }\n\n    mod serialization_tests {\n        use super::*;\n\n        #[test]\n        fn test_serialize_deserialize_midi_file() {\n            let original = MidiFile {\n                header: Header {\n                    format: 1,\n                    num_tracks: 2,\n                    ticks_per_quarter_note: 480,\n                },\n                tracks: vec![\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::NoteOn {\n                                channel: 0,\n                                note: 60,\n                                velocity: 100,\n                            },\n                        }],\n                    },\n                    Track {\n                        events: vec![TimedEvent {\n                            delta_ticks: 0,\n                            event: Event::TempoChange {\n                                microseconds_per_quarter: 500_000,\n                            },\n                        }],\n                    },\n                ],\n            };\n\n            let json = serde_json::to_string(\u0026original).expect(\"Failed to serialize\");\n            let deserialized: MidiFile =\n                serde_json::from_str(\u0026json).expect(\"Failed to deserialize\");\n\n            // Verify structure\n            assert_eq!(deserialized.header.format, 1);\n            assert_eq!(deserialized.header.num_tracks, 2);\n            assert_eq!(deserialized.header.ticks_per_quarter_note, 480);\n            assert_eq!(deserialized.tracks.len(), 2);\n            assert_eq!(deserialized.tracks[0].events.len(), 1);\n            assert_eq!(deserialized.tracks[1].events.len(), 1);\n        }\n\n        #[test]\n        fn test_serialize_deserialize_all_event_types() {\n            let events = vec![\n                Event::NoteOn {\n                    channel: 0,\n                    note: 60,\n                    velocity: 100,\n                },\n                Event::NoteOff {\n                    channel: 0,\n                    note: 60,\n                    velocity: 64,\n                },\n                Event::Aftertouch {\n                    channel: 0,\n                    note: 60,\n                    pressure: 50,\n                },\n                Event::ControlChange {\n                    channel: 0,\n                    controller: 7,\n                    value: 100,\n                },\n                Event::ProgramChange {\n                    channel: 0,\n                    program: 5,\n                },\n                Event::ChannelAftertouch {\n                    channel: 0,\n                    pressure: 64,\n                },\n                Event::PitchBend {\n                    channel: 0,\n                    value: 8192,\n                },\n                Event::TempoChange {\n                    microseconds_per_quarter: 500_000,\n                },\n                Event::TimeSignature {\n                    numerator: 4,\n                    denominator: 4,\n                    clocks_per_click: 24,\n                    thirty_seconds_per_quarter: 8,\n                },\n                Event::KeySignature {\n                    sharps_flats: -2,\n                    is_minor: true,\n                },\n                Event::Text {\n                    text_type: TextType::TrackName,\n                    text: \"Piano\".to_string(),\n                },\n                Event::EndOfTrack,\n                Event::SysEx {\n                    data: vec![0xF0, 0x7E, 0x7F, 0xF7],\n                },\n                Event::Unknown {\n                    status: 0xFF,\n                    data: vec![0x01, 0x02],\n                },\n            ];\n\n            for original_event in events {\n                let json =\n                    serde_json::to_string(\u0026original_event).expect(\"Failed to serialize event\");\n                let _deserialized: Event =\n                    serde_json::from_str(\u0026json).expect(\"Failed to deserialize event\");\n                // If we get here, serialization round-trip succeeded\n            }\n        }\n\n        #[test]\n        fn test_serialize_text_types() {\n            let text_types = vec![\n                TextType::Text,\n                TextType::Copyright,\n                TextType::TrackName,\n                TextType::InstrumentName,\n                TextType::Lyric,\n                TextType::Marker,\n                TextType::CuePoint,\n            ];\n\n            for original_type in text_types {\n                let json =\n                    serde_json::to_string(\u0026original_type).expect(\"Failed to serialize TextType\");\n                let _deserialized: TextType =\n                    serde_json::from_str(\u0026json).expect(\"Failed to deserialize TextType\");\n                // If we get here, serialization round-trip succeeded\n            }\n        }\n    }\n\n    mod edge_case_tests {\n        use super::*;\n\n        #[test]\n        fn test_header_format_0() {\n            let header = Header {\n                format: 0,\n                num_tracks: 1,\n                ticks_per_quarter_note: 96,\n            };\n            assert_eq!(header.format, 0);\n        }\n\n        #[test]\n        fn test_header_format_2() {\n            let header = Header {\n                format: 2,\n                num_tracks: 5,\n                ticks_per_quarter_note: 960,\n            };\n            assert_eq!(header.format, 2);\n        }\n\n        #[test]\n        fn test_high_ticks_per_quarter() {\n            let header = Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 960, // High resolution\n            };\n            assert_eq!(header.ticks_per_quarter_note, 960);\n        }\n\n        #[test]\n        fn test_low_ticks_per_quarter() {\n            let header = Header {\n                format: 1,\n                num_tracks: 1,\n                ticks_per_quarter_note: 96, // Low resolution\n            };\n            assert_eq!(header.ticks_per_quarter_note, 96);\n        }\n\n        #[test]\n        fn test_pitch_bend_positive() {\n            let event = Event::PitchBend {\n                channel: 0,\n                value: 8192, // Center position\n            };\n            if let Event::PitchBend { value, .. } = event {\n                assert_eq!(value, 8192);\n            }\n        }\n\n        #[test]\n        fn test_pitch_bend_negative() {\n            let event = Event::PitchBend {\n                channel: 0,\n                value: -8192, // Max down\n            };\n            if let Event::PitchBend { value, .. } = event {\n                assert_eq!(value, -8192);\n            }\n        }\n\n        #[test]\n        fn test_key_signature_sharps() {\n            let event = Event::KeySignature {\n                sharps_flats: 4, // E major\n                is_minor: false,\n            };\n            if let Event::KeySignature {\n                sharps_flats,\n                is_minor,\n            } = event\n            {\n                assert_eq!(sharps_flats, 4);\n                assert!(!is_minor);\n            }\n        }\n\n        #[test]\n        fn test_key_signature_flats() {\n            let event = Event::KeySignature {\n                sharps_flats: -3, // Eb major\n                is_minor: false,\n            };\n            if let Event::KeySignature {\n                sharps_flats,\n                is_minor,\n            } = event\n            {\n                assert_eq!(sharps_flats, -3);\n                assert!(!is_minor);\n            }\n        }\n\n        #[test]\n        fn test_very_large_delta_ticks() {\n            let event = TimedEvent {\n                delta_ticks: u32::MAX,\n                event: Event::EndOfTrack,\n            };\n            assert_eq!(event.delta_ticks, u32::MAX);\n        }\n\n        #[test]\n        fn test_empty_sysex() {\n            let event = Event::SysEx { data: vec![] };\n            if let Event::SysEx { data } = event {\n                assert!(data.is_empty());\n            }\n        }\n\n        #[test]\n        fn test_empty_text() {\n            let event = Event::Text {\n                text_type: TextType::Text,\n                text: String::new(),\n            };\n            if let Event::Text { text, .. } = event {\n                assert!(text.is_empty());\n            }\n        }\n\n        #[test]\n        fn test_unicode_text() {\n            let event = Event::Text {\n                text_type: TextType::TrackName,\n                text: \"Piano Track\".to_string(),\n            };\n            if let Event::Text { text, .. } = event {\n                assert_eq!(text, \"Piano Track\");\n            }\n        }\n    }\n}\n","traces":[{"line":113,"address":[745344],"length":1,"stats":{"Line":0}},{"line":117,"address":[745464,745393],"length":1,"stats":{"Line":0}},{"line":120,"address":[745527,745502],"length":1,"stats":{"Line":0}},{"line":121,"address":[745504,745726,745532],"length":1,"stats":{"Line":0}},{"line":124,"address":[745546],"length":1,"stats":{"Line":0}},{"line":125,"address":[745553],"length":1,"stats":{"Line":0}},{"line":136,"address":[745614,745560,745633],"length":1,"stats":{"Line":0}},{"line":137,"address":[745622],"length":1,"stats":{"Line":0}},{"line":138,"address":[745567,745637],"length":1,"stats":{"Line":0}},{"line":142,"address":[745744],"length":1,"stats":{"Line":0}},{"line":145,"address":[669779,669776],"length":1,"stats":{"Line":0}},{"line":146,"address":[669792],"length":1,"stats":{"Line":0}},{"line":151,"address":[745920,746650],"length":1,"stats":{"Line":0}},{"line":154,"address":[746123,746075],"length":1,"stats":{"Line":0}},{"line":155,"address":[746172,746199],"length":1,"stats":{"Line":0}},{"line":156,"address":[746174,746207],"length":1,"stats":{"Line":0}},{"line":163,"address":[746554],"length":1,"stats":{"Line":0}},{"line":164,"address":[746360],"length":1,"stats":{"Line":0}},{"line":171,"address":[746656,746201],"length":1,"stats":{"Line":0}},{"line":185,"address":[746672],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":20},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","core","mod.rs"],"content":"//! Core MIDI processing modules\n\npub mod midi;\npub mod analysis;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","mod.rs"],"content":"//! Database models and repositories\n\npub mod models;\npub mod repositories;\n\n// Re-export commonly used types\npub use models::{File, MidiMetadata};\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","analysis.rs"],"content":"//! Analysis result model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct AnalysisResult {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","error.rs"],"content":"//! Database error types\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct DbError {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","midi.rs"],"content":"//! MIDI metadata model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct MidiMetadata {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","midi_file.rs"],"content":"//! MIDI file database model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version (better modular structure)\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct File {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","mod.rs"],"content":"//! Database model types\n\npub mod midi_file;\npub mod midi;\npub mod sequencer;\npub mod analysis;\npub mod search;\npub mod error;\n\n// Re-export main types\npub use midi_file::File;\npub use midi::MidiMetadata;\npub use sequencer::SequencerTrack;\npub use analysis::AnalysisResult;\npub use search::SearchFilters;\npub use error::DbError;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","search.rs"],"content":"//! Search filters model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct SearchFilters {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","models","sequencer.rs"],"content":"//! Sequencer model\n//!\n//! Placeholder - will be populated in Phase 5 with DAW version\n\n// Temporary stub to allow compilation\n#[derive(Debug, Clone)]\npub struct SequencerTrack {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","file_repository.rs"],"content":"//! File repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct FileRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","metadata_repository.rs"],"content":"//! Metadata repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct MetadataRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","mod.rs"],"content":"//! Database repository layer\n\npub mod file_repository;\npub mod metadata_repository;\npub mod search_repository;\npub mod tag_repository;\n\n// Re-export repository types\npub use file_repository::FileRepository;\npub use metadata_repository::MetadataRepository;\npub use search_repository::SearchRepository;\npub use tag_repository::TagRepository;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","search_repository.rs"],"content":"//! Search repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct SearchRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","db","repositories","tag_repository.rs"],"content":"//! Tag repository\n//!\n//! Placeholder - will be populated in Phase 5 with Pipeline version\n\n// Temporary stub to allow compilation\npub struct TagRepository {\n    // Will be filled in Phase 5\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","dojevou","projects","midi-software-center","shared","rust","src","lib.rs"],"content":"//! MIDI Library Shared Code\n//!\n//! This crate contains all shared functionality used by:\n//! - Pipeline (import, process, analyze)\n//! - DAW (playback, sequence, MIDI out)\n//!\n//! ## Structure\n//!\n//! - `core::midi` - MIDI parsing and types\n//! - `core::analysis` - Musical analysis (BPM, key detection, etc.)\n//! - `db::models` - Database model types\n//! - `db::repositories` - Database access layer\n\npub mod core;\npub mod db;\n\n// Re-export top-level modules for convenience\npub use core::midi;\npub use core::analysis;\npub use db::{models, repositories};\n\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn it_works() {\n        assert_eq!(2 + 2, 4);\n    }\n}\n","traces":[],"covered":0,"coverable":0}]};
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      },
    };
  });

  return [...folders, ...files.filter(file => file.path.length === 1)];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener('hashchange', () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.slice(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(
      ({current}) => {
        return {current: [...current, file.path[0]]};
      },
      () => this.updateHash(),
    );
  }

  back(file) {
    this.setState(
      ({current}) => {
        return {current: current.slice(0, current.length - 1)};
      },
      () => this.updateHash(),
    );
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e(
    'div',
    {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e(
      'table',
      {className: 'files-list'},
      e('thead', {className: 'files-list__head'}, e('tr', null, e('th', null, 'Path'), e('th', null, 'Coverage'))),
      e(
        'tbody',
        {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile})),
      ),
    ),
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? (file.covered / file.coverable) * 100 : -1;
  const coverageDelta =
    file.prevRun && (file.covered / file.coverable) * 100 - (file.prevRun.covered / file.prevRun.coverable) * 100;

  return e(
    'tr',
    {
      className:
        'files-list__file' +
        (coverage >= 0 && coverage < 50 ? ' files-list__file_low' : '') +
        (coverage >= 50 && coverage < 80 ? ' files-list__file_medium' : '') +
        (coverage >= 80 ? ' files-list__file_high' : '') +
        (file.is_folder ? ' files-list__file_folder' : ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e(
      'td',
      null,
      file.covered + ' / ' + file.coverable + (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e(
        'span',
        {title: 'Change from the previous run'},
        coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : '',
      ),
    ),
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'}, e(FileHeader, {file, onBack}), e(FileContent, {file}));
}

function FileHeader({file, onBack}) {
  const coverage = (file.covered / file.coverable) * 100;
  const coverageDelta = file.prevRun && coverage - (file.prevRun.covered / file.prevRun.coverable) * 100;

  return e(
    'div',
    {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e(
      'div',
      {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable + (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e(
        'span',
        {title: 'Change from the previous run'},
        coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : '',
      ),
      e('input', {id: 'theme-toggle', type: 'checkbox', hidden: true}),
      e('label', {for: 'theme-toggle', id: 'theme-toggle-label'}, ''),
    ),
  );
}

function FileContent({file}) {
  return e(
    'pre',
    {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      return e(
        'code',
        {
          className: 'code-line' + (covered ? ' code-line_covered' : '') + (uncovered ? ' code-line_uncovered' : ''),
          title: trace ? JSON.stringify(trace.stats, null, 2) : null,
        },
        line,
      );
    }),
  );
}

(function () {
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData &&
    previousData.files.forEach(file => {
      const path = file.path.slice(commonPath.length).join('/');
      prevFilesMap.set(path, file);
    });

  const files = data.files.map(file => {
    const path = file.path.slice(commonPath.length);
    const {covered = 0, coverable = 0} = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: {covered, coverable},
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    },
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));

  const toggle = document.getElementById('theme-toggle');
  const label = document.getElementById('theme-toggle-label');
  label.textContent = '';

  toggle.addEventListener('change', () => {
    if (toggle.checked) {
      document.documentElement.setAttribute('data-theme', 'dark');
      label.textContent = '';
    } else {
      document.documentElement.removeAttribute('data-theme');
      label.textContent = '';
    }
  });
})();
</script>
</body>
</html>